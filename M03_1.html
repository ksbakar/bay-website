<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Logical Connections – Bayesian Statistical Methods in Medicine &amp; Health</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./M03_2.html" rel="next">
<link href="./brief_module_03.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-07c16812f08c4a1591d6ec4fc46327fa.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="site_libs/viz-1.8.2/viz.js"></script>

<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">

<script src="site_libs/grViz-binding-1.0.11/grViz.js"></script>

<script src="site_libs/plotly-binding-4.10.4/plotly.js"></script>

<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>

<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>

<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">

<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>

<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">

<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./M03_1.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistical Methods in Medicine &amp; Health</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Preface</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Introduction</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./installation_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Software Installation Guide</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 1: Bayesian Dreams</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><strong>Navigating Evidence</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Bayesian Inference</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 2: Chaotics</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title"><strong>Prior and Posterior</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title"><strong>Generative Models and Tools</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 3: Bayeswatch - Gaussian</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 4: Bayeswatch - Non Gaussian</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title"><strong>Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title"><strong>More on Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 5: Clusterphobia</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - I</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - II</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 6: Wander into the Wonder!</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title"><strong>Size Matters!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title"><strong>Wander into the Wonder!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learnings" id="toc-learnings" class="nav-link active" data-scroll-target="#learnings"><span class="header-section-number">5.1</span> Learnings</a></li>
  <li><a href="#causality-and-bayesian-inference" id="toc-causality-and-bayesian-inference" class="nav-link" data-scroll-target="#causality-and-bayesian-inference"><span class="header-section-number">5.2</span> Causality and Bayesian Inference</a>
  <ul class="collapse">
  <li><a href="#estimand-estimator-estimate" id="toc-estimand-estimator-estimate" class="nav-link" data-scroll-target="#estimand-estimator-estimate"><span class="header-section-number">5.2.1</span> Estimand, Estimator &amp; Estimate</a></li>
  <li><a href="#bayesian-regression-context" id="toc-bayesian-regression-context" class="nav-link" data-scroll-target="#bayesian-regression-context"><span class="header-section-number">5.2.2</span> Bayesian Regression Context</a></li>
  </ul></li>
  <li><a href="#model-development---gaussian-context" id="toc-model-development---gaussian-context" class="nav-link" data-scroll-target="#model-development---gaussian-context"><span class="header-section-number">5.3</span> Model Development - Gaussian Context</a>
  <ul class="collapse">
  <li><a href="#likelihood-prior-and-posterior" id="toc-likelihood-prior-and-posterior" class="nav-link" data-scroll-target="#likelihood-prior-and-posterior"><span class="header-section-number">5.3.1</span> Likelihood, Prior and Posterior</a></li>
  <li><a href="#bayesian-dag" id="toc-bayesian-dag" class="nav-link" data-scroll-target="#bayesian-dag"><span class="header-section-number">5.3.2</span> Bayesian DAG</a></li>
  </ul></li>
  <li><a href="#model-baesd-results" id="toc-model-baesd-results" class="nav-link" data-scroll-target="#model-baesd-results"><span class="header-section-number">5.4</span> Model-Baesd Results</a>
  <ul class="collapse">
  <li><a href="#priors" id="toc-priors" class="nav-link" data-scroll-target="#priors"><span class="header-section-number">5.4.1</span> Priors</a></li>
  <li><a href="#posteriors" id="toc-posteriors" class="nav-link" data-scroll-target="#posteriors"><span class="header-section-number">5.4.2</span> Posteriors</a></li>
  <li><a href="#mcmc-diagnostics" id="toc-mcmc-diagnostics" class="nav-link" data-scroll-target="#mcmc-diagnostics"><span class="header-section-number">5.4.3</span> MCMC Diagnostics</a></li>
  </ul></li>
  <li><a href="#bayesian-vs.-frequentist" id="toc-bayesian-vs.-frequentist" class="nav-link" data-scroll-target="#bayesian-vs.-frequentist"><span class="header-section-number">5.5</span> Bayesian vs.&nbsp;Frequentist</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">5.6</span> Summary</a></li>
  <li><a href="#live-tutorial-and-discussion" id="toc-live-tutorial-and-discussion" class="nav-link" data-scroll-target="#live-tutorial-and-discussion"><span class="header-section-number">5.7</span> Live tutorial and discussion</a></li>
  <li><a href="#tutorial-exercises" id="toc-tutorial-exercises" class="nav-link" data-scroll-target="#tutorial-exercises"><span class="header-section-number">5.8</span> Tutorial Exercises</a></li>
  <li><a href="#preparation-for-week-6" id="toc-preparation-for-week-6" class="nav-link" data-scroll-target="#preparation-for-week-6"><span class="header-section-number">5.9</span> Preparation for Week 6</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<iframe width="500" height="300" src="https://www.youtube.com/embed/TSO8XgWiQZs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="learnings" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="learnings"><span class="header-section-number">5.1</span> Learnings</h2>
<ul>
<li><strong>Outcomes</strong></li>
</ul>
<p>– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.</p>
<p>– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.</p>
<p>– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.</p>
<ul>
<li><strong>Objectives</strong></li>
</ul>
<p>By the end of this week you should be able to:</p>
<p>– Understand Bayesian model and causality</p>
<p>– Explain the terms Estimand, Estimator &amp; Estimate</p>
<p>– Understand the difference between Bayesian and classical Regression.</p>
<p>– Interpret real-life problems in Bayesian context.</p>
<!--
ref: https://statswithr.github.io/book/introduction-to-bayesian-regression.html

Notes:

In this lecture, we shall explore the applications of Bayesian hierarchical models. 
We will begin by examining the utilisation of Bayesian models within the context of simple linear regression models and subsequently expand these insights to incorporate multiple linear regression. Through this exploration, we will find that employing the non-informative prior results in posterior means, posterior standard deviations, and credible intervals for the coefficients that are consistent with those derived from frequentist ordinary least squares (OLS) linear regression models.

We will start with how to develop a Bayesian model based on causality, or unknown causality with understanding of estimand, estimator and estimate. We wil also explore how DAG can help us to build the model. 

-->
</section>
<section id="causality-and-bayesian-inference" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="causality-and-bayesian-inference"><span class="header-section-number">5.2</span> Causality and Bayesian Inference</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/OBGnaeO4LME" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<!--
Causal salad - ref: McElreath page 17, see the BOX
-->
<p>A causal inference is a conclusion about a cause-and-effect relationship between two or more things. In simple terms, it’s answering the question: “Did X cause Y?” For example, if a study finds that people who drink more water tend to have better skin, causal inference would be the process of figuring out whether drinking water actually causes better skin or if that’s just a coincidence, or maybe due to some other factor (like diet or lifestyle). On the other hand, a correlation is when two things tend to happen together. It shows a relationship, but not necessarily a cause-and-effect one.</p>
<p>Let’s explore with another example. We might think, people who carry lighters are more likely to get lung cancer. This means that there is an association between carrying lighters and lung cancer, but it doesn’t imply that carrying a lighter causes lung cancer. Other factors, like smoking, could be the actual cause.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig_M03_causation.png" style="width:50.0%;height:50.0%" class="figure-img"></p>
<figcaption>Concept of correlation and causation</figcaption>
</figure>
</div>
</div>
</div>
<p>Now, when we conduct causal inference, we must first develop a causal model that is separate from a purely Bayesian (or statistical) model, because observational data by itself is not enough to establish causality. This idea is widely accepted across different philosophical traditions, even though interpretations of how to approach it can vary greatly.</p>
<p>The most cautious view holds that causation is fundamentally unprovable. We can take a slightly less conservative view, which holds that we are able to infer causation, but only under strict and carefully defined conditions, such as randomisation and experimental control. However, many scientific questions cannot be addressed experimentally due to feasibility constraints or ethical concerns.</p>
<p>In fields like health and medicine, we often introduce various control variables into a statistical model, observe changes in estimates, and construct a causal narrative. This approach assumes that only omitted variables can bias causal conclusions, yet even included variables can introduce confusion.</p>
<p>Even if we construct a causal model that appears to make accurate predictions, it may still misrepresent causation. If we rely on such a model to guide interventions, we risk producing unintended or misleading outcomes.</p>
<p>In this course, we will not discuss causal modelling in details, and for interested readers we refer books by <span class="citation" data-cites="pearl2016causal">Pearl, Glymour, and Jewell (<a href="references.html#ref-pearl2016causal" role="doc-biblioref">2016</a>)</span> and <span class="citation" data-cites="hernan2025causal">Hernán and Robins (<a href="references.html#ref-hernan2025causal" role="doc-biblioref">2025</a>)</span>.</p>
<section id="estimand-estimator-estimate" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="estimand-estimator-estimate"><span class="header-section-number">5.2.1</span> Estimand, Estimator &amp; Estimate</h3>
<!--
ref: https://bookdown.org/paul/applied-causal-analysis/estimator.html

-->
<p>Now, let us learn the terms estimand, estimator, and estimate. The estimand is the quantity of interest, i.e., the true value we seek to determine. We define an estimator as the method or procedure that we impliment to mimic/get the estimand. Finally, an estimate is the result (e.g., numerical value) we obtain from applying a specific estimator to data.</p>
<p>Suppose, we want to find out the average effectiveness of a vaccine for a respiratory disease among children in Australia. Our estimand is “the true average vaccine effectiveness for this respiratory disease among all children in Australia.”</p>
<p>Since we can’t measure every child, we take a random sample of 10,000 children (say) and record how well the vaccine protects them from the disease. Using this data, we now need to choose an estimator, which is a method to estimate our estimand.</p>
<p>The simplest approach that we can take is to calculate the average vaccine effectiveness in our sample. In this case, the sample average acts as our estimator, providing an estimate of the true vaccine effectiveness. If our sample average shows 85% effectiveness, then 85% is our estimate based on the sample average estimator.</p>
<p>Now, in a Bayesian framework, the estimand remains the same, which is the true but unknown average vaccine effectiveness among all children in Australia, that we can obtain from the true distribution of the vaccine effectiveness. However, instead of just using the sample average calculated from the 10,000 respondents/children, our estimator in the Bayesian context is the method of obtaining the posterior distribution of vaccine effectiveness. And we already know that this distribution is derived by combining prior knowledge with the likelihood of the observed data using Bayes theorem.</p>
</section>
<section id="bayesian-regression-context" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="bayesian-regression-context"><span class="header-section-number">5.2.2</span> Bayesian Regression Context</h3>
<p>Now, let us explain this in the context of Bayesian model, or regression problem. Considering the example explained earlier, suppose we are interested in understanding how vaccine efficacy for a respiratory-related disease among children in Australia is influenced by certain predictors, such as age, pre-existing health conditions, and socioeconomic status. In this case, our estimand is the set of true regression coefficients that describe the relationship between these predictors and vaccine efficacy.</p>
<p>A perfect way to determine these coefficients would be to measure vaccine efficacy and collect all relevant predictor data (e.g., age, health conditions, and socioeconomic status) for every child in Australia and then fit a model to the entire population data. However, this is practically infeasible. Instead, we can estimate the regression coefficients using a sample observation, and as we have already mentioned, we can take a random sample of 10,000 children in Australia and collect data on their vaccine efficacy and the relevant predictors. Using this data, we fit a Bayesian model (e.g., a Bayesian linear regression model) to estimate the relationship between the predictors and vaccine efficacy.</p>
<p>In the Bayesian framework, we approach this problem by starting with a prior distribution for each regression coefficient, reflecting our prior beliefs about the relationships. For example, based on previous studies, we might believe that younger children have slightly lower vaccine efficacy and use this belief into the prior.</p>
<p>The sample data provides the likelihood, representing the probability of observing the data given different values of the regression coefficients. By applying Bayes theorem, we combine the prior with the likelihood to produce a posterior distribution for each regression coefficient. The posterior distributions represent our updated beliefs about the coefficients after observing the data.</p>
<p>For example, when considering the outcome variable on a continuous scale (i.e., without any transformation), if the posterior mean for the age coefficient is -0.5, it suggests that, on average, each additional year of age is associated with a 0.5 percentage point decrease in vaccine efficacy. Similarly, if the posterior mean for the socioeconomic status coefficient is 2.0, it suggests that higher socioeconomic status is associated with a 2 percentage point increase in vaccine efficacy.</p>
<p>Here, estimand is the true regression coefficients that describe the relationships between the predictors and vaccine efficacy. Estimator is the posterior distributions of the regression coefficients that we get based on the Bayesian model. These distributions summarise the uncertainty about the coefficients. And estimate is the specific value derived from the posterior distributions, such as the posterior mean, median, or mode for each coefficient.</p>
<p>This Bayesian approach allows us not only to estimate the coefficients but to quantify our uncertainty about them, providing a more comprehensive understanding of the predictor influences on vaccine efficacy.</p>
</section>
</section>
<section id="model-development---gaussian-context" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="model-development---gaussian-context"><span class="header-section-number">5.3</span> Model Development - Gaussian Context</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/xQbxW8xa0Sk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>We have discussed about Directed Acyclic Graph (DAG) in one of our previous lectures. Today we will explain DAG for conceptualising and developing Bayesian regression models. It also helps to visually represent any potetntial causal relationships among variables and ensures proper adjustment for confounding factors.</p>
<p>Now we explain this more with an example related to Bone Mineral Density (BMD) measured in <span class="math inline">\(g/cm^2\)</span>. For example, we want to know, how does body mass index (BMI) impact bone mineral density (BMD)?</p>
<p>Here, we are trying to model the relationship between BMI (independent or exposure variable) and BMD (dependent or outcome or endpoint variable). Thus can draw the DAG as:</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-946ede650079bfaebef3" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-946ede650079bfaebef3">{"x":{"diagram":"\n  digraph LR {\n    rankdir=LR;  # Set the direction from left to right\n    M [label = \"BMI\"]\n    B [label = \"BMD\"]\n    M -> B\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>In a Bayesian context, we need to define the likelihood of observing the data given certain parameters and then combine that with a prior belief about those parameters.</p>
<section id="likelihood-prior-and-posterior" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="likelihood-prior-and-posterior"><span class="header-section-number">5.3.1</span> Likelihood, Prior and Posterior</h3>
<p>Let’s identify the likelihood and priors for the example:</p>
<p>BMD is modeled as a random variable that follows a normal distribution:</p>
<p><span class="math display">\[
\text{BMD} \sim N(\mu, \sigma^2)
\]</span></p>
<p>This notation means that for each observed value of BMD, the values are assumed to come from a normal distribution with mean <span class="math inline">\(\mu\)</span>, which is the location of the distribution and variance <span class="math inline">\(\sigma^2\)</span>, which indicates the spread or uncertainty around the mean.</p>
<p>We can now model the mean of the BMD as a function of the exposure variable, BMI. That is, the mean <span class="math inline">\(\mu\)</span> of BMD is determined by a linear relationship with BMI:</p>
<p><span class="math display">\[
\mu = \beta_0 + \beta_1 \cdot \text{BMI}
\]</span></p>
<p>where, <span class="math inline">\(\beta_0\)</span> is the intercept term, which is the expected BMD when BMI is zero, and <span class="math inline">\(\beta_1\)</span> is the slope term, which indicates the change in BMD per unit change in BMI.</p>
<p>So, the likelihood function tells us how probable it is to observe the given BMD data, given specific values for the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Now, let’s define the prior distributions for the model parameters:</p>
<p><span class="math display">\[
\beta_0 \sim N(\mu_0, \sigma_0^2)
\]</span></p>
<p>This states that <span class="math inline">\(\beta_0\)</span> follows a normal distribution with mean <span class="math inline">\(\mu_0\)</span> and variance <span class="math inline">\(\sigma_0^2\)</span>. The prior for <span class="math inline">\(\beta_0\)</span> could represent our belief about the intercept term before observing the data. For instance, if we think that <span class="math inline">\(\beta_0\)</span> (the baseline BMD when BMI is 0) should be close to 0, then we would choose <span class="math inline">\(\mu_0 = 0\)</span>, with some reasonable uncertainty <span class="math inline">\(\sigma_0^2\)</span>.</p>
<p><span class="math display">\[
\beta_1 \sim N(\mu_1, \sigma_1^2)
\]</span></p>
<p>This states that <span class="math inline">\(\beta_1\)</span>, the effect of BMI on BMD, is also normally distributed with a mean of <span class="math inline">\(\mu_1\)</span> and variance <span class="math inline">\(\sigma_1^2\)</span>. In this case, <span class="math inline">\(\mu_1\)</span> reflects our prior belief about the effect of BMI on BMD, and <span class="math inline">\(\sigma_1^2\)</span> reflects the uncertainty about that effect.</p>
<p><span class="math display">\[
\sigma^2 \sim \text{IG}(a, b)
\]</span></p>
<p>This represents the prior belief about the variance of the error terms (the variability in BMD not explained by BMI). It is modeled using an Inverse Gamma distribution, which is a conjugate prior distribution and denoted as $ (a, b)$, where: <span class="math inline">\(a\)</span> is a shape parameter, and <span class="math inline">\(b\)</span> is a scale parameter.</p>
<p>The inverse gamma distribution is commonly used for modelling variance parameters because it is from a conjugate family and produces positive values and can model both large and small variances.</p>
<p>Once we have the likelihood (how the data are distributed given the parameters) and the priors (our initial beliefs about the parameters), we can easily get the posterior distribution and in this case, the posterior distribution for the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\sigma^2\)</span>. This is proportional to:</p>
<p><span class="math display">\[
p(\beta_0, \beta_1, \sigma^2 | \text{BMD}, \text{BMI}) \propto p(\text{BMD} | \beta_0, \beta_1, \sigma^2) \cdot p(\beta_0) \cdot p(\beta_1) \cdot p(\sigma^2)
\]</span></p>
<p>Given the joint posterior distribution, we can write the full conditional distributions for parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\sigma^2\)</span> as:</p>
<p><span class="math display">\[
p(\beta_0 \mid \beta_1, \sigma^2, \text{BMD}, \text{BMI}) \propto N(\text{BMD} \mid \beta_0 + \beta_1 \cdot \text{BMI}, \sigma^2) \cdot N(\beta_0 \mid \mu_0, \sigma_0^2)
\]</span></p>
<p>This is the product of a likelihood and a normal prior, so the conditional posterior is also normal:</p>
<p><span class="math display">\[
\beta_0 \mid \cdot \sim N(\mu_{\beta_0}^*, \sigma_{\beta_0}^{2*})
\]</span></p>
<p>Where:</p>
<p><span class="math display">\[
\sigma_{\beta_0}^{2*} = \left( \frac{n}{\sigma^2} + \frac{1}{\sigma_0^2} \right)^{-1}; \quad \mu_{\beta_0}^* = \sigma_{\beta_0}^{2*} \left( \frac{1}{\sigma^2} \sum_{i=1}^n (\text{BMD}_i - \beta_1 \text{BMI}_i) + \frac{\mu_0}{\sigma_0^2} \right)
\]</span></p>
<p>Now, the conditional distribution for <span class="math inline">\(\beta_1\)</span>:</p>
<p><span class="math display">\[
p(\beta_1 \mid \beta_0, \sigma^2, \text{BMD}, \text{BMI}) \propto N(\text{BMD} \mid \beta_0 + \beta_1 \cdot \text{BMI}, \sigma^2) \cdot N(\beta_1 \mid \mu_1, \sigma_1^2)
\]</span></p>
<p>Hence, the full conditional is normal:</p>
<p><span class="math display">\[
\beta_1 \mid \cdot \sim N(\mu_{\beta_1}^*, \sigma_{\beta_1}^{2*})
\]</span></p>
<p>Where:</p>
<p><span class="math display">\[
\sigma_{\beta_1}^{2*} = \left( \frac{\sum \text{BMI}_i^2}{\sigma^2} + \frac{1}{\sigma_1^2} \right)^{-1}; \quad \mu_{\beta_1}^* = \sigma_{\beta_1}^{2*} \left( \frac{1}{\sigma^2} \sum \text{BMI}_i (\text{BMD}_i - \beta_0) + \frac{\mu_1}{\sigma_1^2} \right)
\]</span></p>
<p>Now, we can write the Conditional distribution for <span class="math inline">\(\sigma^2\)</span> as:</p>
<p><span class="math display">\[
p(\sigma^2 \mid \beta_0, \beta_1, \text{BMD}, \text{BMI}) \propto N(\text{BMD} \mid \beta_0 + \beta_1 \cdot \text{BMI}, \sigma^2) \cdot \text{IG}(a, b)
\]</span></p>
<p>Combining the likelihood (Gaussian) and Inverse Gamma prior, the full conditional is also Inverse Gamma:</p>
<p><span class="math display">\[
\sigma^2 \mid \cdot \sim \text{IG} \left(a + \frac{n}{2},\ b + \frac{1}{2} \sum_{i=1}^n (\text{BMD}_i - \beta_0 - \beta_1 \text{BMI}_i)^2 \right)
\]</span></p>
</section>
<section id="bayesian-dag" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="bayesian-dag"><span class="header-section-number">5.3.2</span> Bayesian DAG</h3>
<p>By using these information in the above example, we write DAG for the Bayesian model as:</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-9f24988aedd02f2480c4" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-9f24988aedd02f2480c4">{"x":{"diagram":"\n  digraph DAG {\n    rankdir=LR;  // Left to Right layout\n\n    // Nodes (observed variables)\n    BMI     [label = \"BMI\", shape = ellipse, style = filled, fillcolor = lightblue]\n    BMD     [label = \"BMD\", shape = ellipse, style = filled, fillcolor = lightcoral]\n\n    // Nodes (parameters)\n    beta_0  [label = \"β₀\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_1  [label = \"β₁\", shape = box, style = filled, fillcolor = lightgrey]\n    sigma2  [label = \"σ\", shape = box, style = filled, fillcolor = lightgrey]\n\n    // Hyperparameters for β₀\n    mu0     [label = \"μ₀\", shape = box, style = filled, fillcolor = lightyellow]\n    sig20   [label = \"σ₀\", shape = box, style = filled, fillcolor = lightyellow]\n\n    // Hyperparameters for β₁\n    mu1     [label = \"μ₁\", shape = box, style = filled, fillcolor = lightyellow]\n    sig21   [label = \"σ₁\", shape = box, style = filled, fillcolor = lightyellow]\n\n    // Hyperparameters for σ\n    a       [label = \"a\", shape = box, style = filled, fillcolor = lightyellow]\n    b       [label = \"b\", shape = box, style = filled, fillcolor = lightyellow]\n\n    // Edges (model structure)\n    BMI     -> BMD\n    beta_0  -> BMD\n    beta_1  -> BMD\n    sigma2  -> BMD\n\n    mu0     -> beta_0\n    sig20   -> beta_0\n\n    mu1     -> beta_1\n    sig21   -> beta_1\n\n    a       -> sigma2\n    b       -> sigma2\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Here, circles represent variables, while squares denote model parameters and hyperparameters. We can also present the DAG in a more visually informative form below, including the hyperparameters along with their corresponding distributions.</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-abb8fab744970c8c6612" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-abb8fab744970c8c6612">{"x":{"diagram":"\n  digraph DAG {\n    rankdir=LR;  # Set direction from left to right\n    \n    # Nodes (parameters and variables)\n    BMI [label = \"BMI\", shape = ellipse, style = filled, fillcolor = lightblue]\n    BMD [label = \"BMD\", shape = ellipse, style = filled, fillcolor = lightcoral]\n    beta_0 [label = \"β₀\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_1 [label = \"β₁\", shape = box, style = filled, fillcolor = lightgrey]\n    sigma2 [label = \"σ\", shape = box, style = filled, fillcolor = lightgrey]\n    prior_beta_0 [label = \"Prior for β₀: N(μ₀, σ₀²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_beta_1 [label = \"Prior for β₁: N(μ₁, σ₁²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_sigma2 [label = \"Prior for σ²: IG(a, b)\", shape = box, style = dashed, fillcolor = lightyellow]\n    \n    # Edges (dependencies between nodes)\n    BMI -> BMD\n    beta_0 -> BMD\n    beta_1 -> BMD\n    sigma2 -> BMD\n    prior_beta_0 -> beta_0\n    prior_beta_1 -> beta_1\n    prior_sigma2 -> sigma2\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Now, let’s break down the concepts of estimand, estimator, and estimate using the Bayesian model represented by the DAG. In this example, the estimand is the quantity or parameter that we aim to estimate from the data, i.e., here the estimands are the parameters we want to infer, <span class="math inline">\(\beta_0\)</span> (intercept), <span class="math inline">\(\beta_1\)</span> (slope), and <span class="math inline">\(\sigma^2\)</span> (variance). Now, estimator is the method we are using, i.e., the Bayesian model with MCMC method to get the posterior distributions of the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\sigma^2\)</span>. In this Bayesian modelling framework, the estimates are the specific values derived from the posterior distributions of the parameters. For example, the mean or median of the posterior distribution of <span class="math inline">\(\beta_0\)</span> could be an estimate of the intercept. Similarly, the mean or median of the posterior distribution of <span class="math inline">\(\beta_1\)</span> could be an estimate of the slope.</p>
</section>
</section>
<section id="model-baesd-results" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="model-baesd-results"><span class="header-section-number">5.4</span> Model-Baesd Results</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/opq8YiD39pI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="priors" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="priors"><span class="header-section-number">5.4.1</span> Priors</h3>
<p>We consider the following prior distributions for the model parameters. Say, we do not know any previous information at the baseline for BMD ( i.e., intercept). Suppose, we do not have any knowledge about the effect of BMI on BMD. Hence, we can consider <span class="math inline">\(\beta_0,\beta_1 \sim N(0, 10^2)\)</span>. Furthermore, let us assume the the variance parameter follows inverse-gamma distribution with hyper-parameters <span class="math inline">\(a=2\)</span> and <span class="math inline">\(b=1\)</span>.</p>
<p>The prior structure we use follows a pattern of weakly informative priors. These help with regularisation by gently pulling parameter estimates toward zero, unless the data provide strong evidence for a large effect. This also helps avoid overestimating effects, a problem sometimes known as the winner’s curse.</p>
<p>Hence, following this structure, we can draw the prior distributions as follows:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(invgamma)  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>x_norm <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>, <span class="at">length.out =</span> <span class="dv">500</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>normal_density <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x_norm, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df_beta <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_norm,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> normal_density</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_beta, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Prior for "</span> <span class="sc">~</span> beta[<span class="dv">0</span>]),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">0</span>]),</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_beta, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Prior for "</span> <span class="sc">~</span> beta[<span class="dv">1</span>]),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]),</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>x_sigma2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">5</span>, <span class="at">length.out =</span> <span class="dv">500</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>sigma2_density <span class="ot">&lt;-</span> <span class="fu">dinvgamma</span>(x_sigma2, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">rate =</span> <span class="dv">1</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>df_sigma2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_sigma2,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> sigma2_density</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_sigma2, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"firebrick"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Prior for "</span> <span class="sc">~</span> sigma<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(sigma<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all three plots</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>(p1 <span class="sc">|</span> p2 <span class="sc">|</span> p3) <span class="sc">+</span> <span class="fu">plot_annotation</span>(<span class="at">title =</span> <span class="st">"Prior Distributions"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_1_files/figure-html/bmd_prior-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Now, we use these prior distributions to obtain the posterior distributions for the model parameters. We use R package “brms” to impliment the Bayesian model.</p>
<p>Note that not all R packages (such as <code>brms</code>) have the option to use the inverse Gamma distribution directly in the R front-end function. We could avoid using Bayesian R packages and write individual Stan code to include the Inverse Gamma prior, but at this stage, that is beyond the scope of this course. Writing in Stan requires a strong understanding of mathematical coding, which may not be suitable for the general audience or students taking this course. Having said that, we encourage interested readers or students to stay in touch with the course coordinator for a deeper dive into writing core Stan code.</p>
<p>Now, a simple solution related to the issue of inverse Gamma distribution is to use a distribution that approximates the inverse Gamma, and here Student’s t-distribution can be a good candidate for such distribution. While they are not equivalent, under certain conditions they can be closely approximated. Now, if</p>
<p><span class="math display">\[
\sigma^2 \sim \text{IG}(a, b), \quad x \mid \sigma^2 \sim N(0, \sigma^2)
\]</span></p>
<p>then marginally,</p>
<p><span class="math display">\[
x \sim \text{Student-}t_{(\nu = 2a)}\left(0, \sqrt{\frac{b}{a}}\right)
\]</span></p>
<p>That is, we can approximate by considering:</p>
<ul>
<li>Degrees of freedom: <span class="math inline">\(\nu = 2a\)</span></li>
<li>Location: <span class="math inline">\(\mu=0\)</span> (for variance parameter we restrict it to the <span class="math inline">\(\mathbb{R}^+\)</span>)</li>
<li>Scale: <span class="math inline">\(\sqrt{\frac{b}{a}}\)</span></li>
</ul>
<p>Now, for <span class="math inline">\(\text{IG}(a=2,b=1)\)</span>, we get the approximation as: <span class="math inline">\(\text{Student-t}(4,0,0.7)\)</span>. Although, in practice, we have seen that for <span class="math inline">\(\sigma\)</span>, use of <span class="math inline">\(\text{Student-t}(3,0,1)\)</span> is often a popular choice for the prior.</p>
<p>Hence, in this course, we will use Student-t distribution instead of the inverse Gamma to represnt the prior distribution for the Bayesian regression coefficient. Note that, in our next lecture, we will also discuss some other possible candidates for the prior distributions.</p>
<p>Now, we can draw the prior distribution plots for inverse Gamma and Student-t distributions with different hyper-parmaters as follows:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>ig_density <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha, beta, x) {</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">dgamma</span>(<span class="dv">1</span> <span class="sc">/</span> x, <span class="at">shape =</span> alpha, <span class="at">rate =</span> beta) <span class="sc">/</span> (x<span class="sc">^</span><span class="dv">2</span>))  </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">20</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)), <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">ig_density</span>(<span class="dv">2</span>, <span class="dv">1</span>, x), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">x =</span> <span class="fu">expression</span>(sigma), </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Inverse-Gamma(2, 1)"</span>) <span class="sc">+</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">20</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)), <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>     <span class="fu">stat_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">ig_density</span>(<span class="fl">1.5</span>, <span class="fl">1.5</span>, x), <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>     <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">x =</span> <span class="fu">expression</span>(sigma), </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>          <span class="at">title =</span> <span class="st">"Inverse-Gamma(1.5, 1.5)"</span>) <span class="sc">+</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>     <span class="fu">theme_minimal</span>()</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">20</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)), <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">dt</span>(x <span class="sc">/</span> <span class="fl">0.707</span>, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">/</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">x =</span> <span class="fu">expression</span>(sigma), </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Student-t(4, 0, 0.707)"</span>) <span class="sc">+</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">20</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)), <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">dt</span>(x <span class="sc">/</span> <span class="dv">1</span>, <span class="at">df =</span> <span class="dv">3</span>) <span class="sc">/</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lwd =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">x =</span> <span class="fu">expression</span>(sigma), </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Student-t(3, 0, 1)"</span>) <span class="sc">+</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, p4, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_1_files/figure-html/bmd_priors_ig_t-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="posteriors" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="posteriors"><span class="header-section-number">5.4.2</span> Posteriors</h3>
<p>We fit the model using the <code>brms</code> package with a single MCMC chain and 2000 iterations. While this example uses one chain, multiple chains can also be specified. Note that for <span class="math inline">\(\sigma\)</span>, we use Student-t prior distribution with degrees of freedom <span class="math inline">\(\nu = 3\)</span> and scale 1. Finally, we obtain a summary of the posterior distributions for the model parameters as follows:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"bmd_restricted.csv"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>bmd_data<span class="sc">$</span>bmi <span class="ot">&lt;-</span> bmd_data<span class="sc">$</span>weight_kg<span class="sc">/</span>(bmd_data<span class="sc">$</span>height_cm<span class="sc">/</span><span class="dv">100</span>)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMD =</span> bmd_data<span class="sc">$</span>bmd,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMI =</span> bmd_data<span class="sc">$</span>bmi,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># model</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>bmd_model <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> BMD <span class="sc">~</span> BMI,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> bmd_data,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"BMI"</span>),   <span class="co"># N(mean, sd) Slope priors</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"Intercept"</span>),   <span class="co"># N(mean, sd) Intercept prior</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">student_t</span>(<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> <span class="st">"sigma"</span>)  </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">1</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">3</span>,</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 3.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.039 seconds (Warm-up)
Chain 1:                0.024 seconds (Sampling)
Chain 1:                0.063 seconds (Total)
Chain 1: </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bmd_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: BMD ~ BMI 
   Data: bmd_data (Number of observations: 169) 
  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 1000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     0.42      0.07     0.29     0.55 1.00     1302      852
BMI           0.01      0.00     0.01     0.02 1.00     1317      852

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.16      0.01     0.14     0.17 1.00      719      614

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#posterior_summary(bmd_model)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(bmd_model)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The Bayesian model output indicates that the estimated intercept is 0.42, representing the expected BMD when BMI is zero, a value that isn’t realistic but is standard when interpreting linear models. The coefficient for BMI is 0.01, suggesting that for every one-unit increase in BMI, BMD increases by approximately 0.01 units on average. The 95% credible interval for this estimate ranges from 0.01 to 0.02, providing strong evidence that the effect of BMI on BMD is positive. The residual standard deviation (noise not explained by BMI) is estimated at 0.16 with a tight credible interval.</p>
</section>
<section id="mcmc-diagnostics" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="mcmc-diagnostics"><span class="header-section-number">5.4.3</span> MCMC Diagnostics</h3>
<p>We see that the convergence diagnostics are excellent, with Rhat values equal to 1.00, showing that the MCMC chains have mixed well. Additionally, the Bulk Effective Sample Size (Bulk_ESS) and Tail Effective Sample Size (Tail_ESS) are both comfortably above 500. ESS values should ideally be over 400–500 for each parameter. Lower ESS suggests that the model might need more iterations or better mixing. The results indicate that the posterior estimates are based on a sufficient number of effective samples and can be considered stable and reliable.</p>
<p>Below we provide the histogram and trace plots related to the posterior distributions of the model parameters. We also provide the autocorrelation plot and posterior predictive check based on the posterior distributions.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bmd_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_1_files/figure-html/bmd_bayes_plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>post_samples <span class="ot">&lt;-</span> <span class="fu">as.array</span>(bmd_model)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#acf(post_samples[, , "b_Intercept"], main = "Autocorrelation: Intercept")</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(post_samples[, , <span class="st">"b_BMI"</span>], <span class="at">main =</span> <span class="st">"Autocorrelation: BMI"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_1_files/figure-html/bmd_bayes_plot-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pp_check</span>(bmd_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_1_files/figure-html/bmd_bayes_plot-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The trace plots show a well-mixed pattern for the MCMC samples. Similarly, we can see that the autocorrelation is low after a few iterations, i.e., the chains are well-mixed. Finally, the posterior predictive check provides further indication that the distribution match with the replications.</p>
</section>
</section>
<section id="bayesian-vs.-frequentist" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="bayesian-vs.-frequentist"><span class="header-section-number">5.5</span> Bayesian vs.&nbsp;Frequentist</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/opq8YiD39pI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>Now, let us compare the posterior distributions we obtained from the Bayesian model with the estimates from frequentist linear regression model.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(BMD <span class="sc">~</span> BMI, <span class="at">data =</span> bmd_data)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>jtools<span class="sc">::</span><span class="fu">summ</span>(lm_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MODEL INFO:
Observations: 169
Dependent Variable: BMD
Type: OLS linear regression 

MODEL FIT:
F(1,167) = 27.98, p = 0.00
R² = 0.14
Adj. R² = 0.14 

Standard errors:OLS
-----------------------------------------------
                    Est.   S.E.   t val.      p
----------------- ------ ------ -------- ------
(Intercept)         0.42   0.07     6.11   0.00
BMI                 0.01   0.00     5.29   0.00
-----------------------------------------------</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>lm_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">summary</span>(lm_model))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>bmi_est <span class="ot">&lt;-</span> lm_coef[<span class="st">"BMI"</span>, <span class="st">"Estimate"</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>bmi_se <span class="ot">&lt;-</span> lm_coef[<span class="st">"BMI"</span>, <span class="st">"Std. Error"</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>ci_low <span class="ot">&lt;-</span> bmi_est <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> bmi_se</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>ci_high <span class="ot">&lt;-</span> bmi_est <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> bmi_se</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(bmd_model)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>post_bmi <span class="ot">&lt;-</span> post<span class="sc">$</span>b_BMI</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>bayes_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(post_bmi)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>bayes_ci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(post_bmi, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> post_bmi), <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="cn">NA</span>) <span class="sc">+</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bmi_est, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_low, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_high, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_mean, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_ci[<span class="dv">1</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_ci[<span class="dv">2</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Bayesian vs Frequentist Estimate of BMI"</span>,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Red: Frequentist (Mean &amp; 95% Confidence Interval)</span><span class="sc">\n</span><span class="st">Blue: Bayesian (Posterior Mean &amp; 95% Credible Interval)"</span>,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Coefficient for BMI"</span>,</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">plot.subtitle =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-42de6afcf116b34060f7" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-42de6afcf116b34060f7">{"x":{"data":[{"x":[0.0062097564263932049,0.0062431886709766373,0.0062766209155600697,0.006310053160143503,0.0063434854047269354,0.0063769176493103678,0.0064103498938938002,0.0064437821384772326,0.006477214383060665,0.0065106466276440983,0.0065440788722275307,0.0065775111168109631,0.0066109433613943955,0.0066443756059778279,0.0066778078505612603,0.0067112400951446936,0.006744672339728126,0.0067781045843115584,0.0068115368288949908,0.0068449690734784232,0.0068784013180618556,0.0069118335626452889,0.0069452658072287213,0.0069786980518121537,0.0070121302963955861,0.0070455625409790185,0.0070789947855624518,0.0071124270301458842,0.0071458592747293166,0.007179291519312749,0.0072127237638961814,0.0072461560084796138,0.0072795882530630462,0.0073130204976464795,0.0073464527422299119,0.0073798849868133443,0.0074133172313967767,0.0074467494759802091,0.0074801817205636424,0.0075136139651470748,0.0075470462097305072,0.0075804784543139396,0.007613910698897372,0.0076473429434808053,0.0076807751880642369,0.0077142074326476701,0.0077476396772311025,0.0077810719218145349,0.0078145041663979682,0.0078479364109813998,0.007881368655564833,0.0079148009001482646,0.0079482331447316978,0.0079816653893151311,0.0080150976338985627,0.0080485298784819959,0.0080819621230654275,0.0081153943676488607,0.008148826612232294,0.0081822588568157256,0.0082156911013991588,0.0082491233459825904,0.0082825555905660236,0.0083159878351494569,0.0083494200797328885,0.00838285232431632,0.0084162845688997533,0.0084497168134831865,0.0084831490580666181,0.0085165813026500514,0.0085500135472334829,0.0085834457918169162,0.0086168780364003494,0.008650310280983781,0.0086837425255672143,0.0087171747701506458,0.0087506070147340791,0.0087840392593175123,0.0088174715039009439,0.0088509037484843772,0.0088843359930678087,0.008917768237651242,0.0089512004822346752,0.0089846327268181068,0.0090180649714015401,0.0090514972159849716,0.0090849294605684049,0.0091183617051518381,0.0091517939497352697,0.0091852261943187029,0.0092186584389021345,0.0092520906834855678,0.009285522928069001,0.0093189551726524326,0.0093523874172358641,0.0093858196618192974,0.0094192519064027307,0.0094526841509861622,0.0094861163955695955,0.009519548640153027,0.0095529808847364603,0.0095864131293198936,0.0096198453739033251,0.0096532776184867584,0.0096867098630701899,0.0097201421076536232,0.0097535743522370565,0.009787006596820488,0.0098204388414039213,0.0098538710859873528,0.0098873033305707861,0.0099207355751542194,0.0099541678197376509,0.0099876000643210842,0.010021032308904516,0.010054464553487949,0.010087896798071382,0.010121329042654814,0.010154761287238245,0.010188193531821679,0.010221625776405112,0.010255058020988545,0.010288490265571977,0.010321922510155408,0.010355354754738842,0.010388786999322275,0.010422219243905708,0.01045565148848914,0.010489083733072571,0.010522515977656004,0.010555948222239438,0.010589380466822871,0.010622812711406302,0.010656244955989734,0.010689677200573167,0.010723109445156601,0.010756541689740032,0.010789973934323465,0.010823406178906897,0.01085683842349033,0.010890270668073763,0.010923702912657195,0.010957135157240627,0.01099056740182406,0.011023999646407493,0.011057431890990926,0.011090864135574358,0.011124296380157789,0.011157728624741223,0.011191160869324656,0.011224593113908089,0.011258025358491521,0.011291457603074952,0.011324889847658386,0.011358322092241819,0.011391754336825252,0.011425186581408684,0.011458618825992115,0.011492051070575549,0.011525483315158982,0.011558915559742415,0.011592347804325847,0.011625780048909278,0.011659212293492711,0.011692644538076145,0.011726076782659576,0.01175950902724301,0.011792941271826441,0.011826373516409874,0.011859805760993308,0.011893238005576739,0.011926670250160171,0.011960102494743604,0.011993534739327037,0.012026966983910471,0.012060399228493902,0.012093831473077334,0.012127263717660767,0.0121606959622442,0.012194128206827633,0.012227560451411065,0.012260992695994496,0.01229442494057793,0.012327857185161363,0.012361289429744796,0.012394721674328228,0.012428153918911659,0.012461586163495093,0.012495018408078526,0.012528450652661957,0.012561882897245391,0.012595315141828822,0.012628747386412256,0.012662179630995689,0.01269561187557912,0.012729044120162554,0.012762476364745985,0.012795908609329418,0.012829340853912852,0.012862773098496283,0.012896205343079715,0.012929637587663148,0.012963069832246581,0.012996502076830015,0.013029934321413446,0.013063366565996878,0.013096798810580311,0.013130231055163744,0.013163663299747178,0.013197095544330609,0.013230527788914041,0.013263960033497474,0.013297392278080907,0.01333082452266434,0.013364256767247772,0.013397689011831204,0.013431121256414637,0.01346455350099807,0.013497985745581502,0.013531417990164935,0.013564850234748366,0.0135982824793318,0.013631714723915233,0.013665146968498664,0.013698579213082096,0.013732011457665529,0.013765443702248963,0.013798875946832396,0.013832308191415827,0.013865740435999259,0.013899172680582692,0.013932604925166125,0.013966037169749559,0.01399946941433299,0.014032901658916422,0.014066333903499855,0.014099766148083288,0.014133198392666722,0.014166630637250151,0.014200062881833585,0.014233495126417018,0.014266927371000451,0.014300359615583885,0.014333791860167314,0.014367224104750748,0.014400656349334181,0.014434088593917614,0.014467520838501047,0.014500953083084477,0.014534385327667911,0.014567817572251344,0.014601249816834777,0.01463468206141821,0.01466811430600164,0.014701546550585073,0.014734978795168507,0.01476841103975194,0.014801843284335373,0.014835275528918803,0.014868707773502236,0.01490214001808567,0.014935572262669103,0.014969004507252536,0.015002436751835966,0.015035868996419399,0.015069301241002832,0.015102733485586266,0.015136165730169696,0.015169597974753129,0.015203030219336562,0.015236462463919995,0.015269894708503429,0.015303326953086858,0.015336759197670292,0.015370191442253725,0.015403623686837158,0.015437055931420592,0.015470488176004021,0.015503920420587455,0.015537352665170888,0.015570784909754321,0.015604217154337754,0.015637649398921184,0.015671081643504618,0.015704513888088051,0.015737946132671484,0.015771378377254917,0.015804810621838347,0.01583824286642178,0.015871675111005214,0.015905107355588647,0.01593853960017208,0.01597197184475551,0.016005404089338943,0.016038836333922377,0.01607226857850581,0.01610570082308924,0.016139133067672673,0.016172565312256106,0.01620599755683954,0.016239429801422973,0.016272862046006403,0.016306294290589836,0.016339726535173269,0.016373158779756702,0.016406591024340136,0.016440023268923565,0.016473455513506999,0.016506887758090432,0.016540320002673865,0.016573752247257299,0.016607184491840728,0.016640616736424162,0.016674048981007595,0.016707481225591028,0.016740913470174461,0.016774345714757891,0.016807777959341325,0.016841210203924758,0.016874642448508191,0.016908074693091624,0.016941506937675054,0.016974939182258487,0.017008371426841921,0.017041803671425354,0.017075235916008784,0.017108668160592217,0.01714210040517565,0.017175532649759084,0.017208964894342517,0.017242397138925947,0.01727582938350938,0.017309261628092813,0.017342693872676247,0.01737612611725968,0.01740955836184311,0.017442990606426543,0.017476422851009976,0.017509855095593409,0.017543287340176843,0.017576719584760273,0.017610151829343706,0.017643584073927139,0.017677016318510572,0.017710448563094006,0.017743880807677435,0.017777313052260869,0.017810745296844302,0.017844177541427735,0.017877609786011165,0.017911042030594598,0.017944474275178032,0.017977906519761465,0.018011338764344898,0.018044771008928328,0.018078203253511761,0.018111635498095194,0.018145067742678628,0.018178499987262061,0.018211932231845491,0.018245364476428924,0.018278796721012357,0.018312228965595791,0.018345661210179224,0.018379093454762654,0.018412525699346087,0.01844595794392952,0.018479390188512954,0.018512822433096387,0.018546254677679817,0.01857968692226325,0.018613119166846683,0.018646551411430116,0.01867998365601355,0.01871341590059698,0.018746848145180413,0.018780280389763846,0.018813712634347279,0.018847144878930709,0.018880577123514142,0.018914009368097576,0.018947441612681009,0.018980873857264442,0.019014306101847872,0.019047738346431305,0.019081170591014739,0.019114602835598172,0.019148035080181605,0.019181467324765035,0.019214899569348468,0.019248331813931902,0.019281764058515335,0.019315196303098768,0.019348628547682198,0.019382060792265631,0.019415493036849064,0.019448925281432498,0.019482357526015931,0.019515789770599361,0.019549222015182794,0.019582654259766227,0.019616086504349661,0.019649518748933094,0.019682950993516524,0.019716383238099957,0.01974981548268339,0.019783247727266823,0.019816679971850253,0.019850112216433687,0.01988354446101712,0.019916976705600553,0.019950408950183986,0.019983841194767416,0.020017273439350849,0.020050705683934283,0.020084137928517716,0.020117570173101149,0.020151002417684579,0.020184434662268012,0.020217866906851446,0.020251299151434879,0.020284731396018312,0.020318163640601742,0.020351595885185175,0.020385028129768609,0.020418460374352042,0.020451892618935475,0.020485324863518905,0.020518757108102338,0.020552189352685771,0.020585621597269205,0.020619053841852638,0.020652486086436068,0.020685918331019501,0.020719350575602934,0.020752782820186368,0.020786215064769797,0.020819647309353231,0.020853079553936664,0.020886511798520097,0.020919944043103531,0.02095337628768696,0.020986808532270394,0.021020240776853827,0.02105367302143726,0.021087105266020693,0.021120537510604123,0.021153969755187556,0.02118740199977099,0.021220834244354423,0.021254266488937856,0.021287698733521286,0.021321130978104719,0.021354563222688153,0.021387995467271586,0.021421427711855019,0.021454859956438449,0.021488292201021882,0.021521724445605316,0.021555156690188749,0.021588588934772182,0.021622021179355612,0.021655453423939045,0.021688885668522478,0.021722317913105912,0.021755750157689342,0.021789182402272775,0.021822614646856208,0.021856046891439641,0.021889479136023075,0.021922911380606508,0.021956343625189938,0.021989775869773371,0.022023208114356804,0.022056640358940238,0.022090072603523671,0.022123504848107101,0.022156937092690534,0.022190369337273967,0.0222238015818574,0.022257233826440834,0.022290666071024264,0.022324098315607697,0.02235753056019113,0.022390962804774563,0.022424395049357997,0.022457827293941426,0.02249125953852486,0.022524691783108293,0.022558124027691726,0.02259155627227516,0.022624988516858589,0.022658420761442023,0.022691853006025456,0.022725285250608889,0.022758717495192322,0.022792149739775752,0.022825581984359185,0.022859014228942619,0.022892446473526052,0.022925878718109482,0.022959310962692915,0.022992743207276348,0.023026175451859782,0.023059607696443215,0.023093039941026645,0.023126472185610078,0.023159904430193511,0.023193336674776945,0.023226768919360378,0.023260201163943808,0.023293633408527241,0.023293633408527241,0.023293633408527241,0.023260201163943808,0.023226768919360378,0.023193336674776945,0.023159904430193511,0.023126472185610078,0.023093039941026645,0.023059607696443215,0.023026175451859782,0.022992743207276348,0.022959310962692915,0.022925878718109482,0.022892446473526052,0.022859014228942619,0.022825581984359185,0.022792149739775752,0.022758717495192322,0.022725285250608889,0.022691853006025456,0.022658420761442023,0.022624988516858589,0.02259155627227516,0.022558124027691726,0.022524691783108293,0.02249125953852486,0.022457827293941426,0.022424395049357997,0.022390962804774563,0.02235753056019113,0.022324098315607697,0.022290666071024264,0.022257233826440834,0.0222238015818574,0.022190369337273967,0.022156937092690534,0.022123504848107101,0.022090072603523671,0.022056640358940238,0.022023208114356804,0.021989775869773371,0.021956343625189938,0.021922911380606508,0.021889479136023075,0.021856046891439641,0.021822614646856208,0.021789182402272775,0.021755750157689342,0.021722317913105912,0.021688885668522478,0.021655453423939045,0.021622021179355612,0.021588588934772182,0.021555156690188749,0.021521724445605316,0.021488292201021882,0.021454859956438449,0.021421427711855019,0.021387995467271586,0.021354563222688153,0.021321130978104719,0.021287698733521286,0.021254266488937856,0.021220834244354423,0.02118740199977099,0.021153969755187556,0.021120537510604123,0.021087105266020693,0.02105367302143726,0.021020240776853827,0.020986808532270394,0.02095337628768696,0.020919944043103531,0.020886511798520097,0.020853079553936664,0.020819647309353231,0.020786215064769797,0.020752782820186368,0.020719350575602934,0.020685918331019501,0.020652486086436068,0.020619053841852638,0.020585621597269205,0.020552189352685771,0.020518757108102338,0.020485324863518905,0.020451892618935475,0.020418460374352042,0.020385028129768609,0.020351595885185175,0.020318163640601742,0.020284731396018312,0.020251299151434879,0.020217866906851446,0.020184434662268012,0.020151002417684579,0.020117570173101149,0.020084137928517716,0.020050705683934283,0.020017273439350849,0.019983841194767416,0.019950408950183986,0.019916976705600553,0.01988354446101712,0.019850112216433687,0.019816679971850253,0.019783247727266823,0.01974981548268339,0.019716383238099957,0.019682950993516524,0.019649518748933094,0.019616086504349661,0.019582654259766227,0.019549222015182794,0.019515789770599361,0.019482357526015931,0.019448925281432498,0.019415493036849064,0.019382060792265631,0.019348628547682198,0.019315196303098768,0.019281764058515335,0.019248331813931902,0.019214899569348468,0.019181467324765035,0.019148035080181605,0.019114602835598172,0.019081170591014739,0.019047738346431305,0.019014306101847872,0.018980873857264442,0.018947441612681009,0.018914009368097576,0.018880577123514142,0.018847144878930709,0.018813712634347279,0.018780280389763846,0.018746848145180413,0.01871341590059698,0.01867998365601355,0.018646551411430116,0.018613119166846683,0.01857968692226325,0.018546254677679817,0.018512822433096387,0.018479390188512954,0.01844595794392952,0.018412525699346087,0.018379093454762654,0.018345661210179224,0.018312228965595791,0.018278796721012357,0.018245364476428924,0.018211932231845491,0.018178499987262061,0.018145067742678628,0.018111635498095194,0.018078203253511761,0.018044771008928328,0.018011338764344898,0.017977906519761465,0.017944474275178032,0.017911042030594598,0.017877609786011165,0.017844177541427735,0.017810745296844302,0.017777313052260869,0.017743880807677435,0.017710448563094006,0.017677016318510572,0.017643584073927139,0.017610151829343706,0.017576719584760273,0.017543287340176843,0.017509855095593409,0.017476422851009976,0.017442990606426543,0.01740955836184311,0.01737612611725968,0.017342693872676247,0.017309261628092813,0.01727582938350938,0.017242397138925947,0.017208964894342517,0.017175532649759084,0.01714210040517565,0.017108668160592217,0.017075235916008784,0.017041803671425354,0.017008371426841921,0.016974939182258487,0.016941506937675054,0.016908074693091624,0.016874642448508191,0.016841210203924758,0.016807777959341325,0.016774345714757891,0.016740913470174461,0.016707481225591028,0.016674048981007595,0.016640616736424162,0.016607184491840728,0.016573752247257299,0.016540320002673865,0.016506887758090432,0.016473455513506999,0.016440023268923565,0.016406591024340136,0.016373158779756702,0.016339726535173269,0.016306294290589836,0.016272862046006403,0.016239429801422973,0.01620599755683954,0.016172565312256106,0.016139133067672673,0.01610570082308924,0.01607226857850581,0.016038836333922377,0.016005404089338943,0.01597197184475551,0.01593853960017208,0.015905107355588647,0.015871675111005214,0.01583824286642178,0.015804810621838347,0.015771378377254917,0.015737946132671484,0.015704513888088051,0.015671081643504618,0.015637649398921184,0.015604217154337754,0.015570784909754321,0.015537352665170888,0.015503920420587455,0.015470488176004021,0.015437055931420592,0.015403623686837158,0.015370191442253725,0.015336759197670292,0.015303326953086858,0.015269894708503429,0.015236462463919995,0.015203030219336562,0.015169597974753129,0.015136165730169696,0.015102733485586266,0.015069301241002832,0.015035868996419399,0.015002436751835966,0.014969004507252536,0.014935572262669103,0.01490214001808567,0.014868707773502236,0.014835275528918803,0.014801843284335373,0.01476841103975194,0.014734978795168507,0.014701546550585073,0.01466811430600164,0.01463468206141821,0.014601249816834777,0.014567817572251344,0.014534385327667911,0.014500953083084477,0.014467520838501047,0.014434088593917614,0.014400656349334181,0.014367224104750748,0.014333791860167314,0.014300359615583885,0.014266927371000451,0.014233495126417018,0.014200062881833585,0.014166630637250151,0.014133198392666722,0.014099766148083288,0.014066333903499855,0.014032901658916422,0.01399946941433299,0.013966037169749559,0.013932604925166125,0.013899172680582692,0.013865740435999259,0.013832308191415827,0.013798875946832396,0.013765443702248963,0.013732011457665529,0.013698579213082096,0.013665146968498664,0.013631714723915233,0.0135982824793318,0.013564850234748366,0.013531417990164935,0.013497985745581502,0.01346455350099807,0.013431121256414637,0.013397689011831204,0.013364256767247772,0.01333082452266434,0.013297392278080907,0.013263960033497474,0.013230527788914041,0.013197095544330609,0.013163663299747178,0.013130231055163744,0.013096798810580311,0.013063366565996878,0.013029934321413446,0.012996502076830015,0.012963069832246581,0.012929637587663148,0.012896205343079715,0.012862773098496283,0.012829340853912852,0.012795908609329418,0.012762476364745985,0.012729044120162554,0.01269561187557912,0.012662179630995689,0.012628747386412256,0.012595315141828822,0.012561882897245391,0.012528450652661957,0.012495018408078526,0.012461586163495093,0.012428153918911659,0.012394721674328228,0.012361289429744796,0.012327857185161363,0.01229442494057793,0.012260992695994496,0.012227560451411065,0.012194128206827633,0.0121606959622442,0.012127263717660767,0.012093831473077334,0.012060399228493902,0.012026966983910471,0.011993534739327037,0.011960102494743604,0.011926670250160171,0.011893238005576739,0.011859805760993308,0.011826373516409874,0.011792941271826441,0.01175950902724301,0.011726076782659576,0.011692644538076145,0.011659212293492711,0.011625780048909278,0.011592347804325847,0.011558915559742415,0.011525483315158982,0.011492051070575549,0.011458618825992115,0.011425186581408684,0.011391754336825252,0.011358322092241819,0.011324889847658386,0.011291457603074952,0.011258025358491521,0.011224593113908089,0.011191160869324656,0.011157728624741223,0.011124296380157789,0.011090864135574358,0.011057431890990926,0.011023999646407493,0.01099056740182406,0.010957135157240627,0.010923702912657195,0.010890270668073763,0.01085683842349033,0.010823406178906897,0.010789973934323465,0.010756541689740032,0.010723109445156601,0.010689677200573167,0.010656244955989734,0.010622812711406302,0.010589380466822871,0.010555948222239438,0.010522515977656004,0.010489083733072571,0.01045565148848914,0.010422219243905708,0.010388786999322275,0.010355354754738842,0.010321922510155408,0.010288490265571977,0.010255058020988545,0.010221625776405112,0.010188193531821679,0.010154761287238245,0.010121329042654814,0.010087896798071382,0.010054464553487949,0.010021032308904516,0.0099876000643210842,0.0099541678197376509,0.0099207355751542194,0.0098873033305707861,0.0098538710859873528,0.0098204388414039213,0.009787006596820488,0.0097535743522370565,0.0097201421076536232,0.0096867098630701899,0.0096532776184867584,0.0096198453739033251,0.0095864131293198936,0.0095529808847364603,0.009519548640153027,0.0094861163955695955,0.0094526841509861622,0.0094192519064027307,0.0093858196618192974,0.0093523874172358641,0.0093189551726524326,0.009285522928069001,0.0092520906834855678,0.0092186584389021345,0.0091852261943187029,0.0091517939497352697,0.0091183617051518381,0.0090849294605684049,0.0090514972159849716,0.0090180649714015401,0.0089846327268181068,0.0089512004822346752,0.008917768237651242,0.0088843359930678087,0.0088509037484843772,0.0088174715039009439,0.0087840392593175123,0.0087506070147340791,0.0087171747701506458,0.0086837425255672143,0.008650310280983781,0.0086168780364003494,0.0085834457918169162,0.0085500135472334829,0.0085165813026500514,0.0084831490580666181,0.0084497168134831865,0.0084162845688997533,0.00838285232431632,0.0083494200797328885,0.0083159878351494569,0.0082825555905660236,0.0082491233459825904,0.0082156911013991588,0.0081822588568157256,0.008148826612232294,0.0081153943676488607,0.0080819621230654275,0.0080485298784819959,0.0080150976338985627,0.0079816653893151311,0.0079482331447316978,0.0079148009001482646,0.007881368655564833,0.0078479364109813998,0.0078145041663979682,0.0077810719218145349,0.0077476396772311025,0.0077142074326476701,0.0076807751880642369,0.0076473429434808053,0.007613910698897372,0.0075804784543139396,0.0075470462097305072,0.0075136139651470748,0.0074801817205636424,0.0074467494759802091,0.0074133172313967767,0.0073798849868133443,0.0073464527422299119,0.0073130204976464795,0.0072795882530630462,0.0072461560084796138,0.0072127237638961814,0.007179291519312749,0.0071458592747293166,0.0071124270301458842,0.0070789947855624518,0.0070455625409790185,0.0070121302963955861,0.0069786980518121537,0.0069452658072287213,0.0069118335626452889,0.0068784013180618556,0.0068449690734784232,0.0068115368288949908,0.0067781045843115584,0.006744672339728126,0.0067112400951446936,0.0066778078505612603,0.0066443756059778279,0.0066109433613943955,0.0065775111168109631,0.0065440788722275307,0.0065106466276440983,0.006477214383060665,0.0064437821384772326,0.0064103498938938002,0.0063769176493103678,0.0063434854047269354,0.006310053160143503,0.0062766209155600697,0.0062431886709766373,0.0062097564263932049,0.0062097564263932049],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.3479638012001653,1.3465290588852703,1.3410661888327617,1.3303993267330163,1.3160258816806538,1.2980669816677577,1.2766571071856903,1.251422727973488,1.222643832898719,1.1912152962806044,1.1573724648532004,1.121359520922298,1.0829999212864749,1.0432485176449187,1.0024956552274387,0.96103466873436461,0.9191736881844127,0.8774706569128673,0.8363342824529616,0.79606524219945207,0.75696311519183435,0.71982386057522552,0.68502691520394465,0.65263440770466552,0.62292881222726559,0.59621891127830995,0.57420502683905561,0.55604058254926347,0.54199125322383479,0.53232152561296475,0.52810308774813741,0.53017274990357277,0.53772674037187473,0.55102273816653535,0.57031787707654669,0.59795319558481463,0.6328989599825654,0.67491709663753219,0.72425346816174929,0.78173329517724144,0.84965124925606017,0.92586673886225934,1.010583667401098,1.1039978391012222,1.2083391886994108,1.3233424513718459,1.4476770194342525,1.5814340579553481,1.7246896244708383,1.8810421232046457,2.0470262781498767,2.2224583071934849,2.4072438978697646,2.6024911747950168,2.808813944864001,3.0236845249774849,3.2468111413635294,3.4778804211643064,3.7184917562000392,3.9665016333686736,4.2207336673086315,4.4807123222412715,4.7461786721908377,5.0174544061982571,5.2922717972704634,5.57008714718466,5.8503579507422803,6.1327213715038251,6.4161445416001666,6.6998318459069717,6.9833219854800523,7.2661702652188787,7.5473152183901639,7.8266070880000109,8.103830869723728,8.3787620467864663,8.6508921962598748,8.9196557195188149,9.1857484296812046,9.4492352962486681,9.7102150671002807,9.96832894568794,10.224384064582569,10.479000044702815,10.732562269942544,10.985492185874685,11.238671090983132,11.492907112197084,11.748811940728737,12.007016823855757,12.268959818735443,12.536078721225035,12.808494496661346,13.086972047720137,13.372286826911749,13.668335537141052,13.974249592558429,14.290440270593422,14.617737491070029,14.958285842763173,15.316098011597095,15.688563872910752,16.076515351303573,16.480781188617545,16.906821147342828,17.354184585518862,17.821268661665318,18.308835888642008,18.817928559642557,19.357709602191029,19.920942786379698,20.508224073627009,21.12012051737484,21.761385519863552,22.434343025573451,23.133694293606712,23.859669290563943,24.612450135663771,25.400507494761506,26.217234963731691,27.060436570456883,27.9297759868128,28.826768860370453,29.75598741633917,30.708719465052699,31.684022876103977,32.680888289251328,33.702293602707712,34.744378138430328,35.802522617360175,36.875187622725875,37.960784316466572,39.060422106316288,40.167438390711077,41.279938382637532,42.396093124256865,43.513838599922629,44.629654291004393,45.74146275630941,46.847569661946544,47.94631972709314,49.03262040668023,50.105928237798175,51.16593837450511,52.211543978337808,53.240746459385463,54.247700083319344,55.237023327895933,56.208382566150831,57.161535988443134,58.092606659503303,59.002477121516861,59.894830889344277,60.770202398340842,61.629204793680664,62.467707209343203,63.292280157038981,64.10443134484089,64.905299333770188,65.695117294500648,66.475121397178967,67.249209286782005,68.018699667894055,68.78490841313787,69.549318022257353,70.314393287258412,71.081438411614201,71.851555117115041,72.626020707836972,73.40814872568059,74.197193346828271,74.993788469954424,75.798504596465179,76.613563559702285,77.439589808022973,78.274919791296654,79.119533074758223,79.973342657261767,80.838931973799433,81.713055470751129,82.594723544966385,83.483308484198218,84.378612925614277,85.280005528626049,86.184792163072203,87.091967489748583,88.000498623190069,88.908819811820507,89.814895170275847,90.717610256117041,91.615839638376798,92.508331999351114,93.390741361643165,94.264161402932174,95.127679570327572,95.98043005034522,96.81945286572649,97.642920080520213,98.452978087662132,99.249311539360349,100.03168113827034,100.79557379245192,101.54479167365915,102.28070839952227,103.00384669705026,103.71394358631645,104.41020581944461,105.09745579847194,105.77695912320638,106.45005180956451,107.11773910421851,107.78339134261626,108.44943192237022,109.11763730397807,109.78981171141774,110.47156438946853,111.16323023341178,111.86655592511443,112.58326481052127,113.31767925934342,114.07420820555711,114.85046011018325,115.64759136659796,116.46666974145802,117.31582602010157,118.19121481481152,119.09105425832188,120.01546210897884,120.96593436961227,121.94808450593374,122.9532328968762,123.9804620632667,125.02874540708636,126.10053291935377,127.19221043566442,128.29865076891349,129.41798360110482,130.54826046320309,131.68885880244625,132.83346094443971,133.97952139184383,135.12463714512415,136.26536444642022,137.39613864631812,138.51546290493266,139.62086558169551,140.70988975316055,141.77355717766002,142.81104901901836,143.82228281506622,144.80510262880901,145.75596773913588,146.66147476229105,147.53035730625049,148.36097099701013,149.15173721191979,149.89274683954835,150.58152996801758,151.22504327463088,151.82231313188129,152.37243398574111,152.85779731280476,153.29185832763849,153.67626907174599,154.01069770983869,154.28948226187521,154.50392012349465,154.66800218821882,154.78188340641273,154.84576678113322,154.84737886077497,154.79388324040164,154.69211282161601,154.54264420078417,154.34506658620242,154.08501283055267,153.78029874378984,153.43178833390257,153.04037249637585,152.60009399565936,152.11125197903965,151.58374843649437,151.01868067148203,150.41716512055305,149.76983404572394,149.08771506152254,148.37420190212947,147.63053637457861,146.85565353257002,146.04622056842365,145.21203282293638,144.35437861661788,143.47454627247191,142.56949698077196,141.64342712089598,140.70059360685667,139.74224823937979,138.76960705231483,137.78000681168857,136.78005752816563,135.77092651446611,134.75376968909649,133.72900183084133,132.6983017719233,131.66426060041326,130.62792583218277,129.59033185122644,128.55304128679145,127.51769553028365,126.48519193792939,125.45642831602562,124.43268945168671,123.41689897663734,122.40829428190037,121.40756962793414,120.41538932171203,119.43459328881232,118.46568752605256,117.50748867434825,116.56032904918858,115.62449703825202,114.70449506917501,113.79634755346609,112.89974104675636,112.01451317483134,111.14182307229346,110.28221470382148,109.4323226795611,108.59152337201276,107.75914683035583,106.93613053342578,106.11962471762897,105.30792531083551,104.50005821146286,103.69507717549394,102.8915472214093,102.08750404944728,101.28193293485405,100.47383552658742,99.661195451578166,98.842333230069983,98.017191704967473,97.185053183632817,96.345244309576401,95.49395769596326,94.633126674557332,93.762815539029631,92.882822931939074,91.991911909340246,91.088558838392331,90.175645367162943,89.253426265379531,88.322198625740754,87.380295053761344,86.429734050270639,85.472091198494624,84.507917883458219,83.537647495277838,82.560616515199143,81.57952126980507,80.594923584727127,79.607370597534612,78.617127934329304,77.625034218057664,76.631937834849822,75.638183328429349,74.644086671147178,73.650032632250273,72.656298556874788,71.662967795121745,70.670100540607308,69.677769944420263,68.686004390045412,67.694559913231643,66.703330423582926,65.712201290427913,64.72097687335615,63.729427027899533,62.737452190004447,61.744956421326542,60.751850058829135,59.757816663510432,58.763131017466179,57.767870312415525,56.772138954924678,55.77608068517273,54.780126503591994,53.784675294647023,52.790091262745399,51.796767889729168,50.805986284967965,49.818225760305587,48.833932294117936,47.853721021256248,46.878650062089818,45.911313986792386,44.950936245132205,43.998231188961078,43.053913301019321,42.121013991643544,41.20028774956026,40.290863732250685,39.393365428813205,38.508396868606212,37.641779806255578,36.789491223236347,35.951728099898652,35.128823833242258,34.323182439188933,33.5368222546117,32.766002918165889,32.010690057750637,31.270805870173337,30.550427103707271,29.846195306542601,29.156221262926749,28.480061683669035,27.81787332075773,27.172136115565429,26.537762601585005,25.914056481697035,25.300305610557423,24.697333381559766,24.103520842934987,23.516476162608612,22.935457236429329,22.359731105561679,21.789682094149018,21.222915595667558,20.658740863989049,20.096642051795417,19.536246286915734,18.977050664691696,18.418457897308524,17.860327558093754,17.302566629504177,16.745290640407465,16.188690360558819,15.633004427150048,15.078559576084567,14.525803948360455,13.976321858217903,13.43017052916294,12.888004506793683,12.350503156669031,11.819612443464218,11.296947049527787,10.782177582578106,10.276103551659711,9.7795258816423321,9.2971949012591217,8.8274452507660666,8.3704244820187963,7.9268241364299152,7.4987723328324929,7.0902000859674077,6.6975080748877742,6.3211275554227102,5.9614545586981418,5.6231511545706647,5.304778816403215,5.004078926356927,4.7211168428353245,4.4561260846515749,4.2153459309071994,3.9919645779561872,3.7857404952697795,3.5964027834316408,3.4261992126619125,3.2753691169288923,3.1397773637675011,3.0189345653107718,2.9123324220092472,2.8233098081799244,2.7476708634971212,2.6838220064855021,2.6311419325832821,2.5897184446857815,2.5605956144942938,2.5399074861106188,2.5269992385098687,2.5212166314181119,2.5230756064413433,2.5309444244780126,2.543211746616949,2.5592560082104048,2.5784618108705608,2.6006972968060289,2.624219527725419,2.6484649960300946,2.6729001334267557,2.6968296967099072,2.7192391577984578,2.7398056463818832,2.7581153758545911,2.773770185310386,2.7853139389510138,2.7928153320606954,2.7963102908919097,2.7955578562172705,2.7900685530985134,2.77827309615056,2.7615521470930409,2.7398409508175221,2.7130946579368413,2.680266434220214,2.6415802217400355,2.5980384325766197,2.5497641414392458,2.4968976698674141,2.438195364304578,2.3754272218284003,0],"text":["density:   2.3754272<br />post_bmi: 0.006209756","density:   2.4381954<br />post_bmi: 0.006243189","density:   2.4968977<br />post_bmi: 0.006276621","density:   2.5497641<br />post_bmi: 0.006310053","density:   2.5980384<br />post_bmi: 0.006343485","density:   2.6415802<br />post_bmi: 0.006376918","density:   2.6802664<br />post_bmi: 0.006410350","density:   2.7130947<br />post_bmi: 0.006443782","density:   2.7398410<br />post_bmi: 0.006477214","density:   2.7615521<br />post_bmi: 0.006510647","density:   2.7782731<br />post_bmi: 0.006544079","density:   2.7900686<br />post_bmi: 0.006577511","density:   2.7955579<br />post_bmi: 0.006610943","density:   2.7963103<br />post_bmi: 0.006644376","density:   2.7928153<br />post_bmi: 0.006677808","density:   2.7853139<br />post_bmi: 0.006711240","density:   2.7737702<br />post_bmi: 0.006744672","density:   2.7581154<br />post_bmi: 0.006778105","density:   2.7398056<br />post_bmi: 0.006811537","density:   2.7192392<br />post_bmi: 0.006844969","density:   2.6968297<br />post_bmi: 0.006878401","density:   2.6729001<br />post_bmi: 0.006911834","density:   2.6484650<br />post_bmi: 0.006945266","density:   2.6242195<br />post_bmi: 0.006978698","density:   2.6006973<br />post_bmi: 0.007012130","density:   2.5784618<br />post_bmi: 0.007045563","density:   2.5592560<br />post_bmi: 0.007078995","density:   2.5432117<br />post_bmi: 0.007112427","density:   2.5309444<br />post_bmi: 0.007145859","density:   2.5230756<br />post_bmi: 0.007179292","density:   2.5212166<br />post_bmi: 0.007212724","density:   2.5269992<br />post_bmi: 0.007246156","density:   2.5399075<br />post_bmi: 0.007279588","density:   2.5605956<br />post_bmi: 0.007313020","density:   2.5897184<br />post_bmi: 0.007346453","density:   2.6311419<br />post_bmi: 0.007379885","density:   2.6838220<br />post_bmi: 0.007413317","density:   2.7476709<br />post_bmi: 0.007446749","density:   2.8233098<br />post_bmi: 0.007480182","density:   2.9123324<br />post_bmi: 0.007513614","density:   3.0189346<br />post_bmi: 0.007547046","density:   3.1397774<br />post_bmi: 0.007580478","density:   3.2753691<br />post_bmi: 0.007613911","density:   3.4261992<br />post_bmi: 0.007647343","density:   3.5964028<br />post_bmi: 0.007680775","density:   3.7857405<br />post_bmi: 0.007714207","density:   3.9919646<br />post_bmi: 0.007747640","density:   4.2153459<br />post_bmi: 0.007781072","density:   4.4561261<br />post_bmi: 0.007814504","density:   4.7211168<br />post_bmi: 0.007847936","density:   5.0040789<br />post_bmi: 0.007881369","density:   5.3047788<br />post_bmi: 0.007914801","density:   5.6231512<br />post_bmi: 0.007948233","density:   5.9614546<br />post_bmi: 0.007981665","density:   6.3211276<br />post_bmi: 0.008015098","density:   6.6975081<br />post_bmi: 0.008048530","density:   7.0902001<br />post_bmi: 0.008081962","density:   7.4987723<br />post_bmi: 0.008115394","density:   7.9268241<br />post_bmi: 0.008148827","density:   8.3704245<br />post_bmi: 0.008182259","density:   8.8274453<br />post_bmi: 0.008215691","density:   9.2971949<br />post_bmi: 0.008249123","density:   9.7795259<br />post_bmi: 0.008282556","density:  10.2761036<br />post_bmi: 0.008315988","density:  10.7821776<br />post_bmi: 0.008349420","density:  11.2969470<br />post_bmi: 0.008382852","density:  11.8196124<br />post_bmi: 0.008416285","density:  12.3505032<br />post_bmi: 0.008449717","density:  12.8880045<br />post_bmi: 0.008483149","density:  13.4301705<br />post_bmi: 0.008516581","density:  13.9763219<br />post_bmi: 0.008550014","density:  14.5258039<br />post_bmi: 0.008583446","density:  15.0785596<br />post_bmi: 0.008616878","density:  15.6330044<br />post_bmi: 0.008650310","density:  16.1886904<br />post_bmi: 0.008683743","density:  16.7452906<br />post_bmi: 0.008717175","density:  17.3025666<br />post_bmi: 0.008750607","density:  17.8603276<br />post_bmi: 0.008784039","density:  18.4184579<br />post_bmi: 0.008817472","density:  18.9770507<br />post_bmi: 0.008850904","density:  19.5362463<br />post_bmi: 0.008884336","density:  20.0966421<br />post_bmi: 0.008917768","density:  20.6587409<br />post_bmi: 0.008951200","density:  21.2229156<br />post_bmi: 0.008984633","density:  21.7896821<br />post_bmi: 0.009018065","density:  22.3597311<br />post_bmi: 0.009051497","density:  22.9354572<br />post_bmi: 0.009084929","density:  23.5164762<br />post_bmi: 0.009118362","density:  24.1035208<br />post_bmi: 0.009151794","density:  24.6973334<br />post_bmi: 0.009185226","density:  25.3003056<br />post_bmi: 0.009218658","density:  25.9140565<br />post_bmi: 0.009252091","density:  26.5377626<br />post_bmi: 0.009285523","density:  27.1721361<br />post_bmi: 0.009318955","density:  27.8178733<br />post_bmi: 0.009352387","density:  28.4800617<br />post_bmi: 0.009385820","density:  29.1562213<br />post_bmi: 0.009419252","density:  29.8461953<br />post_bmi: 0.009452684","density:  30.5504271<br />post_bmi: 0.009486116","density:  31.2708059<br />post_bmi: 0.009519549","density:  32.0106901<br />post_bmi: 0.009552981","density:  32.7660029<br />post_bmi: 0.009586413","density:  33.5368223<br />post_bmi: 0.009619845","density:  34.3231824<br />post_bmi: 0.009653278","density:  35.1288238<br />post_bmi: 0.009686710","density:  35.9517281<br />post_bmi: 0.009720142","density:  36.7894912<br />post_bmi: 0.009753574","density:  37.6417798<br />post_bmi: 0.009787007","density:  38.5083969<br />post_bmi: 0.009820439","density:  39.3933654<br />post_bmi: 0.009853871","density:  40.2908637<br />post_bmi: 0.009887303","density:  41.2002877<br />post_bmi: 0.009920736","density:  42.1210140<br />post_bmi: 0.009954168","density:  43.0539133<br />post_bmi: 0.009987600","density:  43.9982312<br />post_bmi: 0.010021032","density:  44.9509362<br />post_bmi: 0.010054465","density:  45.9113140<br />post_bmi: 0.010087897","density:  46.8786501<br />post_bmi: 0.010121329","density:  47.8537210<br />post_bmi: 0.010154761","density:  48.8339323<br />post_bmi: 0.010188194","density:  49.8182258<br />post_bmi: 0.010221626","density:  50.8059863<br />post_bmi: 0.010255058","density:  51.7967679<br />post_bmi: 0.010288490","density:  52.7900913<br />post_bmi: 0.010321923","density:  53.7846753<br />post_bmi: 0.010355355","density:  54.7801265<br />post_bmi: 0.010388787","density:  55.7760807<br />post_bmi: 0.010422219","density:  56.7721390<br />post_bmi: 0.010455651","density:  57.7678703<br />post_bmi: 0.010489084","density:  58.7631310<br />post_bmi: 0.010522516","density:  59.7578167<br />post_bmi: 0.010555948","density:  60.7518501<br />post_bmi: 0.010589380","density:  61.7449564<br />post_bmi: 0.010622813","density:  62.7374522<br />post_bmi: 0.010656245","density:  63.7294270<br />post_bmi: 0.010689677","density:  64.7209769<br />post_bmi: 0.010723109","density:  65.7122013<br />post_bmi: 0.010756542","density:  66.7033304<br />post_bmi: 0.010789974","density:  67.6945599<br />post_bmi: 0.010823406","density:  68.6860044<br />post_bmi: 0.010856838","density:  69.6777699<br />post_bmi: 0.010890271","density:  70.6701005<br />post_bmi: 0.010923703","density:  71.6629678<br />post_bmi: 0.010957135","density:  72.6562986<br />post_bmi: 0.010990567","density:  73.6500326<br />post_bmi: 0.011024000","density:  74.6440867<br />post_bmi: 0.011057432","density:  75.6381833<br />post_bmi: 0.011090864","density:  76.6319378<br />post_bmi: 0.011124296","density:  77.6250342<br />post_bmi: 0.011157729","density:  78.6171279<br />post_bmi: 0.011191161","density:  79.6073706<br />post_bmi: 0.011224593","density:  80.5949236<br />post_bmi: 0.011258025","density:  81.5795213<br />post_bmi: 0.011291458","density:  82.5606165<br />post_bmi: 0.011324890","density:  83.5376475<br />post_bmi: 0.011358322","density:  84.5079179<br />post_bmi: 0.011391754","density:  85.4720912<br />post_bmi: 0.011425187","density:  86.4297341<br />post_bmi: 0.011458619","density:  87.3802951<br />post_bmi: 0.011492051","density:  88.3221986<br />post_bmi: 0.011525483","density:  89.2534263<br />post_bmi: 0.011558916","density:  90.1756454<br />post_bmi: 0.011592348","density:  91.0885588<br />post_bmi: 0.011625780","density:  91.9919119<br />post_bmi: 0.011659212","density:  92.8828229<br />post_bmi: 0.011692645","density:  93.7628155<br />post_bmi: 0.011726077","density:  94.6331267<br />post_bmi: 0.011759509","density:  95.4939577<br />post_bmi: 0.011792941","density:  96.3452443<br />post_bmi: 0.011826374","density:  97.1850532<br />post_bmi: 0.011859806","density:  98.0171917<br />post_bmi: 0.011893238","density:  98.8423332<br />post_bmi: 0.011926670","density:  99.6611955<br />post_bmi: 0.011960102","density: 100.4738355<br />post_bmi: 0.011993535","density: 101.2819329<br />post_bmi: 0.012026967","density: 102.0875040<br />post_bmi: 0.012060399","density: 102.8915472<br />post_bmi: 0.012093831","density: 103.6950772<br />post_bmi: 0.012127264","density: 104.5000582<br />post_bmi: 0.012160696","density: 105.3079253<br />post_bmi: 0.012194128","density: 106.1196247<br />post_bmi: 0.012227560","density: 106.9361305<br />post_bmi: 0.012260993","density: 107.7591468<br />post_bmi: 0.012294425","density: 108.5915234<br />post_bmi: 0.012327857","density: 109.4323227<br />post_bmi: 0.012361289","density: 110.2822147<br />post_bmi: 0.012394722","density: 111.1418231<br />post_bmi: 0.012428154","density: 112.0145132<br />post_bmi: 0.012461586","density: 112.8997410<br />post_bmi: 0.012495018","density: 113.7963476<br />post_bmi: 0.012528451","density: 114.7044951<br />post_bmi: 0.012561883","density: 115.6244970<br />post_bmi: 0.012595315","density: 116.5603290<br />post_bmi: 0.012628747","density: 117.5074887<br />post_bmi: 0.012662180","density: 118.4656875<br />post_bmi: 0.012695612","density: 119.4345933<br />post_bmi: 0.012729044","density: 120.4153893<br />post_bmi: 0.012762476","density: 121.4075696<br />post_bmi: 0.012795909","density: 122.4082943<br />post_bmi: 0.012829341","density: 123.4168990<br />post_bmi: 0.012862773","density: 124.4326895<br />post_bmi: 0.012896205","density: 125.4564283<br />post_bmi: 0.012929638","density: 126.4851919<br />post_bmi: 0.012963070","density: 127.5176955<br />post_bmi: 0.012996502","density: 128.5530413<br />post_bmi: 0.013029934","density: 129.5903319<br />post_bmi: 0.013063367","density: 130.6279258<br />post_bmi: 0.013096799","density: 131.6642606<br />post_bmi: 0.013130231","density: 132.6983018<br />post_bmi: 0.013163663","density: 133.7290018<br />post_bmi: 0.013197096","density: 134.7537697<br />post_bmi: 0.013230528","density: 135.7709265<br />post_bmi: 0.013263960","density: 136.7800575<br />post_bmi: 0.013297392","density: 137.7800068<br />post_bmi: 0.013330825","density: 138.7696071<br />post_bmi: 0.013364257","density: 139.7422482<br />post_bmi: 0.013397689","density: 140.7005936<br />post_bmi: 0.013431121","density: 141.6434271<br />post_bmi: 0.013464554","density: 142.5694970<br />post_bmi: 0.013497986","density: 143.4745463<br />post_bmi: 0.013531418","density: 144.3543786<br />post_bmi: 0.013564850","density: 145.2120328<br />post_bmi: 0.013598282","density: 146.0462206<br />post_bmi: 0.013631715","density: 146.8556535<br />post_bmi: 0.013665147","density: 147.6305364<br />post_bmi: 0.013698579","density: 148.3742019<br />post_bmi: 0.013732011","density: 149.0877151<br />post_bmi: 0.013765444","density: 149.7698340<br />post_bmi: 0.013798876","density: 150.4171651<br />post_bmi: 0.013832308","density: 151.0186807<br />post_bmi: 0.013865740","density: 151.5837484<br />post_bmi: 0.013899173","density: 152.1112520<br />post_bmi: 0.013932605","density: 152.6000940<br />post_bmi: 0.013966037","density: 153.0403725<br />post_bmi: 0.013999469","density: 153.4317883<br />post_bmi: 0.014032902","density: 153.7802987<br />post_bmi: 0.014066334","density: 154.0850128<br />post_bmi: 0.014099766","density: 154.3450666<br />post_bmi: 0.014133198","density: 154.5426442<br />post_bmi: 0.014166631","density: 154.6921128<br />post_bmi: 0.014200063","density: 154.7938832<br />post_bmi: 0.014233495","density: 154.8473789<br />post_bmi: 0.014266927","density: 154.8457668<br />post_bmi: 0.014300360","density: 154.7818834<br />post_bmi: 0.014333792","density: 154.6680022<br />post_bmi: 0.014367224","density: 154.5039201<br />post_bmi: 0.014400656","density: 154.2894823<br />post_bmi: 0.014434089","density: 154.0106977<br />post_bmi: 0.014467521","density: 153.6762691<br />post_bmi: 0.014500953","density: 153.2918583<br />post_bmi: 0.014534385","density: 152.8577973<br />post_bmi: 0.014567818","density: 152.3724340<br />post_bmi: 0.014601250","density: 151.8223131<br />post_bmi: 0.014634682","density: 151.2250433<br />post_bmi: 0.014668114","density: 150.5815300<br />post_bmi: 0.014701547","density: 149.8927468<br />post_bmi: 0.014734979","density: 149.1517372<br />post_bmi: 0.014768411","density: 148.3609710<br />post_bmi: 0.014801843","density: 147.5303573<br />post_bmi: 0.014835276","density: 146.6614748<br />post_bmi: 0.014868708","density: 145.7559677<br />post_bmi: 0.014902140","density: 144.8051026<br />post_bmi: 0.014935572","density: 143.8222828<br />post_bmi: 0.014969005","density: 142.8110490<br />post_bmi: 0.015002437","density: 141.7735572<br />post_bmi: 0.015035869","density: 140.7098898<br />post_bmi: 0.015069301","density: 139.6208656<br />post_bmi: 0.015102733","density: 138.5154629<br />post_bmi: 0.015136166","density: 137.3961386<br />post_bmi: 0.015169598","density: 136.2653644<br />post_bmi: 0.015203030","density: 135.1246371<br />post_bmi: 0.015236462","density: 133.9795214<br />post_bmi: 0.015269895","density: 132.8334609<br />post_bmi: 0.015303327","density: 131.6888588<br />post_bmi: 0.015336759","density: 130.5482605<br />post_bmi: 0.015370191","density: 129.4179836<br />post_bmi: 0.015403624","density: 128.2986508<br />post_bmi: 0.015437056","density: 127.1922104<br />post_bmi: 0.015470488","density: 126.1005329<br />post_bmi: 0.015503920","density: 125.0287454<br />post_bmi: 0.015537353","density: 123.9804621<br />post_bmi: 0.015570785","density: 122.9532329<br />post_bmi: 0.015604217","density: 121.9480845<br />post_bmi: 0.015637649","density: 120.9659344<br />post_bmi: 0.015671082","density: 120.0154621<br />post_bmi: 0.015704514","density: 119.0910543<br />post_bmi: 0.015737946","density: 118.1912148<br />post_bmi: 0.015771378","density: 117.3158260<br />post_bmi: 0.015804811","density: 116.4666697<br />post_bmi: 0.015838243","density: 115.6475914<br />post_bmi: 0.015871675","density: 114.8504601<br />post_bmi: 0.015905107","density: 114.0742082<br />post_bmi: 0.015938540","density: 113.3176793<br />post_bmi: 0.015971972","density: 112.5832648<br />post_bmi: 0.016005404","density: 111.8665559<br />post_bmi: 0.016038836","density: 111.1632302<br />post_bmi: 0.016072269","density: 110.4715644<br />post_bmi: 0.016105701","density: 109.7898117<br />post_bmi: 0.016139133","density: 109.1176373<br />post_bmi: 0.016172565","density: 108.4494319<br />post_bmi: 0.016205998","density: 107.7833913<br />post_bmi: 0.016239430","density: 107.1177391<br />post_bmi: 0.016272862","density: 106.4500518<br />post_bmi: 0.016306294","density: 105.7769591<br />post_bmi: 0.016339727","density: 105.0974558<br />post_bmi: 0.016373159","density: 104.4102058<br />post_bmi: 0.016406591","density: 103.7139436<br />post_bmi: 0.016440023","density: 103.0038467<br />post_bmi: 0.016473456","density: 102.2807084<br />post_bmi: 0.016506888","density: 101.5447917<br />post_bmi: 0.016540320","density: 100.7955738<br />post_bmi: 0.016573752","density: 100.0316811<br />post_bmi: 0.016607184","density:  99.2493115<br />post_bmi: 0.016640617","density:  98.4529781<br />post_bmi: 0.016674049","density:  97.6429201<br />post_bmi: 0.016707481","density:  96.8194529<br />post_bmi: 0.016740913","density:  95.9804301<br />post_bmi: 0.016774346","density:  95.1276796<br />post_bmi: 0.016807778","density:  94.2641614<br />post_bmi: 0.016841210","density:  93.3907414<br />post_bmi: 0.016874642","density:  92.5083320<br />post_bmi: 0.016908075","density:  91.6158396<br />post_bmi: 0.016941507","density:  90.7176103<br />post_bmi: 0.016974939","density:  89.8148952<br />post_bmi: 0.017008371","density:  88.9088198<br />post_bmi: 0.017041804","density:  88.0004986<br />post_bmi: 0.017075236","density:  87.0919675<br />post_bmi: 0.017108668","density:  86.1847922<br />post_bmi: 0.017142100","density:  85.2800055<br />post_bmi: 0.017175533","density:  84.3786129<br />post_bmi: 0.017208965","density:  83.4833085<br />post_bmi: 0.017242397","density:  82.5947235<br />post_bmi: 0.017275829","density:  81.7130555<br />post_bmi: 0.017309262","density:  80.8389320<br />post_bmi: 0.017342694","density:  79.9733427<br />post_bmi: 0.017376126","density:  79.1195331<br />post_bmi: 0.017409558","density:  78.2749198<br />post_bmi: 0.017442991","density:  77.4395898<br />post_bmi: 0.017476423","density:  76.6135636<br />post_bmi: 0.017509855","density:  75.7985046<br />post_bmi: 0.017543287","density:  74.9937885<br />post_bmi: 0.017576720","density:  74.1971933<br />post_bmi: 0.017610152","density:  73.4081487<br />post_bmi: 0.017643584","density:  72.6260207<br />post_bmi: 0.017677016","density:  71.8515551<br />post_bmi: 0.017710449","density:  71.0814384<br />post_bmi: 0.017743881","density:  70.3143933<br />post_bmi: 0.017777313","density:  69.5493180<br />post_bmi: 0.017810745","density:  68.7849084<br />post_bmi: 0.017844178","density:  68.0186997<br />post_bmi: 0.017877610","density:  67.2492093<br />post_bmi: 0.017911042","density:  66.4751214<br />post_bmi: 0.017944474","density:  65.6951173<br />post_bmi: 0.017977907","density:  64.9052993<br />post_bmi: 0.018011339","density:  64.1044313<br />post_bmi: 0.018044771","density:  63.2922802<br />post_bmi: 0.018078203","density:  62.4677072<br />post_bmi: 0.018111635","density:  61.6292048<br />post_bmi: 0.018145068","density:  60.7702024<br />post_bmi: 0.018178500","density:  59.8948309<br />post_bmi: 0.018211932","density:  59.0024771<br />post_bmi: 0.018245364","density:  58.0926067<br />post_bmi: 0.018278797","density:  57.1615360<br />post_bmi: 0.018312229","density:  56.2083826<br />post_bmi: 0.018345661","density:  55.2370233<br />post_bmi: 0.018379093","density:  54.2477001<br />post_bmi: 0.018412526","density:  53.2407465<br />post_bmi: 0.018445958","density:  52.2115440<br />post_bmi: 0.018479390","density:  51.1659384<br />post_bmi: 0.018512822","density:  50.1059282<br />post_bmi: 0.018546255","density:  49.0326204<br />post_bmi: 0.018579687","density:  47.9463197<br />post_bmi: 0.018613119","density:  46.8475697<br />post_bmi: 0.018646551","density:  45.7414628<br />post_bmi: 0.018679984","density:  44.6296543<br />post_bmi: 0.018713416","density:  43.5138386<br />post_bmi: 0.018746848","density:  42.3960931<br />post_bmi: 0.018780280","density:  41.2799384<br />post_bmi: 0.018813713","density:  40.1674384<br />post_bmi: 0.018847145","density:  39.0604221<br />post_bmi: 0.018880577","density:  37.9607843<br />post_bmi: 0.018914009","density:  36.8751876<br />post_bmi: 0.018947442","density:  35.8025226<br />post_bmi: 0.018980874","density:  34.7443781<br />post_bmi: 0.019014306","density:  33.7022936<br />post_bmi: 0.019047738","density:  32.6808883<br />post_bmi: 0.019081171","density:  31.6840229<br />post_bmi: 0.019114603","density:  30.7087195<br />post_bmi: 0.019148035","density:  29.7559874<br />post_bmi: 0.019181467","density:  28.8267689<br />post_bmi: 0.019214900","density:  27.9297760<br />post_bmi: 0.019248332","density:  27.0604366<br />post_bmi: 0.019281764","density:  26.2172350<br />post_bmi: 0.019315196","density:  25.4005075<br />post_bmi: 0.019348629","density:  24.6124501<br />post_bmi: 0.019382061","density:  23.8596693<br />post_bmi: 0.019415493","density:  23.1336943<br />post_bmi: 0.019448925","density:  22.4343430<br />post_bmi: 0.019482358","density:  21.7613855<br />post_bmi: 0.019515790","density:  21.1201205<br />post_bmi: 0.019549222","density:  20.5082241<br />post_bmi: 0.019582654","density:  19.9209428<br />post_bmi: 0.019616087","density:  19.3577096<br />post_bmi: 0.019649519","density:  18.8179286<br />post_bmi: 0.019682951","density:  18.3088359<br />post_bmi: 0.019716383","density:  17.8212687<br />post_bmi: 0.019749815","density:  17.3541846<br />post_bmi: 0.019783248","density:  16.9068211<br />post_bmi: 0.019816680","density:  16.4807812<br />post_bmi: 0.019850112","density:  16.0765154<br />post_bmi: 0.019883544","density:  15.6885639<br />post_bmi: 0.019916977","density:  15.3160980<br />post_bmi: 0.019950409","density:  14.9582858<br />post_bmi: 0.019983841","density:  14.6177375<br />post_bmi: 0.020017273","density:  14.2904403<br />post_bmi: 0.020050706","density:  13.9742496<br />post_bmi: 0.020084138","density:  13.6683355<br />post_bmi: 0.020117570","density:  13.3722868<br />post_bmi: 0.020151002","density:  13.0869720<br />post_bmi: 0.020184435","density:  12.8084945<br />post_bmi: 0.020217867","density:  12.5360787<br />post_bmi: 0.020251299","density:  12.2689598<br />post_bmi: 0.020284731","density:  12.0070168<br />post_bmi: 0.020318164","density:  11.7488119<br />post_bmi: 0.020351596","density:  11.4929071<br />post_bmi: 0.020385028","density:  11.2386711<br />post_bmi: 0.020418460","density:  10.9854922<br />post_bmi: 0.020451893","density:  10.7325623<br />post_bmi: 0.020485325","density:  10.4790000<br />post_bmi: 0.020518757","density:  10.2243841<br />post_bmi: 0.020552189","density:   9.9683289<br />post_bmi: 0.020585622","density:   9.7102151<br />post_bmi: 0.020619054","density:   9.4492353<br />post_bmi: 0.020652486","density:   9.1857484<br />post_bmi: 0.020685918","density:   8.9196557<br />post_bmi: 0.020719351","density:   8.6508922<br />post_bmi: 0.020752783","density:   8.3787620<br />post_bmi: 0.020786215","density:   8.1038309<br />post_bmi: 0.020819647","density:   7.8266071<br />post_bmi: 0.020853080","density:   7.5473152<br />post_bmi: 0.020886512","density:   7.2661703<br />post_bmi: 0.020919944","density:   6.9833220<br />post_bmi: 0.020953376","density:   6.6998318<br />post_bmi: 0.020986809","density:   6.4161445<br />post_bmi: 0.021020241","density:   6.1327214<br />post_bmi: 0.021053673","density:   5.8503580<br />post_bmi: 0.021087105","density:   5.5700871<br />post_bmi: 0.021120538","density:   5.2922718<br />post_bmi: 0.021153970","density:   5.0174544<br />post_bmi: 0.021187402","density:   4.7461787<br />post_bmi: 0.021220834","density:   4.4807123<br />post_bmi: 0.021254266","density:   4.2207337<br />post_bmi: 0.021287699","density:   3.9665016<br />post_bmi: 0.021321131","density:   3.7184918<br />post_bmi: 0.021354563","density:   3.4778804<br />post_bmi: 0.021387995","density:   3.2468111<br />post_bmi: 0.021421428","density:   3.0236845<br />post_bmi: 0.021454860","density:   2.8088139<br />post_bmi: 0.021488292","density:   2.6024912<br />post_bmi: 0.021521724","density:   2.4072439<br />post_bmi: 0.021555157","density:   2.2224583<br />post_bmi: 0.021588589","density:   2.0470263<br />post_bmi: 0.021622021","density:   1.8810421<br />post_bmi: 0.021655453","density:   1.7246896<br />post_bmi: 0.021688886","density:   1.5814341<br />post_bmi: 0.021722318","density:   1.4476770<br />post_bmi: 0.021755750","density:   1.3233425<br />post_bmi: 0.021789182","density:   1.2083392<br />post_bmi: 0.021822615","density:   1.1039978<br />post_bmi: 0.021856047","density:   1.0105837<br />post_bmi: 0.021889479","density:   0.9258667<br />post_bmi: 0.021922911","density:   0.8496512<br />post_bmi: 0.021956344","density:   0.7817333<br />post_bmi: 0.021989776","density:   0.7242535<br />post_bmi: 0.022023208","density:   0.6749171<br />post_bmi: 0.022056640","density:   0.6328990<br />post_bmi: 0.022090073","density:   0.5979532<br />post_bmi: 0.022123505","density:   0.5703179<br />post_bmi: 0.022156937","density:   0.5510227<br />post_bmi: 0.022190369","density:   0.5377267<br />post_bmi: 0.022223802","density:   0.5301727<br />post_bmi: 0.022257234","density:   0.5281031<br />post_bmi: 0.022290666","density:   0.5323215<br />post_bmi: 0.022324098","density:   0.5419913<br />post_bmi: 0.022357531","density:   0.5560406<br />post_bmi: 0.022390963","density:   0.5742050<br />post_bmi: 0.022424395","density:   0.5962189<br />post_bmi: 0.022457827","density:   0.6229288<br />post_bmi: 0.022491260","density:   0.6526344<br />post_bmi: 0.022524692","density:   0.6850269<br />post_bmi: 0.022558124","density:   0.7198239<br />post_bmi: 0.022591556","density:   0.7569631<br />post_bmi: 0.022624989","density:   0.7960652<br />post_bmi: 0.022658421","density:   0.8363343<br />post_bmi: 0.022691853","density:   0.8774707<br />post_bmi: 0.022725285","density:   0.9191737<br />post_bmi: 0.022758717","density:   0.9610347<br />post_bmi: 0.022792150","density:   1.0024957<br />post_bmi: 0.022825582","density:   1.0432485<br />post_bmi: 0.022859014","density:   1.0829999<br />post_bmi: 0.022892446","density:   1.1213595<br />post_bmi: 0.022925879","density:   1.1573725<br />post_bmi: 0.022959311","density:   1.1912153<br />post_bmi: 0.022992743","density:   1.2226438<br />post_bmi: 0.023026175","density:   1.2514227<br />post_bmi: 0.023059608","density:   1.2766571<br />post_bmi: 0.023093040","density:   1.2980670<br />post_bmi: 0.023126472","density:   1.3160259<br />post_bmi: 0.023159904","density:   1.3303993<br />post_bmi: 0.023193337","density:   1.3410662<br />post_bmi: 0.023226769","density:   1.3465291<br />post_bmi: 0.023260201","density:   1.3479638<br />post_bmi: 0.023293633","density:   1.3479638<br />post_bmi: 0.023293633","density:   1.3479638<br />post_bmi: 0.023293633","density:   1.3465291<br />post_bmi: 0.023260201","density:   1.3410662<br />post_bmi: 0.023226769","density:   1.3303993<br />post_bmi: 0.023193337","density:   1.3160259<br />post_bmi: 0.023159904","density:   1.2980670<br />post_bmi: 0.023126472","density:   1.2766571<br />post_bmi: 0.023093040","density:   1.2514227<br />post_bmi: 0.023059608","density:   1.2226438<br />post_bmi: 0.023026175","density:   1.1912153<br />post_bmi: 0.022992743","density:   1.1573725<br />post_bmi: 0.022959311","density:   1.1213595<br />post_bmi: 0.022925879","density:   1.0829999<br />post_bmi: 0.022892446","density:   1.0432485<br />post_bmi: 0.022859014","density:   1.0024957<br />post_bmi: 0.022825582","density:   0.9610347<br />post_bmi: 0.022792150","density:   0.9191737<br />post_bmi: 0.022758717","density:   0.8774707<br />post_bmi: 0.022725285","density:   0.8363343<br />post_bmi: 0.022691853","density:   0.7960652<br />post_bmi: 0.022658421","density:   0.7569631<br />post_bmi: 0.022624989","density:   0.7198239<br />post_bmi: 0.022591556","density:   0.6850269<br />post_bmi: 0.022558124","density:   0.6526344<br />post_bmi: 0.022524692","density:   0.6229288<br />post_bmi: 0.022491260","density:   0.5962189<br />post_bmi: 0.022457827","density:   0.5742050<br />post_bmi: 0.022424395","density:   0.5560406<br />post_bmi: 0.022390963","density:   0.5419913<br />post_bmi: 0.022357531","density:   0.5323215<br />post_bmi: 0.022324098","density:   0.5281031<br />post_bmi: 0.022290666","density:   0.5301727<br />post_bmi: 0.022257234","density:   0.5377267<br />post_bmi: 0.022223802","density:   0.5510227<br />post_bmi: 0.022190369","density:   0.5703179<br />post_bmi: 0.022156937","density:   0.5979532<br />post_bmi: 0.022123505","density:   0.6328990<br />post_bmi: 0.022090073","density:   0.6749171<br />post_bmi: 0.022056640","density:   0.7242535<br />post_bmi: 0.022023208","density:   0.7817333<br />post_bmi: 0.021989776","density:   0.8496512<br />post_bmi: 0.021956344","density:   0.9258667<br />post_bmi: 0.021922911","density:   1.0105837<br />post_bmi: 0.021889479","density:   1.1039978<br />post_bmi: 0.021856047","density:   1.2083392<br />post_bmi: 0.021822615","density:   1.3233425<br />post_bmi: 0.021789182","density:   1.4476770<br />post_bmi: 0.021755750","density:   1.5814341<br />post_bmi: 0.021722318","density:   1.7246896<br />post_bmi: 0.021688886","density:   1.8810421<br />post_bmi: 0.021655453","density:   2.0470263<br />post_bmi: 0.021622021","density:   2.2224583<br />post_bmi: 0.021588589","density:   2.4072439<br />post_bmi: 0.021555157","density:   2.6024912<br />post_bmi: 0.021521724","density:   2.8088139<br />post_bmi: 0.021488292","density:   3.0236845<br />post_bmi: 0.021454860","density:   3.2468111<br />post_bmi: 0.021421428","density:   3.4778804<br />post_bmi: 0.021387995","density:   3.7184918<br />post_bmi: 0.021354563","density:   3.9665016<br />post_bmi: 0.021321131","density:   4.2207337<br />post_bmi: 0.021287699","density:   4.4807123<br />post_bmi: 0.021254266","density:   4.7461787<br />post_bmi: 0.021220834","density:   5.0174544<br />post_bmi: 0.021187402","density:   5.2922718<br />post_bmi: 0.021153970","density:   5.5700871<br />post_bmi: 0.021120538","density:   5.8503580<br />post_bmi: 0.021087105","density:   6.1327214<br />post_bmi: 0.021053673","density:   6.4161445<br />post_bmi: 0.021020241","density:   6.6998318<br />post_bmi: 0.020986809","density:   6.9833220<br />post_bmi: 0.020953376","density:   7.2661703<br />post_bmi: 0.020919944","density:   7.5473152<br />post_bmi: 0.020886512","density:   7.8266071<br />post_bmi: 0.020853080","density:   8.1038309<br />post_bmi: 0.020819647","density:   8.3787620<br />post_bmi: 0.020786215","density:   8.6508922<br />post_bmi: 0.020752783","density:   8.9196557<br />post_bmi: 0.020719351","density:   9.1857484<br />post_bmi: 0.020685918","density:   9.4492353<br />post_bmi: 0.020652486","density:   9.7102151<br />post_bmi: 0.020619054","density:   9.9683289<br />post_bmi: 0.020585622","density:  10.2243841<br />post_bmi: 0.020552189","density:  10.4790000<br />post_bmi: 0.020518757","density:  10.7325623<br />post_bmi: 0.020485325","density:  10.9854922<br />post_bmi: 0.020451893","density:  11.2386711<br />post_bmi: 0.020418460","density:  11.4929071<br />post_bmi: 0.020385028","density:  11.7488119<br />post_bmi: 0.020351596","density:  12.0070168<br />post_bmi: 0.020318164","density:  12.2689598<br />post_bmi: 0.020284731","density:  12.5360787<br />post_bmi: 0.020251299","density:  12.8084945<br />post_bmi: 0.020217867","density:  13.0869720<br />post_bmi: 0.020184435","density:  13.3722868<br />post_bmi: 0.020151002","density:  13.6683355<br />post_bmi: 0.020117570","density:  13.9742496<br />post_bmi: 0.020084138","density:  14.2904403<br />post_bmi: 0.020050706","density:  14.6177375<br />post_bmi: 0.020017273","density:  14.9582858<br />post_bmi: 0.019983841","density:  15.3160980<br />post_bmi: 0.019950409","density:  15.6885639<br />post_bmi: 0.019916977","density:  16.0765154<br />post_bmi: 0.019883544","density:  16.4807812<br />post_bmi: 0.019850112","density:  16.9068211<br />post_bmi: 0.019816680","density:  17.3541846<br />post_bmi: 0.019783248","density:  17.8212687<br />post_bmi: 0.019749815","density:  18.3088359<br />post_bmi: 0.019716383","density:  18.8179286<br />post_bmi: 0.019682951","density:  19.3577096<br />post_bmi: 0.019649519","density:  19.9209428<br />post_bmi: 0.019616087","density:  20.5082241<br />post_bmi: 0.019582654","density:  21.1201205<br />post_bmi: 0.019549222","density:  21.7613855<br />post_bmi: 0.019515790","density:  22.4343430<br />post_bmi: 0.019482358","density:  23.1336943<br />post_bmi: 0.019448925","density:  23.8596693<br />post_bmi: 0.019415493","density:  24.6124501<br />post_bmi: 0.019382061","density:  25.4005075<br />post_bmi: 0.019348629","density:  26.2172350<br />post_bmi: 0.019315196","density:  27.0604366<br />post_bmi: 0.019281764","density:  27.9297760<br />post_bmi: 0.019248332","density:  28.8267689<br />post_bmi: 0.019214900","density:  29.7559874<br />post_bmi: 0.019181467","density:  30.7087195<br />post_bmi: 0.019148035","density:  31.6840229<br />post_bmi: 0.019114603","density:  32.6808883<br />post_bmi: 0.019081171","density:  33.7022936<br />post_bmi: 0.019047738","density:  34.7443781<br />post_bmi: 0.019014306","density:  35.8025226<br />post_bmi: 0.018980874","density:  36.8751876<br />post_bmi: 0.018947442","density:  37.9607843<br />post_bmi: 0.018914009","density:  39.0604221<br />post_bmi: 0.018880577","density:  40.1674384<br />post_bmi: 0.018847145","density:  41.2799384<br />post_bmi: 0.018813713","density:  42.3960931<br />post_bmi: 0.018780280","density:  43.5138386<br />post_bmi: 0.018746848","density:  44.6296543<br />post_bmi: 0.018713416","density:  45.7414628<br />post_bmi: 0.018679984","density:  46.8475697<br />post_bmi: 0.018646551","density:  47.9463197<br />post_bmi: 0.018613119","density:  49.0326204<br />post_bmi: 0.018579687","density:  50.1059282<br />post_bmi: 0.018546255","density:  51.1659384<br />post_bmi: 0.018512822","density:  52.2115440<br />post_bmi: 0.018479390","density:  53.2407465<br />post_bmi: 0.018445958","density:  54.2477001<br />post_bmi: 0.018412526","density:  55.2370233<br />post_bmi: 0.018379093","density:  56.2083826<br />post_bmi: 0.018345661","density:  57.1615360<br />post_bmi: 0.018312229","density:  58.0926067<br />post_bmi: 0.018278797","density:  59.0024771<br />post_bmi: 0.018245364","density:  59.8948309<br />post_bmi: 0.018211932","density:  60.7702024<br />post_bmi: 0.018178500","density:  61.6292048<br />post_bmi: 0.018145068","density:  62.4677072<br />post_bmi: 0.018111635","density:  63.2922802<br />post_bmi: 0.018078203","density:  64.1044313<br />post_bmi: 0.018044771","density:  64.9052993<br />post_bmi: 0.018011339","density:  65.6951173<br />post_bmi: 0.017977907","density:  66.4751214<br />post_bmi: 0.017944474","density:  67.2492093<br />post_bmi: 0.017911042","density:  68.0186997<br />post_bmi: 0.017877610","density:  68.7849084<br />post_bmi: 0.017844178","density:  69.5493180<br />post_bmi: 0.017810745","density:  70.3143933<br />post_bmi: 0.017777313","density:  71.0814384<br />post_bmi: 0.017743881","density:  71.8515551<br />post_bmi: 0.017710449","density:  72.6260207<br />post_bmi: 0.017677016","density:  73.4081487<br />post_bmi: 0.017643584","density:  74.1971933<br />post_bmi: 0.017610152","density:  74.9937885<br />post_bmi: 0.017576720","density:  75.7985046<br />post_bmi: 0.017543287","density:  76.6135636<br />post_bmi: 0.017509855","density:  77.4395898<br />post_bmi: 0.017476423","density:  78.2749198<br />post_bmi: 0.017442991","density:  79.1195331<br />post_bmi: 0.017409558","density:  79.9733427<br />post_bmi: 0.017376126","density:  80.8389320<br />post_bmi: 0.017342694","density:  81.7130555<br />post_bmi: 0.017309262","density:  82.5947235<br />post_bmi: 0.017275829","density:  83.4833085<br />post_bmi: 0.017242397","density:  84.3786129<br />post_bmi: 0.017208965","density:  85.2800055<br />post_bmi: 0.017175533","density:  86.1847922<br />post_bmi: 0.017142100","density:  87.0919675<br />post_bmi: 0.017108668","density:  88.0004986<br />post_bmi: 0.017075236","density:  88.9088198<br />post_bmi: 0.017041804","density:  89.8148952<br />post_bmi: 0.017008371","density:  90.7176103<br />post_bmi: 0.016974939","density:  91.6158396<br />post_bmi: 0.016941507","density:  92.5083320<br />post_bmi: 0.016908075","density:  93.3907414<br />post_bmi: 0.016874642","density:  94.2641614<br />post_bmi: 0.016841210","density:  95.1276796<br />post_bmi: 0.016807778","density:  95.9804301<br />post_bmi: 0.016774346","density:  96.8194529<br />post_bmi: 0.016740913","density:  97.6429201<br />post_bmi: 0.016707481","density:  98.4529781<br />post_bmi: 0.016674049","density:  99.2493115<br />post_bmi: 0.016640617","density: 100.0316811<br />post_bmi: 0.016607184","density: 100.7955738<br />post_bmi: 0.016573752","density: 101.5447917<br />post_bmi: 0.016540320","density: 102.2807084<br />post_bmi: 0.016506888","density: 103.0038467<br />post_bmi: 0.016473456","density: 103.7139436<br />post_bmi: 0.016440023","density: 104.4102058<br />post_bmi: 0.016406591","density: 105.0974558<br />post_bmi: 0.016373159","density: 105.7769591<br />post_bmi: 0.016339727","density: 106.4500518<br />post_bmi: 0.016306294","density: 107.1177391<br />post_bmi: 0.016272862","density: 107.7833913<br />post_bmi: 0.016239430","density: 108.4494319<br />post_bmi: 0.016205998","density: 109.1176373<br />post_bmi: 0.016172565","density: 109.7898117<br />post_bmi: 0.016139133","density: 110.4715644<br />post_bmi: 0.016105701","density: 111.1632302<br />post_bmi: 0.016072269","density: 111.8665559<br />post_bmi: 0.016038836","density: 112.5832648<br />post_bmi: 0.016005404","density: 113.3176793<br />post_bmi: 0.015971972","density: 114.0742082<br />post_bmi: 0.015938540","density: 114.8504601<br />post_bmi: 0.015905107","density: 115.6475914<br />post_bmi: 0.015871675","density: 116.4666697<br />post_bmi: 0.015838243","density: 117.3158260<br />post_bmi: 0.015804811","density: 118.1912148<br />post_bmi: 0.015771378","density: 119.0910543<br />post_bmi: 0.015737946","density: 120.0154621<br />post_bmi: 0.015704514","density: 120.9659344<br />post_bmi: 0.015671082","density: 121.9480845<br />post_bmi: 0.015637649","density: 122.9532329<br />post_bmi: 0.015604217","density: 123.9804621<br />post_bmi: 0.015570785","density: 125.0287454<br />post_bmi: 0.015537353","density: 126.1005329<br />post_bmi: 0.015503920","density: 127.1922104<br />post_bmi: 0.015470488","density: 128.2986508<br />post_bmi: 0.015437056","density: 129.4179836<br />post_bmi: 0.015403624","density: 130.5482605<br />post_bmi: 0.015370191","density: 131.6888588<br />post_bmi: 0.015336759","density: 132.8334609<br />post_bmi: 0.015303327","density: 133.9795214<br />post_bmi: 0.015269895","density: 135.1246371<br />post_bmi: 0.015236462","density: 136.2653644<br />post_bmi: 0.015203030","density: 137.3961386<br />post_bmi: 0.015169598","density: 138.5154629<br />post_bmi: 0.015136166","density: 139.6208656<br />post_bmi: 0.015102733","density: 140.7098898<br />post_bmi: 0.015069301","density: 141.7735572<br />post_bmi: 0.015035869","density: 142.8110490<br />post_bmi: 0.015002437","density: 143.8222828<br />post_bmi: 0.014969005","density: 144.8051026<br />post_bmi: 0.014935572","density: 145.7559677<br />post_bmi: 0.014902140","density: 146.6614748<br />post_bmi: 0.014868708","density: 147.5303573<br />post_bmi: 0.014835276","density: 148.3609710<br />post_bmi: 0.014801843","density: 149.1517372<br />post_bmi: 0.014768411","density: 149.8927468<br />post_bmi: 0.014734979","density: 150.5815300<br />post_bmi: 0.014701547","density: 151.2250433<br />post_bmi: 0.014668114","density: 151.8223131<br />post_bmi: 0.014634682","density: 152.3724340<br />post_bmi: 0.014601250","density: 152.8577973<br />post_bmi: 0.014567818","density: 153.2918583<br />post_bmi: 0.014534385","density: 153.6762691<br />post_bmi: 0.014500953","density: 154.0106977<br />post_bmi: 0.014467521","density: 154.2894823<br />post_bmi: 0.014434089","density: 154.5039201<br />post_bmi: 0.014400656","density: 154.6680022<br />post_bmi: 0.014367224","density: 154.7818834<br />post_bmi: 0.014333792","density: 154.8457668<br />post_bmi: 0.014300360","density: 154.8473789<br />post_bmi: 0.014266927","density: 154.7938832<br />post_bmi: 0.014233495","density: 154.6921128<br />post_bmi: 0.014200063","density: 154.5426442<br />post_bmi: 0.014166631","density: 154.3450666<br />post_bmi: 0.014133198","density: 154.0850128<br />post_bmi: 0.014099766","density: 153.7802987<br />post_bmi: 0.014066334","density: 153.4317883<br />post_bmi: 0.014032902","density: 153.0403725<br />post_bmi: 0.013999469","density: 152.6000940<br />post_bmi: 0.013966037","density: 152.1112520<br />post_bmi: 0.013932605","density: 151.5837484<br />post_bmi: 0.013899173","density: 151.0186807<br />post_bmi: 0.013865740","density: 150.4171651<br />post_bmi: 0.013832308","density: 149.7698340<br />post_bmi: 0.013798876","density: 149.0877151<br />post_bmi: 0.013765444","density: 148.3742019<br />post_bmi: 0.013732011","density: 147.6305364<br />post_bmi: 0.013698579","density: 146.8556535<br />post_bmi: 0.013665147","density: 146.0462206<br />post_bmi: 0.013631715","density: 145.2120328<br />post_bmi: 0.013598282","density: 144.3543786<br />post_bmi: 0.013564850","density: 143.4745463<br />post_bmi: 0.013531418","density: 142.5694970<br />post_bmi: 0.013497986","density: 141.6434271<br />post_bmi: 0.013464554","density: 140.7005936<br />post_bmi: 0.013431121","density: 139.7422482<br />post_bmi: 0.013397689","density: 138.7696071<br />post_bmi: 0.013364257","density: 137.7800068<br />post_bmi: 0.013330825","density: 136.7800575<br />post_bmi: 0.013297392","density: 135.7709265<br />post_bmi: 0.013263960","density: 134.7537697<br />post_bmi: 0.013230528","density: 133.7290018<br />post_bmi: 0.013197096","density: 132.6983018<br />post_bmi: 0.013163663","density: 131.6642606<br />post_bmi: 0.013130231","density: 130.6279258<br />post_bmi: 0.013096799","density: 129.5903319<br />post_bmi: 0.013063367","density: 128.5530413<br />post_bmi: 0.013029934","density: 127.5176955<br />post_bmi: 0.012996502","density: 126.4851919<br />post_bmi: 0.012963070","density: 125.4564283<br />post_bmi: 0.012929638","density: 124.4326895<br />post_bmi: 0.012896205","density: 123.4168990<br />post_bmi: 0.012862773","density: 122.4082943<br />post_bmi: 0.012829341","density: 121.4075696<br />post_bmi: 0.012795909","density: 120.4153893<br />post_bmi: 0.012762476","density: 119.4345933<br />post_bmi: 0.012729044","density: 118.4656875<br />post_bmi: 0.012695612","density: 117.5074887<br />post_bmi: 0.012662180","density: 116.5603290<br />post_bmi: 0.012628747","density: 115.6244970<br />post_bmi: 0.012595315","density: 114.7044951<br />post_bmi: 0.012561883","density: 113.7963476<br />post_bmi: 0.012528451","density: 112.8997410<br />post_bmi: 0.012495018","density: 112.0145132<br />post_bmi: 0.012461586","density: 111.1418231<br />post_bmi: 0.012428154","density: 110.2822147<br />post_bmi: 0.012394722","density: 109.4323227<br />post_bmi: 0.012361289","density: 108.5915234<br />post_bmi: 0.012327857","density: 107.7591468<br />post_bmi: 0.012294425","density: 106.9361305<br />post_bmi: 0.012260993","density: 106.1196247<br />post_bmi: 0.012227560","density: 105.3079253<br />post_bmi: 0.012194128","density: 104.5000582<br />post_bmi: 0.012160696","density: 103.6950772<br />post_bmi: 0.012127264","density: 102.8915472<br />post_bmi: 0.012093831","density: 102.0875040<br />post_bmi: 0.012060399","density: 101.2819329<br />post_bmi: 0.012026967","density: 100.4738355<br />post_bmi: 0.011993535","density:  99.6611955<br />post_bmi: 0.011960102","density:  98.8423332<br />post_bmi: 0.011926670","density:  98.0171917<br />post_bmi: 0.011893238","density:  97.1850532<br />post_bmi: 0.011859806","density:  96.3452443<br />post_bmi: 0.011826374","density:  95.4939577<br />post_bmi: 0.011792941","density:  94.6331267<br />post_bmi: 0.011759509","density:  93.7628155<br />post_bmi: 0.011726077","density:  92.8828229<br />post_bmi: 0.011692645","density:  91.9919119<br />post_bmi: 0.011659212","density:  91.0885588<br />post_bmi: 0.011625780","density:  90.1756454<br />post_bmi: 0.011592348","density:  89.2534263<br />post_bmi: 0.011558916","density:  88.3221986<br />post_bmi: 0.011525483","density:  87.3802951<br />post_bmi: 0.011492051","density:  86.4297341<br />post_bmi: 0.011458619","density:  85.4720912<br />post_bmi: 0.011425187","density:  84.5079179<br />post_bmi: 0.011391754","density:  83.5376475<br />post_bmi: 0.011358322","density:  82.5606165<br />post_bmi: 0.011324890","density:  81.5795213<br />post_bmi: 0.011291458","density:  80.5949236<br />post_bmi: 0.011258025","density:  79.6073706<br />post_bmi: 0.011224593","density:  78.6171279<br />post_bmi: 0.011191161","density:  77.6250342<br />post_bmi: 0.011157729","density:  76.6319378<br />post_bmi: 0.011124296","density:  75.6381833<br />post_bmi: 0.011090864","density:  74.6440867<br />post_bmi: 0.011057432","density:  73.6500326<br />post_bmi: 0.011024000","density:  72.6562986<br />post_bmi: 0.010990567","density:  71.6629678<br />post_bmi: 0.010957135","density:  70.6701005<br />post_bmi: 0.010923703","density:  69.6777699<br />post_bmi: 0.010890271","density:  68.6860044<br />post_bmi: 0.010856838","density:  67.6945599<br />post_bmi: 0.010823406","density:  66.7033304<br />post_bmi: 0.010789974","density:  65.7122013<br />post_bmi: 0.010756542","density:  64.7209769<br />post_bmi: 0.010723109","density:  63.7294270<br />post_bmi: 0.010689677","density:  62.7374522<br />post_bmi: 0.010656245","density:  61.7449564<br />post_bmi: 0.010622813","density:  60.7518501<br />post_bmi: 0.010589380","density:  59.7578167<br />post_bmi: 0.010555948","density:  58.7631310<br />post_bmi: 0.010522516","density:  57.7678703<br />post_bmi: 0.010489084","density:  56.7721390<br />post_bmi: 0.010455651","density:  55.7760807<br />post_bmi: 0.010422219","density:  54.7801265<br />post_bmi: 0.010388787","density:  53.7846753<br />post_bmi: 0.010355355","density:  52.7900913<br />post_bmi: 0.010321923","density:  51.7967679<br />post_bmi: 0.010288490","density:  50.8059863<br />post_bmi: 0.010255058","density:  49.8182258<br />post_bmi: 0.010221626","density:  48.8339323<br />post_bmi: 0.010188194","density:  47.8537210<br />post_bmi: 0.010154761","density:  46.8786501<br />post_bmi: 0.010121329","density:  45.9113140<br />post_bmi: 0.010087897","density:  44.9509362<br />post_bmi: 0.010054465","density:  43.9982312<br />post_bmi: 0.010021032","density:  43.0539133<br />post_bmi: 0.009987600","density:  42.1210140<br />post_bmi: 0.009954168","density:  41.2002877<br />post_bmi: 0.009920736","density:  40.2908637<br />post_bmi: 0.009887303","density:  39.3933654<br />post_bmi: 0.009853871","density:  38.5083969<br />post_bmi: 0.009820439","density:  37.6417798<br />post_bmi: 0.009787007","density:  36.7894912<br />post_bmi: 0.009753574","density:  35.9517281<br />post_bmi: 0.009720142","density:  35.1288238<br />post_bmi: 0.009686710","density:  34.3231824<br />post_bmi: 0.009653278","density:  33.5368223<br />post_bmi: 0.009619845","density:  32.7660029<br />post_bmi: 0.009586413","density:  32.0106901<br />post_bmi: 0.009552981","density:  31.2708059<br />post_bmi: 0.009519549","density:  30.5504271<br />post_bmi: 0.009486116","density:  29.8461953<br />post_bmi: 0.009452684","density:  29.1562213<br />post_bmi: 0.009419252","density:  28.4800617<br />post_bmi: 0.009385820","density:  27.8178733<br />post_bmi: 0.009352387","density:  27.1721361<br />post_bmi: 0.009318955","density:  26.5377626<br />post_bmi: 0.009285523","density:  25.9140565<br />post_bmi: 0.009252091","density:  25.3003056<br />post_bmi: 0.009218658","density:  24.6973334<br />post_bmi: 0.009185226","density:  24.1035208<br />post_bmi: 0.009151794","density:  23.5164762<br />post_bmi: 0.009118362","density:  22.9354572<br />post_bmi: 0.009084929","density:  22.3597311<br />post_bmi: 0.009051497","density:  21.7896821<br />post_bmi: 0.009018065","density:  21.2229156<br />post_bmi: 0.008984633","density:  20.6587409<br />post_bmi: 0.008951200","density:  20.0966421<br />post_bmi: 0.008917768","density:  19.5362463<br />post_bmi: 0.008884336","density:  18.9770507<br />post_bmi: 0.008850904","density:  18.4184579<br />post_bmi: 0.008817472","density:  17.8603276<br />post_bmi: 0.008784039","density:  17.3025666<br />post_bmi: 0.008750607","density:  16.7452906<br />post_bmi: 0.008717175","density:  16.1886904<br />post_bmi: 0.008683743","density:  15.6330044<br />post_bmi: 0.008650310","density:  15.0785596<br />post_bmi: 0.008616878","density:  14.5258039<br />post_bmi: 0.008583446","density:  13.9763219<br />post_bmi: 0.008550014","density:  13.4301705<br />post_bmi: 0.008516581","density:  12.8880045<br />post_bmi: 0.008483149","density:  12.3505032<br />post_bmi: 0.008449717","density:  11.8196124<br />post_bmi: 0.008416285","density:  11.2969470<br />post_bmi: 0.008382852","density:  10.7821776<br />post_bmi: 0.008349420","density:  10.2761036<br />post_bmi: 0.008315988","density:   9.7795259<br />post_bmi: 0.008282556","density:   9.2971949<br />post_bmi: 0.008249123","density:   8.8274453<br />post_bmi: 0.008215691","density:   8.3704245<br />post_bmi: 0.008182259","density:   7.9268241<br />post_bmi: 0.008148827","density:   7.4987723<br />post_bmi: 0.008115394","density:   7.0902001<br />post_bmi: 0.008081962","density:   6.6975081<br />post_bmi: 0.008048530","density:   6.3211276<br />post_bmi: 0.008015098","density:   5.9614546<br />post_bmi: 0.007981665","density:   5.6231512<br />post_bmi: 0.007948233","density:   5.3047788<br />post_bmi: 0.007914801","density:   5.0040789<br />post_bmi: 0.007881369","density:   4.7211168<br />post_bmi: 0.007847936","density:   4.4561261<br />post_bmi: 0.007814504","density:   4.2153459<br />post_bmi: 0.007781072","density:   3.9919646<br />post_bmi: 0.007747640","density:   3.7857405<br />post_bmi: 0.007714207","density:   3.5964028<br />post_bmi: 0.007680775","density:   3.4261992<br />post_bmi: 0.007647343","density:   3.2753691<br />post_bmi: 0.007613911","density:   3.1397774<br />post_bmi: 0.007580478","density:   3.0189346<br />post_bmi: 0.007547046","density:   2.9123324<br />post_bmi: 0.007513614","density:   2.8233098<br />post_bmi: 0.007480182","density:   2.7476709<br />post_bmi: 0.007446749","density:   2.6838220<br />post_bmi: 0.007413317","density:   2.6311419<br />post_bmi: 0.007379885","density:   2.5897184<br />post_bmi: 0.007346453","density:   2.5605956<br />post_bmi: 0.007313020","density:   2.5399075<br />post_bmi: 0.007279588","density:   2.5269992<br />post_bmi: 0.007246156","density:   2.5212166<br />post_bmi: 0.007212724","density:   2.5230756<br />post_bmi: 0.007179292","density:   2.5309444<br />post_bmi: 0.007145859","density:   2.5432117<br />post_bmi: 0.007112427","density:   2.5592560<br />post_bmi: 0.007078995","density:   2.5784618<br />post_bmi: 0.007045563","density:   2.6006973<br />post_bmi: 0.007012130","density:   2.6242195<br />post_bmi: 0.006978698","density:   2.6484650<br />post_bmi: 0.006945266","density:   2.6729001<br />post_bmi: 0.006911834","density:   2.6968297<br />post_bmi: 0.006878401","density:   2.7192392<br />post_bmi: 0.006844969","density:   2.7398056<br />post_bmi: 0.006811537","density:   2.7581154<br />post_bmi: 0.006778105","density:   2.7737702<br />post_bmi: 0.006744672","density:   2.7853139<br />post_bmi: 0.006711240","density:   2.7928153<br />post_bmi: 0.006677808","density:   2.7963103<br />post_bmi: 0.006644376","density:   2.7955579<br />post_bmi: 0.006610943","density:   2.7900686<br />post_bmi: 0.006577511","density:   2.7782731<br />post_bmi: 0.006544079","density:   2.7615521<br />post_bmi: 0.006510647","density:   2.7398410<br />post_bmi: 0.006477214","density:   2.7130947<br />post_bmi: 0.006443782","density:   2.6802664<br />post_bmi: 0.006410350","density:   2.6415802<br />post_bmi: 0.006376918","density:   2.5980384<br />post_bmi: 0.006343485","density:   2.5497641<br />post_bmi: 0.006310053","density:   2.4968977<br />post_bmi: 0.006276621","density:   2.4381954<br />post_bmi: 0.006243189","density:   2.3754272<br />post_bmi: 0.006209756","density:   2.3754272<br />post_bmi: 0.006209756"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"transparent","dash":"solid"},"fill":"toself","fillcolor":"rgba(135,206,235,0.5)","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.014298892399134707,0.014298892399134707],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.01429889","type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(255,0,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.0090005357312124556,0.0090005357312124556],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.009000536","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(255,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.019597249067056958,0.019597249067056958],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.01959725","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(255,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.014333168374387091,0.014333168374387091],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.01433317","type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(0,0,255,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.0093058553832983375,0.0093058553832983375],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.009305855","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(0,0,255,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.019342949408175908,0.019342949408175908],"y":[-7.7423689430387483,162.58974780381371],"text":"xintercept: 0.01934295","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(0,0,255,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":44.825238688252384,"r":7.3059360730593621,"b":40.182648401826491,"l":43.105022831050235},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"<b> Bayesian vs Frequentist Estimate of BMI <\/b>","font":{"color":"rgba(0,0,0,1)","family":"","size":18.596928185969279},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.0053555625772865028,0.024147827257633942],"tickmode":"array","ticktext":["0.010","0.015","0.020"],"tickvals":[0.01,0.014999999999999999,0.02],"categoryorder":"array","categoryarray":["0.010","0.015","0.020"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"Coefficient for BMI","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-7.7423689430387483,162.58974780381371],"tickmode":"array","ticktext":["0","50","100","150"],"tickvals":[0,49.999999999999993,100,150],"categoryorder":"array","categoryarray":["0","50","100","150"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"Density","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"45c81d232754":{"x":{},"type":"scatter"},"45c8f9121a0":{"xintercept":{}},"45c82d911c13":{"xintercept":{}},"45c84f7d569a":{"xintercept":{}},"45c842a4a15":{"xintercept":{}},"45c822041ca1":{"xintercept":{}},"45c87df95d18":{"xintercept":{}}},"cur_data":"45c81d232754","visdat":{"45c81d232754":["function (y) ","x"],"45c8f9121a0":["function (y) ","x"],"45c82d911c13":["function (y) ","x"],"45c84f7d569a":["function (y) ","x"],"45c842a4a15":["function (y) ","x"],"45c822041ca1":["function (y) ","x"],"45c87df95d18":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>The graph compares our Bayesian and frequentist estimates of the BMI coefficient. The x-axis shows the BMI coefficient, and the y-axis shows the density. For the Bayesian estimate, we use a blue shaded area, with a solid blue vertical line representing the posterior mean, and the shaded area showing the 95% credible interval. For the frequentist estimate, we use two red dashed vertical lines to mark the maximum likelihood estimate (MLE) and the 95% confidence interval. This comparison helps us see the differences in how we estimate the BMI coefficient and the uncertainty in each method.</p>
<p>In our next lecture, we will look at how different types of prior distributions affect the posterior in a Bayesian hierarchical model, and how these results differ from those in the frequentist approach.</p>
</section>
<section id="summary" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="summary"><span class="header-section-number">5.6</span> Summary</h2>
<p>Today’s lecture focused on understanding the relationship between causality and Bayesian inference, and how we can clearly distinguish between estimators, estimands, and estimates. We explored Bayesian linear regression in detail, highlighting its key differences compared to frequentist regression.</p>
</section>
<section id="live-tutorial-and-discussion" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="live-tutorial-and-discussion"><span class="header-section-number">5.7</span> Live tutorial and discussion</h2>
<p>The final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!</p>
</section>
<section id="tutorial-exercises" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="tutorial-exercises"><span class="header-section-number">5.8</span> Tutorial Exercises</h2>
<p>Solutions will be provided later after the tutorial.</p>
</section>
<section id="preparation-for-week-6" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="preparation-for-week-6"><span class="header-section-number">5.9</span> Preparation for Week 6</h2>
<p>In week 5 you will be required to .</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-hernan2025causal" class="csl-entry" role="listitem">
Hernán, M, and J Robins. 2025. <em>Causal Inference: What If</em>. Boca Raton: Chapman &amp; Hall/CRC.
</div>
<div id="ref-pearl2016causal" class="csl-entry" role="listitem">
Pearl, Judea, Madelyn Glymour, and Nicholas P Jewell. 2016. <em>Causal Inference in Statistics: A Primer</em>. John Wiley &amp; Sons.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./brief_module_03.html" class="pagination-link" aria-label="**Module 3: Bayeswatch - Gaussian**">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><strong>Module 3: Bayeswatch - Gaussian</strong></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./M03_2.html" class="pagination-link" aria-label="**Prior Tweaks and More**">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>