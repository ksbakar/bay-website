[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistical Methods in Medicine & Health",
    "section": "",
    "text": "Preface\nThe application of Bayesian methods in medicine and health sciences has become increasingly vital as we strive to enhance our understanding of improve diagnostic accuracy, and personalise treatment plans. This course is designed to introduce students with a background in medicine and health sciences to the principles and practices of Bayesian statistics, providing a practical framework for applying these methods in their respective fields.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Bayesian methods offer a unique approach to statistical analysis by incorporating prior knowledge and continuously updating the posterior probability as new evidence becomes available. This dynamic approach is particularly suited to the medical and health sciences, where new data is constantly emerging, and decisions often need to be made in the face of uncertainty.\nThe aim of this course is to explain Bayesian statistics and demonstrate its practical applications in medicine and health sciences. We will start with the foundational concepts, gradually building up to more advanced topics, ensuring a comprehensive understanding that is both accessible and relevant to medical professionals, researchers, and students. Each chapter includes real-world examples, case studies, and practical exercises to reinforce the concepts discussed and illustrate their application in clinical and research settings.\nThroughout the course, we will explore the following key areas:\n\nBayesian Dreams! Navigating Evidence and Inference: Understanding the basics of Bayesian philosophy and how it differs from traditional frequentist approaches. Learning how to update beliefs in light of new data using Bayes’ theorem. Exploring directed acyclic graph (DAG) in the Bayesian modelling context, with graphical representations of the probabilistic relationships between variables and parameters.\nChaotics? Prior Problems, Tools, and Computation: Exploring the role of prior information and how it influences posterior conclusions. Bayesian context of exact inference and computational techniques for approximating complex posterior distributions such as Markov chain Monte Carlo (MCMC). Generative models with prior and posterior predictive checks.\nBayeswatch! Keeping an Eye on Your Model: Applying Bayesian methods to regression analysis in clinical and health research. Extending Bayesian linear model into generalised linear model (GLM) setting (e.g., logistic and Poisson regressions), and explanation with DAG. Explore key tactics on the choice for hyper-parameters of prior distributions.\nClusterphobia? Let Bayes Handle It!: Understanding and implementing hierarchical models for complex data structures common in health sciences. Extension of the Bayesian linear mixed models (LMM) into Bayesian generalised linear mixed models (GLMM) with binomial and Poisson distributions.\nSize Matters! Bayesian Secrets to the Right Sample: Bayesian sample size calculations to design clinical trials. Discussion of adaptations with relevant sample size calculations using Bayesian methods.\nWander into the Wonder!: Bayesian model choice (e.g., Bayes factor, deviance information criterion (DIC), Watanabe-Akaike information criterion (WAIC) and leave-one-out (LOO) cross-validation). Bayesian shrinkage, missing data analysis and measurement errors.\n\nThe field of medicine and health sciences is inherently multidisciplinary, and so too is this course. It is crafted to bridge the gap between statistical theory and medical practice, enabeling healthcare professionals to make more informed, data-driven decisions. Whether you are a student eager to learn about Bayesian statistics, or a biostatistician or clinician or a health professional looking to enhance your research skills, or a researcher aiming to apply Bayesian methods to your work, this course provides the tools and knowledge you need to succeed.\nWe hope that by the end of this journey, you will not only appreciate the power and flexibility of Bayesian methods but also feel confident in applying these techniques to improve patient outcomes and advance medical research.\nWelcome to the world of Bayesian methods in medicine and health sciences. Let’s begin.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari,\nand Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition).\nChapman; Hall/CRC.\n\n\nGelman, Andrew, and Cosma Rohilla Shalizi. 2013. “Philosophy and\nthe Practice of Bayesian Statistics.” British Journal of\nMathematical and Statistical Psychology 66 (1): 8–38.\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r,\nJAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "M012.html",
    "href": "M012.html",
    "title": "2  Bayesian Inference",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "M011.html#learning-objectives",
    "href": "M011.html#learning-objectives",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nThis is a book created from markdown and executable code."
  },
  {
    "objectID": "M011.html#learning-activities",
    "href": "M011.html#learning-activities",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.2 Learning Activities",
    "text": "1.2 Learning Activities\nSee Knuth (1984) for additional discussion of literate programming."
  },
  {
    "objectID": "M011.html#preparation-for-week-2",
    "href": "M011.html#preparation-for-week-2",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.3 Preparation for Week 2",
    "text": "1.3 Preparation for Week 2\nasdfa"
  },
  {
    "objectID": "M011.html#introduction",
    "href": "M011.html#introduction",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.4 Introduction",
    "text": "1.4 Introduction\nasdafs\nVedio\n…\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "M011.html#exercises",
    "href": "M011.html#exercises",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\nsdfads"
  },
  {
    "objectID": "M011.html#live-tutorial-and-discussion",
    "href": "M011.html#live-tutorial-and-discussion",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.6 Live tutorial and discussion",
    "text": "1.6 Live tutorial and discussion\nasdfa"
  },
  {
    "objectID": "M011.html#summary",
    "href": "M011.html#summary",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.7 Summary",
    "text": "1.7 Summary"
  },
  {
    "objectID": "M011.html#section",
    "href": "M011.html#section",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.8 ",
    "text": "1.8 \n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "M01_1.html#learning-objectives",
    "href": "M01_1.html#learning-objectives",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.2 Learning Objectives",
    "text": "1.2 Learning Objectives\nIn today’s lecture we will:\n\nUnderstand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learning-activities",
    "href": "M01_1.html#learning-activities",
    "title": "1  Degrees of Beliefs and Evidence",
    "section": "1.2 Learning Activities",
    "text": "1.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#preparation-for-week-2",
    "href": "M01_1.html#preparation-for-week-2",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.11 Preparation for Week 2",
    "text": "1.11 Preparation for Week 2\nIn week 2, we will start exploring Bayesian dreams and learn the fundamental concepts related to Bayesian inference and models.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#introduction",
    "href": "M01_1.html#introduction",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\n\n\n\n\n\nThomas Bayes (The IMS Bulletin, 1988, vol-17(3), pp.276-278)\n\n\n\n\n\n\nThomas Bayes, who is remembered through the term “Bayesian,” passed away in 1761 without having the chance to formally present or publish his groundbreaking findings. Two years after his death, it was Richard Price who, in 1763, introduced Bayes’ extraordinary work to the Royal Statistical Society. Bayes had been carefully constructing a probabilistic framework to tackle inverse problems. Concurrently, Richard Price (1723–1791) and Pierre-Simon Laplace (1749–1827) played crucial roles in advancing and applying this transformative idea to practical real-world scenarios.\nTo fully understand the Bayesian framework, it is essential to become familiar with several key terms commonly used in Bayesian discussions, such as Bayesian inference, prior, posterior, and Bayesian modeling. Throughout this course, we will gradually explore these fundamental concepts. Before deeply examining these important terms, it is beneficial to consider the Bayesian philosophy.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#exercises",
    "href": "M01_1.html#exercises",
    "title": "1  Belief-O-Meter: Navigating Evidence",
    "section": "1.9 Exercises",
    "text": "1.9 Exercises\nSolutions will be provided later after the tutorial.\n\n1.9.1 Question 1:\n\nConsider a rare disease that is thought to occur in 0.1% of the population. This can be our prior belief that a person selected at random has the disease. Using a particular blood test a physician observes that out of the patients with disease, 99% of the time the test result is positive. This is also known as the hit rate. Suppose 5% of the time when the disease is absent but the test falsely indicates that the disease is present, i.e., the false alarm or false positive rate is 5%.\nConsider, we sample a person at random from the population, administer\nAlso assume that 1% of the population without the disease have the same symptom. A randomly chosen person from the population is blood tested and is shown to have the symptom. What is the conditional probability that the person has the disease?\nHere we have the probability of the event that a randomly chosen person has the disease, i.e., \\(Pr(D)=0.001\\), since 0.1% of the population has the disease and 0.999% will not have the disease, i.e., \\((1-Pr(D))=Pr(D')=0.999\\).\nWe also know that 99% possess symptom, i.e., the probability of the event that a randomly chosen person has the symptom given disease \\(Pr(S|D)=0.99\\), and the probability of symptom without disease is \\(Pr(S|D')=0.01\\). Now to get the probability of disease given symptom we can write: \\[\nPr(\\text{disease}|\\text{symptom})=Pr(D|S)\n\\]\n\\[\nPr(D|S) = \\frac{Pr(S|D)\\times Pr(D)}{Pr(S|D)\\times Pr(D) + Pr(S|D')\\times Pr(D')}\n\\]\n\\[\nPr(D|S) = \\frac{0.99\\times 0.001}{0.99\\times 0.001 + 0.01\\times 0.999} = 0.09\n\\]\nwhich is 9% since the disease is rare (i.e., 0.1% occurrence) and a large portion of the population might have symptom but not the disease.\nA blood test for the person with symptom might provide a further insight, this will be a new evidence. Hence if we are interested to get the posterior probability of having the disease, the prior probability 0.1% would get revised to 9%. Thus we write: \\[\nPr(\\text{disease}|\\text{positive})=\\frac{0.99\\times 0.09}{0.99\\times 0.09 + 0.01\\times 0.91} = 0.908\n\\] This probability is much higher since it combines the evidence from two events, i.e., symptoms and tests. This illustrates an aspect of the Bayesian world view: the prior probability gets continually updated in the light of new evidence.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Belief-O-Meter: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#live-tutorial-and-discussion",
    "href": "M01_1.html#live-tutorial-and-discussion",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.9 Live tutorial and discussion",
    "text": "1.9 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#summary",
    "href": "M01_1.html#summary",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.8 Summary",
    "text": "1.8 Summary\nThe key concept of this week’s lecture is that Bayesian ways of thinking are inherently more suited to solving real-life problems compared to frequentist/classical approaches, as they allow for the inclusion of prior information in decision-making, providing a clear advantage in calculating inverse probability.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#section",
    "href": "M01_1.html#section",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.7 ",
    "text": "1.7"
  },
  {
    "objectID": "M01_2.html#section",
    "href": "M01_2.html#section",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.13 ",
    "text": "2.13 \n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-objectives",
    "href": "M01_2.html#learning-objectives",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.2 Learning Objectives",
    "text": "2.2 Learning Objectives\nBy the end of this week you should be able to:\n\nDescribe Bayesian inference using probability distributions.\nUnderstand Bayesian learning.\nDraw DAG for Bayesian models.\nFormulate examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-activities",
    "href": "M01_2.html#learning-activities",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.2 Learning Activities",
    "text": "2.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#preparation-for-week-3",
    "href": "M01_2.html#preparation-for-week-3",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.12 Preparation for Week 3",
    "text": "2.12 Preparation for Week 3\nNext week we will start Module 02 of this unit, where our main focus will be to understand different types of prior distributions and how they influence the posteriors.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#introduction",
    "href": "M01_2.html#introduction",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem, which describes how prior beliefs are updated with new data. Following out previous lecture, if we denote \\(Pr(H)\\) as the probability of initial beliefe about \\(H\\) before seeing data, we can write the updated beliefe about \\(H\\) given the data \\(D\\) as: \\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\] where, \\(Pr(D)\\) is the probabilty of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of model that incorporates Bayes throrem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#exercises",
    "href": "M01_2.html#exercises",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\nsdfads\nhow to choose an appropriate likelihood? ref -Lambert, page 71, sec: 4.6, 4.8\nexplain conjugacy - lambert, use normal dist with known mu\nnormal model with known variance\n\n2.9.1 Poisson Model\n\n\n\n2.9.2 Exponential Model",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#live-tutorial-and-discussion",
    "href": "M01_2.html#live-tutorial-and-discussion",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Live tutorial and discussion",
    "text": "2.10 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#summary",
    "href": "M01_2.html#summary",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Summary",
    "text": "2.9 Summary\nToday’s lecture explored Bayesian inference, focusing on how to derive it analytically, we also learn Bayesian updating, posterior odds and Directed Acyclic Graphs (DAGs).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-objectives",
    "href": "M02_1.html#learning-objectives",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.2 Learning Objectives",
    "text": "3.2 Learning Objectives\nBy the end of this week you should be able to:\n\nUnderstand the importance of prior distributions.\nCalculate posterior using Bayesian exact inference.\nDistinguish between different types of Prior distributions\nFormulate examples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-activities",
    "href": "M02_1.html#learning-activities",
    "title": "3  Prior and Posterior Distributions",
    "section": "3.2 Learning Activities",
    "text": "3.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#introduction",
    "href": "M02_1.html#introduction",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.3 Introduction",
    "text": "3.3 Introduction\nIn Bayesian statistics, integrating prior distributions is fundamental for incorporating existing knowledge about parameters ahead of data analysis, which includes historical data and domain expertise, and plays an important role in informed decision-making from the posterior distribution.\nIn cases of limited or incomplete data, priors are crucial for generating stable posterior estimates. They enhance model-building flexibility by accommodating various parameter types and clarifying the distinction between prior knowledge and new data. For example, when evaluating the probability of rare events, a well-informed prior, such as a Beta distribution, helps avoid unrealistic predictions, even with small sample sizes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#exercises",
    "href": "M02_1.html#exercises",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.12 Exercises",
    "text": "4.12 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#live-tutorial-and-discussion",
    "href": "M02_1.html#live-tutorial-and-discussion",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.13 Live tutorial and discussion",
    "text": "4.13 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#summary",
    "href": "M02_1.html#summary",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.14 Summary",
    "text": "4.14 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#section",
    "href": "M02_1.html#section",
    "title": "3  Directed Acyclic Graph (DAG) (Week 3)",
    "section": "3.7 ",
    "text": "3.7"
  },
  {
    "objectID": "M02_1.html#preparation-for-week-2",
    "href": "M02_1.html#preparation-for-week-2",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.12 Preparation for Week 2",
    "text": "4.12 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course."
  },
  {
    "objectID": "M02_2.html#learning-objectives",
    "href": "M02_2.html#learning-objectives",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.2 Learning Objectives",
    "text": "4.2 Learning Objectives\nBy the end of this week you should be able to:\n\nCreate generative models\nUnderstand traceable and untraceable solutions\nExplain the convergence of MCMC.\nConduct prior predictive check.\nConduct posterior predictive check.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learning-activities",
    "href": "M02_2.html#learning-activities",
    "title": "4  Tools and Generative Models",
    "section": "4.2 Learning Activities",
    "text": "4.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#introduction",
    "href": "M02_2.html#introduction",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.3 Introduction",
    "text": "4.3 Introduction\nGenerative models are essential tools in statistical analysis, enabling the understanding and simulation of complex data structures. Bayesian methods play a crucial role in solving such problems. However, a key challenge in Bayesian analysis is ensuring convergence in Markov Chain Monte Carlo (MCMC) simulations, which is vital for generating samples that accurately represent the target distribution.\nTo assess the reliability of Bayesian models, prior and posterior predictive checks are commonly used to validate the coherence between the model and observed data. These checks provide a rigorous framework for informed decision-making in applications where generative models are employed.\nThis lecture explores the role of Bayesian tools in statistical modeling, highlighting their challenges, evaluation methods, and practical implications.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#exercises",
    "href": "M02_2.html#exercises",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.7 Exercises",
    "text": "4.7 Exercises\nhttps://m-clark.github.io/easy-bayes/shinystan.html\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#live-tutorial-and-discussion",
    "href": "M02_2.html#live-tutorial-and-discussion",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.8 Live tutorial and discussion",
    "text": "4.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#summary",
    "href": "M02_2.html#summary",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.9 Summary",
    "text": "4.9 Summary\nasddf",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#section",
    "href": "M02_2.html#section",
    "title": "4  Tools and Generative Models (Week 4)",
    "section": "4.7 ",
    "text": "4.7"
  },
  {
    "objectID": "M02_2.html#preparation-for-week-2",
    "href": "M02_2.html#preparation-for-week-2",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.10 Preparation for Week 2",
    "text": "4.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.\n\n\n\n\nBernardo, JM, MJ Bayarri, JO Berger, AP Dawid, D Heckerman, AFM Smith, and M West. 2007. “Generative or Discriminative? Getting the Best of Both Worlds.” Bayesian Statistics 8 (3): 3–24.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learning-objectives",
    "href": "M03_1.html#learning-objectives",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.2 Learning Objectives",
    "text": "5.2 Learning Objectives\nBy the end of this week you should be able to:\n\nUnderstand Bayesian model and causality\nExplain the terms Estimand, Estimator & Estimate\nUnderstand the difference between Bayesian and classical Regression.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learning-activities",
    "href": "M03_1.html#learning-activities",
    "title": "5  Bayesian Regressions - I",
    "section": "5.2 Learning Activities",
    "text": "5.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayesian Regressions - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#introduction",
    "href": "M03_1.html#introduction",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.3 Introduction",
    "text": "5.3 Introduction\nasdafs\n\nIn this lecture, we shall explore the application of Bayesian inference methodologies to linear regression models. We will begin by examining the utilization of Bayesian statistics within the context of simple linear regression models and subsequently expand these insights to encompass multiple linear regression models. Through this exploration, we will find that employing the non-informative prior results in posterior means, posterior standard deviations, and credible intervals for the coefficients that are consistent with those derived from frequentist ordinary least squares (OLS) linear regression models.\nWe will start with how to develop a Bayesian model based on causality, or unknown causality with understanding of estimand, estimator and estimate. We wil also explore how DAG can help us to build the model.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#exercises",
    "href": "M03_1.html#exercises",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.9 Exercises",
    "text": "5.9 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#live-tutorial-and-discussion",
    "href": "M03_1.html#live-tutorial-and-discussion",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.10 Live tutorial and discussion",
    "text": "5.10 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#summary",
    "href": "M03_1.html#summary",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.11 Summary",
    "text": "5.11 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#section",
    "href": "M03_1.html#section",
    "title": "5  Bayesian Regressions - Part 1 (Week 5)",
    "section": "5.7 ",
    "text": "5.7"
  },
  {
    "objectID": "M03_1.html#preparation-for-week-2",
    "href": "M03_1.html#preparation-for-week-2",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.12 Preparation for Week 2",
    "text": "5.12 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learning-objectives",
    "href": "M03_2.html#learning-objectives",
    "title": "6  Bayeswatch! Part - II",
    "section": "",
    "text": "Understand the Bayesian GLM\nUnderstand the difference between Bayesian and classical GLM.\nFormulate problems and solutions using Bayesian GLM.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learning-activities",
    "href": "M03_2.html#learning-activities",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.2 Learning Activities",
    "text": "6.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#introduction",
    "href": "M03_2.html#introduction",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.3 Introduction",
    "text": "6.3 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#exercises",
    "href": "M03_2.html#exercises",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#live-tutorial-and-discussion",
    "href": "M03_2.html#live-tutorial-and-discussion",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.7 Live tutorial and discussion",
    "text": "6.7 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#summary",
    "href": "M03_2.html#summary",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.8 Summary",
    "text": "6.8 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#section",
    "href": "M03_2.html#section",
    "title": "6  Bayesian Regressions - Part 2 (Week 6)",
    "section": "6.7 ",
    "text": "6.7"
  },
  {
    "objectID": "M03_2.html#preparation-for-week-2",
    "href": "M03_2.html#preparation-for-week-2",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.9 Preparation for Week 2",
    "text": "6.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learning-objectives",
    "href": "M04_1.html#learning-objectives",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "",
    "text": "Explain clusterd data.\nDescribe hierarchical or multilevel Models.\nFit Bayesian linear mixed models.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learning-activities",
    "href": "M04_1.html#learning-activities",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.2 Learning Activities",
    "text": "7.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#introduction",
    "href": "M04_1.html#introduction",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.3 Introduction",
    "text": "7.3 Introduction\nasdafs\nhttps://m-clark.github.io/mixed-models-with-R/bayesian.html\nMultilevel structure : https://bookdown.org/marklhc/notes_bookdown/hierarchical-multilevel-models.html\nhttps://m-clark.github.io/easy-bayes/rstanarm-mixed-model.html",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#exercises",
    "href": "M04_1.html#exercises",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.7 Exercises",
    "text": "7.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#live-tutorial-and-discussion",
    "href": "M04_1.html#live-tutorial-and-discussion",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.8 Live tutorial and discussion",
    "text": "7.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#summary",
    "href": "M04_1.html#summary",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.9 Summary",
    "text": "7.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#section",
    "href": "M04_1.html#section",
    "title": "7  Clustered Data Modelling - Part 1 (Week 7)",
    "section": "7.7 ",
    "text": "7.7"
  },
  {
    "objectID": "M04_1.html#preparation-for-week-2",
    "href": "M04_1.html#preparation-for-week-2",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.10 Preparation for Week 2",
    "text": "7.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learning-objectives",
    "href": "M04_2.html#learning-objectives",
    "title": "8  Clusterphobia? Part - II",
    "section": "",
    "text": "Construct multilevel models for binary outcome.\nUnderstand the difference between Bayesian and classical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learning-activities",
    "href": "M04_2.html#learning-activities",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.2 Learning Activities",
    "text": "8.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#introduction",
    "href": "M04_2.html#introduction",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.3 Introduction",
    "text": "8.3 Introduction\nasdafs\nMarginal effects:\nref: https://joshuawiley.com/brmsmargins/articles/fixed-effects-marginaleffects.html\nref: https://cran.r-project.org/web/packages/brmsmargins/vignettes/mixed-effects-marginaleffects.html",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#exercises",
    "href": "M04_2.html#exercises",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.6 Exercises",
    "text": "8.6 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#live-tutorial-and-discussion",
    "href": "M04_2.html#live-tutorial-and-discussion",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.7 Live tutorial and discussion",
    "text": "8.7 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#summary",
    "href": "M04_2.html#summary",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.8 Summary",
    "text": "8.8 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#section",
    "href": "M04_2.html#section",
    "title": "8  Clustered Data Modelling - Part 2 (Week 8)",
    "section": "8.7 ",
    "text": "8.7"
  },
  {
    "objectID": "M04_2.html#preparation-for-week-2",
    "href": "M04_2.html#preparation-for-week-2",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.9 Preparation for Week 2",
    "text": "8.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayesian-philosophy",
    "href": "M01_1.html#bayesian-philosophy",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.3 Bayesian Philosophy",
    "text": "1.3 Bayesian Philosophy\n\n\nBayesian philosophy revolves around the concept of “degrees of belief” in scientific reasoning. But what does that actually mean? Simply put, it views probability as a measure of our confidence in an event, which updates as we gather new evidence. Unlike traditional frequentist statistics, which treat probability as an objective, fixed value, Bayesian thinking sees it as a dynamic, subjective measure that evolves with new data and insights.\nLet’s explain a bit more using examples:\n\n\n\n\n\nBayesian World (Philosophy)\n\n\n\n\nSuppose a medical practitioner is treating a patient who might have a particular illness, like type-2 diabetes. Initially, based on the patient’s age, family history, and some initial symptoms, the medical practitioner might believe there’s a 20% chance the patient has diabetes. This belief is a prior probability.\nNow, the medical practitioner orders a blood test to check the patient’s blood sugar levels. When the results come back, they show elevated sugar levels, which increase the likelihood of diabetes. The medical practitioner updates their belief based on this new evidence, which is called the posterior probability.\nSo, Bayesian philosophy evolves starting with an initial belief (prior), and then updating that belief as new data (like test results) comes in. In short, it’s a flexible way of thinking where beliefs are adjusted as information is acquired.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#classical-vs.-bayesian",
    "href": "M01_1.html#classical-vs.-bayesian",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.5 Classical vs. Bayesian",
    "text": "2.5 Classical vs. Bayesian\n\n\nMcElreath (2020)\nHistory:\nThe development of Bayesian statistical inference dates back to the late 18th century, preceding many contemporary methodologies. Its application continued into the 19th century. However, after World War I, statisticians like Sir Ronald Fisher, who opposed Bayesian concepts, reduced its prominence. Fisher’s 1925 statistical handbook made only scant mention of Bayesian analysis, then referred to as “inverse probability,” thus diminishing its influence in mainstream statistics. Throughout the latter half of the 20th century, Bayesian analysis gradually regained acceptance. The advent of novel computational technologies in the 1990s significantly increased the application of Bayesian methods.\n\nData and Parameter:\nData represents known elements, whereas parameters are unknown quantities inferred from data. Within the Bayesian framework, this distinction becomes less clear; a variable may be either observed or unobserved, yet it is governed by the same distribution function. Consequently, an assumption can serve as a “likelihood” or a “prior” depending on the context, without altering the model. This connection between certainty (data) and uncertainty (parameters) facilitates the management of measurement errors and missing data in modeling.\n\nReliable Inference:\nThere exists a notion that a specific number of observations is necessary for reliable statistical estimates. For example, at least 30 observations are typically required for a Gaussian distribution. This notion is rooted in traditional statistical inference, where methods are validated for large sample sizes, a concept known as asymptotic behavior, which introduces uncertainty with smaller samples.\nConversely, Bayesian estimates remain valid regardless of sample size. While larger samples are advantageous, Bayesian methods provide meaningful results even with limited data. However, they necessitate a careful selection of the “prior,” which significantly influences the final inference. An improperly chosen prior can skew conclusions. Understanding the world demands thoughtful consideration, without resorting to shortcuts.\n\nRole of Data:\nThe distinctions between Bayesian and non-Bayesian methodologies are notable, yet these differences can sometimes overshadow their underlying commonalities. In many Bayesian and non-Bayesian models, the most critical assumptions typically concern the likelihood functions and their connections with the parameters. These assumptions guide the inferences drawn from each dataset. As the sample size grows, the significance of the likelihood increases. This shared emphasis on likelihood clarifies why Bayesian and non-Bayesian inferences frequently yield similar results.\n\nFurthermore, a common misunderstanding regarding Bayesian data analysis and inference is the belief that they are exclusively defined by Bayes’ theorem. Any inferential method employing probability theory incorporates Bayes’ theorem. Numerous examples labeled as “Bayesian” often lack distinctive attributes and instead rely on observed data frequencies, resembling non-Bayesian methods. The distinctiveness of Bayesian techniques lies in their application of Bayes’ theorem to measure the uncertainty associated with theoretical constructs not directly observable, such as parameters and models. Both methodologies can produce robust inferences, although they are grounded in different principles and entail unique trade-offs.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayes-theorem",
    "href": "M01_1.html#bayes-theorem",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.7 Bayes’ Theorem",
    "text": "1.7 Bayes’ Theorem\n\n\nLet’s now go back to the example related to type-2 diabetes, where, a medical practitioner hypothise based on patient’s background history that the patient has a chance of having diabetes.\nThus, we have two events:\n\nThe hypothesis that medical practitioner’s guess is correct \\((G=[+])\\).\nThe evidence: Blood test showing elevated sugar levels \\((E=[+])\\).\n\nNow, given this experimental evidence of elevated blood sugar, how sure are the medical practitioner that their guess about the diabetes is accurate?\n\\[\nPr(\\text{Guess is correct} | \\text{Positive evidence}) = \\text{ ?}\n\\]\nHence, using conditional probability expression we write:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]},\\text{E=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(\\text{G=[+]},\\text{E=[+]})\\) is the joint probabiity that both \\((G=[+])\\) and \\((E=[+])\\) occur. We can rearrange and write the joint probability as:\n\\[\nPr(\\text{G=[+]},\\text{E=[+]}) = Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})\n\\]\nHence, by substituting the joint probability the Bayes theorem states:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(E=[+])\\) is the marginal probability for the blood test showing high suger levels for all possible hypotheses, here, the possible hypotheses are: \\(G=[+]\\) and \\(G=[-]\\). Hence, we write \\(Pr(\\text{G=[+]}|\\text{E=[+]})\\) as:\n\\[\n\\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})+Pr(\\text{G=[-]})\\times Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(Pr(\\text{G=[+]})\\) and \\(Pr(\\text{G=[-]})\\) are the probabilities of the medical practitioner’s guess is correct and incorrect respectively, thus we write \\(Pr(\\text{G=[-]}) = 1-Pr(\\text{G=[+]})\\) or vise versa.\nWe clearly see that the degree of belief probability after including the evidence is equal to the probability of guess before incorporating the evidence and probability of the evidence with the medical practitioner’s guess.\n\n1.7.1 Example\nTo explain the above example we write, \\(Pr(\\text{G=[+]})=0.2\\), as the medical practitioner guessed that there is a 20% chance the patient has diabetes. The complement, the probability that the patient does not have diabetes, is \\(Pr(\\text{G=[-]})=0.8\\).\nNow, let us define the test’s accuracy:\n\nSensitivity (True Positive Rate or Hit Rate): \\(Pr(\\text{E=[+]}|\\text{G=[+]})=0.85\\), i.e., 85% of diabetics test positive.\nSpecificity (True Negative Rate): \\(Pr(\\text{E=[-]}|\\text{G=[-]})=0.90\\), i.e., 90% of non-diabetics test negative.\nFalse Positive Rate (False Alarm): \\(Pr(\\text{E=[+]}|\\text{G=[-]})=1-Pr(\\text{E=[-]}|\\text{G=[-]})=1-0.9=0.10\\), i.e., 10% of non-diabetics test positive.\n\nThe question is: Given that the test result is positive, how sure is the medical practitioner that the patient truly has diabetes?\nThis is expressed as the posterior probability , which we compute using Bayes’ theorem:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{(0.2\\times 0.85)}{(0.2\\times 0.85) + (0.8\\times 0.1)} = 0.68\n\\]\nAfter observing a positive blood sugar test, the probability that the patient has diabetes increases from 20% to 68%. This means the medical practitioner is now 68% confident in their updated belief that the patient has diabetes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze",
    "href": "M01_1.html#the-maze",
    "title": "1  Degrees of Beliefs and Evidence",
    "section": "1.6 The Maze",
    "text": "1.6 The Maze\n\nBayesian analysis is a logical framework that helps update our beliefs based on new information. It allows us to reason about uncertainty by combining what we already know with evidence we gather to refine our understanding.\nA helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works—it continuously updates our understanding as more evidence comes in.\nTo see this in practice, consider a doctor diagnosing a patient’s illness. Initially, the doctor forms a hypothesis based on the patient’s symptoms and medical history. For instance, they might think there’s a 60% chance of a respiratory infection, a 20% chance of asthma, and a 20% chance of another condition. This initial estimate represents the prior belief. The doctor then orders a chest X-ray, which reveals signs typically associated with respiratory infections. This new evidence increases the likelihood of that diagnosis compared to the alternatives. By combining the initial belief with the X-ray results, the doctor updates the probabilities, now thinking there’s an 80% chance of a respiratory infection, 10% for asthma, and 10% for something else. Additional tests, such as blood work or lung function tests, provide further evidence, allowing the doctor to refine the probabilities until they are confident in the diagnosis.\nThis iterative process is what makes Bayesian analysis so powerful. It doesn’t discard initial beliefs but continuously refines them in light of new evidence. Whether used in medicine, machine learning, or everyday decisions, Bayesian methods ensure that our conclusions are informed, logical, and adaptable as more information becomes available.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-frequency-bayes-rule",
    "href": "M01_1.html#dual-factor-frequency-bayes-rule",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.6 Dual-Factor Frequency (Bayes’ Rule)",
    "text": "2.6 Dual-Factor Frequency (Bayes’ Rule)\n\nKruschke (2014)"
  },
  {
    "objectID": "M01_2.html#bayesian-inference",
    "href": "M01_2.html#bayesian-inference",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.2 Bayesian Inference",
    "text": "2.2 Bayesian Inference\n\n\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote \\(Pr(H)\\) as the probability of initial belief about \\(H\\) before seeing data, we can write the updated belief about \\(H\\) given the data \\(D\\) as:\n\\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\]\nwhere, \\(Pr(D)\\) is the probability of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-updating",
    "href": "M01_2.html#bayesian-updating",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Bayesian Updating",
    "text": "2.10 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior.\nGoing back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#prior-distribution",
    "href": "M01_2.html#prior-distribution",
    "title": "3  Bayesian Inference",
    "section": "3.6 Prior Distribution",
    "text": "3.6 Prior Distribution\nasdf\nconjugacy explain with binomial, poisson distribution exampels. ??\nwhy conjugacy is useful - ref: lambert, page 202, sec:9.3 (beta-bino) and 9.4 (gamma-poiss) and 9.5 (normal-known sigma)\nnon-conjugacy ref:???"
  },
  {
    "objectID": "M01_2.html#more-insights-into-prior-distribution",
    "href": "M01_2.html#more-insights-into-prior-distribution",
    "title": "3  Bayesian Inference",
    "section": "3.8 More Insights into Prior Distribution",
    "text": "3.8 More Insights into Prior Distribution\n\n\n3.8.1 Informative Prior Distribution\n\n\n\n3.8.2 Non-informative Prior Distribution\n\n\n\n3.8.3 Weakly Informative Prior Distribution\n\n\n\n3.8.4 Eliciting Prior Distribution\n\n\n\n3.8.5 Prior Sensitivity",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#exercises-1",
    "href": "M01_1.html#exercises-1",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.10 Exercises",
    "text": "2.10 Exercises\nsdfads\nref: sahu page 73, sec 4.3"
  },
  {
    "objectID": "M02_1.html#dag",
    "href": "M02_1.html#dag",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.4 DAG",
    "text": "4.4 DAG\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables in a model. In a DAG, nodes represent variables, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\nIn the context of Bayesian modeling, DAGs are crucial as they visually encode the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the Binomial model example, we can write a DAG for the Bayesian model as:\n\n\n\n\n\n graph LR\n      A[\"$$x^2$$\"] --&gt;|\"$$\\sqrt{x+3}$$\"| B(\"$$\\frac{1}{2}$$\")\n      A --&gt;|\"$$\\overbrace{a+b+c}^{\\text{note}}$$\"| C(\"$$\\pi r^2$$\")\n      B --&gt; D(\"$$x = \\begin{cases} a &\\text{if } b \\\\ c &\\text{if } d \\end{cases}$$\")\n      C --&gt; E(\"$$x(t)=c_1\\begin{bmatrix}-\\cos{t}+\\sin{t}\\\\ 2\\cos{t} \\end{bmatrix}e^{2t}$$\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Directed Acyclic Graph (DAG)**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#estimand-estimator-estimateestimation",
    "href": "M02_1.html#estimand-estimator-estimateestimation",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.6 Estimand, Estimator & Estimate/Estimation",
    "text": "4.6 Estimand, Estimator & Estimate/Estimation\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Directed Acyclic Graph (DAG)**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#bayesian-dag",
    "href": "M02_1.html#bayesian-dag",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.6 Bayesian DAG",
    "text": "4.6 Bayesian DAG\nasdf - graphical representations of the probabilistic relationships between variables and parameters"
  },
  {
    "objectID": "M02_1.html#bayesian-causal-inference",
    "href": "M02_1.html#bayesian-causal-inference",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.11 Bayesian Causal Inference",
    "text": "4.11 Bayesian Causal Inference\nref: https://onlinelibrary.wiley.com/doi/10.1002/sim.8761\nref: https://bookdown.org/paul/applied-causal-analysis/\nref: paper: https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0153\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learning-objectives",
    "href": "M05_1.html#learning-objectives",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learning-activities",
    "href": "M05_1.html#learning-activities",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.2 Learning Activities",
    "text": "9.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#introduction",
    "href": "M05_1.html#introduction",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.3 Introduction",
    "text": "9.3 Introduction\nasdafs\nref shinyapp: https://ibl.mdanderson.org/shinyapps/BayesESS/\nref: power-priors: https://journal.r-project.org/articles/RJ-2023-016/",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#exercises",
    "href": "M05_1.html#exercises",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#live-tutorial-and-discussion",
    "href": "M05_1.html#live-tutorial-and-discussion",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.8 Live tutorial and discussion",
    "text": "9.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#summary",
    "href": "M05_1.html#summary",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.9 Summary",
    "text": "9.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#preparation-for-week-2",
    "href": "M05_1.html#preparation-for-week-2",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.10 Preparation for Week 2",
    "text": "9.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learning-objectives",
    "href": "M05_2.html#learning-objectives",
    "title": "10  Size Matters! Part - II",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learning-activities",
    "href": "M05_2.html#learning-activities",
    "title": "10  Size Matters! Part - II",
    "section": "10.2 Learning Activities",
    "text": "10.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#introduction",
    "href": "M05_2.html#introduction",
    "title": "10  Size Matters! Part - II",
    "section": "10.3 Introduction",
    "text": "10.3 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#exercises",
    "href": "M05_2.html#exercises",
    "title": "10  Size Matters! Part - II",
    "section": "10.8 Exercises",
    "text": "10.8 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#live-tutorial-and-discussion",
    "href": "M05_2.html#live-tutorial-and-discussion",
    "title": "10  Size Matters! Part - II",
    "section": "10.9 Live tutorial and discussion",
    "text": "10.9 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#summary",
    "href": "M05_2.html#summary",
    "title": "10  Size Matters! Part - II",
    "section": "10.10 Summary",
    "text": "10.10 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#preparation-for-week-2",
    "href": "M05_2.html#preparation-for-week-2",
    "title": "10  Size Matters! Part - II",
    "section": "10.11 Preparation for Week 2",
    "text": "10.11 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learning-objectives",
    "href": "M06_1.html#learning-objectives",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learning-activities",
    "href": "M06_1.html#learning-activities",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.2 Learning Activities",
    "text": "11.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#introduction",
    "href": "M06_1.html#introduction",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.3 Introduction",
    "text": "11.3 Introduction\nasdafs\nVedio",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#exercises",
    "href": "M06_1.html#exercises",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.7 Exercises",
    "text": "11.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#live-tutorial-and-discussion",
    "href": "M06_1.html#live-tutorial-and-discussion",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.8 Live tutorial and discussion",
    "text": "11.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#summary",
    "href": "M06_1.html#summary",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.9 Summary",
    "text": "11.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#preparation-for-week-2",
    "href": "M06_1.html#preparation-for-week-2",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.10 Preparation for Week 2",
    "text": "11.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learning-objectives",
    "href": "M06_2.html#learning-objectives",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learning-activities",
    "href": "M06_2.html#learning-activities",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.2 Learning Activities",
    "text": "12.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#introduction",
    "href": "M06_2.html#introduction",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.3 Introduction",
    "text": "12.3 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#exercises",
    "href": "M06_2.html#exercises",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.7 Exercises",
    "text": "12.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#live-tutorial-and-discussion",
    "href": "M06_2.html#live-tutorial-and-discussion",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.8 Live tutorial and discussion",
    "text": "12.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#summary",
    "href": "M06_2.html#summary",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.9 Summary",
    "text": "12.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#preparation-for-week-2",
    "href": "M06_2.html#preparation-for-week-2",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.10 Preparation for Week 2",
    "text": "12.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-frequency",
    "href": "M01_1.html#dual-factor-frequency",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.6 Dual-Factor Frequency",
    "text": "2.6 Dual-Factor Frequency\n\nKruschke (2014)\nTo understand Bayes’ Theorem, lets start with a simple case of probability based on a two-way table."
  },
  {
    "objectID": "M02_1.html#bayesian-dag-models",
    "href": "M02_1.html#bayesian-dag-models",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.10 Bayesian DAG & Models",
    "text": "4.10 Bayesian DAG & Models\nasdf - graphical representations of the probabilistic relationships between variables and parameters",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#correlation-vs-causation",
    "href": "M02_1.html#correlation-vs-causation",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.9 Correlation vs Causation",
    "text": "4.9 Correlation vs Causation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#generative-models",
    "href": "M02_2.html#generative-models",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.3 Generative Models",
    "text": "4.3 Generative Models\n\n\nA generative model is designed to generate new data points by capturing the intricate probability distributions of existing datasets. By learning these distributions, the model can produce data that reflects the characteristics of original datasets, simulating realistic examples. A generative model can also be used to understand how a set of observed data could have arisen from a set of underlying causes, which we will discuss more later in this course.\nIn Bayesian modeling, generative models are particularly useful as they provide a framework for estimating the likelihood of data under different hypotheses. This capability enhances Bayesian inference processes, allowing for more effective prior and posterior distribution updates. The flexibility of generative models in simulating various scenarios can also improve the robustness and accuracy of Bayesian models, ultimately refining the decision-making and predictive capabilities inherent in Bayesian analysis.\nNote that, in this course, we use “generative model” broadly to consider the origins of a particular dataset. However, this term also has a more specific definition, especially as it contrasts with “discriminative models”, for details see Bernardo et al. (2007).\n\nLet’s explain this using the example we discussed earlier related to the vaccine efficacy rate, where we collected data from \\(n=10\\) individuals and the vaccine was effective for 8 individuals. Recall that we also consider a prior probabilty for the effectiveness, which was \\(0.7\\). Given this information we now recreate the data.\n\nData generation:\n\nIn a generative modelling context, we simulate data for these 10 individuals by considering success probability \\(\\theta = 0.8\\).\n\n\nCode\nn &lt;- 10     # Number of individuals\ntheta &lt;- 0.8    # Probability of success\nsize &lt;- 1  # Number of experiments/replications\nset.seed(123)  \ndata &lt;- rbinom(size, n, theta)\npaste(\"Number of success: \",data,\" out of \",n, \"individuals\")\n\n\n[1] \"Number of success:  9  out of  10 individuals\"\n\n\nWe can see that our simulation using one replication yields probability 0.9, whereas actual data shows \\(\\theta = 0.8\\). Hence, to reflect actual data we need to simulate data for multiple replications, which yields an average value for \\(\\theta = 0.8\\).\n\n\nCode\nlibrary(ggplot2)\nn &lt;- 10     \ntheta &lt;- 0.8    \nsize &lt;- 1000  \nset.seed(123)  \ndata &lt;- rbinom(size, n, theta)\nprint(\"First 10 simulated outcomes:\")\n\n\n[1] \"First 10 simulated outcomes:\"\n\n\nCode\nprint(head(data, 10))\n\n\n [1]  9  7  8  6  6 10  8  6  8  8\n\n\nCode\nprint(quantile(data,prob=c(0.025,0.5,0.975)))\n\n\n 2.5%   50% 97.5% \n    5     8    10 \n\n\nCode\nprint(quantile(data))\n\n\n  0%  25%  50%  75% 100% \n   3    7    8    9   10 \n\n\nCode\ndf &lt;- data.frame(Successes = data)\nggplot(df, aes(x = Successes)) +\n  geom_histogram(\n    breaks = seq(-0.5, n + 0.5, by = 1),\n    fill = \"skyblue\",\n    color = \"black\",\n    boundary = -0.5\n  ) +\n  scale_x_continuous(\n    breaks = 0:n,\n    name = \"Number of successes\"\n  ) +\n  labs(\n    title = paste(\"Histogram of Simulated Binomial Data (n =\", n, \", θ =\", theta, \")\"),\n    y = \"Frequency\",\n    x = \"Number of successes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNow, for instance we … check Mc",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#traceable-and-untraceable-solutions",
    "href": "M02_2.html#traceable-and-untraceable-solutions",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.4 Traceable and Untraceable Solutions",
    "text": "4.4 Traceable and Untraceable Solutions\nA traceable solution manifests when the posterior distribution can be explicitly determined in a closed-form mathematical expression, facilitating straightforward analysis. This situation arises particularly when the prior distribution and the likelihood function are chosen such that the posterior distribution remains within a recognized family of probability distributions.\nFor example, when a conjugate prior is used, the posterior has a known or a same functional form as the prior. This helps to derive posterior parameters easily with simple calculations. This also helps to derive the posterior using exact solutions without relying on numerical or approximation methods. For a Bernoulli model, we have already discussed earlier in Lecture 2, which reflects: \\[\\begin{align}\n\\text{Distribution: } & y \\sim \\text{Ber}(\\theta);\\\\\n\\text{Likelihood: } & Y = \\sum^n y \\sim \\text{Binomial}(n,\\theta);\\\\\n\\text{Prior: } & \\theta \\sim \\text{Beta}(a,b);\\\\\n\\text{Posterior: } & \\theta|Y \\sim \\text{Beta}(a+\\sum^n y,b+n-\\sum^n y);\\\\\n\\end{align}\\]\nAn untraceable solution emerges in situations where the posterior distribution cannot be expressed in a closed-form expression. This phenomenon occurs when the likelihood function and the prior distribution are incompatible, resulting in the emergence of complex integrals within Bayes’ theorem that are analytically intractable.\nFor example, use of non-conjugate priors. Often complex likelihood functions, such as those involving hierarchical models, mixture models, or high-dimensional data also yields a posterior form of distribution with untraceable solutions, even if we consider conjugate priors for the model parameters. For a non-Gaussian likelihood, use of a uniform prior also yields untraceable solution.\n\n\n\n\n\n\n\n\n\n\nTraceable Solutions\nUntraceable Solutions\n\n\n\n\nPosterior\nClosed-form expression\nRequires approximation or sampling\n\n\nPrior-Likelihood Relation\nOften relies on conjugacy\nNo conjugacy needed\n\n\nComputation\nExact and straightforward\nComputationally intensive\n\n\nFlexibility\nLimited (conjugate priors only)\nHigh (any prior-likelihood combination)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#mcmc-convergence-diagnostics",
    "href": "M02_2.html#mcmc-convergence-diagnostics",
    "title": "4  Tools and Generative Models",
    "section": "4.7 MCMC convergence diagnostics",
    "text": "4.7 MCMC convergence diagnostics\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#prior-and-posterior-predictive-checks",
    "href": "M02_2.html#prior-and-posterior-predictive-checks",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.6 Prior and Posterior Predictive Checks",
    "text": "4.6 Prior and Posterior Predictive Checks\n\n\nasdf\nhttps://statswithr.github.io/book/inference-and-decision-making-with-multiple-parameters.html#sec:NG-predictive",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-development",
    "href": "M03_1.html#model-development",
    "title": "6  Bayesian Regressions - Part 1",
    "section": "6.4 Model Development",
    "text": "6.4 Model Development\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayesian Regressions - Part 1**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#prior-sensitivity",
    "href": "M03_1.html#prior-sensitivity",
    "title": "6  Bayesian Regressions - I",
    "section": "6.7 Prior Sensitivity",
    "text": "6.7 Prior Sensitivity\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayesian Regressions - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#comparison-with-classical-approach",
    "href": "M03_1.html#comparison-with-classical-approach",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.7 Comparison with Classical Approach",
    "text": "5.7 Comparison with Classical Approach\n\n\nasdf\nuse rstan, rstanarm or brms",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#model-development",
    "href": "M03_2.html#model-development",
    "title": "7  Bayesian Regressions - II",
    "section": "7.4 Model Development",
    "text": "7.4 Model Development\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#prior-sensitivity",
    "href": "M03_2.html#prior-sensitivity",
    "title": "7  Bayesian Regressions - II",
    "section": "7.5 Prior Sensitivity",
    "text": "7.5 Prior Sensitivity\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#comparison-with-classical-approach",
    "href": "M03_2.html#comparison-with-classical-approach",
    "title": "7  Bayesian Regressions - II",
    "section": "7.6 Comparison with Classical Approach",
    "text": "7.6 Comparison with Classical Approach\nasdf\nVedio\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#clustered-data-multilevel-modles",
    "href": "M04_1.html#clustered-data-multilevel-modles",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.4 Clustered Data & Multilevel Modles",
    "text": "7.4 Clustered Data & Multilevel Modles\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#varying-intercept-model",
    "href": "M04_1.html#varying-intercept-model",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.5 Varying Intercept Model",
    "text": "7.5 Varying Intercept Model\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#varying-slope-model",
    "href": "M04_1.html#varying-slope-model",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "7.6 Varying Slope Model",
    "text": "7.6 Varying Slope Model\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#conditional-and-marginal-models",
    "href": "M04_2.html#conditional-and-marginal-models",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.4 Conditional and Marginal Models",
    "text": "8.4 Conditional and Marginal Models\nasdf",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#comparison-with-classical-approach",
    "href": "M04_2.html#comparison-with-classical-approach",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.5 Comparison with Classical Approach",
    "text": "8.5 Comparison with Classical Approach\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#bayesian-perspective-of-rct",
    "href": "M05_1.html#bayesian-perspective-of-rct",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.4 Bayesian Perspective of RCT",
    "text": "9.4 Bayesian Perspective of RCT\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#bayesian-decision-rules-for-rct",
    "href": "M05_1.html#bayesian-decision-rules-for-rct",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.5 Bayesian Decision Rules for RCT",
    "text": "9.5 Bayesian Decision Rules for RCT\n\n\nBayesian Decision Rule: ref: Berry book, sec 2.5.2, page 66",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#comparison-with-classical-approach",
    "href": "M05_1.html#comparison-with-classical-approach",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "9.6 Comparison with Classical Approach",
    "text": "9.6 Comparison with Classical Approach\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#adaptivity-in-rct",
    "href": "M05_2.html#adaptivity-in-rct",
    "title": "10  Size Matters! Part - II",
    "section": "10.4 Adaptivity in RCT",
    "text": "10.4 Adaptivity in RCT\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#bayesian-predictive-probability",
    "href": "M05_2.html#bayesian-predictive-probability",
    "title": "10  Size Matters! Part - II",
    "section": "10.5 Bayesian Predictive Probability:",
    "text": "10.5 Bayesian Predictive Probability:\nref: Berry book, sec: 2.5.1 page 64",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#stopping-rules-for-adaptation",
    "href": "M05_2.html#stopping-rules-for-adaptation",
    "title": "10  Size Matters! Part - II",
    "section": "10.6 Stopping Rules for Adaptation",
    "text": "10.6 Stopping Rules for Adaptation\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#prior-influence",
    "href": "M05_2.html#prior-influence",
    "title": "10  Size Matters! Part - II",
    "section": "10.7 Prior Influence",
    "text": "10.7 Prior Influence\n\n\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#criterion-based",
    "href": "M06_1.html#criterion-based",
    "title": "12  Bayesian Model Choice",
    "section": "12.4 Criterion-Based",
    "text": "12.4 Criterion-Based\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Bayesian Model Choice**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#shrinkage-based",
    "href": "M06_1.html#shrinkage-based",
    "title": "12  Bayesian Model Choice",
    "section": "12.5 Shrinkage-Based",
    "text": "12.5 Shrinkage-Based\nasdf\nref: lambert page 225, sec: 10.5 (AIC, DIC, WAIC, LOO-CV)\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Bayesian Model Choice**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#missing-data",
    "href": "M06_2.html#missing-data",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.4 Missing Data",
    "text": "12.4 Missing Data\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#measurement-errors",
    "href": "M06_2.html#measurement-errors",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.5 Measurement Errors",
    "text": "12.5 Measurement Errors\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#approximate-bayesian-computation",
    "href": "M06_2.html#approximate-bayesian-computation",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.6 Approximate Bayesian Computation",
    "text": "12.6 Approximate Bayesian Computation\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-probabilities",
    "href": "M01_1.html#dual-factor-probabilities",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.6 Dual-Factor Probabilities",
    "text": "1.6 Dual-Factor Probabilities\n\nKruschke (2014)\nBayesians do not imagine repetitions of an experiment in order to define and specify a probability. Probability is merely taken as a measure of certainty in a particular belief. This implies that the probability is used as a way to quantify how certain we are about a belief or an event happening. Before diving into Bayes’ theorem, let’s first understand some key concepts in probability distributions, which I assume you have already learned in the PSI unit.\nThere are many situations in which we are interested in the conjunction of two outcomes. As a specific example for developing these ideas, consider a situation where the probabilities of various combinations of people’s eye color and hair color. The data come from a particular convenience sample (Snee, 1974), and are not meant to be representative of any larger population.\n\n\n\n\n\nDual-Factor (Snee, 1974); Kruschke (2014)\n\n\n\n\nThe above Table considers four possible eye colors, listed in its rows, and four possible hair colors, listed across its columns. In each of its main cells, the table indicates the joint probability of particular combinations of eye color and hair color. For example, the top-left cell indicates that the joint probability of brown eyes and black hair is 0.11 (i.e., 11%). Notice that not all combinations of eye color and hair color are equally likely. For example, the joint probability of blue eyes and black hair is only 0.03 (i.e., 3%).\nWe may be interested in the probabilities of the eye colors overall, collapsed across hair colors. These probabilities are indicated in the right margin of the table, and they are therefore called marginal probabilities. They are computed simply by summing the joint probabilities in each row, to produce the row sums. For example, the marginal probability of green eyes, irrespective of hair color, is 0.11. The joint values indicated in the table do not all sum exactly to the displayed marginal values because of rounding error from the original data.\nWe often want to know the probability of one outcome, given that we know another outcome is true. For example, suppose I sample a person at random from the population. Suppose I tell you that this person has blue eyes. Conditional on that information, what is the probability that the person has blond hair (or any other particular hair color)? It is intuitively clear how to compute the answer: We see from the blue-eye row of the above Table that the total (i.e., marginal) amount of blue-eyed people is 0.36, and that 0.16 of the population has blue eyes and blond hair. Therefore, of the 0.36 with blue eyes, the fraction 0.16/0.36 has blond hair. In other words, of the blue-eyed people, 45% have blond hair.We also note that of the blue-eyed people, 0.03/0.36 = 8% have black hair.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#exact-inference",
    "href": "M01_2.html#exact-inference",
    "title": "3  Bayesian Inference",
    "section": "3.7 Exact Inference",
    "text": "3.7 Exact Inference\n\nThe solutions for posterior distribution explained in the previous section are based on exact inference using closed form of the posterior distribution. The exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given conjugate prior distribution and data likelihood. For instance, in the previous example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging. In this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in Module 2, Lecture 4.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#prior-and-posterior-distributions",
    "href": "M01_2.html#prior-and-posterior-distributions",
    "title": "3  Bayesian Inference",
    "section": "3.6 Prior and Posterior Distributions",
    "text": "3.6 Prior and Posterior Distributions\nGelman et al. (2013)\n\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst we will provide some examples on how prior distributions can be useful in real-world applications, especially considering health and medical data. We have already know that the prior distribution enables researchers to integrate previous knowledge or expert opinions into their statistical models, thereby improving the precision of their decisions. For example, we might be interested in tailoring treatments and interventions based on prior knowledge, enhancing their personalization and efficacy for individual patients. For instance, if historical data indicates a 70% effectiveness rate for a certain drug in patients with similar profiles, a prior distribution (informative) can incorporate this information to predict the likelihood of success in a new patient. The synthesizing of prior knowledge with current data yields more reliable conclusions. For example, if new data shows a 80% effectiveness rate, Bayesian method leads to a refined probability of treatment success, say 75%. Use of prior information is also beneficial when historical data is sparse or in the early stages of research on new treatments. In such scenarios, the prior distribution could start with a neutral assumption (non-informative), such as a 50% effectiveness rate, and adjust as more information becomes available.\nNow we will explore some situations for estimating posterior distributions using priors, in the context of statistical models, where we want to estimate only a single parameter of the model. We will explain these models where the posterior distribution has a closed form of distribution based on data and prior distributions. Fortunately, there are models where for a particular choice of prior results in a posterior that has the same type of distribution as the prior. The property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. This closed form offers easy probability calculations, simplifying updates with new data and contrasting with methods needing numerical approximations for precise inference, which we will explain more later in this lecture.\n\n3.6.1 Binomial Model\n\nWe can write Binomial model with parameters \\(\\theta\\) and \\(n\\) trials as \\[\\begin{align}\np(y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\end{align}\\] If we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\), the write the distribution as: \\[\\begin{align}\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\end{align}\\] where, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write \\[\\begin{align}\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\end{align}\\] With some simple calculations, we can write the marginal likelihood as: \\[\\begin{align}\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\end{align}\\] Hence, we get the analytical form of the posterior distribution of \\(\\theta\\) as: \\[\\begin{align}\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\end{align}\\] which follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).\nTo explore this with example, let us consider the example we explained earlier on the effectiveness rate of a certain drug in patients with similar profiles. Here, we write the prior distribution of 70% effectiveness, i.e., \\(p(\\theta)=0.7\\). To reflect this probability into Beta prior distribution hyper-parameters \\(a\\) and \\(b\\), we can consider \\(a=7\\) and \\(b=3\\). This is derived from the mean of the Beta distribution, i.e., \\(\\frac{a}{a+b}=0.7\\). Note that there are also other combinations of \\(a\\) and \\(b\\) values that can also lead to the probability 0.7.\nNow, if new data shows a 80% effectiveness rate, where we collect data from \\(n=10\\) individuals. Then we can write the posterior distribution of \\(\\theta\\), i.e., \\(p(\\theta|y)\\) as: \\[\\begin{align}\n\\text{Beta}(a+y,b+n-y) &= \\text{Beta}(7+8,3+10-8) \\\\\n&= \\text{Beta}(15,5)\n\\end{align}\\] This yields a mean \\(\\frac{15}{15+5}=0.75\\). Thus, based on the mean of the Beta distribution, we can say analytically, Bayesian method leads to a 75% refined probability of treatment success.\nexplain with R code …",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#preparation-for-week-4",
    "href": "M02_1.html#preparation-for-week-4",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.15 Preparation for Week 4",
    "text": "4.15 Preparation for Week 4\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.\n\n\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#causality-and-bayesian-model",
    "href": "M02_1.html#causality-and-bayesian-model",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.7 Causality and Bayesian Model",
    "text": "4.7 Causality and Bayesian Model\n\nCausal inference requires the establishment of a causal model that is separate from a Bayesian model, given that observational data alone do not suffice. This is widely accepted across different philosophical perspectives. Nonetheless, interpretations differ considerably. The most conservative viewpoint treats “causation” as an unprovable notion. A slightly less conservative approach posits that causation can be inferred only under stringent conditions involving randomization and experimental control. However, many scientific investigations cannot be feasibly examined through experimental study. Other cases might be feasible but raise ethical concerns. In disciplines like health and medicine, the dominant approach involves incorporating various “control” variables into a statistical model, observing changes in estimates, and then developing a causal narrative. This concept is based on the assumption that only omitted variables can lead to incorrect conclusions about causation. However, variables that are included can also lead to confusion. When constructing a causal model that appears to make accurate predictions might still mislead us about causation. If such a model is used to design an intervention, it is likely to result in inaccurate outcomes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html",
    "href": "M02_1.html",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "",
    "text": "3.1 Learning Outcomes\nL02: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\nL04: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M01_1.html",
    "href": "M01_1.html",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "",
    "text": "1.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nIn today’s lecture we will:\n– Understand Bayesian philosophy.\n– Describe the motivation of doing Bayesian analysis.\n– Understand the difference between Bayesian and classical statistical methods.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html",
    "href": "M01_2.html",
    "title": "2  Bayesian Dreams: Inference",
    "section": "",
    "text": "2.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Describe Bayesian inference using probability distributions.\n– Understand Bayesian learning.\n– Draw DAG for Bayesian models.\n– Formulate examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_2.html",
    "href": "M02_2.html",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "",
    "text": "4.1 Learning Outcomes\nL03:\nL04:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#dag",
    "href": "M01_2.html#dag",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.8 DAG",
    "text": "2.8 DAG\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\nIn the context of Bayesian modeling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the Bernoullie model example, we can write a DAG as:\n\n\n\n\n\ngraph LR\n    subgraph \"Hyper-parameter\"\n        C[\"$$a$$\"]:::inputNode\n        D[\"$$b$$\"]:::inputNode\n    end\n    subgraph \"Parameter\"\n        A[\"$$\\\\theta$$\"]:::processNode\n    end\n    subgraph \"Outcome\"\n        Y[\"$$y$$\"]:::outputNode\n    end\n\n    C --&gt; A\n    D --&gt; A\n    A --&gt; Y\n\n    classDef inputNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef processNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef outputNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef subgraphTitle fill:none,stroke:none,color:#000,font-weight:bold;\n    \n\n\n\n\n\n\nThis is a simple graphical model, where \\(y\\) depends on \\(\\theta\\), with \\(\\theta\\) being a logical function of hyper-parameters \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#causality-and-bayesian-model",
    "href": "M01_2.html#causality-and-bayesian-model",
    "title": "3  Bayesian Inference",
    "section": "3.8 Causality and Bayesian Model",
    "text": "3.8 Causality and Bayesian Model\n\nCausal inference requires the establishment of a causal model that is separate from a Bayesian model, given that observational data alone do not suffice. This is widely accepted across different philosophical perspectives. Nonetheless, interpretations differ considerably. The most conservative viewpoint treats “causation” as an unprovable notion. A slightly less conservative approach posits that causation can be inferred only under stringent conditions involving randomization and experimental control. However, many scientific investigations cannot be feasibly examined through experimental study. Other cases might be feasible but raise ethical concerns. In disciplines like health and medicine, the dominant approach involves incorporating various “control” variables into a statistical model, observing changes in estimates, and then developing a causal narrative. This concept is based on the assumption that only omitted variables can lead to incorrect conclusions about causation. However, variables that are included can also lead to confusion. When constructing a causal model that appears to make accurate predictions might still mislead us about causation. If such a model is used to design an intervention, it is likely to result in inaccurate outcomes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#estimand-estimator-estimate",
    "href": "M01_2.html#estimand-estimator-estimate",
    "title": "3  Bayesian Inference",
    "section": "3.9 Estimand, Estimator & Estimate",
    "text": "3.9 Estimand, Estimator & Estimate\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\nFor example, suppose we are interested in the mean height of all male adults in the United States. Our estimand is “the mean height of all male adults in the United States”. A foolproof way to find this mean exactly would be to measure the height of each and every male adult in the United States and compute the mean. But that sounds too hard, so instead we decide to estimate the mean height by taking a random sample of male adults in the United States and measuring the height of each individual. Suppose we take a random sample of 100 adult men in the United States and measure their heights. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand.\nThe most obvious thing to do would be to compute the sample average of the heights. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average is 70 inches. Then 70 inches is the estimate of our estimand provided by the “sample average” estimator.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#correlation-vs-causation",
    "href": "M01_2.html#correlation-vs-causation",
    "title": "3  Bayesian Inference",
    "section": "3.10 Correlation vs Causation",
    "text": "3.10 Correlation vs Causation",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-dag-models",
    "href": "M01_2.html#bayesian-dag-models",
    "title": "3  Bayesian Inference",
    "section": "3.11 Bayesian DAG & Models",
    "text": "3.11 Bayesian DAG & Models\nasdf - graphical representations of the probabilistic relationships between variables and parameters",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-causal-inference",
    "href": "M01_2.html#bayesian-causal-inference",
    "title": "3  Bayesian Inference",
    "section": "3.12 Bayesian Causal Inference",
    "text": "3.12 Bayesian Causal Inference\nref: https://onlinelibrary.wiley.com/doi/10.1002/sim.8761\nref: https://bookdown.org/paul/applied-causal-analysis/\nref: paper: https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0153",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-and-posterior-distributions",
    "href": "M02_1.html#prior-and-posterior-distributions",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.4 Prior and Posterior Distributions",
    "text": "4.4 Prior and Posterior Distributions\nGelman et al. (2013)\n\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst we will provide some examples on how prior distributions can be useful in real-world applications, especially considering health and medical data. We have already know that the prior distribution enables researchers to integrate previous knowledge or expert opinions into their statistical models, thereby improving the precision of their decisions. For example, we might be interested in tailoring treatments and interventions based on prior knowledge, enhancing their personalization and efficacy for individual patients. For instance, if historical data indicates a 70% effectiveness rate for a certain drug in patients with similar profiles, a prior distribution (informative) can incorporate this information to predict the likelihood of success in a new patient. The synthesizing of prior knowledge with current data yields more reliable conclusions. For example, if new data shows a 80% effectiveness rate, Bayesian method leads to a refined probability of treatment success, say 75%. Use of prior information is also beneficial when historical data is sparse or in the early stages of research on new treatments. In such scenarios, the prior distribution could start with a neutral assumption (non-informative), such as a 50% effectiveness rate, and adjust as more information becomes available.\nNow we will explore some situations for estimating posterior distributions using priors, in the context of statistical models, where we want to estimate only a single parameter of the model. We will explain these models where the posterior distribution has a closed form of distribution based on data and prior distributions. Fortunately, there are models where for a particular choice of prior results in a posterior that has the same type of distribution as the prior. The property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. This closed form offers easy probability calculations, simplifying updates with new data and contrasting with methods needing numerical approximations for precise inference, which we will explain more later in this lecture.\n\n4.4.1 Binomial Model\n\n…\nTo explore this with example, let us consider the example we explained earlier on the effectiveness rate of a certain drug in patients with similar profiles. Here, we write the prior distribution of 70% effectiveness, i.e., \\(p(\\theta)=0.7\\). To reflect this probability into Beta prior distribution hyper-parameters \\(a\\) and \\(b\\), we can consider \\(a=7\\) and \\(b=3\\). This is derived from the mean of the Beta distribution, i.e., \\(\\frac{a}{a+b}=0.7\\). Note that there are also other combinations of \\(a\\) and \\(b\\) values that can also lead to the probability 0.7.\nNow, if new data shows a 80% effectiveness rate, where we collect data from \\(n=10\\) individuals. Then we can write the posterior distribution of \\(\\theta\\), i.e., \\(p(\\theta|y)\\) as: \\[\\begin{align}\n\\text{Beta}(a+y,b+n-y) &= \\text{Beta}(7+8,3+10-8) \\\\\n&= \\text{Beta}(15,5)\n\\end{align}\\] This yields a mean \\(\\frac{15}{15+5}=0.75\\). Thus, based on the mean of the Beta distribution, we can say analytically, Bayesian method leads to a 75% refined probability of treatment success.\nexplain with R code …",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Directed Acyclic Graph (DAG)**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#exact-inference",
    "href": "M02_1.html#exact-inference",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.4 Exact Inference",
    "text": "3.4 Exact Inference\n\nThe solutions for posterior distribution explained in the previous section for Bernoulli model are based on exact inference using closed form of the posterior distribution.\nThe exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given conjugate prior distribution and data likelihood. In the Bernoulli model example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging.\nIn this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in our next lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#more-insights-into-prior-distribution",
    "href": "M02_1.html#more-insights-into-prior-distribution",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.5 More Insights into Prior Distribution",
    "text": "3.5 More Insights into Prior Distribution\n\n\n\nUnderstanding the appropriate selection of prior distributions in modeling is crucial. Prior distributions can be categorised as informative, non-informative, weakly informative, or based on expert judgment. This section explores into these various types of prior distributions, examining their applicability and relevance.\n\n3.5.1 Informative Prior Distribution\n\nAn informative prior is a type of prior distribution that is based on information that provides significant idea about the parameters being estimated. Since informative priors reflect more certainty, they tend to be more concentrated around a certain value. The informative prior has a strong impact on the posterior distribution, especially when the data is limited or noisy. In cases with substantial data, the posterior may still be mostly driven by the observed data, but the prior will still play a role in shaping the final outcome.\nOur previous example on the efficacy rate of a certain vaccine in patients with similar profiles is an example of having an informative prior. Now, let’s consider that the efficacy rate of the vaccine range from 70% to 90%. Now in a pilot study we observe 16 successes out of 20 trials, i.e., the efficacy rate is still 80%. Hence, we can easily get the posterior distribution of the efficacy rate from \\(\\text{Beta}(24, 6)\\) distribution, if we consider the prior average success rate of 80%, which can be calculated from the range 70% to 90%. Numerically, we can plot the prior and posterior distributions using R code as:\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 8\nb_prior &lt;- 2\nn &lt;- 20  \nk &lt;- 16  \na_post &lt;- a_prior + k\nb_post &lt;- b_prior + (n - k)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Beta-Binomial Model: Prior vs Posterior Distributions\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nThe informative prior in this example allows you to start with a reasonable expectation (from historical data) and update it with observed results. This is especially useful when the sample size is small or the observed data alone might not be robust enough to guide decision-making.\n\n\n\n3.5.2 Non-informative Prior Distribution\n\nA non-informative prior (also known as an uninformative prior or objective prior) is a type of prior distribution used in Bayesian statistics that is intended to have minimal influence on the posterior distribution. It reflects a lack of specific prior knowledge about the parameter of interest, allowing the data to drive the inference as much as possible.\nNon-informative priors are often used when the goal is to let the observed data dominate the analysis. These are useful in cases where objectivity is critical or where prior knowledge is genuinely unavailable, but they may not always be appropriate when prior information exists.\nNon-informative priors often reflect a high degree of uncertainty about the parameter’s value, and might end up with parameter estimates similar to the estimates obtained from frequentist approach.\nBefore going into details, let’s explain some prior distribution concepts:\nImproper Priors: Prior distributions that do not integrate to 1 and therefore are not valid probability distributions but can still be useful for inference if they lead to proper posterior distributions. For instance, \\(p(\\theta) \\propto 1/\\theta\\) for scale parameters.\nFlat Priors: Priors that are constant over the range of the parameter (often used for parameters with bounded support).\nNow, we will discuss some common approaches to defining non-informative priors:\n\nUniform Priors:\n\nUniform priors assign equal probability across all possible values of a parameter, assuming no preference for any particular value (e.g., (p() $), where for a probability parameter \\(\\theta\\) in a Bernoulli model, a uniform prior on \\(\\text{Unif}[0, 1]\\) implies no prior belief about the likelihood of success. From the plot below we cannot visualize the likelihood function (scaled), as the posterior distribution and likelihood functions are same.\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100       \ntrue_theta &lt;- 0.8  \ndata &lt;- rbinom(n, size = 1, prob = true_theta)  \nsuccesses &lt;- sum(data)  \nfailures &lt;- n - successes\n\n# Uniform prior: P(theta) ∝ 1 on [0, 1]\n# The uniform prior is equivalent to Beta(1, 1).\n\n# Posterior distribution:\n# Given prior Beta(a, b) and likelihood from Binomial(n, theta),\n# Posterior is Beta(a + successes, b + failures)\n\na_prior &lt;- 1  \nb_prior &lt;- 1  \na_post &lt;- a_prior + successes\nb_post &lt;- b_prior + failures\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(successes, size = n, prob = theta_vals)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nprior_density &lt;- dbeta(theta_vals, a_prior, b_prior)\nposterior_density &lt;- dbeta(theta_vals, a_post, b_post)\n\n# Scale likelihood for comparison (to make it visually compatible)\nlikelihood_scaled &lt;- likelihood / max(likelihood) * max(posterior_density)\n\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, posterior_density, likelihood_scaled),\n  type = rep(c(\"Prior (Uniform)\", \"Posterior\", \"Likelihood (Scaled)\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior, Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))\n\n\n\n\n\n\n\n\n\n\nJeffreys Priors:\n\nA non-informative prior derived based on the Fisher information matrix, ensuring invariance under reparameterisation. This prior is proportional to the square root of the determinant of the Fisher information: \\(p(\\theta) \\propto \\sqrt{I(\\theta)}\\), where \\(I(\\theta)\\) is the Fisher information.\nBinomial distribution\nLet us now explain this using Binomial distribution, where we observe 16 successes out of 20 trials, i.e., the efficacy rate is 80% observed from a pilot survey.\n\n\nCode\nlibrary(ggplot2)\njeffreys_prior &lt;- function(theta) {\n  return(1 / sqrt(theta * (1 - theta)))  \n}\nlikelihood &lt;- function(theta, k, n) {\n  return(choose(n, k) * theta^k * (1 - theta)^(n - k))  \n}\nn &lt;- 20  \nk &lt;- 16 \n# Avoid 0 and 1 for numerical stability\ntheta_vals &lt;- seq(0.01, 0.99, length.out = 1000)  \nprior_density &lt;- jeffreys_prior(theta_vals)\nlikelihood_density &lt;- likelihood(theta_vals, k, n)\nposterior_density &lt;- likelihood_density * prior_density\n# Normalize posterior\nposterior_density &lt;- posterior_density / sum(posterior_density)  \nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood\", \"Posterior\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Binomial Model\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nNormal Distribution\nLet’s consider a normal distribution with known variance \\(\\sigma^2\\). We write the Fisher information for the mean parameter \\(\\mu\\) as \\(I(\\mu) =\\frac{n}{\\sigma^2}\\), where \\(n\\) is the sample size. Hence, we write the Jeffreys prior for \\(\\mu\\) as the proportional to the square root of the Fisher information, i.e., \\[\\begin{align}\np(\\mu) \\propto \\sqrt{I(\\mu)}\n\\end{align}\\] Thus, the prior is uniform over the parameter space. We write the posterior for \\(\\mu\\) follows normal distribution with mean \\(\\bar{y}\\) (sample mean) and variance \\(\\sigma^2/n\\).\nNow let us explain with an eample. Suppose a new antihypertensive drug is tested in a clinical trial, and researchers measure the reduction in systolic blood pressure (in mmHg) among patients. Where, most patients experience a blood pressure reduction of around 5 mmHg, but there is natural variability, which is about 2 standard deviation. Now considering Jeffreys non-infmative prior, we can get the posterior distribution of the systolic blood pressure.\nFollowing this we draw the density plots using R code as follows:\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100        \ntrue_mu &lt;- 5    \nsigma &lt;- 2      \ndata &lt;- rnorm(n, mean = true_mu, sd = sigma)  \n# Fisher information for the mean is: I(mu) = n / sigma^2\nfisher_info &lt;- n / sigma^2 \n# Jeffreys prior is proportional to sqrt(I(mu)). For the mean of a normal distribution, it's constant, i.e., uniform over the parameter space\njeffreys_prior &lt;- function(mu) {\n  return(rep(1, length(mu)))  \n}\n\nsample_mean &lt;- mean(data)\nposterior_mean &lt;- sample_mean\nposterior_sd &lt;- sigma / sqrt(n)\n\nlikelihood &lt;- function(mu) {\n  return(dnorm(mu, mean = sample_mean, sd = sigma / sqrt(n)))\n}\n\nmu_vals &lt;- seq(true_mu - 3 * sigma, true_mu + 3 * sigma, length.out = 1000)\n\nprior_density &lt;- jeffreys_prior(mu_vals)\nlikelihood_density &lt;- likelihood(mu_vals)\nposterior_density &lt;- dnorm(mu_vals, mean = posterior_mean, sd = posterior_sd)\n\nlikelihood_density &lt;- likelihood_density / max(likelihood_density) * max(posterior_density)\n\nplot_data &lt;- data.frame(\n  mu = rep(mu_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood (Scaled)\", \"Posterior\"), each = length(mu_vals))\n)\nggplot(plot_data, aes(x = mu, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior, Likelihood, and Posterior Distributions\",\n    x = expression(mu),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nDespite being called “non-informative,” their choice can still involve subjective decisions. Some priors, like uniform priors, may appear non-informative in one parameterisation but informative in another (e.g., uniform in \\(\\theta\\) vs. \\(\\log(\\theta)\\)). Improper priors can lead to issues in interpretation and sometimes require careful mathematical justification.\n\n\n3.5.3 Weakly Informative Prior Distribution\n\nA weakly informative prior distribution in Bayesian statistics is characterized as proper, yet it is designed to provide information that is intentionally less robust than the actual prior knowledge available. This type of prior serves as a compromise between a non-informative prior, which imposes minimal assumptions about the parameter, and a strongly informative prior, which incorporates extensive prior knowledge.\nBy occupying this middle ground, weakly informative priors offer constrained but meaningful insights into the parameters of interest, allowing for natural constraints inherent in the problem.\nLet’s explain this with the example of efficacy rate of the vaccine. Now assume that the success rate of the vaccine is about 50%, and we can consider the prior distribution as \\(\\text{Beta}(2,2)\\). This symmetric pattern favours the efficacy rate around 0.5 but also allows a wide range of plausible values. This prior avoids extreme values (near 0 or 1) unless strongly supported by the data. Now, suppose 30 trials out of \\(n = 50\\) shows success. Hence, we get the posterior distribution as \\(\\text{Beta}(32,22)\\). Below you can see the density plots of the distributions.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2\nb_prior &lt;- 2\nn &lt;- 50\ny &lt;- 30\na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\np &lt;- seq(0, 1, length.out = 1000)\n\nprior &lt;- dbeta(p, a_prior, b_prior)\n# Scaled for visualisation\nlikelihood &lt;- dbinom(y, n, p) * 100  \nposterior &lt;- dbeta(p, a_post, b_post)\n\nplot_data &lt;- data.frame(\n  p = p,\n  Likelihood = likelihood,\n  Posterior = posterior,\n  Prior = prior\n)\ndata_long &lt;- reshape2::melt(plot_data, id = \"p\", variable.name = \"Distribution\", value.name = \"Density\")\nggplot(data_long, aes(x = p, y = Density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior (weakly informative), Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nWeakly informative priors are common in modern Bayesian modeling, where it balances interpretability, robustness, and computational efficiency. We will explain more about the weakly informative prior when we will learn about Bayesian regression models.\n\n\n\n\n\n  \n      \n         2  **Bayesian Dreams: Inference**\n                \n  \n  \n      \n        4  **Chaotics: Generative Models and Tools**",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-language",
    "href": "M01_2.html#bayesian-language",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.6 Bayesian Language",
    "text": "2.6 Bayesian Language\n\n\n\nWe will learn a common language for illustrating and denoting the Bayesian models. This will help us to develop and write complex Bayesian models in a simpler way that we will learn later in this course.\nLet’s explain this using a Bernoulli model with parameter \\(\\theta\\). We write the probability distribution in the following form: \\[\\begin{align}\ny \\sim \\text{Bernoulli}(\\theta)\n\\end{align}\\] This refers to \\(y\\) follows Bernoulli distribution with parameter \\(\\theta\\). We write the likelihood function in the following form (which is also in the form of Binomial distribution):\n\\[\np(y|\\theta) \\propto   \\theta^y (1-\\theta)^{n-y}\n\\]\nNote that we replaced “=” with “\\(\\propto\\)” as the term \\(\\begin{pmatrix}n\\\\y \\end{pmatrix}\\) is a constant, which does not depend on the parameter \\(\\theta\\). Now, considering prior conjugacy, we assume that \\(\\theta\\) follows a Beta distribution with shape parameters \\(a\\) and \\(b\\) and we write \\(\\theta \\sim \\text{Beta}(a,b)\\) and define\n\\[\np(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\n\\]\nThus, the posterior distribution of \\(\\theta\\) can be written as \\(\\theta|y \\sim \\text{Beta}(a+y,b+n-y)\\) and defined as:\n\\[\np(\\theta|y) \\propto \\theta^y (1-\\theta)^{n-y}\\theta^{a-1}(1-\\theta)^{b-1} =\\theta^{y+a-1} (1-\\theta)^{n-y+b-1}\n\\]\n\\[\np(\\theta|y) \\propto \\theta^{y+a-1} (1-\\theta)^{n-y+b-1}\n\\]\nWe have again included the “\\(\\propto\\)” term, as we will learn in our next two lectures that the marginal distribution of the data, i.e., \\(p(y)\\) does not depend on the model parameter and can therefore be omitted when obtaining the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#background",
    "href": "M01_1.html#background",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.2 Background",
    "text": "1.2 Background\n\n\n\n\n\nThomas Bayes (The IMS Bulletin, 1988, vol-17(3), pp.276-278)\n\n\n\n\nThomas Bayes, who is remembered through the term “Bayesian,” passed away in 1761 without having the chance to formally present or publish his groundbreaking findings. Two years after his death, it was Richard Price who, in 1763, introduced Bayes’ extraordinary work to the Royal Statistical Society. Bayes had been developing a probabilistic framework to tackle inverse problems. Later, Richard Price (1723–1791) and Pierre-Simon Laplace (1749–1827) played crucial roles in advancing and applying this transformative idea to practical real-world scenarios.\nTo fully understand the Bayesian framework, it is essential to become familiar with several key terms commonly used in Bayesian discussions, such as Bayesian inference, prior, posterior, and Bayesian modeling. Throughout this course, we will gradually explore and learn these fundamental concepts.\nBefore that, let’s start understanding the Bayesian philosophy.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#concepts-classical-vs.-bayesian",
    "href": "M01_1.html#concepts-classical-vs.-bayesian",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.5 Concepts: Classical vs. Bayesian",
    "text": "1.5 Concepts: Classical vs. Bayesian\n\n\nThroughout this course, we will provide relative comparisons of frequentists and Bayesian statistical methods, using examples. Let us now explain some key conceptual aspects of these two approaches.\nHistory:\n\nThe origins of Bayesian statistical inference trace back to the late 18th century, predating many modern methodologies. Its use continued into the 19th century, but after World War I, statisticians like Sir Ronald Fisher, who opposed Bayesian concepts, contributed to its decline. Fisher’s 1925 statistical handbook briefly mentioned Bayesian analysis—then known as “inverse probability”—further pushing it to the margins of mainstream statistics. However, in the latter half of the 20th century, Bayesian methods gradually regained acceptance. This resurgence was particularly driven by advancements in computational technology during the 1990s, which greatly expanded their practical applications.\nData and Parameter:\n\nData represents known elements, whereas parameters are unknown quantities inferred from data. Within the Bayesian framework, this distinction becomes less clear; a variable may be either observed or unobserved, yet it is governed by the same distribution function. Consequently, an assumption can serve as a “likelihood” or a “prior” depending on the context, without altering the model. This connection between certainty (data) and uncertainty (parameters) facilitates the management of measurement errors and missing data in modeling.\nReliable Inference:\n\nThere exists a notion that a specific number of observations is necessary for reliable statistical estimates. For example, at least 30 observations are typically required for a Gaussian distribution. This notion is rooted in traditional statistical inference, where methods are validated for large sample sizes, a concept known as asymptotic behavior.\nConversely, Bayesian estimates remain valid regardless of sample size. While larger samples are advantageous, Bayesian methods provide meaningful results even with limited data. However, they necessitate a careful selection of the “prior,” which significantly influences the final inference. An improperly chosen prior can skew conclusions. Understanding the world demands thoughtful consideration, without resorting to shortcuts.\nRole of Data:\n\nThe distinctions between Bayesian and non-Bayesian methodologies are notable, yet these differences can sometimes overshadow their underlying commonalities. In many Bayesian and non-Bayesian models, the most critical assumptions typically concern the likelihood functions and their connections with the parameters. These assumptions guide the inferences drawn from each dataset. As the sample size grows, the significance of the likelihood increases. This shared emphasis on likelihood clarifies why Bayesian and non-Bayesian inferences frequently yield similar results.\nFurthermore, a common misunderstanding regarding Bayesian data analysis and inference is the belief that they are exclusively defined by Bayes’ theorem. Any inferential method employing probability theory incorporates Bayes’ theorem. Numerous examples labeled as “Bayesian” often lack distinctive attributes and instead rely on observed data frequencies, resembling non-Bayesian methods. The distinctiveness of Bayesian techniques lies in their application of Bayes’ theorem to measure the uncertainty associated with theoretical constructs not directly observable, such as parameters and models. Both methodologies can produce robust inferences, although they are grounded in different principles and entail unique trade-offs.\n\n\n\n1.5.1 Example:\nTo demonstrate where the Bayesian method is clearly more advantageous than the Frequentist method, let’s consider a scenario with limited data. The Bayesian approach can make use of prior knowledge, whereas the frequentist method relies purely on the data at hand. In situations with small sample sizes or limited data, the Bayesian method can give more insightful results.\nImagine a scenario where we have a small sample size from a clinical trial and we want to test whether a drug is effective in treating a rare disease. We have only 5 patients, and the treatment shows that 3 out of 5 patients recovered. For the control group 1 out of 5 patients recovered. The issue here is that the data is very sparse, so relying on a frequentist approach may lead to an unreliable conclusion because of the small sample size. The p-value might not be informative because small sample sizes lead to high variability. Whereas, Bayesian approach combines the sparse data with prior knowledge, offering more stable and informed results (even we use a non-informative prior).\nFor frequentist, the proportion test will provide a p-value indicating if the recovery rates are significantly different between the two groups. For this example, we get p-value =0.52. Whereas, the Bayesian approach will provide the posterior distributions for the treatment and placebo recovery rates. Additionally, you will get the probability that the treatment recovery rate is higher than the placebo recovery rate as 0.882 based on the posterior samples.\nNow, if we know control group has about 70% recovery rate, and considering this prior information in Bayesian setting, we get that the orobability of treatment recovery rate greater than the control rate is 0.58.\n\n\n\n\n\nUniform Prior\n\n\n\n\n\n\n\n\n\nInformed Prior\n\n\n\n\nIn brief, Bayesian Method can incorporate prior knowledge (such as known rates from similar treatments of the diseases), improving estimates even with small sample sizes. Instead of a single p-value, Bayesian analysis gives a full posterior distribution, providing a richer interpretation of the uncertainty in the treatment’s effectiveness. Finally, Bayesian approach is less affected by small sample sizes, as it uses prior distributions and provides more stable estimates.\nWe will discuss more on the distributional aspect in our next lecture. Before that we explain the Bayesian theorem using probabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-models",
    "href": "M01_2.html#bayesian-models",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Bayesian Models",
    "text": "2.3 Bayesian Models\n\nWe have explained Bayes’ rule in our previous lecture, now we will see how Bayes rule can be structured for model development using parameter and data. In a Bayesian model, a parameter is a quantity that we assume is uncertain and assign a probability distribution to it. Unlike in frequentist statistics, where parameters are fixed but unknown, Bayesian statistics treats parameters as random variables with their own probability distributions.\nLet us denote \\(\\theta\\) as the parameter and \\(D\\) as data. Hence, we write a model using the data likelihood \\(p(D|\\theta)\\), and prior distribution \\(p(\\theta)\\) of the model parameter \\(\\theta\\) (note that we have changed the notation from \\(Pr(.)\\) to \\(p(.)\\), where \\(Pr(.)\\) refers to probability and \\(p(.)\\) refers to probability distribution):\n\\[\np(D|\\theta) \\times p(\\theta)\n\\]\nHence, Bayes rule can be used to understand the parameter values, given the data,, i.e.,\n\\[\np(\\theta|D)\n\\]\nThus, using the Dual-Factor table explained in previous lecture, we can write\n\n\n\n\n\nData-Parameter; Kruschke (2014)\n\n\n\n\nWhere, each cell of the table holds the joint probability density of the specific combination of parameter value \\(\\theta\\) and data value \\(D\\), denoted \\(p(D, \\theta)\\), and which we know can be algebraically re-expressed as \\(p(D|\\theta)\\times p(\\theta)\\).\nThus, we write the Bayes rule for data and parameter model as:\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)\\times p(\\theta)}{p(D)};\n\\]\nwhere,\n\\[\\begin{align}\np(D) &= \\sum_{\\theta^*} p(D|\\theta^*) p(\\theta^*); \\quad \\text{ if discrete}; \\\\\np(D) &= \\int p(D|\\theta^*) p(\\theta^*) \\text{d}\\theta^*; \\quad \\text{ if continuous};\n\\end{align}\\]\nHere, \\(p(\\theta)\\) is the prior information about \\(\\theta\\) without observing data; \\(p(D|\\theta)\\) is the likelihood, i.e., data could be generated with model parameter \\(\\theta\\); and \\(p(D)\\) is the marginal likelihood obtained from data by averaging across all possible parameters.\nThe posterior distribution of \\(\\theta\\) is:\n\\[\np(\\theta|D) = \\text{ Credibility of }\\theta\\text{ based on data and evidence}\n\\]\nThe posterior probability distribution \\(p(\\theta|D)\\) is the main goal of Bayesian inference. The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value, and this can be obtained by collecting more data.\nWe will now explore with examples on obtaining posterior distributions of the model parameter \\(\\theta\\) for different data distributions (i.e., models), e.g., binomial, normal and poisson distributions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#binomial-model",
    "href": "M01_2.html#binomial-model",
    "title": "3  Bayesian Inference",
    "section": "3.5 Binomial Model",
    "text": "3.5 Binomial Model\n\nWe can write Binomial model with parameters \\(\\theta\\) and \\(n\\) trials as \\[\\begin{align}\np(y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\end{align}\\] If we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\), the write the distribution as: \\[\\begin{align}\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\end{align}\\] where, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write \\[\\begin{align}\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\end{align}\\] With some simple calculations, we can write the marginal likelihood as: \\[\\begin{align}\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\end{align}\\] Hence, we get the analytical form of the posterior distribution of \\(\\theta\\) as: \\[\\begin{align}\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\end{align}\\] which follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-odds",
    "href": "M01_2.html#bayesian-odds",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.5 Bayesian Odds",
    "text": "2.5 Bayesian Odds\n\n\nWe can also think the question in terms of odds, such as what odds should I give for my guess? To define odds we can write\n\\[\n\\text{Odds of an event} = \\frac{Pr(\\text{event})}{1-Pr(\\text{event})}\n\\]\nLet’s revisit the medical practitioner example from our first lecture to clarify this concept. Imagine the practitioner assessing a patient for diabetes. Initially, they have a prior belief about the patient’s likelihood of having the condition. After conducting a blood test that reveals elevated sugar levels, this new evidence increases the probability of diabetes. The practitioner then updates their belief accordingly, refining their assessment based on the test results. We wanted to know, given this experimental evidence, how sure are the medical practitioner that their guess about the diabetes is accurate?\nThus, to reflect the medical practitioner example by Bayesian odds, we write:\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = \\text{Odds}(\\text{G}) \\times \\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})\\) is the odds of the guess is correct given the evidence, and \\(\\text{Odds}(\\text{G})\\) is the odds of the guess that we define:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{Pr(\\text{G=[+]})}{Pr(\\text{G=[-]})}\n\\]\nand \\(\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\\) is the ratio of evidence under the guess \\(\\text{G}\\).\nThis reflects\n\\[\n\\text{posterior or updated odds} = \\text{prior or initial odds}\\times \\text{relative explanatory power}\n\\]\nThis explains that evidence (i.e., data/information) always changes the outcome, which could be probability, probability distributions or odds or any other outcome of interest.\nExample\nLet us explain this again with the type-2 diabetes example, where based on the patient’s age, family history, and some initial symptoms, the medical practitioner guessed that there’s a 20% chance the patient has diabetes. This belief is a prior probability. The odds form of this probability is:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{0.2}{0.8} = 0.25\n\\]\nSo, the prior odds of the patient having diabetes are 1:4 (one in four) guessed by the medical practitioner.\nThe blood test result shows elevated sugar levels. To assess how much this result affects our belief, we use the ratio of evidence under the guess \\(\\text{G}\\) (also known as the likelihood ratio).\nSuppose the medical practitioner has historically observed from boold test that 85% of diabetic patients have elevated sugar levels, while only 10% of non-diabetic patients do (e.g., due to other factors). Hence, we write\n\\[\n\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})} = \\frac{0.85}{0.10} = 8.5\n\\]\nThis means the test result (elevated sugar) is 8.5 times more likely in someone with diabetes than in someone without it.\nNow, the posterior odds\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = 0.25 \\times 8.5 = 2.125\n\\]\nSo, the updated odds is 2.125:1, i.e., the patient is 2.125 times more likely to have diabetes than non-diabetic individuals after considering the test result.\nUsing the well known relationship between odds and probability, we can also get back the posterior probability from the posterior odds as:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})}{1+\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})} = \\frac{2.125}{1+2.125} = 0.68\n\\]\nIn summary we write, before the test, the medical practitioner believed there was a 20% chance of diabetes. After seeing the elevated blood sugar result, the probability increased to 68% (compare the example in lecture 1), because the test result is 8.5 times more likely in diabetic than non-diabetic individuals. The practitioner may now recommend further tests (e.g., an HbA1c test) before confirming the diagnosis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-distributions",
    "href": "M02_1.html#prior-distributions",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.3 Prior Distributions",
    "text": "3.3 Prior Distributions\n\n\n\n\nGelman et al. (2013)\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst we will provide some examples on how prior distributions can be useful in real-world applications, especially considering health and medical data.\nWe know that the prior distribution enables researchers to integrate previous knowledge or expert opinions into their statistical models, and hence improve the precision of their decisions. For example, we might be interested in tailoring treatments and interventions based on prior knowledge, enhancing their personalisation and efficacy for individual patients.\nSuppose, historical data indicates a 70% effectiveness rate for a certain drug in patients with similar profiles, a prior distribution (informative) can incorporate this information to predict the likelihood of success in a new patient. The synthesizing of prior knowledge with current data yields more reliable conclusions. For example, if new data shows a 80% effectiveness rate, Bayesian method leads to a refined probability of treatment success, say 75%.\nUse of prior information is also beneficial when historical data is sparse or in the early stages of research on new treatments. In such scenarios, the prior distribution could start with a neutral assumption (non-informative), such as a probability of effectiveness as 0.5, and adjust as more information becomes available.\nNow we will explore some situations for estimating posterior distributions using priors, in the context of statistical models, where we want to estimate only a single parameter of the model. We will explain these models where the posterior distribution has a closed form of distribution based on data and prior distributions. Interestingly, there are models where for a particular choice of prior results in a posterior that has the same type of distribution as the prior.\nThe property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. This closed form offers easy probability calculations, simplifying updates with new data and contrasting with methods needing numerical approximations for precise inference, which we will explain more later in this lecture.\n\n3.3.1 Bernoulli Model\n\n…\nTo explore this with example, let us consider the example we explained earlier on the efficacy rate of a certain vaccine in patients with similar profiles. Here, we write the prior distribution of 70% effectiveness, i.e., \\(p(\\theta)=0.7\\). To reflect this probability into Beta prior distribution hyper-parameters \\(a\\) and \\(b\\), we can consider \\(a=7\\) and \\(b=3\\). This is derived from the mean of the Beta distribution, i.e., \\(\\frac{a}{a+b}=0.7\\). Note that there are also other combinations of \\(a\\) and \\(b\\) values that can also lead to the probability 0.7.\nNow, if the new data shows a 80% efficacy rate, where we collect data from \\(n=10\\) individuals. Then we can write the posterior distribution of \\(\\theta\\), i.e., \\(p(\\theta|y)\\) as:\n\\[\\begin{align}\n\\text{Beta}(a+y,b+n-y) &= \\text{Beta}(7+8,3+10-8) \\\\\n&= \\text{Beta}(15,5)\n\\end{align}\\]\nThis yields a mean \\(\\frac{15}{15+5}=0.75\\). Thus, based on the mean of the Beta distribution, we can say analytically, Bayesian method leads to a 75% refined probability of treatment success.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#estimand-estimator-estimate",
    "href": "M02_1.html#estimand-estimator-estimate",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.8 Estimand, Estimator & Estimate",
    "text": "4.8 Estimand, Estimator & Estimate\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\nFor example, suppose we are interested in the mean height of all male adults in the United States. Our estimand is “the mean height of all male adults in the United States”. A foolproof way to find this mean exactly would be to measure the height of each and every male adult in the United States and compute the mean. But that sounds too hard, so instead we decide to estimate the mean height by taking a random sample of male adults in the United States and measuring the height of each individual. Suppose we take a random sample of 100 adult men in the United States and measure their heights. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand.\nThe most obvious thing to do would be to compute the sample average of the heights. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average is 70 inches. Then 70 inches is the estimate of our estimand provided by the “sample average” estimator.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M03_1.html",
    "href": "M03_1.html",
    "title": "5  Bayeswatch! Part - I",
    "section": "",
    "text": "5.1 Learning Outcomes",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#causality-and-bayesian-model",
    "href": "M03_1.html#causality-and-bayesian-model",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.4 Causality and Bayesian Model",
    "text": "5.4 Causality and Bayesian Model\n\n\n\nCausal inference requires the establishment of a causal model that is separate from a Bayesian model, given that observational data alone do not suffice. This is widely accepted across different philosophical perspectives. Nonetheless, interpretations differ considerably. The most conservative viewpoint treats “causation” as an unprovable notion. A slightly less conservative approach posits that causation can be inferred only under stringent conditions involving randomization and experimental control. However, many scientific investigations cannot be feasibly examined through experimental study. Other cases might be feasible but raise ethical concerns. In disciplines like health and medicine, the dominant approach involves incorporating various “control” variables into a statistical model, observing changes in estimates, and then developing a causal narrative. This concept is based on the assumption that only omitted variables can lead to incorrect conclusions about causation. However, variables that are included can also lead to confusion. When constructing a causal model that appears to make accurate predictions might still mislead us about causation. If such a model is used to design an intervention, it is likely to result in inaccurate outcomes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#estimand-estimator-estimate",
    "href": "M03_1.html#estimand-estimator-estimate",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.5 Estimand, Estimator & Estimate",
    "text": "5.5 Estimand, Estimator & Estimate\n\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\n\n5.5.1 Bayesian Context\nSuppose we are interested in the mean vaccine efficacy for a respiratory-related disease among children in Australia. Our estimand is “the mean vaccine efficacy for the respiratory-related disease among all children in Australia”, Now we take a random sample of 10,000 children in Australia and measure the vaccine’s efficacy in preventing the respiratory-related disease in each child. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand. The most obvious thing to do would be to compute the sample average of the vaccine efficacies. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average indicates a vaccine efficacy of 85%. Then 85% is the estimate of our estimand provided by the “sample average” estimator.\nThe key link to Bayesian thinking is the use of prior information, the combination of prior beliefs with observed data, and the resulting posterior distribution that provides a more comprehensive understanding of the estimand and its uncertainty. In the context of this Bayesian example the estimand is the true, but unknown, mean vaccine efficacy for the respiratory-related disease among all children in Australia. This is the quantity we are ultimately interested in estimating. The estimator is the posterior distribution of the vaccine efficacy. This distribution is derived by combining the prior information with the likelihood of the observed data using Bayes’ theorem. A specific summary statistic of the posterior distribution, such as the posterior mean or posterior median, can also serve as an estimator. The estimate is the specific value or summary of the posterior distribution. For example, if the posterior mean vaccine efficacy is 85%, then 85% is the estimate of the estimand provided by the posterior mean estimator.\n\n\n5.5.2 Regression Context\nNow, let us explain this example in the context of regression problem. Suppose we are interested in understanding how vaccine efficacy for a respiratory-related disease among children in Australia is influenced by certain predictors, such as age, pre-existing health conditions, and socioeconomic status. In this case, our estimand is the set of true regression coefficients that describe the relationship between these predictors and vaccine efficacy.\nA foolproof way to determine these coefficients would be to measure vaccine efficacy and collect all relevant predictor data (e.g., age, health conditions, and socioeconomic status) for every child in Australia and then fit a regression model to the entire population data. However, this is infeasible. Instead, we decide to estimate the regression coefficients using a sample of children.\nHence, we take a random sample of 10,000 children in Australia and collect data on their vaccine efficacy and the relevant predictors. Using this data, we fit a regression model (e.g., a linear regression model) to estimate the relationship between the predictors and vaccine efficacy.\nIn the Bayesian framework, we approach this problem by starting with a prior distribution for each regression coefficient, reflecting our prior beliefs about the relationships. For instance, based on previous studies, we might believe that younger children have slightly lower vaccine efficacy and encode this belief into the prior.\nThe sample data provides the likelihood, representing the probability of observing the data given different values of the regression coefficients. By applying Bayes’ theorem, we combine the prior with the likelihood to produce a posterior distribution for each regression coefficient. The posterior distributions represent our updated beliefs about the coefficients after observing the data.\nFor example, if the posterior mean for the age coefficient is -0.5, it suggests that, on average, each additional year of age is associated with a 0.5% decrease in vaccine efficacy. If the posterior mean for the socioeconomic status coefficient is 2.0, it suggests that higher socioeconomic status is associated with a 2% increase in vaccine efficacy.\nHere, estimand is the true regression coefficients that describe the relationships between the predictors and vaccine efficacy. Estimator is the posterior distributions of the regression coefficients. These distributions summarize the uncertainty about the coefficients. And estimate is the specific value derived from the posterior distributions, such as the posterior mean, median, or mode for each coefficient.\nThis Bayesian approach allows us not only to estimate the coefficients but also to quantify our uncertainty about them, providing a more comprehensive understanding of the predictors’ influence on vaccine efficacy.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-development-using-dag",
    "href": "M03_1.html#model-development-using-dag",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.6 Model Development using DAG",
    "text": "5.6 Model Development using DAG\n\n\nA Directed Acyclic Graph (DAG) can be a helpful tool for conceptualizing and developing regression models. It helps to visually represent causal relationships among variables and ensures proper adjustment for confounding factors.\nNow we explain this more with an example related to Bone Mineral Density (BMD). For example, we want to model the relationship between Bone Mineral Density (BMD) and Age, considering other potential factors like Sex and Body Mass Index (BMI).\nAs people age, their bone mineral density (BMD) decreases naturally over time. Age also influences physical activity, as older individuals tend to be less active. It affects body weight, or BMI, because aging can lead to changes in weight, which in turn impacts bone density. Physical activity strengthens bones, directly improving BMD. Dietary calcium intake supports bone health and contributes directly to BMD as well. Sex influences both BMD and BMI, with women being more likely to experience a decline in bone density, such as in cases of osteoporosis. Body weight, or BMI, also directly affects BMD, as changes in weight can influence bone strength.\n\n\n\n\n\n graph TD\n    A(\"Age\") --&gt; B(\"BMD\")\n    A --&gt; P(\"Physical Activity\") --&gt; B\n    A --&gt; M(\"BMI\") --&gt; B\n    S(\"Sex\") --&gt; B\n    S --&gt; M --&gt; B\n    D(\"Dietary Calcium Intake\") --&gt; M\n\n\n\n\n\n\nIn this example, the estimand is the specific quantity or effect that you are trying to measure based on the causal relationship outlined in the DAG. In this case, the estimand is the causal effect of age on BMD. For example: the average change in BMD for a one-year increase in age, while accounting for confounders like sex, physical activity, BMI, and dietary calcium intake.\nHere, the estimator is the regression model, a multiple linear regression model that adjusts for confounders (Sex, Physical Activity, BMI, and Dietary Calcium Intake) to isolate the effect of Age on BMD.\nThe estimate is the actual numerical value obtained for the causal effect of age on BMD from the data using the chosen estimator, i.e., the estimate is the numerical value (e.g., -0.005) derived from the regression analysis, representing the change in BMD per year of age.\n\n5.6.1 Confounders, Mediators and Adjustment Variables:\nIdentifying Key Variables\nExposure (Independent Variable): Age (Primary factor influencing BMD)\nOutcome (Dependent Variable): Bone Mineral Density (BMD)\nConfounders (Affect both Age and BMD, creating bias) Sex: Men and women have different bone density patterns and risks of osteoporosis. Dietary Calcium Intake: Affects bone density and may vary across age groups.\nMediator (Lies on the causal pathway from Age to BMD) Body Mass Index (BMI): Age affects BMI, which in turn influences BMD.\nAdjustment Variables (To control confounding and estimate the direct effect of Age on BMD) Sex Dietary Calcium Intake Physical Activity (since it is influenced by Age and also impacts BMD)\nConfounders are variables that influence both the exposure (Age) and the outcome (BMD). Based on the DAG, Sex, Physical Activity, BMI, and Dietary Calcium Intake are potential confounders.\nDecide on Variables to Adjust For, i.e., adjust for Sex, Physical Activity, and Dietary Calcium Intake to control for their effects. Adjust for BMI, as it is a mediator between Age and BMD.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_2.html",
    "href": "M03_2.html",
    "title": "6  Bayeswatch! Part - II",
    "section": "",
    "text": "6.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-diagnostics",
    "href": "M03_1.html#model-diagnostics",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.8 Model Diagnostics",
    "text": "5.8 Model Diagnostics\nhttps://m-clark.github.io/easy-bayes/shinystan.html\nshinystan for model diag.\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#logistic-regression",
    "href": "M03_2.html#logistic-regression",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.4 Logistic Regression",
    "text": "6.4 Logistic Regression\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#poisson-regression",
    "href": "M03_2.html#poisson-regression",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.5 Poisson Regression",
    "text": "6.5 Poisson Regression\n\n\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html",
    "href": "M04_1.html",
    "title": "7  Clusterphobia? Let Bayes Handle It!",
    "section": "",
    "text": "7.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Let Bayes Handle It!**</span>"
    ]
  },
  {
    "objectID": "M04_2.html",
    "href": "M04_2.html",
    "title": "8  Clusterphobia? Part - II",
    "section": "",
    "text": "8.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_1.html",
    "href": "M05_1.html",
    "title": "9  Size Matters! Bayesian Secrets to the Right Sample",
    "section": "",
    "text": "9.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Bayesian Secrets to the Right Sample**</span>"
    ]
  },
  {
    "objectID": "M05_2.html",
    "href": "M05_2.html",
    "title": "10  Size Matters! Part - II",
    "section": "",
    "text": "10.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html",
    "href": "M06_1.html",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "",
    "text": "11.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_2.html",
    "href": "M06_2.html",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "",
    "text": "12.1 Learning Objectives\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#model-with-binary-variable",
    "href": "M01_2.html#model-with-binary-variable",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.4 Model with Binary Variable",
    "text": "2.4 Model with Binary Variable\n\nSuppose we have a binary observation i.e., can take values either 0 or 1, which follows Bernoulli distribution with parameter \\(\\theta\\). We already know that for \\(n&gt;1\\) number of trials the Bernoulli distribution yields a Binomial distribution. Considering \\(Y\\) as the random variable of number of successes in \\(n\\) trials for the Binomial distribution, we can write:\n\\[\np(Y=y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\]\nThis also represents the likelihood of a Bernoulli variable.\nNow, if we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\) (i.e., shape parameters of Beta distribution), then we can write the probability density function of the prior distribution as:\n\\[\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\]\nwhere, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write\n\\[\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\]\nWith some simple calculations, we can write the marginal likelihood as:\n\\[\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\]\nHence, we get the analytical form of the posterior distribution of \\(\\theta\\) as:\n\\[\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\]\nwhich follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).\nExample:\nLet us explain this with the type-2 diabetes example we discussed earlier. Now, the medical practitioner is trying to estimate the probability that a patient has type-2 diabetes \\(\\theta\\) based on both prior knowledge and a new diagnostic test result.\nBefore any test, the medical practitioner relies on existing medical data. Suppose past research suggests that for a certain risk group the probability of having type-2 diabetes is 0.5. We represent this belief using a \\(Beta(a=2,b=2)\\). This prior suggests that while any probability is possible, \\(\\theta\\) is likely to be around 0.5, with room for updating.\nNow, we assume the test result corresponds to 7 positive cases out of 10 tests, meaning, \\(n=10\\) and \\(y=7\\).\nHence, we get the posterior distribution of medical practitioner’s new belief about the probability of the patient having the disease as: \\(Beta(2+7,2+3)=Beta(9,5)\\).\nWe can see from the density plots, the posterior shifts toward higher probabilities of type-2 diabetes, meaning the medical practitioner is now more confident that the patient may have type-2 diabetes.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2   \nb_prior &lt;- 2   \nn &lt;- 10        \ny &lt;- 7         \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\ntheta &lt;- seq(0, 1, length.out = 100)\nprior_density &lt;- dbeta(theta, a_prior, b_prior)\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\nposterior_density &lt;- dbeta(theta, a_post, b_post)\ndata &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(prior_density, likelihood, posterior_density),\n  Distribution = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\nggplot(data, aes(x = theta, y = density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(title = \"Prior, Likelihood, and Posterior Distributions\",\n       x = expression(theta),\n       y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-outcomes",
    "href": "M01_2.html#learning-outcomes",
    "title": "2  The Big Dream",
    "section": "2.2 Learning Outcomes",
    "text": "2.2 Learning Outcomes\nLO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\nLO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**The Big Dream**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learning-outcomes",
    "href": "M02_2.html#learning-outcomes",
    "title": "4  Tools and Generative Models",
    "section": "4.3 Learning Outcomes",
    "text": "4.3 Learning Outcomes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#solving-untraceability",
    "href": "M02_2.html#solving-untraceability",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.5 Solving Untraceability",
    "text": "4.5 Solving Untraceability\nDifferent types of algorithms have been developed to tackle untraceable solutions. Such as numerical integration, Markov chain Monte Carlo (MCMC), variational inference, Laplace approximation etc. In this couse, we will learn how to use and impliment these algorithms to solve real-life problems. We refer Gelman et al. (2013) Chapter (..) for details on this for those interested to explore more.\n\n4.5.1 MCMC algorithms\nref: https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo\nIn this course, we will focus on learning Markov chain Monte Carlo (MCMC) algorithms, which is a sampling based approach to approximate the posterior distribution when direct sampling is difficult or computationally impractical.\nA Markov chain is a stochastic process where the next state depends only on the current state, not on the sequence of states that preceded it. This property is called the Markov property. The transition between states is defined by a transition probability matrix or kernel. Monte Carlo methods involve random sampling to estimate numerical quantities, such as integrals, expectations, or probabilities. MCMC combines this with Markov chains to generate samples.\nSome common MCMC algorithms include Metropolis-Hastings (MH) algorithm, Gibbs sampling, Hamiltonian Monte Carlo (HMC) etc. MH is a general MCMC method that generates candidate samples from a proposal distribution. A candidate is accepted or rejected based on an acceptance probability, ensuring the chain converges to the target distribution. Whereas, Gibbs sampling is a special case of the Metropolis-Hastings algorithm. Updates one variable at a time by sampling from its conditional distribution while keeping other variables fixed. The Hamiltonian Monte Carlo (HMC) algorithm uses gradient information from the target distribution to propose new samples, making it more efficient for high-dimensional problems.\nHere’s a summary table comparing the Metropolis-Hastings (MH) algorithm, Gibbs Sampling, and Hamiltonian Monte Carlo (HMC), focusing on when each method is most useful:\n\n\n\n\n\n\n\n\n\n\nMetropolis-Hastings (MH)\nGibbs Sampling\nHamiltonian Monte Carlo (HMC)\n\n\n\n\nApplicability\nGeneral-purpose; works for most distributions, even when structure is unknown.\nRequires easily derived and sampled conditional distributions.\nRequires gradients of the target distribution.\n\n\nFlexibility\nHighly flexible; can handle multimodal or complex distributions.\nLimited to cases where conditional distributions exist.\nBest for smooth, high-dimensional, continuous distributions.\n\n\nEfficiency\nMay require many iterations due to rejection.\nEfficient for models with structured dependencies.\nHighly efficient in high dimensions.\n\n\nParameter Tuning\nRequires tuning of the proposal distribution (e.g., step size).\nNo tuning required.\nRequires tuning of step size and number of leapfrog steps.\n\n\nCorrelated Variables\nCan handle correlated variables with appropriate proposal design.\nMay struggle with high correlation due to sequential updates.\nHandles correlation effectively with gradient-based proposals.\n\n\nModel Type\nSuitable for any distribution, discrete or continuous.\nBest for structured models (e.g., hierarchical Bayesian).\nOnly for continuous, differentiable distributions.\n\n\nComplexity of Implementation\nRelatively simple to implement.\nSimple if conditional distributions are available.\nMore complex due to gradient computations.\n\n\nComputation Cost Per Step\nLow to moderate, depending on the proposal.\nLow per iteration.\nHigh due to gradient and Hamiltonian computations.\n\n\n\n\n\n4.5.2 MCMC convergence diagnostics\n\n\nIf all chains exhibit good mixing and overlap significantly, convergence is likely achieved. For example: A poorly mixed trace might stay in one region for too long or exhibit a trend. Each chain fluctuates randomly, indicating that it explores the target distribution.\nAutocorrelation should decay quickly (close to 0 at larger lags), indicating less dependence between consecutive samples. Slow decay indicates that the chain is not exploring efficiently.\nGelman-Rubin Diagnostic \\(\\hat{R}\\) near 1 indicates convergence. Gelman-Rubin Plot will show how \\(\\hat{R}\\) decreases over iterations. A flat line near 1 confirms that all chains have reached the stationary distribution.\n\n4.5.2.1 MH algorithm\nWe want to sample from a standard normal distribution \\(N(0,1)\\) using the Metropolis-Hastings algorithm, starting from an arbitrary initial point. This allows us to observe how the MCMC chain gradually converges to the target distribution. We write the target density \\(y\\sim N(0,1)\\) as: \\[\\begin{align}\np(y) &= \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{y^2}{2}\\right)\n\\end{align}\\]\n\n\nCode\n# Load required package\nif (!requireNamespace(\"coda\", quietly = TRUE)) install.packages(\"coda\")\nlibrary(coda)\n\n# Metropolis-Hastings function\nmetropolis_hastings &lt;- function(target_density, proposal_sd, n_iter, initial_value) {\n  chain &lt;- numeric(n_iter)\n  chain[1] &lt;- initial_value\n  \n  for (i in 2:n_iter) {\n    proposal &lt;- rnorm(1, mean = chain[i - 1], sd = proposal_sd)\n    acceptance_prob &lt;- min(1, target_density(proposal) / target_density(chain[i - 1]))\n    if (runif(1) &lt; acceptance_prob) {\n      chain[i] &lt;- proposal\n    } else {\n      chain[i] &lt;- chain[i - 1]\n    }\n  }\n  \n  return(chain)\n}\n\n# Define the target density (Standard Normal)\ntarget_density &lt;- function(x) dnorm(x, mean = 0, sd = 1)\n\n# Run multiple chains\nset.seed(123)\nn_iter &lt;- 10000\nn_chains &lt;- 3\nchains &lt;- list(\n  chain1 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 10),\n  chain2 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = -10),\n  chain3 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 5)\n)\n\n# Convert chains to mcmc.list (for coda package)\nmcmc_chains &lt;- mcmc.list(\n  mcmc(chains$chain1),\n  mcmc(chains$chain2),\n  mcmc(chains$chain3)\n)\n\n# 1. Trace Plots\npar(mfrow = c(1, 3))  # 1 row, 3 columns for each chain\nfor (i in 1:n_chains) {\n  plot(mcmc_chains[[i]], type = \"l\", col = \"blue\", \n       main = paste(\"Trace Plot: Chain\", i), \n       xlab = \"Iteration\", ylab = \"Value\")\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 2. Autocorrelation Plots\npar(mfrow = c(1, 3))  # Reset to 1 row, 3 columns for autocorrelation plots\nfor (i in 1:n_chains) {\n  autocorr.plot(mcmc_chains[[i]], main = paste(\"Autocorrelation: Chain\", i), lag.max = 50)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Gelman-Rubin Diagnostic\ngelman_diag &lt;- gelman.diag(mcmc_chains)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]          1          1\n\n\nCode\n# 4. Gelman-Rubin Plot\ngelman.plot(mcmc_chains)\n\n\n\n\n\n\n\n\n\n\n\n4.5.2.2 Gibbs sampling\nLet’s use Gibbs Sampling to sample from a bivariate normal distribution where the marginal distributions of each variable are normal, but the two variables are correlated. We’ll then assess the convergence using trace plots, autocorrelation plots, and the Gelman-Rubin diagnostic.\nThe joint density is the bivariate normal distribution: \\[\\begin{align}\np(x,y) &= \\frac{1}{2\\pi\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left(x^2-2\\rho x y +y^2 \\right) \\right)\n\\end{align}\\] where \\(\\rho\\) is the correlation between \\(x\\) and \\(y\\)\n\n\nCode\n# Load required library\nif (!requireNamespace(\"coda\", quietly = TRUE)) install.packages(\"coda\")\nlibrary(coda)\n\n# Gibbs Sampling Function\ngibbs_sampling &lt;- function(n_iter, rho, initial_values) {\n  x &lt;- numeric(n_iter)\n  y &lt;- numeric(n_iter)\n  \n  # Set initial values\n  x[1] &lt;- initial_values[1]\n  y[1] &lt;- initial_values[2]\n  \n  # Gibbs sampling iterations\n  for (i in 2:n_iter) {\n    # Sample x given y\n    x[i] &lt;- rnorm(1, mean = rho * y[i - 1], sd = sqrt(1 - rho^2))\n    # Sample y given x\n    y[i] &lt;- rnorm(1, mean = rho * x[i], sd = sqrt(1 - rho^2))\n  }\n  \n  return(data.frame(x = x, y = y))\n}\n\n# Parameters\nset.seed(123)         # For reproducibility\nn_iter &lt;- 1000       # Number of iterations\nrho &lt;- 0.8            # Correlation between x and y\ninitial_values &lt;- c(0, 0)  # Initial values for x and y\n\n# Run three independent Gibbs sampling chains\nchain1 &lt;- gibbs_sampling(n_iter, rho, c(0, 0))\nchain2 &lt;- gibbs_sampling(n_iter, rho, c(10, 10))\nchain3 &lt;- gibbs_sampling(n_iter, rho, c(-10, -10))\n\n# Convert chains to mcmc.list (for coda package)\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(chain1)),\n  mcmc(as.matrix(chain2)),\n  mcmc(as.matrix(chain3))\n)\n\n# 1. Trace Plots\npar(mfrow = c(2, 3))  # 2 rows, 3 columns for x and y of each chain\nfor (i in 1:3) {\n  plot(mcmc_chains[[i]][, \"x\"], type = \"l\", col = \"blue\",\n       main = paste(\"Trace Plot: Chain\", i, \"(x)\"), \n       xlab = \"Iteration\", ylab = \"Value\")\n  plot(mcmc_chains[[i]][, \"y\"], type = \"l\", col = \"red\",\n       main = paste(\"Trace Plot: Chain\", i, \"(y)\"), \n       xlab = \"Iteration\", ylab = \"Value\")\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 2. Autocorrelation Plots\npar(mfrow = c(2, 3))  # Reset to 2 rows, 3 columns for autocorrelation plots\nfor (i in 1:3) {\n  autocorr.plot(mcmc_chains[[i]][, \"x\"], main = paste(\"Autocorrelation: Chain\", i, \"(x)\"))\n  autocorr.plot(mcmc_chains[[i]][, \"y\"], main = paste(\"Autocorrelation: Chain\", i, \"(y)\"))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Gelman-Rubin Diagnostic\ngelman_diag &lt;- gelman.diag(mcmc_chains)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n  Point est. Upper C.I.\nx          1       1.02\ny          1       1.02\n\nMultivariate psrf\n\n1\n\n\nCode\n# 4. Gelman-Rubin Plot\ngelman.plot(mcmc_chains)\n\n\n\n\n\n\n\n\n\n\n\n4.5.2.3 HMC\nHamiltonian Monte Carlo (HMC) is a powerful MCMC algorithm that uses information about the gradient of the log-probability density to efficiently sample from complex distributions. Below, we provide an example of implementing HMC using R with the rstan package, which includes a highly optimized implementation of HMC.\nref: https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html\n\n\nCode\n# Load required packages\nlibrary(rstan)\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.6 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\nDo not specify '-march=native' in 'LOCAL_CPPFLAGS' or a Makevars file\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:coda':\n\n    traceplot\n\n\nCode\nlibrary(bayesplot)\n\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\nCode\n# Generate synthetic data\nset.seed(42)\ntrue_mu &lt;- 5.0\ntrue_sigma &lt;- 2.0\nn_samples &lt;- 100\ny &lt;- rnorm(n_samples, mean = true_mu, sd = true_sigma)\n\n# Plot the data\nhist(y, breaks = 20, col = \"lightblue\", main = \"Observed Data\", xlab = \"y\")\n\n\n\n\n\n\n\n\n\nCode\n# Stan model code\nstan_code &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;        // Number of observations\n  vector[N] y;           // Observed data\n}\nparameters {\n  real mu;               // Mean\n  real&lt;lower=0&gt; sigma;   // Standard deviation\n}\nmodel {\n  mu ~ normal(0, 10);    // Prior for mu\n  sigma ~ normal(0, 10); // Prior for sigma\n  y ~ normal(mu, sigma); // Likelihood\n}\n\"\n\n# Prepare data for Stan\nstan_data &lt;- list(\n  N = length(y),\n  y = y\n)\n\n# Fit the model using Stan\nfit &lt;- stan(\n  model_code = stan_code,\n  data = stan_data,\n  iter = 2000,      # Total number of iterations (1000 warmup + 1000 sampling)\n  warmup = 1000,    # Warm-up iterations\n  chains = 3,       # Number of Markov chains\n  seed = 42         # For reproducibility\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.021 seconds (Warm-up)\nChain 1:                0.018 seconds (Sampling)\nChain 1:                0.039 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.02 seconds (Warm-up)\nChain 2:                0.018 seconds (Sampling)\nChain 2:                0.038 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.031 seconds (Warm-up)\nChain 3:                0.033 seconds (Sampling)\nChain 3:                0.064 seconds (Total)\nChain 3: \n\n\nCode\n# Summarize the posterior distributions\nprint(fit, pars = c(\"mu\", \"sigma\"))\n\n\nInference for Stan model: anon_model.\n3 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=3000.\n\n      mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat\nmu    5.07       0 0.21 4.64 4.93 5.07 5.21  5.49  2863    1\nsigma 2.11       0 0.15 1.83 2.00 2.10 2.21  2.43  2560    1\n\nSamples were drawn using NUTS(diag_e) at Mon Mar 24 09:14:28 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCode\n# MCMC plots\nlibrary(bayesplot)\nmcmc_trace(fit, pars = c(\"mu\", \"sigma\"))\n\n\n\n\n\n\n\n\n\nCode\nmcmc_areas(fit, pars = c(\"mu\", \"sigma\"))\n\n\n\n\n\n\n\n\n\nCode\nmcmc_acf_bar(fit, pars = c(\"mu\", \"sigma\"))\n\n\n\n\n\n\n\n\n\nCode\n# Convert chains to mcmc.list (for coda package)\nlibrary(coda)\nposterior_samples &lt;- as.array(fit)\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(posterior_samples[,1,])),\n  mcmc(as.matrix(posterior_samples[,2,])),\n  mcmc(as.matrix(posterior_samples[,3,]))\n)\n\ngelman_diag &lt;- gelman.diag(mcmc_chains)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu          1.01       1.02\nsigma       1.00       1.00\nlp__        1.01       1.02\n\nMultivariate psrf\n\n1.01\n\n\nCode\n# Gelman-Rubin Plot\ngelman.plot(mcmc_chains)\n\n\n\n\n\n\n\n\n\nCode\n# R hat\nrhats &lt;- rhat(fit)\nrhats\n\n\n      mu    sigma     lp__ \n1.000407 0.999803 1.001008 \n\n\nCode\nmcmc_rhat(rhats) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Effective sample size\nratios_cp &lt;- neff_ratio(fit)\nprint(ratios_cp)\n\n\n       mu     sigma      lp__ \n0.9542813 0.8532551 0.5125224 \n\n\nCode\nmcmc_neff(ratios_cp, size = 2) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\n# use shinystan\n#library(shinystan)\n#launch_shinystan(fit)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-outcomes",
    "href": "M02_1.html#learning-outcomes",
    "title": "3  Prior and Posterior Distributions",
    "section": "3.3 Learning Outcomes",
    "text": "3.3 Learning Outcomes",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#criterion-and-shrinkage-based",
    "href": "M06_1.html#criterion-and-shrinkage-based",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.4 Criterion and Shrinkage Based",
    "text": "11.4 Criterion and Shrinkage Based\nasdf ref - lambert page 225, sec: 10.5 (AIC, DIC, WAIC, LOO-CV)\nasdf ref - … spike-slab priors (mixture-priors), Bayesian lasso",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#hypothesis-testing-with-bf",
    "href": "M06_1.html#hypothesis-testing-with-bf",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.5 Hypothesis Testing with BF",
    "text": "11.5 Hypothesis Testing with BF\nref: https://statswithr.github.io/book/hypothesis-testing-with-normal-populations.html",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-model-averaging",
    "href": "M06_1.html#bayesian-model-averaging",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.6 Bayesian Model Averaging",
    "text": "11.6 Bayesian Model Averaging\nref: https://statswithr.github.io/book/bayesian-model-choice.html#bayesian-model-averaging\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learning-outcomes",
    "href": "M01_1.html#learning-outcomes",
    "title": "1  The Big Dream",
    "section": "1.2 Learning Outcomes",
    "text": "1.2 Learning Outcomes\nLO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\nLO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**The Big Dream**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#problems-use-another-example",
    "href": "M01_1.html#problems-use-another-example",
    "title": "1  Belief-O-Meter: Navigating Evidence",
    "section": "1.8 Problems – use another example",
    "text": "1.8 Problems – use another example",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Belief-O-Meter: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze-logical-framework",
    "href": "M01_1.html#the-maze-logical-framework",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.4 The Maze: Logical Framework",
    "text": "1.4 The Maze: Logical Framework\n\nBayesian analysis is a logical framework that helps update our beliefs based on continuous new information. A helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works — it continuously updates our understanding as more evidence comes in.\nTo see this in practice, let’s consider an example explained below.\n\n1.4.1 Example:\nA medical practitioner had seen many cases of pneumonia before, but this one was tricky. A 55-year-old patient, had been admitted with high fever, cough, and shortness of breath. Based on his symptoms and an initial chest X-ray, the practitioner diagnosed him with bacterial pneumonia and started him on a standard antibiotic.\nAt this point, their belief was strong that the chosen antibiotic would work—this was their prior probability based on past experience.\nDay 2:\nAfter 24 hours, the patient wasn’t improving. Thier fever remained high, and their breathing was still labored.\nThe practitioner now had new evidence — the treatment wasn’t working as quickly as it should. Applying Bayesian reasoning, they adjusted their belief:\n\nThe probability that this was a typical bacterial pneumonia responding to first-line antibiotics decreased.\n\nThe probability that it was a resistant strain of bacteria or even a different type of infection increased.\n\nThey needed more information.\nDay 3:\nThe practitioner ordered a sputum culture to check for antibiotic-resistant bacteria. In the meantime, they updated the treatment, switching the patient to a broader-spectrum antibiotic.\n\nIf the new antibiotic worked, it would confirm that the initial one was ineffective, meaning resistant bacteria were likely the cause.\n\nIf the patient still didn’t improve, it could mean this wasn’t bacterial pneumonia at all—it might be a viral infection instead.\n\nAgain, their belief about the cause of the patient’s illness shifted based on new evidence.\nDay 4:\nThe test results came in: The patient’s infection was caused by a drug-resistant strain of bacteria. This confirmed that the initial choice of antibiotics was ineffective.\nWith this new evidence, the practitioner’s belief was now much stronger that the broader-spectrum antibiotic was the right choice.\nThe Lesson of Bayesian Thinking\nThe medical practitioner didn’t just rely on their initial belief. Instead, they continuously updated their understanding as new evidence emerged—just like someone navigating a maze learns from every wrong turn. This process demonstrates how Bayesian reasoning helps in making data-driven, logical decisions—not just by guessing, but by continuously refining our beliefs with new information, ultimately leading to the best possible decision.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#tutorial-exercises",
    "href": "M01_1.html#tutorial-exercises",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.10 Tutorial Exercises",
    "text": "1.10 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#directed-acyclic-graph-dag",
    "href": "M01_2.html#directed-acyclic-graph-dag",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.7 Directed Acyclic Graph (DAG)",
    "text": "2.7 Directed Acyclic Graph (DAG)\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\n\nBayesian models:\n\nIn the context of Bayesian modelling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the model with binary observations, we write a DAG as:\n\n\nCode\nlibrary(DiagrammeR)\n\ngrViz(\"\ndigraph flowchart {\n  graph [layout = dot, rankdir = LR]\n\n  node [shape = rectangle, style = filled, color = white]\n  \n  subgraph cluster_0 {\n    label = 'Hyper-parameter'\n    color = lightblue\n    node [color=lightblue]\n    a [label='a']\n    b [label='b']\n  }\n\n  subgraph cluster_1 {\n    label = 'Parameter'\n    color = lightgray\n    node [color=lightgray]\n    theta [label='θ']\n  }\n\n  subgraph cluster_2 {\n    label = 'Outcome'\n    color = lightsteelblue\n    node [color=lightsteelblue]\n    y [label='y']\n  }\n\n  edge[arrowhead=normal]\n\n  a -&gt; theta\n  b -&gt; theta\n  theta -&gt; y\n}\n\")\n\n\n\n\n\n\nThis is a simple graphical model, where \\(y\\) depends on \\(\\theta\\), with \\(\\theta\\) being a logical function of hyper-parameters \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#tutorial-exercises",
    "href": "M01_2.html#tutorial-exercises",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.11 Tutorial Exercises",
    "text": "2.11 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example-1",
    "href": "M01_2.html#example-1",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Example",
    "text": "2.10 Example\n\n2.10.1 Decision Making:\n\nIn this example, we will see how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed. However, if you make the wrong decision, your research project is shut down.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): 10% prevalence \\(H_1\\): \\(&gt;10%\\) prevalence\np-value based on 5 samples: \\(Pr(k\\ge 1|n=5,p=0.10)=1-Pr(k= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\\)\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\] and\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of whether \\(H_0\\) or \\(H_1\\) is correct are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods as:\n\n\n\n\n\n\n\n\n\nObserved Data\nFrequentist ( Pr(y % ) )\nBayesian ( Pr(10% n, y) )\nBayesian ( Pr(20% n, y) )\n\n\n\n\n( n = 5, y = 1 )\n0.41\n0.45\n0.55\n\n\n( n = 10, y = 2 )\n0.26\n0.39\n0.61\n\n\n( n = 15, y = 3 )\n0.18\n0.34\n0.66\n\n\n( n = 20, y = 4 )\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where ( p = 0.20 ). As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as ( p = 0.20 ) and the alternative as ( p &lt; 0.20 )—we would have reached different conclusions. This highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.10.2 Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\)mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\)mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\n\n\nCode\n# Load necessary libraries\nlibrary(BayesFactor)  # For Bayesian t-test\nlibrary(ggplot2)      # For visualization\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Simulate data for two groups\nn_A &lt;- 50  # Sample size for Drug A\nn_B &lt;- 50  # Sample size for Drug B\n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(\"Frequentist t-test results:\")\n\n\n[1] \"Frequentist t-test results:\"\n\n\nCode\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). Cannot incorporate prior knowledge about the effectiveness of similar drugs. Requires a fixed sample size before testing.\nBayesian\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge. If previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", posterior_prob, \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.4124978 0.09383364 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method incorporates that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.\nThe Bayesian approach gives a richer, more flexible analysis by quantifying uncertainty and updating beliefs dynamically—ideal for real-world decision-making.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#inference",
    "href": "M01_2.html#inference",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Inference",
    "text": "2.3 Inference\n\n\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote\\(Pr(H)\\) as the probability of initial belief about \\(H\\) before seeing data, we can write the updated beliefe about \\(H\\) given the data \\(D\\) as:\n\\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\]\nwhere, \\(Pr(D)\\) is the probability of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.\n\n2.3.1 Example - Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example-test-for-two-means",
    "href": "M01_2.html#example-test-for-two-means",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Example: Test for two means",
    "text": "2.9 Example: Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\) mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\) mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist Method\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\nWe get the frequentist t-test result:\n\n\nCode\n# For Bayesian t-test\nlibrary(BayesFactor)  \nlibrary(ggplot2)\n\nset.seed(123)\n\nn_A &lt;- 50  \nn_B &lt;- 50  \n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). We cannot incorporate any prior knowledge about the effectiveness of similar drugs. It also requires a fixed sample size before testing.\nBayesian Method\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge.\nIf previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\) or \\(Pr(\\mu_B &lt; \\mu_A)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", round(posterior_prob[1],2), \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.41 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method can incorporate that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---decision-making",
    "href": "M01_2.html#example---decision-making",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.7 Example - Decision Making:",
    "text": "2.7 Example - Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---test-for-two-means",
    "href": "M01_2.html#example---test-for-two-means",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.8 Example - Test for two means",
    "text": "2.8 Example - Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\) mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\) mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist Method\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\nWe get the frequentist t-test result:\n\n\nCode\n# For Bayesian t-test\nlibrary(BayesFactor)  \nlibrary(ggplot2)\n\nset.seed(123)\n\nn_A &lt;- 50  \nn_B &lt;- 50  \n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). We cannot incorporate any prior knowledge about the effectiveness of similar drugs. It also requires a fixed sample size before testing.\nBayesian Method\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge.\nIf previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\) or \\(Pr(\\mu_B &lt; \\mu_A)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", round(posterior_prob[1],2), \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.41 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method can incorporate that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---bayesian-updating",
    "href": "M01_2.html#example---bayesian-updating",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Example - Bayesian Updating",
    "text": "2.9 Example - Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior.\nGoing back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#examples",
    "href": "M01_2.html#examples",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.8 Examples:",
    "text": "2.8 Examples:\n\n2.8.1 Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nWe can write this example using a DAG, where we can represent the relationships between the prior probabilities, likelihoods, and posterior probabilities.\n\nHypothesis (H₀ and H₁): These represent the two possible prevalence values (10% for H₀, 20% for H₁).\nData (y): The observed data (the number of successes in 5 samples, e.g., the presence of disease).\nLikelihoods (Pr(y=1|H₀) and Pr(y=1|H₁)): The likelihood of observing the data under each hypothesis.\nPrior Probabilities (Pr(H₀) and Pr(H₁)): The prior belief about the hypotheses (both have a prior probability of 0.5).\nPosterior Probabilities (Pr(H₀|y=1) and Pr(H₁|y=1)): The updated belief about the hypotheses after observing the data.\n\n\n\nCode\nlibrary(DiagrammeR)\n\n# Create a directed acyclic graph (DAG)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  H0 [label = 'H₀: 10% prevalence', width = 1.5]\n  H1 [label = 'H₁: 20% prevalence', width = 1.5]\n  y [label = 'y: Data (Successes in 5 samples)', width = 1.5]\n  PrH0 [label = 'Pr(H₀) = 0.5', width = 1.5]\n  PrH1 [label = 'Pr(H₁) = 0.5', width = 1.5]\n  LikelihoodH0 [label = 'Pr(y|H₀) ~ 0.33', width = 1.5]\n  LikelihoodH1 [label = 'Pr(y|H₁) ~ 0.41', width = 1.5]\n  PosteriorH0 [label = 'Pr(H₀|y=1) ~ 0.45', width = 1.5]\n  PosteriorH1 [label = 'Pr(H₁|y=1) ~ 0.55', width = 1.5]\n\n  # Define the edges (relationships)\n  PrH0 -&gt; LikelihoodH0\n  PrH1 -&gt; LikelihoodH1\n  H0 -&gt; LikelihoodH0\n  H1 -&gt; LikelihoodH1\n  LikelihoodH0 -&gt; y\n  LikelihoodH1 -&gt; y\n  y -&gt; PosteriorH0\n  y -&gt; PosteriorH1\n}\n\")\n\n# Render the DAG\ndag\n\n\n\n\n\n\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.8.2 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  \n  # Prior node\n  Prior [label = 'Prior p(θ)', width = 1.5]\n  \n  # Data observations\n  D1 [label = 'D₁: Observation (YES)', width = 2]\n  Dots [label = '...', width = 0.5]\n  D6 [label = 'D₆: Observation (NO)', width = 2]\n  \n  # Posterior updates\n  Posterior_D1 [label = 'Posterior p(θ|D₁)', width = 2]\n  Posterior_D6 [label = 'Posterior p(θ|D₁, ..., D₆)', width = 2]\n\n  # Define the edges (relationships)\n  Prior -&gt; D1\n  D1 -&gt; Posterior_D1\n  Posterior_D1 -&gt; Dots\n  Dots -&gt; D6\n  D6 -&gt; Posterior_D6\n\n  # Layout: top to bottom style\n  rankdir = TB\n}\n\")\ndag\n\n\n\n\n\n\nInvariance to data-order\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior. Hence, going back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learnings",
    "href": "M01_2.html#learnings",
    "title": "2  Bayesian Dreams: Inference",
    "section": "",
    "text": "Outcomes\n\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learnings",
    "href": "M01_1.html#learnings",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  }
]