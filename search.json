[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistical Methods in Medicine & Health",
    "section": "",
    "text": "Preface\nThe application of Bayesian methods in medicine and health sciences has become increasingly vital as we strive to enhance our understanding of improve diagnostic accuracy, and personalise treatment plans. This course is designed to introduce students with a background in medicine and health sciences to the principles and practices of Bayesian statistics, providing a practical framework for applying these methods in their respective fields.",
    "crumbs": [
      "**Preface**"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Bayesian methods offer a unique approach to statistical analysis by incorporating prior knowledge and continuously updating the posterior probability as new evidence becomes available. This dynamic approach is particularly suited to the medical and health sciences, where new data is constantly emerging, and decisions often need to be made in the face of uncertainty.\nThe aim of this course is to explain Bayesian statistics and demonstrate its practical applications in medicine and health sciences. We will start with the foundational concepts, gradually building up to more advanced topics, ensuring a comprehensive understanding that is both accessible and relevant to medical professionals, researchers, and students. Each chapter includes real-world examples, case studies, and practical exercises to reinforce the concepts discussed and illustrate their application in clinical and research settings.\nThroughout the course, we will explore the following key areas:\n\nBayesian Dreams! Navigating Evidence and Inference: Understanding the basics of Bayesian philosophy and how it differs from traditional frequentist approaches. Learning how to update beliefs in light of new data using Bayes’ theorem. Exploring directed acyclic graph (DAG) in the Bayesian modelling context, with graphical representations of the probabilistic relationships between variables and parameters.\nChaotics? Prior Problems, Tools, and Computation: Exploring the role of prior information and how it influences posterior conclusions. Bayesian context of exact inference and computational techniques for approximating complex posterior distributions such as Markov chain Monte Carlo (MCMC). Generative models with prior and posterior predictive checks.\nBayeswatch! Keeping an Eye on Your Model: Applying Bayesian methods to regression analysis in clinical and health research. Extending Bayesian models beyond normality assumptions (i.e., generalised linear models such as logistic and Poisson regressions), and explanation with DAG. Explore key tactics on the choice for hyper-parameters of prior distributions.\nClusterphobia? Let Bayes Handle It!: Understanding and implementing hierarchical models for complex data structures common in health sciences. Learing the use of latent process modelling in Bayesian hierarchy (i.e., similar to mixed models in frequentist settings) with both normal and non-normal (e.g., binomial and Poisson) distributions.\nSize Matters! Bayesian Secrets to the Right Sample: Bayesian sample size calculations, in particular to aid the sample size selection to design trials. Discussion of adaptations with relevant sample size calculations using Bayesian methods.\nWander into the Wonder!: Bayesian model choice (e.g., Bayes factor, deviance information criterion (DIC), Watanabe-Akaike information criterion (WAIC) and leave-one-out (LOO) cross-validation). Bayesian shrinkage, missing data analysis and measurement errors.\n\nThe field of medicine and health sciences is inherently multidisciplinary, and so too is this course. It is crafted to bridge the gap between statistical theory and medical practice, enabeling healthcare professionals to make more informed, data-driven decisions. Whether you are a student eager to learn about Bayesian statistics, or a biostatistician or clinician or a health professional looking to enhance your research skills, or a researcher aiming to apply Bayesian methods to your work, this course provides the tools and knowledge you need to succeed.\nWe hope that by the end of this journey, you will not only appreciate the power and flexibility of Bayesian methods but also feel confident in applying these techniques to improve patient outcomes and advance medical research.\nWelcome to the world of Bayesian methods in medicine and health sciences. Let’s begin.",
    "crumbs": [
      "**Introduction**"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari,\nand Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition).\nChapman; Hall/CRC.\n\n\nGelman, Andrew, and Cosma Rohilla Shalizi. 2013. “Philosophy and\nthe Practice of Bayesian Statistics.” British Journal of\nMathematical and Statistical Psychology 66 (1): 8–38.\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r,\nJAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "M012.html",
    "href": "M012.html",
    "title": "2  Bayesian Inference",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "M011.html#learning-objectives",
    "href": "M011.html#learning-objectives",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nThis is a book created from markdown and executable code."
  },
  {
    "objectID": "M011.html#learning-activities",
    "href": "M011.html#learning-activities",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.2 Learning Activities",
    "text": "1.2 Learning Activities\nSee Knuth (1984) for additional discussion of literate programming."
  },
  {
    "objectID": "M011.html#preparation-for-week-2",
    "href": "M011.html#preparation-for-week-2",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.3 Preparation for Week 2",
    "text": "1.3 Preparation for Week 2\nasdfa"
  },
  {
    "objectID": "M011.html#introduction",
    "href": "M011.html#introduction",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.4 Introduction",
    "text": "1.4 Introduction\nasdafs\nVedio\n…\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "M011.html#exercises",
    "href": "M011.html#exercises",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\nsdfads"
  },
  {
    "objectID": "M011.html#live-tutorial-and-discussion",
    "href": "M011.html#live-tutorial-and-discussion",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.6 Live tutorial and discussion",
    "text": "1.6 Live tutorial and discussion\nasdfa"
  },
  {
    "objectID": "M011.html#summary",
    "href": "M011.html#summary",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.7 Summary",
    "text": "1.7 Summary"
  },
  {
    "objectID": "M011.html#section",
    "href": "M011.html#section",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.8 ",
    "text": "1.8 \n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "M01_1.html#learning-objectives",
    "href": "M01_1.html#learning-objectives",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.2 Learning Objectives",
    "text": "1.2 Learning Objectives\nIn today’s lecture we will:\n\nUnderstand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learning-activities",
    "href": "M01_1.html#learning-activities",
    "title": "1  Degrees of Beliefs and Evidence",
    "section": "1.2 Learning Activities",
    "text": "1.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#preparation-for-week-2",
    "href": "M01_1.html#preparation-for-week-2",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.11 Preparation for Week 2",
    "text": "1.11 Preparation for Week 2\nIn week 2, we will start exploring Bayesian dreams and learn the fundamental concepts related to Bayesian inference and models.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#introduction",
    "href": "M01_1.html#introduction",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\n\n\n\n\n\nThomas Bayes (The IMS Bulletin, 1988, vol-17(3), pp.276-278)\n\n\n\n\n\n\nThomas Bayes, who is remembered through the term “Bayesian,” passed away in 1761 without having the chance to formally present or publish his groundbreaking findings. Two years after his death, it was Richard Price who, in 1763, introduced Bayes’ extraordinary work to the Royal Statistical Society. Bayes had been carefully constructing a probabilistic framework to tackle inverse problems. Concurrently, Richard Price (1723–1791) and Pierre-Simon Laplace (1749–1827) played crucial roles in advancing and applying this transformative idea to practical real-world scenarios.\nTo fully understand the Bayesian framework, it is essential to become familiar with several key terms commonly used in Bayesian discussions, such as Bayesian inference, prior, posterior, and Bayesian modeling. Throughout this course, we will gradually explore these fundamental concepts. Before deeply examining these important terms, it is beneficial to consider the Bayesian philosophy.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#exercises",
    "href": "M01_1.html#exercises",
    "title": "1  Belief-O-Meter: Navigating Evidence",
    "section": "1.9 Exercises",
    "text": "1.9 Exercises\nSolutions will be provided later after the tutorial.\n\n1.9.1 Question 1:\n\nConsider a rare disease that is thought to occur in 0.1% of the population. This can be our prior belief that a person selected at random has the disease. Using a particular blood test a physician observes that out of the patients with disease, 99% of the time the test result is positive. This is also known as the hit rate. Suppose 5% of the time when the disease is absent but the test falsely indicates that the disease is present, i.e., the false alarm or false positive rate is 5%.\nConsider, we sample a person at random from the population, administer\nAlso assume that 1% of the population without the disease have the same symptom. A randomly chosen person from the population is blood tested and is shown to have the symptom. What is the conditional probability that the person has the disease?\nHere we have the probability of the event that a randomly chosen person has the disease, i.e., \\(Pr(D)=0.001\\), since 0.1% of the population has the disease and 0.999% will not have the disease, i.e., \\((1-Pr(D))=Pr(D')=0.999\\).\nWe also know that 99% possess symptom, i.e., the probability of the event that a randomly chosen person has the symptom given disease \\(Pr(S|D)=0.99\\), and the probability of symptom without disease is \\(Pr(S|D')=0.01\\). Now to get the probability of disease given symptom we can write: \\[\nPr(\\text{disease}|\\text{symptom})=Pr(D|S)\n\\]\n\\[\nPr(D|S) = \\frac{Pr(S|D)\\times Pr(D)}{Pr(S|D)\\times Pr(D) + Pr(S|D')\\times Pr(D')}\n\\]\n\\[\nPr(D|S) = \\frac{0.99\\times 0.001}{0.99\\times 0.001 + 0.01\\times 0.999} = 0.09\n\\]\nwhich is 9% since the disease is rare (i.e., 0.1% occurrence) and a large portion of the population might have symptom but not the disease.\nA blood test for the person with symptom might provide a further insight, this will be a new evidence. Hence if we are interested to get the posterior probability of having the disease, the prior probability 0.1% would get revised to 9%. Thus we write: \\[\nPr(\\text{disease}|\\text{positive})=\\frac{0.99\\times 0.09}{0.99\\times 0.09 + 0.01\\times 0.91} = 0.908\n\\] This probability is much higher since it combines the evidence from two events, i.e., symptoms and tests. This illustrates an aspect of the Bayesian world view: the prior probability gets continually updated in the light of new evidence.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Belief-O-Meter: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#live-tutorial-and-discussion",
    "href": "M01_1.html#live-tutorial-and-discussion",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.9 Live tutorial and discussion",
    "text": "1.9 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#summary",
    "href": "M01_1.html#summary",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.8 Summary",
    "text": "1.8 Summary\nThe key concept of this week’s lecture is that Bayesian ways of thinking are inherently more suited to solving real-life problems compared to frequentist/classical approaches, as they allow for the inclusion of prior information in decision-making, providing a clear advantage in calculating inverse probability.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#section",
    "href": "M01_1.html#section",
    "title": "1  Degrees of Beliefs and Evidence (Week 1)",
    "section": "1.7 ",
    "text": "1.7"
  },
  {
    "objectID": "M01_2.html#section",
    "href": "M01_2.html#section",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.13 ",
    "text": "2.13 \n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-objectives",
    "href": "M01_2.html#learning-objectives",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.2 Learning Objectives",
    "text": "2.2 Learning Objectives\nBy the end of this week you should be able to:\n\nDescribe Bayesian inference using probability distributions.\nUnderstand Bayesian learning.\nDraw DAG for Bayesian models.\nFormulate examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-activities",
    "href": "M01_2.html#learning-activities",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.2 Learning Activities",
    "text": "2.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#preparation-for-week-3",
    "href": "M01_2.html#preparation-for-week-3",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.12 Preparation for Week 3",
    "text": "2.12 Preparation for Week 3\nNext week we will start Module 02 of this unit, where our main focus will be to understand different types of prior distributions and how they influence the posteriors.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#introduction",
    "href": "M01_2.html#introduction",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem, which describes how prior beliefs are updated with new data. Following out previous lecture, if we denote \\(Pr(H)\\) as the probability of initial beliefe about \\(H\\) before seeing data, we can write the updated beliefe about \\(H\\) given the data \\(D\\) as: \\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\] where, \\(Pr(D)\\) is the probabilty of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of model that incorporates Bayes throrem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#exercises",
    "href": "M01_2.html#exercises",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\nsdfads\nhow to choose an appropriate likelihood? ref -Lambert, page 71, sec: 4.6, 4.8\nexplain conjugacy - lambert, use normal dist with known mu\nnormal model with known variance\n\n2.9.1 Poisson Model\n\n\n\n2.9.2 Exponential Model",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#live-tutorial-and-discussion",
    "href": "M01_2.html#live-tutorial-and-discussion",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Live tutorial and discussion",
    "text": "2.10 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#summary",
    "href": "M01_2.html#summary",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Summary",
    "text": "2.9 Summary\nToday’s lecture explored Bayesian inference, focusing on how to derive it analytically, we also learn Bayesian updating, posterior odds and Directed Acyclic Graphs (DAGs).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-objectives",
    "href": "M02_1.html#learning-objectives",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.2 Learning Objectives",
    "text": "3.2 Learning Objectives\nBy the end of this week you should be able to:\n\nUnderstand the importance of prior distributions.\nCalculate posterior using Bayesian exact inference.\nDistinguish between different types of Prior distributions\nFormulate examples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-activities",
    "href": "M02_1.html#learning-activities",
    "title": "3  Prior and Posterior Distributions",
    "section": "3.2 Learning Activities",
    "text": "3.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#introduction",
    "href": "M02_1.html#introduction",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.3 Introduction",
    "text": "3.3 Introduction\nIn Bayesian statistics, integrating prior distributions is fundamental for incorporating existing knowledge about parameters ahead of data analysis, which includes historical data and domain expertise, and plays an important role in informed decision-making from the posterior distribution.\nIn cases of limited or incomplete data, priors are crucial for generating stable posterior estimates. They enhance model-building flexibility by accommodating various parameter types and clarifying the distinction between prior knowledge and new data. For example, when evaluating the probability of rare events, a well-informed prior, such as a Beta distribution, helps avoid unrealistic predictions, even with small sample sizes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#exercises",
    "href": "M02_1.html#exercises",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.12 Exercises",
    "text": "4.12 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#live-tutorial-and-discussion",
    "href": "M02_1.html#live-tutorial-and-discussion",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.5 Live tutorial and discussion",
    "text": "3.5 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#summary",
    "href": "M02_1.html#summary",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.4 Summary",
    "text": "3.4 Summary\nToday’s lecture focused on understanding different types of prior distributions and their role in deriving the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#section",
    "href": "M02_1.html#section",
    "title": "3  Directed Acyclic Graph (DAG) (Week 3)",
    "section": "3.7 ",
    "text": "3.7"
  },
  {
    "objectID": "M02_1.html#preparation-for-week-2",
    "href": "M02_1.html#preparation-for-week-2",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.12 Preparation for Week 2",
    "text": "4.12 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course."
  },
  {
    "objectID": "M02_2.html#learning-objectives",
    "href": "M02_2.html#learning-objectives",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.2 Learning Objectives",
    "text": "4.2 Learning Objectives\nBy the end of this week you should be able to:\n\nCreate generative models\nUnderstand traceable and untraceable solutions\nExplain the convergence of MCMC.\nConduct prior predictive check.\nConduct posterior predictive check.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learning-activities",
    "href": "M02_2.html#learning-activities",
    "title": "4  Tools and Generative Models",
    "section": "4.2 Learning Activities",
    "text": "4.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#introduction",
    "href": "M02_2.html#introduction",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.3 Introduction",
    "text": "4.3 Introduction\nGenerative models are essential tools in statistical analysis, enabling the understanding and simulation of complex data structures. Bayesian methods play a crucial role in solving such problems. However, a key challenge in Bayesian analysis is ensuring convergence in Markov Chain Monte Carlo (MCMC) simulations, which is vital for generating samples that accurately represent the target distribution.\nTo assess the reliability of Bayesian models, prior and posterior predictive checks are commonly used to validate the coherence between the model and observed data. These checks provide a rigorous framework for informed decision-making in applications where generative models are employed.\nThis lecture explores the role of Bayesian tools in statistical modeling, highlighting their challenges, evaluation methods, and practical implications.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#exercises",
    "href": "M02_2.html#exercises",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.6 Exercises",
    "text": "4.6 Exercises\n\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#live-tutorial-and-discussion",
    "href": "M02_2.html#live-tutorial-and-discussion",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.9 Live tutorial and discussion",
    "text": "4.9 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#summary",
    "href": "M02_2.html#summary",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.8 Summary",
    "text": "4.8 Summary\nToday’s lecture focused on understanding generative models, and how we can use generative models to answer research questions using Bayesian methods. We learn when to use exact inference and MCMC based optimisations, together their types. Finally we illustrate the prior and posterior predictive checks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#section",
    "href": "M02_2.html#section",
    "title": "4  Tools and Generative Models (Week 4)",
    "section": "4.7 ",
    "text": "4.7"
  },
  {
    "objectID": "M02_2.html#preparation-for-week-2",
    "href": "M02_2.html#preparation-for-week-2",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.9 Preparation for Week 2",
    "text": "4.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.\n\n\n\n\nBernardo, JM, MJ Bayarri, JO Berger, AP Dawid, D Heckerman, AFM Smith, and M West. 2007. “Generative or Discriminative? Getting the Best of Both Worlds.” Bayesian Statistics 8 (3): 3–24.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learning-objectives",
    "href": "M03_1.html#learning-objectives",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.2 Learning Objectives",
    "text": "5.2 Learning Objectives\nBy the end of this week you should be able to:\n\nUnderstand Bayesian model and causality\nExplain the terms Estimand, Estimator & Estimate\nUnderstand the difference between Bayesian and classical Regression.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learning-activities",
    "href": "M03_1.html#learning-activities",
    "title": "5  Bayesian Regressions - I",
    "section": "5.2 Learning Activities",
    "text": "5.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayesian Regressions - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#introduction",
    "href": "M03_1.html#introduction",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction\nasdafs\n\nIn this lecture, we shall explore the application of Bayesian inference methodologies using hierarchical models. We will begin by examining the utilisation of Bayesian methods within the context of simple linear regression models and subsequently expand these insights to encompass multiple linear regression. Through this exploration, we will find that employing the non-informative prior results in posterior means, posterior standard deviations, and credible intervals for the coefficients that are consistent with those derived from frequentist ordinary least squares (OLS) linear regression models.\nWe will start with how to develop a Bayesian model based on causality, or unknown causality with understanding of estimand, estimator and estimate. We wil also explore how DAG can help us to build the model.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#exercises",
    "href": "M03_1.html#exercises",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.9 Exercises",
    "text": "5.9 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#live-tutorial-and-discussion",
    "href": "M03_1.html#live-tutorial-and-discussion",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.10 Live tutorial and discussion",
    "text": "5.10 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#summary",
    "href": "M03_1.html#summary",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.11 Summary",
    "text": "5.11 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#section",
    "href": "M03_1.html#section",
    "title": "5  Bayesian Regressions - Part 1 (Week 5)",
    "section": "5.7 ",
    "text": "5.7"
  },
  {
    "objectID": "M03_1.html#preparation-for-week-2",
    "href": "M03_1.html#preparation-for-week-2",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.12 Preparation for Week 2",
    "text": "5.12 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learning-objectives",
    "href": "M03_2.html#learning-objectives",
    "title": "6  Bayeswatch! Part - II",
    "section": "",
    "text": "Understand the Bayesian GLM\nUnderstand the difference between Bayesian and classical GLM.\nFormulate problems and solutions using Bayesian GLM.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learning-activities",
    "href": "M03_2.html#learning-activities",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.2 Learning Activities",
    "text": "6.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#introduction",
    "href": "M03_2.html#introduction",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.2 Introduction",
    "text": "6.2 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#exercises",
    "href": "M03_2.html#exercises",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.5 Exercises",
    "text": "6.5 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#live-tutorial-and-discussion",
    "href": "M03_2.html#live-tutorial-and-discussion",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.6 Live tutorial and discussion",
    "text": "6.6 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#summary",
    "href": "M03_2.html#summary",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.7 Summary",
    "text": "6.7 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#section",
    "href": "M03_2.html#section",
    "title": "6  Bayesian Regressions - Part 2 (Week 6)",
    "section": "6.7 ",
    "text": "6.7"
  },
  {
    "objectID": "M03_2.html#preparation-for-week-2",
    "href": "M03_2.html#preparation-for-week-2",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.8 Preparation for Week 2",
    "text": "6.8 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learning-objectives",
    "href": "M04_1.html#learning-objectives",
    "title": "7  Clusterphobia? Part - I",
    "section": "",
    "text": "Explain clusterd data.\nDescribe hierarchical or multilevel Models.\nFit Bayesian linear mixed models.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learning-activities",
    "href": "M04_1.html#learning-activities",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.2 Learning Activities",
    "text": "7.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#introduction",
    "href": "M04_1.html#introduction",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.2 Introduction",
    "text": "7.2 Introduction\nasdafs\nhttps://m-clark.github.io/mixed-models-with-R/bayesian.html\nMultilevel structure : https://bookdown.org/marklhc/notes_bookdown/hierarchical-multilevel-models.html\nhttps://m-clark.github.io/easy-bayes/rstanarm-mixed-model.html",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#exercises",
    "href": "M04_1.html#exercises",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.6 Exercises",
    "text": "7.6 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#live-tutorial-and-discussion",
    "href": "M04_1.html#live-tutorial-and-discussion",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.7 Live tutorial and discussion",
    "text": "7.7 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#summary",
    "href": "M04_1.html#summary",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.8 Summary",
    "text": "7.8 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#section",
    "href": "M04_1.html#section",
    "title": "7  Clustered Data Modelling - Part 1 (Week 7)",
    "section": "7.7 ",
    "text": "7.7"
  },
  {
    "objectID": "M04_1.html#preparation-for-week-2",
    "href": "M04_1.html#preparation-for-week-2",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.9 Preparation for Week 2",
    "text": "7.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learning-objectives",
    "href": "M04_2.html#learning-objectives",
    "title": "8  Clusterphobia? Part - II",
    "section": "",
    "text": "Construct multilevel models for binary outcome.\nUnderstand the difference between Bayesian and classical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learning-activities",
    "href": "M04_2.html#learning-activities",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.2 Learning Activities",
    "text": "8.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#introduction",
    "href": "M04_2.html#introduction",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.2 Introduction",
    "text": "8.2 Introduction\nasdafs\nMarginal effects:\nref: https://joshuawiley.com/brmsmargins/articles/fixed-effects-marginaleffects.html\nref: https://cran.r-project.org/web/packages/brmsmargins/vignettes/mixed-effects-marginaleffects.html",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#exercises",
    "href": "M04_2.html#exercises",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.5 Exercises",
    "text": "8.5 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#live-tutorial-and-discussion",
    "href": "M04_2.html#live-tutorial-and-discussion",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.6 Live tutorial and discussion",
    "text": "8.6 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#summary",
    "href": "M04_2.html#summary",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.7 Summary",
    "text": "8.7 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#section",
    "href": "M04_2.html#section",
    "title": "8  Clustered Data Modelling - Part 2 (Week 8)",
    "section": "8.7 ",
    "text": "8.7"
  },
  {
    "objectID": "M04_2.html#preparation-for-week-2",
    "href": "M04_2.html#preparation-for-week-2",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.8 Preparation for Week 2",
    "text": "8.8 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayesian-philosophy",
    "href": "M01_1.html#bayesian-philosophy",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.3 Bayesian Philosophy",
    "text": "1.3 Bayesian Philosophy\n\n\nBayesian philosophy revolves around the concept of “degrees of belief” in scientific reasoning. But what does that actually mean? Simply put, it views probability as a measure of our confidence in an event, which updates as we gather new evidence. Unlike traditional frequentist statistics, which treat probability as an objective, fixed value, Bayesian thinking sees it as a dynamic, subjective measure that evolves with new data and insights.\nLet’s explain a bit more using examples:\n\n\n\n\n\nBayesian World (Philosophy)\n\n\n\n\nSuppose a medical practitioner is treating a patient who might have a particular illness, like type-2 diabetes. Initially, based on the patient’s age, family history, and some initial symptoms, the medical practitioner might believe there’s a 20% chance the patient has diabetes. This belief is a prior probability.\nNow, the medical practitioner orders a blood test to check the patient’s blood sugar levels. When the results come back, they show elevated sugar levels, which increase the likelihood of diabetes. The medical practitioner updates their belief based on this new evidence, which is called the posterior probability.\nSo, Bayesian philosophy evolves starting with an initial belief (prior), and then updating that belief as new data (like test results) comes in. In short, it’s a flexible way of thinking where beliefs are adjusted as information is acquired.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#classical-vs.-bayesian",
    "href": "M01_1.html#classical-vs.-bayesian",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.5 Classical vs. Bayesian",
    "text": "2.5 Classical vs. Bayesian\n\n\nMcElreath (2020)\nHistory:\nThe development of Bayesian statistical inference dates back to the late 18th century, preceding many contemporary methodologies. Its application continued into the 19th century. However, after World War I, statisticians like Sir Ronald Fisher, who opposed Bayesian concepts, reduced its prominence. Fisher’s 1925 statistical handbook made only scant mention of Bayesian analysis, then referred to as “inverse probability,” thus diminishing its influence in mainstream statistics. Throughout the latter half of the 20th century, Bayesian analysis gradually regained acceptance. The advent of novel computational technologies in the 1990s significantly increased the application of Bayesian methods.\n\nData and Parameter:\nData represents known elements, whereas parameters are unknown quantities inferred from data. Within the Bayesian framework, this distinction becomes less clear; a variable may be either observed or unobserved, yet it is governed by the same distribution function. Consequently, an assumption can serve as a “likelihood” or a “prior” depending on the context, without altering the model. This connection between certainty (data) and uncertainty (parameters) facilitates the management of measurement errors and missing data in modeling.\n\nReliable Inference:\nThere exists a notion that a specific number of observations is necessary for reliable statistical estimates. For example, at least 30 observations are typically required for a Gaussian distribution. This notion is rooted in traditional statistical inference, where methods are validated for large sample sizes, a concept known as asymptotic behavior, which introduces uncertainty with smaller samples.\nConversely, Bayesian estimates remain valid regardless of sample size. While larger samples are advantageous, Bayesian methods provide meaningful results even with limited data. However, they necessitate a careful selection of the “prior,” which significantly influences the final inference. An improperly chosen prior can skew conclusions. Understanding the world demands thoughtful consideration, without resorting to shortcuts.\n\nRole of Data:\nThe distinctions between Bayesian and non-Bayesian methodologies are notable, yet these differences can sometimes overshadow their underlying commonalities. In many Bayesian and non-Bayesian models, the most critical assumptions typically concern the likelihood functions and their connections with the parameters. These assumptions guide the inferences drawn from each dataset. As the sample size grows, the significance of the likelihood increases. This shared emphasis on likelihood clarifies why Bayesian and non-Bayesian inferences frequently yield similar results.\n\nFurthermore, a common misunderstanding regarding Bayesian data analysis and inference is the belief that they are exclusively defined by Bayes’ theorem. Any inferential method employing probability theory incorporates Bayes’ theorem. Numerous examples labeled as “Bayesian” often lack distinctive attributes and instead rely on observed data frequencies, resembling non-Bayesian methods. The distinctiveness of Bayesian techniques lies in their application of Bayes’ theorem to measure the uncertainty associated with theoretical constructs not directly observable, such as parameters and models. Both methodologies can produce robust inferences, although they are grounded in different principles and entail unique trade-offs.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayes-theorem",
    "href": "M01_1.html#bayes-theorem",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.7 Bayes’ Theorem",
    "text": "1.7 Bayes’ Theorem\n\n\nLet’s now go back to the example related to type-2 diabetes, where, a medical practitioner hypothise based on patient’s background history that the patient has a chance of having diabetes.\nThus, we have two events:\n\nThe hypothesis that medical practitioner’s guess is correct \\((G=[+])\\).\nThe evidence: Blood test showing elevated sugar levels \\((E=[+])\\).\n\nNow, given this experimental evidence of elevated blood sugar, how sure are the medical practitioner that their guess about the diabetes is accurate?\n\\[\nPr(\\text{Guess is correct} | \\text{Positive evidence}) = \\text{ ?}\n\\]\nHence, using conditional probability expression we write:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]},\\text{E=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(\\text{G=[+]},\\text{E=[+]})\\) is the joint probabiity that both \\((G=[+])\\) and \\((E=[+])\\) occur. We can rearrange and write the joint probability as:\n\\[\nPr(\\text{G=[+]},\\text{E=[+]}) = Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})\n\\]\nHence, by substituting the joint probability the Bayes theorem states:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(E=[+])\\) is the marginal probability for the blood test showing high suger levels for all possible hypotheses, here, the possible hypotheses are: \\(G=[+]\\) and \\(G=[-]\\). Hence, we write \\(Pr(\\text{G=[+]}|\\text{E=[+]})\\) as:\n\\[\n\\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})+Pr(\\text{G=[-]})\\times Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(Pr(\\text{G=[+]})\\) and \\(Pr(\\text{G=[-]})\\) are the probabilities of the medical practitioner’s guess is correct and incorrect respectively, thus we write \\(Pr(\\text{G=[-]}) = 1-Pr(\\text{G=[+]})\\) or vise versa.\nWe clearly see that the degree of belief probability after including the evidence is equal to the probability of guess before incorporating the evidence and probability of the evidence with the medical practitioner’s guess.\n\n1.7.1 Example\nTo explain the above example we write, \\(Pr(\\text{G=[+]})=0.2\\), as the medical practitioner guessed that there is a 20% chance the patient has diabetes. The complement, the probability that the patient does not have diabetes, is \\(Pr(\\text{G=[-]})=0.8\\).\nNow, let us define the test’s accuracy:\n\nSensitivity (True Positive Rate or Hit Rate): \\(Pr(\\text{E=[+]}|\\text{G=[+]})=0.85\\), i.e., 85% of diabetics test positive.\nSpecificity (True Negative Rate): \\(Pr(\\text{E=[-]}|\\text{G=[-]})=0.90\\), i.e., 90% of non-diabetics test negative.\nFalse Positive Rate (False Alarm): \\(Pr(\\text{E=[+]}|\\text{G=[-]})=1-Pr(\\text{E=[-]}|\\text{G=[-]})=1-0.9=0.10\\), i.e., 10% of non-diabetics test positive.\n\nThe question is: Given that the test result is positive, how sure is the medical practitioner that the patient truly has diabetes?\nThis is expressed as the posterior probability , which we compute using Bayes’ theorem:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{(0.2\\times 0.85)}{(0.2\\times 0.85) + (0.8\\times 0.1)} = 0.68\n\\]\nAfter observing a positive blood sugar test, the probability that the patient has diabetes increases from 20% to 68%. This means the medical practitioner is now 68% confident in their updated belief that the patient has diabetes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze",
    "href": "M01_1.html#the-maze",
    "title": "1  Degrees of Beliefs and Evidence",
    "section": "1.6 The Maze",
    "text": "1.6 The Maze\n\nBayesian analysis is a logical framework that helps update our beliefs based on new information. It allows us to reason about uncertainty by combining what we already know with evidence we gather to refine our understanding.\nA helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works—it continuously updates our understanding as more evidence comes in.\nTo see this in practice, consider a doctor diagnosing a patient’s illness. Initially, the doctor forms a hypothesis based on the patient’s symptoms and medical history. For instance, they might think there’s a 60% chance of a respiratory infection, a 20% chance of asthma, and a 20% chance of another condition. This initial estimate represents the prior belief. The doctor then orders a chest X-ray, which reveals signs typically associated with respiratory infections. This new evidence increases the likelihood of that diagnosis compared to the alternatives. By combining the initial belief with the X-ray results, the doctor updates the probabilities, now thinking there’s an 80% chance of a respiratory infection, 10% for asthma, and 10% for something else. Additional tests, such as blood work or lung function tests, provide further evidence, allowing the doctor to refine the probabilities until they are confident in the diagnosis.\nThis iterative process is what makes Bayesian analysis so powerful. It doesn’t discard initial beliefs but continuously refines them in light of new evidence. Whether used in medicine, machine learning, or everyday decisions, Bayesian methods ensure that our conclusions are informed, logical, and adaptable as more information becomes available.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Degrees of Beliefs and Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-frequency-bayes-rule",
    "href": "M01_1.html#dual-factor-frequency-bayes-rule",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.6 Dual-Factor Frequency (Bayes’ Rule)",
    "text": "2.6 Dual-Factor Frequency (Bayes’ Rule)\n\nKruschke (2014)"
  },
  {
    "objectID": "M01_2.html#bayesian-inference",
    "href": "M01_2.html#bayesian-inference",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.2 Bayesian Inference",
    "text": "2.2 Bayesian Inference\n\n\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote \\(Pr(H)\\) as the probability of initial belief about \\(H\\) before seeing data, we can write the updated belief about \\(H\\) given the data \\(D\\) as:\n\\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\]\nwhere, \\(Pr(D)\\) is the probability of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-updating",
    "href": "M01_2.html#bayesian-updating",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Bayesian Updating",
    "text": "2.10 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior.\nGoing back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#prior-distribution",
    "href": "M01_2.html#prior-distribution",
    "title": "3  Bayesian Inference",
    "section": "3.6 Prior Distribution",
    "text": "3.6 Prior Distribution\nasdf\nconjugacy explain with binomial, poisson distribution exampels. ??\nwhy conjugacy is useful - ref: lambert, page 202, sec:9.3 (beta-bino) and 9.4 (gamma-poiss) and 9.5 (normal-known sigma)\nnon-conjugacy ref:???"
  },
  {
    "objectID": "M01_2.html#more-insights-into-prior-distribution",
    "href": "M01_2.html#more-insights-into-prior-distribution",
    "title": "3  Bayesian Inference",
    "section": "3.8 More Insights into Prior Distribution",
    "text": "3.8 More Insights into Prior Distribution\n\n\n3.8.1 Informative Prior Distribution\n\n\n\n3.8.2 Non-informative Prior Distribution\n\n\n\n3.8.3 Weakly Informative Prior Distribution\n\n\n\n3.8.4 Eliciting Prior Distribution\n\n\n\n3.8.5 Prior Sensitivity",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#exercises-1",
    "href": "M01_1.html#exercises-1",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.10 Exercises",
    "text": "2.10 Exercises\nsdfads\nref: sahu page 73, sec 4.3"
  },
  {
    "objectID": "M02_1.html#dag",
    "href": "M02_1.html#dag",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.4 DAG",
    "text": "4.4 DAG\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables in a model. In a DAG, nodes represent variables, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\nIn the context of Bayesian modeling, DAGs are crucial as they visually encode the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the Binomial model example, we can write a DAG for the Bayesian model as:\n\n\n\n\n\n graph LR\n      A[\"$$x^2$$\"] --&gt;|\"$$\\sqrt{x+3}$$\"| B(\"$$\\frac{1}{2}$$\")\n      A --&gt;|\"$$\\overbrace{a+b+c}^{\\text{note}}$$\"| C(\"$$\\pi r^2$$\")\n      B --&gt; D(\"$$x = \\begin{cases} a &\\text{if } b \\\\ c &\\text{if } d \\end{cases}$$\")\n      C --&gt; E(\"$$x(t)=c_1\\begin{bmatrix}-\\cos{t}+\\sin{t}\\\\ 2\\cos{t} \\end{bmatrix}e^{2t}$$\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Directed Acyclic Graph (DAG)**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#estimand-estimator-estimateestimation",
    "href": "M02_1.html#estimand-estimator-estimateestimation",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.6 Estimand, Estimator & Estimate/Estimation",
    "text": "4.6 Estimand, Estimator & Estimate/Estimation\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Directed Acyclic Graph (DAG)**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#bayesian-dag",
    "href": "M02_1.html#bayesian-dag",
    "title": "4  Directed Acyclic Graph (DAG)",
    "section": "4.6 Bayesian DAG",
    "text": "4.6 Bayesian DAG\nasdf - graphical representations of the probabilistic relationships between variables and parameters"
  },
  {
    "objectID": "M02_1.html#bayesian-causal-inference",
    "href": "M02_1.html#bayesian-causal-inference",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.11 Bayesian Causal Inference",
    "text": "4.11 Bayesian Causal Inference\nref: https://onlinelibrary.wiley.com/doi/10.1002/sim.8761\nref: https://bookdown.org/paul/applied-causal-analysis/\nref: paper: https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0153\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learning-objectives",
    "href": "M05_1.html#learning-objectives",
    "title": "9  Size Matters! Part - I",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learning-activities",
    "href": "M05_1.html#learning-activities",
    "title": "9  Size Matters! Part - I",
    "section": "9.2 Learning Activities",
    "text": "9.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#introduction",
    "href": "M05_1.html#introduction",
    "title": "9  Size Matters! Part - I",
    "section": "9.2 Introduction",
    "text": "9.2 Introduction\nasdafs\nref shinyapp: https://ibl.mdanderson.org/shinyapps/BayesESS/\nref: power-priors: https://journal.r-project.org/articles/RJ-2023-016/",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#exercises",
    "href": "M05_1.html#exercises",
    "title": "9  Size Matters! Part - I",
    "section": "9.6 Exercises",
    "text": "9.6 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#live-tutorial-and-discussion",
    "href": "M05_1.html#live-tutorial-and-discussion",
    "title": "9  Size Matters! Part - I",
    "section": "9.7 Live tutorial and discussion",
    "text": "9.7 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#summary",
    "href": "M05_1.html#summary",
    "title": "9  Size Matters! Part - I",
    "section": "9.8 Summary",
    "text": "9.8 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#preparation-for-week-2",
    "href": "M05_1.html#preparation-for-week-2",
    "title": "9  Size Matters! Part - I",
    "section": "9.9 Preparation for Week 2",
    "text": "9.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learning-objectives",
    "href": "M05_2.html#learning-objectives",
    "title": "10  Size Matters! Part - II",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learning-activities",
    "href": "M05_2.html#learning-activities",
    "title": "10  Size Matters! Part - II",
    "section": "10.2 Learning Activities",
    "text": "10.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#introduction",
    "href": "M05_2.html#introduction",
    "title": "10  Size Matters! Part - II",
    "section": "10.2 Introduction",
    "text": "10.2 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#exercises",
    "href": "M05_2.html#exercises",
    "title": "10  Size Matters! Part - II",
    "section": "10.7 Exercises",
    "text": "10.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#live-tutorial-and-discussion",
    "href": "M05_2.html#live-tutorial-and-discussion",
    "title": "10  Size Matters! Part - II",
    "section": "10.8 Live tutorial and discussion",
    "text": "10.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#summary",
    "href": "M05_2.html#summary",
    "title": "10  Size Matters! Part - II",
    "section": "10.9 Summary",
    "text": "10.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#preparation-for-week-2",
    "href": "M05_2.html#preparation-for-week-2",
    "title": "10  Size Matters! Part - II",
    "section": "10.10 Preparation for Week 2",
    "text": "10.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learning-objectives",
    "href": "M06_1.html#learning-objectives",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learning-activities",
    "href": "M06_1.html#learning-activities",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.2 Learning Activities",
    "text": "11.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#introduction",
    "href": "M06_1.html#introduction",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.2 Introduction",
    "text": "11.2 Introduction\nasdafs\nVedio",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#exercises",
    "href": "M06_1.html#exercises",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.6 Exercises",
    "text": "11.6 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#live-tutorial-and-discussion",
    "href": "M06_1.html#live-tutorial-and-discussion",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.7 Live tutorial and discussion",
    "text": "11.7 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#summary",
    "href": "M06_1.html#summary",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.8 Summary",
    "text": "11.8 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#preparation-for-week-2",
    "href": "M06_1.html#preparation-for-week-2",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.9 Preparation for Week 2",
    "text": "11.9 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learning-objectives",
    "href": "M06_2.html#learning-objectives",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "",
    "text": "Understand Bayesian philosophy.\nDescribe the motivation of doing Bayesian analysis.\nUnderstand the difference between Bayesian and classical statistical methods.\nInterpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learning-activities",
    "href": "M06_2.html#learning-activities",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.2 Learning Activities",
    "text": "12.2 Learning Activities\nThis week’s learning activity include:\n\n\n\nLearning Activity\nLearning Objectives\n\n\n\n\nVideo\n1,3\n\n\nReadings\n2,3,4\n\n\nExercises\n4\n\n\nLive tutorial/discussion\n1,2,3,4",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#introduction",
    "href": "M06_2.html#introduction",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.3 Introduction",
    "text": "12.3 Introduction\nasdafs",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#exercises",
    "href": "M06_2.html#exercises",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.5 Exercises",
    "text": "12.5 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#live-tutorial-and-discussion",
    "href": "M06_2.html#live-tutorial-and-discussion",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.6 Live tutorial and discussion",
    "text": "12.6 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#summary",
    "href": "M06_2.html#summary",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.7 Summary",
    "text": "12.7 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#preparation-for-week-2",
    "href": "M06_2.html#preparation-for-week-2",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.8 Preparation for Week 2",
    "text": "12.8 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-frequency",
    "href": "M01_1.html#dual-factor-frequency",
    "title": "2  Degrees of Beliefs and Evidence",
    "section": "2.6 Dual-Factor Frequency",
    "text": "2.6 Dual-Factor Frequency\n\nKruschke (2014)\nTo understand Bayes’ Theorem, lets start with a simple case of probability based on a two-way table."
  },
  {
    "objectID": "M02_1.html#bayesian-dag-models",
    "href": "M02_1.html#bayesian-dag-models",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.10 Bayesian DAG & Models",
    "text": "4.10 Bayesian DAG & Models\nasdf - graphical representations of the probabilistic relationships between variables and parameters",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#correlation-vs-causation",
    "href": "M02_1.html#correlation-vs-causation",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.9 Correlation vs Causation",
    "text": "4.9 Correlation vs Causation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#generative-models",
    "href": "M02_2.html#generative-models",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.2 Generative Models",
    "text": "4.2 Generative Models\n\n\nA generative model is designed to generate new data points by capturing the intricate probability distributions of existing datasets. By learning these distributions, the model can produce data that reflects the characteristics of original datasets, simulating realistic examples. A generative model can also be used to understand how a set of observed data could have arisen from a set of underlying causes, which we will discuss more later in this course.\nIn Bayesian modeling, generative models are particularly useful as they provide a framework for estimating the likelihood of data under different hypotheses. This capability enhances Bayesian inference processes, allowing for more effective prior and posterior distribution updates. The flexibility of generative models in simulating various scenarios can also improve the robustness and accuracy of Bayesian models, and refines the decision-making and predictive capabilities.\nNote that, in this course, we use “generative model” broadly to consider the origins of a particular dataset. However, this term also has a more specific definition, especially as it contrasts with “discriminative models”, for details see Bernardo et al. (2007).\n\nExample\nLet’s explain this using the example we discussed earlier related to the vaccine efficacy rate. Let use assume that we collect data from \\(n=100\\) individuals and the vaccine was effective for 80 individuals. Let us also assume the prior probabilty for the effectiveness as \\(0.7\\). Given this information we now recreate the data.\n\nData generation:\n\nIn a generative modelling context, we simulate data for these 100 individuals by considering success probability \\(\\theta = 0.8\\).\n\n\nCode\nn &lt;- 100\ntheta &lt;- 0.8  \nsize &lt;- 1  \nset.seed(1234)  \ndata &lt;- rbinom(size, n, theta)\npaste(\"Number of success: \",data,\" out of \",n, \"individuals\")\n\n\n[1] \"Number of success:  85  out of  100 individuals\"\n\n\nWe can see that our simulation using one replication yields probability 0.85, whereas, actual data shows \\(\\theta = 0.8\\). Hence, to reflect actual data we need to replicate the data simulation for multiple times, which yields an average value for \\(\\theta \\approx 0.8\\) and upper and lower 95% credible interval (0.72,0.88).\n\n\nCode\nlibrary(ggplot2)\n\nn &lt;- 100     \ntheta &lt;- 0.8    \nsize &lt;- 1000  \n\nset.seed(123)  \ndata &lt;- rbinom(size, n, theta)\nci &lt;- quantile(data, probs = c(0.025, 0.975))\ndf &lt;- data.frame(Successes = data)\nggplot(df, aes(x = Successes)) +\n  geom_histogram(\n    breaks = seq(-0.5, n + 0.5, by = 1),\n    fill = \"skyblue\",\n    color = \"black\",\n    boundary = -0.5\n  ) +\n  scale_x_continuous(\n    breaks = NULL,  \n    name = NULL     \n  ) +\n  labs(\n    title = paste(\"Histogram of Simulated Binomial Data (n =\", n, \", θ =\", theta, \")\"),\n    y = \"Frequency\"\n  ) +\n  geom_vline(xintercept = ci[1], linetype = \"dashed\", color = \"red\", size = 1) +\n  geom_vline(xintercept = ci[2], linetype = \"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = ci[1], y = max(table(data)) * 0.9, label = paste0(\"2.5%: \", ci[1]), color = \"red\", angle = 90, vjust = -0.5) +\n  annotate(\"text\", x = ci[2], y = max(table(data)) * 0.9, label = paste0(\"97.5%: \", ci[2]), color = \"red\", angle = 90, vjust = -0.5) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_blank(),  \n    axis.ticks.x = element_blank()  \n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#traceable-and-untraceable-solutions",
    "href": "M02_2.html#traceable-and-untraceable-solutions",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.3 Traceable and Untraceable Solutions",
    "text": "4.3 Traceable and Untraceable Solutions\nA traceable solution manifests when the posterior distribution can be explicitly determined in a closed-form mathematical expression, facilitating straightforward analysis. This situation arises particularly when the prior distribution and the likelihood function are chosen such that the posterior distribution remains within a recognized family of probability distributions.\nFor example, when a conjugate prior is used, the posterior has a known or a same functional form as the prior. This helps to derive posterior parameters easily with simple calculations. This also helps to derive the posterior using exact solutions without relying on numerical or approximation methods. For a Bernoulli model, we have already discussed earlier in Lecture 2, which reflects:\n\\[\n\\text{Prior: } \\theta \\sim \\text{Beta}(a,b);\n\\]\n\\[\n\\text{Posterior: } \\theta|y \\sim \\text{Beta}(a+y,b+n-y)\n\\]\nAn untraceable solution emerges in situations where the posterior distribution cannot be expressed in a closed-form expression. This phenomenon occurs when the likelihood function and the prior distribution are incompatible, resulting in the emergence of complex integrals within Bayes’ theorem that are analytically intractable.\nFor example, use of non-conjugate priors. Often complex likelihood functions, such as those involving hierarchical models, mixture models, or high-dimensional data also yields a posterior form of distribution with untraceable solutions, even if we consider conjugate priors for the model parameters. For a non-Gaussian likelihood, use of a uniform prior also yields untraceable solution.\n\n\n\n\n\n\n\n\n\n\nTraceable Solutions\nUntraceable Solutions\n\n\n\n\nPosterior\nClosed-form expression\nRequires approximation or sampling\n\n\nPrior-Likelihood Relation\nOften relies on conjugacy\nNo conjugacy needed\n\n\nComputation\nExact and straightforward\nComputationally intensive\n\n\nFlexibility\nLimited (conjugate priors only)\nHigh (any prior-likelihood combination)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#mcmc-convergence-diagnostics",
    "href": "M02_2.html#mcmc-convergence-diagnostics",
    "title": "4  Tools and Generative Models",
    "section": "4.7 MCMC convergence diagnostics",
    "text": "4.7 MCMC convergence diagnostics\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#prior-and-posterior-predictive-checks",
    "href": "M02_2.html#prior-and-posterior-predictive-checks",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.7 Prior and Posterior Predictive Checks",
    "text": "4.7 Prior and Posterior Predictive Checks\n\n\n\n\n4.7.1 Prior Predictive Checks\nPrior predictive checks involve simulating data from the model before observing real data to assess whether the chosen prior distribution is reasonable. Then we compare this simulated data with the actual observation, if available. This step helps to ensure that our prior assumptions align with the real-world outcomes.\nPrior predictive check is important in Bayesian simulations. We can use this to understand the influence of prior on possible outcomes. It can also help us to avoid overly informed prior, which might lead to a strong influence on the posterior distribution. For example, if a prior on disease prevalence suggests 90% probability when we know it’s closer to 5%, then the prior is not reasonable. Thus, for implausible simulated data, we can say that the prior is too vague, too strong, or poorly chosen.\n\nSteps to perform prior predictive check\n\nBefore collecting data, choose a prior for the parameter, say \\(\\theta\\), if we are modeling a Bernoulli process, where assume the prior follows Beta distribution, i.e., \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\).\nFor instance, let’s assume:\n\\[\n\\theta \\sim \\text{Beta}(1, 1) \\quad \\text{(Uniform prior, meaning all values are equally likely).}\n\\]\nNow, we generate or simulate data from the prior distribution, i.e., first sample \\(\\theta\\) from the prior and then generate data \\(y\\) using a defined model.\nFor example, if we are modeling the efficacy rate of a certain vaccine in patients with similar profiles, then\n\nSample \\(\\theta^{sim} \\sim \\text{Beta}(1,1)\\).\nSimulate \\(y^{sim} \\sim \\text{Bernoulli}(\\theta^{sim})\\) for \\(n\\) trials.\n\nThis gives us a distribution of possible datasets before seeing real data.\nIn the next step, we compare the simulated data with what we would expect or any available data. This can be done by plotting histograms or summary statistics of the simulated data. We can then check if the range and spread of simulated values make sense.\nFor example, if we assume a Beta(2, 2) prior, we expect \\(\\theta\\) to be centered around 0.5. Whereas, for Beta(1, 1) (i.e., Uniform prior), simulated values will be more spread out. If we assume Beta(100, 5), then most values will be very high (\\(\\theta\\) close to 1).\nNow, if simulated data looks unrealistic, the prior may need adjusting. This step prevents misleading results and improves Bayesian inference quality.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\nprior_predictive_check &lt;- function(alpha, beta, n_trials = 10, n_sim = 1000) {\n  theta_samples &lt;- rbeta(n_sim, alpha, beta)\n  bernoulli_samples &lt;- rbinom(n_sim, size = n_trials, prob = theta_samples)\n  df &lt;- data.frame(Theta = theta_samples, Successes = bernoulli_samples)\n  p1 &lt;- ggplot(df, aes(x = Theta)) +\n    geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n    labs(title = paste(\"Prior Distribution: Beta(\", alpha, \",\", beta, \")\"),\n         x = expression(theta), y = \"Frequency\") +\n    theme_minimal()\n  p2 &lt;- ggplot(df, aes(x = Successes)) +\n    geom_bar(fill = \"coral\", color = \"black\", alpha = 0.7) +\n    labs(title = paste(\"Simulated Successes (n =\", n_trials, \")\"),\n         x = \"Number of Successes\", y = \"Frequency\") +\n    theme_minimal()\n  gridExtra::grid.arrange(p1,p2,ncol=2)\n}\n\n# Example 1: Uniform Prior (Beta(1,1)) - No strong belief\n#prior_predictive_check(alpha = 1, beta = 1)\n# Example 2: Informative Prior (Beta(2,2)) - Believes success rate around 50%\n#prior_predictive_check(alpha = 2, beta = 2)\n# Example 3: Strong Prior (Beta(100,5)) - Believes success rate is high\n#prior_predictive_check(alpha = 100, beta = 5)\n# Example 4: Weak Prior (Beta(0.5, 0.5)) - Encourages extreme values (0 or 1)\n#prior_predictive_check(alpha = 0.5, beta = 0.5)\n\n\nLet’s now look at two examples in a health and medical context:\n-Perfect Example: Estimating the probability of a successful treatment for a specific medical condition based on prior knowledge.\nSuppose, a new drug treatment has been tested on patients with a specific medical condition. Previous studies indicate that the drug has a 70% success rate in patients with similar characteristics. We are uncertain about the exact probability of success, but the previous studies give us a reasonable prior belief about the success rate.\nThe Beta(7,3) prior reflects our belief that the treatment has a 70% success rate on average. This prior configuration is centered around 0.7, with a reasonable spread, allowing for some variation while keeping the treatment’s effectiveness as a reasonable estimate.\n\n\nCode\nprior_predictive_check(alpha = 7, beta = 3, n_trials = 10, n_sim = 1000)\n\n\n\n\n\n\n\n\n\nHistogram of \\(\\theta\\) shows most of the values around 0.7, reflecting the prior belief that the drug has a 70% success rate. For the simulated data we can see out of 10 trials, on average, 7 out of 10 patients are expected to succeed, but some variability (e.g., 6, 8 successes) is expected due to the spread of the prior.\n-Imperfect Example: Assuming a unreasonably high success rate for a new treatment without proper evidence.\nNow, assume a new drug for treating a condition has been introduced, but no clinical trials have been conducted yet. Despite this lack of data, the manufacturer assumes an overly optimistic success rate of 90% based on limited anecdotal evidence.\nBeta(90,10) prior assumes a very high success rate (about 90%), which is unrealistic without substantial evidence. This prior leads to a very narrow distribution, with values almost always close to 0.9, indicating extremely high success rates.\n\n\nCode\nprior_predictive_check(alpha = 90, beta = 10, n_trials = 10, n_sim = 1000)\n\n\n\n\n\n\n\n\n\nHere, histogram of \\(\\theta\\) shows that most values are close to 0.9, and similarly, simulations result show an unrealistic scenario for a new drug with little evidence backing the success rate.\n\n\n4.7.2 Posterior Predictive Checks\nA posterior predictive check is a technique used in Bayesian statistics to assess how well a fitted model explains the observed data. It involves generating or simulating new data from the posterior predictive distribution and comparing it to the observed data to check for discrepancies. If the generated data looks similar to the observed data, the model is considered a good fit; if not, the model may be inadequate.\nUse of posterior predictive checks help to detect model misspecification, can provide intuitive, visual validation of the model’s performance.\n\nSteps to perform posterior predictive check\n\nWe first estimate the posterior distribution of the model parameters, say \\(\\theta\\) given the observed data \\(y\\). Then draw samples from the posterior predictive distribution (say \\(p(\\tilde{y}|y)\\), where \\(\\tilde{y}\\) is the predicted data), which represents hypothetical new data (\\(\\tilde{y}\\)) generated by the model.\nHence, use visualisations (e.g., histograms, density plots, scatter plots) or statistical summaries (e.g., mean, variance) to compare the simulated data to the actual observed data.\nIf the simulated data deviates significantly from the observed data, it suggests the model may be misspecified.\nLet’s consider a Bernoulli model, where suppose we have a dataset of \\(n\\) observations. Hence, the posterior predictive distribution for new data \\(\\tilde{y}\\) is:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta\n\\]\nTo check if our model fits well, we generate new (simulated) data \\(\\tilde{y}^{(sim)}\\), and the compare \\(\\tilde{y}^{(sim)}\\) to observed data \\(y\\).\nIf simulated data is similar to observed data, the model is reasonable. Whereas, if there is a mismatch, the model might be misspecified (e.g., wrong prior, incorrect likelihood assumption).\n-Example\nSuppose we want to estimate the probability of a successful treatment for a specific medical condition using Bayesian inference. The model assumes that each patient’s treatment outcome follows a Bernoulli distribution, and we use a Beta prior to express our prior beliefs about the success rate. We then perform a posterior predictive check to assess the model fit by simulating new data and comparing it to observed outcomes.\nAssume that we collected data from 30 patients who underwent treatment, of which 18 patients recovered (successes), while 12 did not recover (failures). Considering a uniform prior for \\(\\theta\\), i.e., \\(\\theta \\sim \\text{Beta}(1,1)\\), we can get the following plots for posterior distribution, and posterior predictive checks.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nposterior_predictive_check &lt;- function(alpha, beta, n_trials, successes, n_sim = 1000) {\n  posterior_alpha &lt;- alpha + successes\n  posterior_beta &lt;- beta + (n_trials - successes)\n  theta_samples &lt;- rbeta(n_sim, posterior_alpha, posterior_beta)\n  bernoulli_samples &lt;- rbinom(n_sim, size = n_trials, prob = theta_samples)\n  df &lt;- data.frame(Theta = theta_samples, Successes = bernoulli_samples)\n  p1 &lt;- ggplot(df, aes(x = Theta)) +\n    geom_density(fill = \"skyblue\", alpha = 0.7) +\n    labs(title = paste(\"Posterior Distribution: Beta(\", posterior_alpha, \",\", posterior_beta, \")\"),\n         x = expression(theta), y = \"Density\") +\n    theme_minimal()\n  p2 &lt;- ggplot(df, aes(x = Successes)) +\n    geom_bar(fill = \"coral\", color = \"black\", alpha = 0.7) +\n    geom_vline(xintercept = successes, color = \"red\", linetype = \"dashed\", size = 1) +\n    labs(title = paste(\"Posterior Predictive Check (n =\", n_trials, \")\"),\n         x = \"Number of Successful Treatments\", y = \"Frequency\") +\n    theme_minimal()\n  gridExtra::grid.arrange(p1, p2, ncol = 2)\n}\n\n# n=30 patients, y=18 successful treatments, Beta(1,1) prior\nposterior_predictive_check(alpha = 1, beta = 1, n_trials = 30, successes = 18)\n\n\n\n\n\n\n\n\n\nWe can see that the observed number of successful treatments (18) falls within the distribution of simulated outcomes, which implies that the model is consistent with the data.\nOn the other hand, if the observed value significantly deviates, it may indicate model misspecification, requiring adjustments to the prior or likelihood assumptions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-development",
    "href": "M03_1.html#model-development",
    "title": "6  Bayesian Regressions - Part 1",
    "section": "6.4 Model Development",
    "text": "6.4 Model Development\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayesian Regressions - Part 1**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#prior-sensitivity",
    "href": "M03_1.html#prior-sensitivity",
    "title": "6  Bayesian Regressions - I",
    "section": "6.7 Prior Sensitivity",
    "text": "6.7 Prior Sensitivity\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayesian Regressions - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#comparison-with-classical-approach",
    "href": "M03_1.html#comparison-with-classical-approach",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.6 Comparison with Classical Approach",
    "text": "5.6 Comparison with Classical Approach\n\n\nasdf\n\n\nCode\nlibrary(brms)\n\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nset.seed(123)\nn &lt;- 200\nsex &lt;- sample(c(\"Male\", \"Female\"), n, replace = TRUE)\nage &lt;- round(rnorm(n, mean = 50, sd = 10))\nbmi &lt;- round(rnorm(n, mean = 25, sd = 4), 1)\nbmd &lt;- 1.0 + 0.015 * bmi - 0.005 * age + ifelse(sex == \"Female\", -0.01, 0) + rnorm(n, 0, 0.05)\nbmd_data &lt;- tibble(\n  BMD = round(bmd, 2),\n  BMI = bmi,\n  Age = age,\n  Sex = factor(sex)\n)\n# model\nbmd_model &lt;- brm(\n  formula = BMD ~ BMI + Age + Sex,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 1), class = \"b\"),   # Slope priors\n    prior(normal(0, 1), class = \"Intercept\"),   # Intercept prior\n    prior(student_t(3, 0, 1), class = \"sigma\")  # Approximate Inv-Gamma(2,1)\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\nCompiling Stan program...\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.49 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.17 seconds (Warm-up)\nChain 1:                0.131 seconds (Sampling)\nChain 1:                0.301 seconds (Total)\nChain 1: \n\n\nCode\nsummary(bmd_model)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI + Age + Sex \n   Data: bmd_data (Number of observations: 200) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.99      0.03     0.93     1.04 1.00     1236      767\nBMI           0.01      0.00     0.01     0.02 1.00     1306      576\nAge          -0.00      0.00    -0.01    -0.00 1.00     1198      787\nSexMale       0.01      0.01     0.00     0.03 1.00      616      518\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.05      0.00     0.05     0.05 1.00      597      558\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nplot(bmd_model)\n\n\n\n\n\n\n\n\n\nMarginal effects in brms show the predicted effect of each predictor on the response, averaging over the effects of other variables. So you’re essentially asking:\n“What does the relationship between BMI and BMD look like, averaged over all values of Age and Sex?”\nIt gives you a partial effect plot — a clean way to visualize how each predictor (like BMI, Age, or Sex) influences the outcome (BMD), based on the posterior distribution.\n\n\nCode\n# Add raw data overlay\nplot(conditional_effects(bmd_model, effects = \"BMI\"), points = TRUE)\n\n\n\n\n\n\n\n\n\nCode\nplot(conditional_effects(bmd_model, effects = \"Age\"), points = TRUE)\n\n\n\n\n\n\n\n\n\nCode\nplot(conditional_effects(bmd_model, effects = \"Sex\"), points = TRUE)\n\n\n\n\n\n\n\n\n\nFor a continuous variable (e.g. BMI or Age): A smooth line showing how BMD changes as BMI increases\nWider or narrower ribbons depending on how uncertain the model is\nFor a categorical variable (e.g. Sex): A point estimate (mean BMD) for each group\nError bars showing uncertainty\n\n\nCode\nlibrary(bayesplot)\n\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'bayesplot'\n\n\nThe following object is masked from 'package:brms':\n\n    rhat\n\n\nCode\nlibrary(brms)\nposterior &lt;- as_draws_df(bmd_model)\n\n# Select relevant parameters\nmcmc_areas(\n  posterior,\n  #pars = c(\"b_Intercept\", \"b_BMI\", \"b_Age\", \"b_SexMale\"),\n  pars = c(\"b_BMI\", \"b_Age\", \"b_SexMale\"),\n  prob = 0.95  # 95% credible intervals\n)\n\n\n\n\n\n\n\n\n\nCode\n# Posterior intervals using intervals plot\nmcmc_intervals(\n  posterior,\n  pars = c(\"b_Intercept\", \"b_BMI\", \"b_Age\", \"b_SexMale\"),\n  prob = 0.95\n)\n\n\nWarning: `prob_outer` (0.9) is less than `prob` (0.95)\n... Swapping the values of `prob_outer` and `prob`\n\n\n\n\n\n\n\n\n\nCode\n# Good for diagnosing convergence\nmcmc_trace(\n  posterior,\n  pars = c(\"b_Intercept\", \"b_BMI\", \"b_Age\", \"b_SexMale\")\n)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Posterior predictive check\npp_check(bmd_model)\n\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\n\nCode\npp_check(bmd_model, type = \"hist\")\n\n\nUsing 10 posterior draws for ppc type 'hist' by default.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nCode\npp_check(bmd_model, type = \"boxplot\", group = \"Sex\")\n\n\nUsing 10 posterior draws for ppc type 'boxplot' by default.\n\n\nWarning: The following arguments were unrecognized and ignored: group\n\n\n\n\n\n\n\n\n\nCode\npp_check(bmd_model, type = \"scatter_avg\")\n\n\nUsing all posterior draws for ppc type 'scatter_avg' by default.\n\n\n\n\n\n\n\n\n\nCode\npp_check(bmd_model, type = \"ecdf_overlay\")\n\n\nUsing 10 posterior draws for ppc type 'ecdf_overlay' by default.\n\n\n\n\n\n\n\n\n\nIf the posterior predictive plots match the observed data closely, your model fits well.\nIf the posterior predictive data looks too wide/narrow or misses patterns, you might need:\nBetter predictors\nA different model family\nTransformation of variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#model-development",
    "href": "M03_2.html#model-development",
    "title": "7  Bayesian Regressions - II",
    "section": "7.4 Model Development",
    "text": "7.4 Model Development\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#prior-sensitivity",
    "href": "M03_2.html#prior-sensitivity",
    "title": "7  Bayesian Regressions - II",
    "section": "7.5 Prior Sensitivity",
    "text": "7.5 Prior Sensitivity\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#comparison-with-classical-approach",
    "href": "M03_2.html#comparison-with-classical-approach",
    "title": "7  Bayesian Regressions - II",
    "section": "7.6 Comparison with Classical Approach",
    "text": "7.6 Comparison with Classical Approach\nasdf\nVedio\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Bayesian Regressions - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#clustered-data-multilevel-modles",
    "href": "M04_1.html#clustered-data-multilevel-modles",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.3 Clustered Data & Multilevel Modles",
    "text": "7.3 Clustered Data & Multilevel Modles\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#varying-intercept-model",
    "href": "M04_1.html#varying-intercept-model",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.4 Varying Intercept Model",
    "text": "7.4 Varying Intercept Model\nasdf",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#varying-slope-model",
    "href": "M04_1.html#varying-slope-model",
    "title": "7  Clusterphobia? Part - I",
    "section": "7.5 Varying Slope Model",
    "text": "7.5 Varying Slope Model\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#conditional-and-marginal-models",
    "href": "M04_2.html#conditional-and-marginal-models",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.3 Conditional and Marginal Models",
    "text": "8.3 Conditional and Marginal Models\nasdf",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#comparison-with-classical-approach",
    "href": "M04_2.html#comparison-with-classical-approach",
    "title": "8  Clusterphobia? Part - II",
    "section": "8.4 Comparison with Classical Approach",
    "text": "8.4 Comparison with Classical Approach\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#bayesian-perspective-of-rct",
    "href": "M05_1.html#bayesian-perspective-of-rct",
    "title": "9  Size Matters! Part - I",
    "section": "9.3 Bayesian Perspective of RCT",
    "text": "9.3 Bayesian Perspective of RCT\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#bayesian-decision-rules-for-rct",
    "href": "M05_1.html#bayesian-decision-rules-for-rct",
    "title": "9  Size Matters! Part - I",
    "section": "9.4 Bayesian Decision Rules for RCT",
    "text": "9.4 Bayesian Decision Rules for RCT\n\n\nBayesian Decision Rule: ref: Berry book, sec 2.5.2, page 66",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#comparison-with-classical-approach",
    "href": "M05_1.html#comparison-with-classical-approach",
    "title": "9  Size Matters! Part - I",
    "section": "9.5 Comparison with Classical Approach",
    "text": "9.5 Comparison with Classical Approach\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#adaptivity-in-rct",
    "href": "M05_2.html#adaptivity-in-rct",
    "title": "10  Size Matters! Part - II",
    "section": "10.3 Adaptivity in RCT",
    "text": "10.3 Adaptivity in RCT\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#bayesian-predictive-probability",
    "href": "M05_2.html#bayesian-predictive-probability",
    "title": "10  Size Matters! Part - II",
    "section": "10.4 Bayesian Predictive Probability:",
    "text": "10.4 Bayesian Predictive Probability:\nref: Berry book, sec: 2.5.1 page 64",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#stopping-rules-for-adaptation",
    "href": "M05_2.html#stopping-rules-for-adaptation",
    "title": "10  Size Matters! Part - II",
    "section": "10.5 Stopping Rules for Adaptation",
    "text": "10.5 Stopping Rules for Adaptation\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#prior-influence",
    "href": "M05_2.html#prior-influence",
    "title": "10  Size Matters! Part - II",
    "section": "10.6 Prior Influence",
    "text": "10.6 Prior Influence\n\n\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#criterion-based",
    "href": "M06_1.html#criterion-based",
    "title": "12  Bayesian Model Choice",
    "section": "12.4 Criterion-Based",
    "text": "12.4 Criterion-Based\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Bayesian Model Choice**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#shrinkage-based",
    "href": "M06_1.html#shrinkage-based",
    "title": "12  Bayesian Model Choice",
    "section": "12.5 Shrinkage-Based",
    "text": "12.5 Shrinkage-Based\nasdf\nref: lambert page 225, sec: 10.5 (AIC, DIC, WAIC, LOO-CV)\n…\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Bayesian Model Choice**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#missing-data",
    "href": "M06_2.html#missing-data",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.2 Missing Data",
    "text": "12.2 Missing Data\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#measurement-errors",
    "href": "M06_2.html#measurement-errors",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.3 Measurement Errors",
    "text": "12.3 Measurement Errors\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#approximate-bayesian-computation",
    "href": "M06_2.html#approximate-bayesian-computation",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "12.4 Approximate Bayesian Computation",
    "text": "12.4 Approximate Bayesian Computation\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-probabilities",
    "href": "M01_1.html#dual-factor-probabilities",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.6 Dual-Factor Probabilities",
    "text": "1.6 Dual-Factor Probabilities\n\nKruschke (2014)\nBayesians do not imagine repetitions of an experiment in order to define and specify a probability. Probability is merely taken as a measure of certainty in a particular belief. This implies that the probability is used as a way to quantify how certain we are about a belief or an event happening. Before diving into Bayes’ theorem, let’s first understand some key concepts in probability distributions, which I assume you have already learned in the PSI unit.\nThere are many situations in which we are interested in the conjunction of two outcomes. As a specific example for developing these ideas, consider a situation where the probabilities of various combinations of people’s eye color and hair color. The data come from a particular convenience sample (Snee, 1974), and are not meant to be representative of any larger population.\n\n\n\n\n\nDual-Factor (Snee, 1974); Kruschke (2014)\n\n\n\n\nThe above Table considers four possible eye colors, listed in its rows, and four possible hair colors, listed across its columns. In each of its main cells, the table indicates the joint probability of particular combinations of eye color and hair color. For example, the top-left cell indicates that the joint probability of brown eyes and black hair is 0.11 (i.e., 11%). Notice that not all combinations of eye color and hair color are equally likely. For example, the joint probability of blue eyes and black hair is only 0.03 (i.e., 3%).\nWe may be interested in the probabilities of the eye colors overall, collapsed across hair colors. These probabilities are indicated in the right margin of the table, and they are therefore called marginal probabilities. They are computed simply by summing the joint probabilities in each row, to produce the row sums. For example, the marginal probability of green eyes, irrespective of hair color, is 0.11. The joint values indicated in the table do not all sum exactly to the displayed marginal values because of rounding error from the original data.\nWe often want to know the probability of one outcome, given that we know another outcome is true. For example, suppose I sample a person at random from the population. Suppose I tell you that this person has blue eyes. Conditional on that information, what is the probability that the person has blond hair (or any other particular hair color)? It is intuitively clear how to compute the answer: We see from the blue-eye row of the above Table that the total (i.e., marginal) amount of blue-eyed people is 0.36, and that 0.16 of the population has blue eyes and blond hair. Therefore, of the 0.36 with blue eyes, the fraction 0.16/0.36 has blond hair. In other words, of the blue-eyed people, 45% have blond hair.We also note that of the blue-eyed people, 0.03/0.36 = 8% have black hair.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#exact-inference",
    "href": "M01_2.html#exact-inference",
    "title": "3  Bayesian Inference",
    "section": "3.7 Exact Inference",
    "text": "3.7 Exact Inference\n\nThe solutions for posterior distribution explained in the previous section are based on exact inference using closed form of the posterior distribution. The exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given conjugate prior distribution and data likelihood. For instance, in the previous example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging. In this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in Module 2, Lecture 4.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#prior-and-posterior-distributions",
    "href": "M01_2.html#prior-and-posterior-distributions",
    "title": "3  Bayesian Inference",
    "section": "3.6 Prior and Posterior Distributions",
    "text": "3.6 Prior and Posterior Distributions\nGelman et al. (2013)\n\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst we will provide some examples on how prior distributions can be useful in real-world applications, especially considering health and medical data. We have already know that the prior distribution enables researchers to integrate previous knowledge or expert opinions into their statistical models, thereby improving the precision of their decisions. For example, we might be interested in tailoring treatments and interventions based on prior knowledge, enhancing their personalization and efficacy for individual patients. For instance, if historical data indicates a 70% effectiveness rate for a certain drug in patients with similar profiles, a prior distribution (informative) can incorporate this information to predict the likelihood of success in a new patient. The synthesizing of prior knowledge with current data yields more reliable conclusions. For example, if new data shows a 80% effectiveness rate, Bayesian method leads to a refined probability of treatment success, say 75%. Use of prior information is also beneficial when historical data is sparse or in the early stages of research on new treatments. In such scenarios, the prior distribution could start with a neutral assumption (non-informative), such as a 50% effectiveness rate, and adjust as more information becomes available.\nNow we will explore some situations for estimating posterior distributions using priors, in the context of statistical models, where we want to estimate only a single parameter of the model. We will explain these models where the posterior distribution has a closed form of distribution based on data and prior distributions. Fortunately, there are models where for a particular choice of prior results in a posterior that has the same type of distribution as the prior. The property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. This closed form offers easy probability calculations, simplifying updates with new data and contrasting with methods needing numerical approximations for precise inference, which we will explain more later in this lecture.\n\n3.6.1 Binomial Model\n\nWe can write Binomial model with parameters \\(\\theta\\) and \\(n\\) trials as \\[\\begin{align}\np(y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\end{align}\\] If we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\), the write the distribution as: \\[\\begin{align}\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\end{align}\\] where, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write \\[\\begin{align}\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\end{align}\\] With some simple calculations, we can write the marginal likelihood as: \\[\\begin{align}\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\end{align}\\] Hence, we get the analytical form of the posterior distribution of \\(\\theta\\) as: \\[\\begin{align}\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\end{align}\\] which follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).\nTo explore this with example, let us consider the example we explained earlier on the effectiveness rate of a certain drug in patients with similar profiles. Here, we write the prior distribution of 70% effectiveness, i.e., \\(p(\\theta)=0.7\\). To reflect this probability into Beta prior distribution hyper-parameters \\(a\\) and \\(b\\), we can consider \\(a=7\\) and \\(b=3\\). This is derived from the mean of the Beta distribution, i.e., \\(\\frac{a}{a+b}=0.7\\). Note that there are also other combinations of \\(a\\) and \\(b\\) values that can also lead to the probability 0.7.\nNow, if new data shows a 80% effectiveness rate, where we collect data from \\(n=10\\) individuals. Then we can write the posterior distribution of \\(\\theta\\), i.e., \\(p(\\theta|y)\\) as: \\[\\begin{align}\n\\text{Beta}(a+y,b+n-y) &= \\text{Beta}(7+8,3+10-8) \\\\\n&= \\text{Beta}(15,5)\n\\end{align}\\] This yields a mean \\(\\frac{15}{15+5}=0.75\\). Thus, based on the mean of the Beta distribution, we can say analytically, Bayesian method leads to a 75% refined probability of treatment success.\nexplain with R code …",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#preparation-for-week-4",
    "href": "M02_1.html#preparation-for-week-4",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.7 Preparation for Week 4",
    "text": "3.7 Preparation for Week 4\nIn week 4 you will be required to .\n\n\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.\n\n\nLambert, Ben. 2018. A Student’s Guide to Bayesian Statistics. SAGE Publications Ltd.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#causality-and-bayesian-model",
    "href": "M02_1.html#causality-and-bayesian-model",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.7 Causality and Bayesian Model",
    "text": "4.7 Causality and Bayesian Model\n\nCausal inference requires the establishment of a causal model that is separate from a Bayesian model, given that observational data alone do not suffice. This is widely accepted across different philosophical perspectives. Nonetheless, interpretations differ considerably. The most conservative viewpoint treats “causation” as an unprovable notion. A slightly less conservative approach posits that causation can be inferred only under stringent conditions involving randomization and experimental control. However, many scientific investigations cannot be feasibly examined through experimental study. Other cases might be feasible but raise ethical concerns. In disciplines like health and medicine, the dominant approach involves incorporating various “control” variables into a statistical model, observing changes in estimates, and then developing a causal narrative. This concept is based on the assumption that only omitted variables can lead to incorrect conclusions about causation. However, variables that are included can also lead to confusion. When constructing a causal model that appears to make accurate predictions might still mislead us about causation. If such a model is used to design an intervention, it is likely to result in inaccurate outcomes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M02_1.html",
    "href": "M02_1.html",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "",
    "text": "3.1 Learning\n– L02: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– L04: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.\nBy the end of this week you should be able to:\n– Understand the importance of prior distributions.\n– Calculate posterior using Bayesian exact inference.\n– Distinguish between different types of Prior distributions\n– Formulate examples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M01_1.html",
    "href": "M01_1.html",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "",
    "text": "1.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nIn today’s lecture we will:\n– Understand Bayesian philosophy.\n– Describe the motivation of doing Bayesian analysis.\n– Understand the difference between Bayesian and classical statistical methods.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html",
    "href": "M01_2.html",
    "title": "2  Bayesian Dreams: Inference",
    "section": "",
    "text": "2.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Describe Bayesian inference using probability distributions.\n– Understand Bayesian learning.\n– Draw DAG for Bayesian models.\n– Formulate examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_2.html",
    "href": "M02_2.html",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "",
    "text": "4.1 Learnings\nL03: Explain how these generative models can be used for inference, prediction and model criticism.\nL04: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.\nBy the end of this week you should be able to:\n– Create generative models\n– Understand traceable and untraceable solutions\n– Explain the convergence of MCMC.\n– Conduct prior predictive check.\n– Conduct posterior predictive check.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#dag",
    "href": "M01_2.html#dag",
    "title": "2  Belief-O-Meter: Bayesian Inference",
    "section": "2.8 DAG",
    "text": "2.8 DAG\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\nIn the context of Bayesian modeling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the Bernoullie model example, we can write a DAG as:\n\n\n\n\n\ngraph LR\n    subgraph \"Hyper-parameter\"\n        C[\"$$a$$\"]:::inputNode\n        D[\"$$b$$\"]:::inputNode\n    end\n    subgraph \"Parameter\"\n        A[\"$$\\\\theta$$\"]:::processNode\n    end\n    subgraph \"Outcome\"\n        Y[\"$$y$$\"]:::outputNode\n    end\n\n    C --&gt; A\n    D --&gt; A\n    A --&gt; Y\n\n    classDef inputNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef processNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef outputNode fill:#fff,stroke:#333,stroke-width:2px;\n    classDef subgraphTitle fill:none,stroke:none,color:#000,font-weight:bold;\n    \n\n\n\n\n\n\nThis is a simple graphical model, where \\(y\\) depends on \\(\\theta\\), with \\(\\theta\\) being a logical function of hyper-parameters \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Belief-O-Meter: Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#causality-and-bayesian-model",
    "href": "M01_2.html#causality-and-bayesian-model",
    "title": "3  Bayesian Inference",
    "section": "3.8 Causality and Bayesian Model",
    "text": "3.8 Causality and Bayesian Model\n\nCausal inference requires the establishment of a causal model that is separate from a Bayesian model, given that observational data alone do not suffice. This is widely accepted across different philosophical perspectives. Nonetheless, interpretations differ considerably. The most conservative viewpoint treats “causation” as an unprovable notion. A slightly less conservative approach posits that causation can be inferred only under stringent conditions involving randomization and experimental control. However, many scientific investigations cannot be feasibly examined through experimental study. Other cases might be feasible but raise ethical concerns. In disciplines like health and medicine, the dominant approach involves incorporating various “control” variables into a statistical model, observing changes in estimates, and then developing a causal narrative. This concept is based on the assumption that only omitted variables can lead to incorrect conclusions about causation. However, variables that are included can also lead to confusion. When constructing a causal model that appears to make accurate predictions might still mislead us about causation. If such a model is used to design an intervention, it is likely to result in inaccurate outcomes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#estimand-estimator-estimate",
    "href": "M01_2.html#estimand-estimator-estimate",
    "title": "3  Bayesian Inference",
    "section": "3.9 Estimand, Estimator & Estimate",
    "text": "3.9 Estimand, Estimator & Estimate\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\nFor example, suppose we are interested in the mean height of all male adults in the United States. Our estimand is “the mean height of all male adults in the United States”. A foolproof way to find this mean exactly would be to measure the height of each and every male adult in the United States and compute the mean. But that sounds too hard, so instead we decide to estimate the mean height by taking a random sample of male adults in the United States and measuring the height of each individual. Suppose we take a random sample of 100 adult men in the United States and measure their heights. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand.\nThe most obvious thing to do would be to compute the sample average of the heights. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average is 70 inches. Then 70 inches is the estimate of our estimand provided by the “sample average” estimator.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#correlation-vs-causation",
    "href": "M01_2.html#correlation-vs-causation",
    "title": "3  Bayesian Inference",
    "section": "3.10 Correlation vs Causation",
    "text": "3.10 Correlation vs Causation",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-dag-models",
    "href": "M01_2.html#bayesian-dag-models",
    "title": "3  Bayesian Inference",
    "section": "3.11 Bayesian DAG & Models",
    "text": "3.11 Bayesian DAG & Models\nasdf - graphical representations of the probabilistic relationships between variables and parameters",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-causal-inference",
    "href": "M01_2.html#bayesian-causal-inference",
    "title": "3  Bayesian Inference",
    "section": "3.12 Bayesian Causal Inference",
    "text": "3.12 Bayesian Causal Inference\nref: https://onlinelibrary.wiley.com/doi/10.1002/sim.8761\nref: https://bookdown.org/paul/applied-causal-analysis/\nref: paper: https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0153",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-and-posterior-distributions",
    "href": "M02_1.html#prior-and-posterior-distributions",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.2 Prior and Posterior Distributions",
    "text": "3.2 Prior and Posterior Distributions\n\n\n\n\nGelman et al. (2013)\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst, let’s look at some real-world examples of how prior distributions play a crucial role, particularly in health and medical data.\nWe already got a flavour that prior distributions allow researchers to incorporate existing knowledge or expert opinions into their statistical models, improving the precision of their conclusions. For example, when designing treatments/interventions, prior knowledge helps tailor them to individual patients, enhancing both personalisation and effectiveness.\nImagine historical data shows that a certain drug has a 70% success rate in patients with similar profiles. By using an informative prior distribution, we can incorporate this insight to estimate the likelihood of success for a new patient. If fresh data suggests an 80% effectiveness rate, Bayesian methods refine this estimate, leading to a more balanced probability—say, around 75%. This synthesis of prior knowledge with new evidence results in more reliable conclusions.\nPrior information is also invaluable when historical data is limited or when researching new treatments. In such cases, a non-informative prior—such as assuming an initial effectiveness probability of 0.5—can be used, gradually updating as more data becomes available.\n\n3.2.1 Posterior Summary\n\nThe posterior distribution is a valid probability distribution obtained through Bayesian inference, representing the updated beliefs about a parameter after incorporating prior knowledge and observed data. While the full posterior distribution provides a comprehensive summary of uncertainty, policymakers often require point estimates to facilitate decision-making. Common Bayesian point estimates include the posterior mean, posterior median, and maximum a posteriori (MAP) estimate. Among these, the posterior mean and median are generally preferred over the MAP estimate because MAP focuses solely on the mode of the posterior density, ignoring the overall distribution’s shape and probability mass. This can lead to misleading inferences, especially when the posterior distribution is skewed or multimodal. Moreover, since MAP is a mode, it may lie far from the regions of high probability mass, making it a less robust estimator compared to the mean or median.\n\n\n\n\n\nPosterior Point Estimates; Lambert (2018)\n\n\n\n\nBeyond point estimates, it is also important to quantify uncertainty, which is where credible intervals come into play. A credible interval provides an interval within which the true parameter value is likely to lie with a specified probability (e.g., 95%). Unlike frequentist confidence intervals, credible intervals have a direct probabilistic interpretation: if a 95% credible interval for a parameter is \\([a, b]\\), we can say there is a 95% probability that the parameter lies within this range, given the observed data and prior information. This makes credible intervals particularly useful for policy decisions, as they provide a natural way to express uncertainty in estimates, allowing decision-makers to weigh risks and benefits accordingly.\nExample\nConsider a policymaker estimating the proportion of a population that supports a new public health initiative. Suppose they collect survey data from 1,000 people, where 600 respondents express support. A Bayesian approach models this as a binomial likelihood with a Beta prior (a common conjugate prior for proportions). If the prior is \\(\\text{Beta}(2,2)\\), which represents a weak prior belief that the proportion is roughly uniform between 0 and 1, the posterior distribution is updated using the observed data:\n\\[\n\\theta | \\text{data} \\sim \\text{Beta}(2 + 600, 2 + 400) = \\text{Beta}(602, 402)\n\\]\nFrom this posterior, the policymaker can derive different point estimates:\n\nPosterior Mean: Given a \\(\\text{Beta}(a, b)\\) distribution, the mean is $ $, which in this case is:\n\n\\[\n\\frac{602}{602 + 402} = 0.60\n\\]\nThis suggests that, on average, the Bayesian model estimates 60% of the population supports the initiative.\n\nPosterior Median: This is the value that splits the posterior probability into two equal halves. For a Beta distribution, the median can be approximated numerically, where we can write the median approximately\n\n\\[\n\\frac{a-1/3}{a+b-2/3} = \\frac{602-1/3}{602+402-2/3} \\approx 0.6\n\\] and in this case, it is close to 0.6.\n\nMaximum a Posteriori (MAP): The MAP estimate is the mode of the Beta distribution, which for \\(\\text{Beta}(\\alpha, \\beta)\\) is:\n\n\\[\n\\frac{a - 1}{a + b - 2} = \\frac{601}{1000} = 0.601\n\\]\nWhile close to the posterior mean, the MAP estimate can be problematic in other cases, particularly with skewed distributions, since it focuses only on the density’s peak rather than the overall probability mass.\n\nCredible Interval: To express uncertainty, the policymaker can compute a 95% credible interval, which provides a range where the true proportion likely falls. For the \\(\\text{Beta}(602, 402)\\) distribution, the central 95% credible interval (obtained numerically) is approximately \\((0.576, 0.623)\\).\n\nThis means that, given the data and prior, there is a 95% probability that the true proportion of public support lies between 57.6% and 62.3%. This interval gives a clearer sense of uncertainty than a single point estimate and helps policymakers make informed decisions while considering potential variations in public opinion.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\na &lt;- 602  \nb &lt;- 402  \n\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nposterior_density &lt;- dbeta(theta_vals, a, b)\n\nposterior_mean &lt;- a / (a + b)\nposterior_median &lt;- qbeta(0.5, a, b)\nposterior_map &lt;- (a - 1) / (a + b - 2)\ncredible_interval &lt;- qbeta(c(0.025, 0.975), a, b)\n\nposterior_df &lt;- data.frame(theta = theta_vals, density = posterior_density)\n\nggplot(posterior_df, aes(x = theta, y = density)) +\n  geom_line(color = \"blue\", size = 1) +\n  \n  geom_vline(xintercept = posterior_mean, color = \"red\", linetype = \"dashed\", size = 1) +\n  \n  geom_vline(xintercept = posterior_median, color = \"green\", linetype = \"dotted\", size = 1) +\n  \n  geom_vline(xintercept = posterior_map, color = \"purple\", linetype = \"dotdash\", size = 1) +\n  \n  geom_ribbon(aes(ymin = 0, ymax = density), \n              data = subset(posterior_df, theta &gt;= credible_interval[1] & theta &lt;= credible_interval[2]),\n              fill = \"gray\", alpha = 0.3) +\n  \n  geom_vline(xintercept = credible_interval[1], color = \"gray\", linetype = \"solid\", size = 1) +\n  geom_vline(xintercept = credible_interval[2], color = \"gray\", linetype = \"solid\", size = 1) +\n  \n  labs(title = \"Posterior Distribution of θ\",\n       x = \"θ (Proportion)\",\n       y = \"Density\",\n       caption = \"Red: Mean, Green: Median, Purple: MAP, Gray: 95% Credible Interval\") +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Exact Inference\n\n\nThe exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given prior distribution and data likelihood.\nWe have already seen from the Bernoullie distribution example that, choosing a particular type of prior distribution results in a posterior that belongs to the same distribution family. This property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. In the Bernoulli model example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nBelow we present some common pairs of likelihoods and priors related to conjugacy:\n\n\n\n\n\n\n\n\nLikelihood\nConjugate Prior\nPosterior Distribution\n\n\n\n\n\\(\\text{Bernoulli}(\\theta)\\)\n\\(\\text{Beta}(a, b)\\)\n\\(\\text{Beta}(a + y, b + n-y)\\)\n\n\n\\(\\text{Poisson}(\\lambda)\\)\n\\(\\text{Gamma}(a, b)\\)\n\\(\\text{Gamma}(a + y, b + n)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Known variance)\n\\(\\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\\(\\mathcal{N}(\\mu_n, \\sigma_n^2)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Unknown variance)\nNormal-Gamma \\((\\mu_0, \\lambda_0, \\alpha, \\beta)\\)\nNormal-Gamma \\((\\mu_n, \\lambda_n, \\alpha_n, \\beta_n)\\)\n\n\n\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging, if we want to.\nIn this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in our next lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#exact-inference",
    "href": "M02_1.html#exact-inference",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.3 Exact Inference",
    "text": "3.3 Exact Inference\n\n\nThe exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given conjugate prior distribution and data likelihood. In the Bernoulli model example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging, if we want to.\nIn this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in our next lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#more-insights-into-prior-distribution",
    "href": "M02_1.html#more-insights-into-prior-distribution",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.3 More Insights into Prior Distribution",
    "text": "3.3 More Insights into Prior Distribution\n\nUnderstanding the appropriate selection of prior distributions in modeling is crucial. Prior distributions can be categorised as informative, non-informative, weakly informative, or based on expert judgment. This section explores into these various types of prior distributions, examining their applicability and relevance.\n\n3.3.1 Informative Prior Distribution\n\n\n\nAn informative prior is a type of prior distribution that is based on information that provides significant idea about the parameters being estimated. Since informative priors reflect more certainty, they tend to be more concentrated around a certain value. The informative prior has a strong influence on the posterior distribution, especially when the data is limited or noisy. In cases with substantial data, the posterior may still be mostly driven by the observed data, but the prior will still play a role in shaping the final outcome.\nTo explain it more, suppose, we want to know the efficacy rate of a certain vaccine in patients with similar profiles. Let’s consider that the efficacy rate of the vaccine range from 70% to 90%, which we know from literature. Now from a pilot study we observe 16 successes out of 20 trials, i.e., the efficacy rate is still 80%. Hence, we can easily get the posterior distribution of the efficacy rate from \\(\\text{Beta}(24, 6)\\) distribution, if we consider the prior average success rate of 80%, which is calculated from the range 70% to 90%. Numerically, we can plot the prior and posterior distributions as:\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 8\nb_prior &lt;- 2\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(8,2)], i.e., 80% vs Posterior Distributions [Beta(24,6)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 9\nb_prior &lt;- 4\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(9,4)], i.e., 70% vs Posterior Distributions [Beta(25,8)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 10\nb_prior &lt;- 1\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(10,1)], i.e., 90% vs Posterior Distributions [Beta(26,5)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nThe informative prior in this example allows you to start with a reasonable expectation (from historical data) and update it with observed results. This is especially useful when the sample size is small or the observed data alone might not be robust enough to guide decision-making.\n\n\n\n3.3.2 Non-informative Prior Distribution\n\n\n\nA non-informative prior (also known as an uninformative prior or objective prior) is a type of prior distribution used in Bayesian statistics that is intended to have minimal influence on the posterior distribution. It reflects a lack of specific prior knowledge about the parameter of interest, allowing the data to drive the inference as much as possible.\nNon-informative priors are often used when the goal is to let the observed data dominate the analysis. These are useful in cases where objectivity is critical or where prior knowledge is genuinely unavailable, but they may not always be appropriate when prior information exists.\nNon-informative priors often reflect a high degree of uncertainty about the parameter’s value, and might end up with parameter estimates similar to the estimates obtained from frequentist approach.\nBefore going into details, let’s explain some prior distribution concepts:\nImproper Priors: Prior distributions that do not integrate to 1 and therefore are not valid probability distributions but can still be useful for inference if they lead to proper posterior distributions. For instance, \\(p(\\theta) \\propto 1/\\theta\\) for scale parameters.\nFlat Priors: Priors that are constant over the range of the parameter (often used for parameters with bounded support).\nNow, we will discuss some common approaches to defining non-informative priors:\n\nUniform Priors:\n\nUniform priors assign equal probability across all possible values of a parameter, assuming no preference for any particular value (e.g., \\(p(\\theta) \\propto 1\\), where for a probability parameter \\(\\theta\\) in a Bernoulli model, a uniform prior on \\(\\text{Unif}[0, 1]\\) implies no prior belief about the likelihood of success. From the plot below we cannot visualize the likelihood function (scaled), as the posterior distribution and likelihood functions are same.\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100       \ntrue_theta &lt;- 0.8  \ndata &lt;- rbinom(n, size = 1, prob = true_theta)  \nsuccesses &lt;- sum(data)  \nfailures &lt;- n - successes\n# Uniform prior: P(theta) ∝ 1 on [0, 1]\n# The uniform prior is equivalent to Beta(1, 1).\na_prior &lt;- 1  \nb_prior &lt;- 1  \na_post &lt;- a_prior + successes\nb_post &lt;- b_prior + failures\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(successes, size = n, prob = theta_vals)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nprior_density &lt;- dbeta(theta_vals, a_prior, b_prior)\nposterior_density &lt;- dbeta(theta_vals, a_post, b_post)\n# likelihood - scaled\nlikelihood_scaled &lt;- likelihood / max(likelihood) * max(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, posterior_density, likelihood_scaled),\n  type = rep(c(\"Prior (Uniform)\", \"Posterior\", \"Likelihood (Scaled)\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior, Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))\n\n\n\n\n\n\n\n\n\n\nJeffreys’ Priors:\n\nJeffreys’ prior is a non-informative prior derived based on the Fisher information matrix, ensuring invariance under reparameterisation. This prior is proportional to the square root of the determinant of the Fisher information: \\(p(\\theta) \\propto \\sqrt{|I(\\theta)|}\\), where \\(I(\\theta)\\) is the Fisher information.\nJeffreys’ prior is invariant under reparameterisation means that if you change the parameterization of a model (i.e., if you make a transformation of the parameters), the form of the Jeffreys’ prior does not change.\nBinomial distribution\nLet us now explain this using Binomial distribution, where we observe 16 successes out of 20 trials, i.e., the efficacy rate is 80% observed from a pilot survey.\nNow, we write the Fisher information matrix as: \\(I(\\theta)=\\frac{n}{\\theta(1-\\theta)}\\). Hence, we get Jeffreys prior for \\(\\theta\\) as:\n\\[\np(\\theta) \\propto \\sqrt{\\left| \\frac{n}{\\theta(1-\\theta)}\\right|} \\propto \\frac{1}{\\sqrt{\\theta(1-\\theta)}}\n\\]\nwhere, we can ignore \\(\\sqrt{n}\\) using the proportional sign, as it is free from the model parameter \\(\\theta\\). Hence, we can plot the distributions as:\n\n\nCode\nlibrary(ggplot2)\njeffreys_prior &lt;- function(theta) {\n  return(1 / sqrt(theta * (1 - theta)))  \n}\nlikelihood &lt;- function(theta, k, n) {\n  return(choose(n, k) * theta^k * (1 - theta)^(n - k))  \n}\nn &lt;- 20  \nk &lt;- 16 \ntheta_vals &lt;- seq(0.01, 0.99, length.out = 1000)  \nprior_density &lt;- jeffreys_prior(theta_vals)\nlikelihood_density &lt;- likelihood(theta_vals, k, n)\nposterior_density &lt;- likelihood_density * prior_density\nprior_density &lt;- prior_density / sum(prior_density)\nlikelihood_density &lt;- likelihood_density / sum(likelihood_density)\nposterior_density &lt;- posterior_density / sum(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood\", \"Posterior\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Binomial Model\",\n    x = expression(theta),\n    y = \"Scaled Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nNormal Distribution\nLet’s consider a normal distribution with known variance \\(\\sigma^2\\). We write the Fisher information for the mean parameter \\(\\mu\\) as \\(I(\\mu) =\\frac{n}{\\sigma^2}\\), where \\(n\\) is the sample size. Hence, we write the Jeffreys prior for \\(\\mu\\) as the proportional to the square root of the Fisher information, i.e.,\n\\[\np(\\mu) \\propto \\sqrt{|I(\\mu)|} = \\sqrt{\\frac{n}{\\sigma^2}}\n\\]\nSince, \\(\\sigma^2\\) is a constant, hence for the mean of a normal distribution, it’s constant, i.e., Jeffreys prior is \\(p(\\mu) \\propto 1\\), and \\(-\\infty \\le \\mu \\le \\infty\\).\nThus, the prior is uniform over the parameter space. We write the posterior for \\(\\mu\\) follows normal distribution with mean \\(\\bar{y}\\) (sample mean) and variance \\(\\sigma^2/n\\).\nNow let us explain with an eample. Suppose a new antihypertensive drug is tested in a clinical trial, and researchers measure the reduction in systolic blood pressure (in mmHg) among patients. Where, most patients experience a blood pressure reduction of around 5 mmHg, but there is natural variability, which is about 2 standard deviation. Now considering Jeffreys non-informative prior, we can get the posterior distribution of the systolic blood pressure.\nFollowing this we draw the density plots using R code as follows:\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100        \ntrue_mu &lt;- 5    \nsigma &lt;- 2      \ndata &lt;- rnorm(n, mean = true_mu, sd = sigma)  \n# Fisher information for the mean is: I(mu) = n / sigma^2\nfisher_info &lt;- n / sigma^2 \n# Jeffreys prior is proportional to sqrt(I(mu)). For the mean of a normal distribution, it's constant, i.e., uniform over the parameter space\njeffreys_prior &lt;- function(mu) {\n  return(rep(1, length(mu)))  \n}\nsample_mean &lt;- mean(data)\nposterior_mean &lt;- sample_mean\nposterior_sd &lt;- sigma / sqrt(n)\n\nlikelihood &lt;- function(mu) {\n  return(dnorm(mu, mean = sample_mean, sd = sigma / sqrt(n)))\n}\n\nmu_vals &lt;- seq(true_mu - 3 * sigma, true_mu + 3 * sigma, length.out = 1000)\n\nprior_density &lt;- jeffreys_prior(mu_vals)\nlikelihood_density &lt;- likelihood(mu_vals)\nposterior_density &lt;- dnorm(mu_vals, mean = posterior_mean, sd = posterior_sd)\n\nlikelihood_density &lt;- likelihood_density / max(likelihood_density) * max(posterior_density)\n\nplot_data &lt;- data.frame(\n  mu = rep(mu_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood (Scaled)\", \"Posterior\"), each = length(mu_vals))\n)\nggplot(plot_data, aes(x = mu, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Normal Model\",\n    x = expression(mu),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nFurther Notes\nDespite being called “non-informative,” their choice can still involve subjective decisions. Some priors, like uniform priors, may appear non-informative in one parameterisation but informative in another (e.g., uniform in \\(\\theta\\) vs. \\(\\log(\\theta)\\)).\nTo explain this, consider a the case where we defined a uniform prior for \\(\\theta\\), i.e., \\(p(\\theta) = \\text{constant}\\), implies that all values of \\(\\theta\\) are equally likely. Now, suppose we reparameterise the problem using a new variable, say logit transformation:\n\\[\n\\phi = \\log \\frac{\\theta}{1 - \\theta}\n\\]\nIf \\(\\theta\\) follows a \\(\\text{Unif}[0, 1]\\) prior, what does this imply about \\(\\phi\\)? Using the change of variables formula for probability densities:\n\\[\np(\\phi) = p(\\theta) \\left| \\frac{d\\theta}{d\\phi} \\right|\n\\]\nSince \\(\\theta = \\frac{e^\\phi}{1 + e^\\phi}\\), its derivative is:\n\\[\n\\frac{d\\theta}{d\\phi} = \\frac{e^\\phi}{(1 + e^\\phi)^2}\n\\]\nSubstituting this into the density transformation:\n\\[\np(\\phi) \\propto \\frac{\\exp(\\phi)}{(1 + \\exp(\\phi))^2}\n\\]\nwhich is the logistic distribution rather than a uniform distribution. This shows that a uniform prior on \\(\\theta\\) induces a highly structured prior on \\(\\phi\\), meaning that the prior is no longer flat in the transformed space. We will learning more about this in hierarchical modelling.\nThis concept is crucial in Bayesian statistics, as it shows that non-informative priors are not always truly non-informative; their informativeness depends on the chosen parameter space.\n\n\n3.3.3 Weakly Informative Prior Distribution\n\n\n\nA weakly informative prior distribution in Bayesian statistics is characterised as proper, yet it is designed to provide information that is intentionally less robust than the actual prior knowledge available.\nLet’s explain this with the example of efficacy rate of the vaccine. If we consider a \\(\\text{Beta}(1,1)\\) prior for the parameter \\(\\theta\\), then we have already discussed that the prior is a flat line, which represents a non-informative situation. Now, considering a \\(\\text{Beta}(0.5,0.5)\\) prior might lead to a distribution similar to Jefferys’ prior. Whereas, if we consider a \\(\\text{Beta}(2,2)\\) prior, then it favours a middle value (0.5) but still flexible. This prior avoids extreme values (near 0 or 1) unless strongly supported by the data. Below, we can plot all these three different priors.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nbeta_1_1 &lt;- dbeta(theta_vals, 1, 1)    # Uniform prior\nbeta_0_5_0_5 &lt;- dbeta(theta_vals, 0.5, 0.5)  # Jeffreys' prior\nbeta_2_2 &lt;- dbeta(theta_vals, 2, 2)    # Weakly informative prior\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(beta_1_1, beta_0_5_0_5, beta_2_2),\n  type = rep(c(\"Beta(1,1) - Uniform\", \"Beta(0.5,0.5) - Jeffreys\", \"Beta(2,2) - Weakly Informative\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(title = \"Comparison of Different Beta Priors\",\n       x = expression(theta), \n       y = \"Density\", \n       color = \"Distribution\") +\n  ylim(0,3) +\n  theme_minimal() +\n  scale_color_viridis_d(option = \"cvidis\")\n\n\n\n\n\n\n\n\n\nNow assume that the success rate of the vaccine is about 50%, and we can consider the prior distribution as \\(\\text{Beta}(2,2)\\). This symmetric pattern favours the efficacy rate around 0.5 but also allows a wide range of plausible values. Now, suppose 30 trials out of \\(n = 50\\) shows success. Hence, we get the posterior distribution as \\(\\text{Beta}(32,22)\\). Below you can see the density plots of the distributions.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2\nb_prior &lt;- 2\nn &lt;- 50\ny &lt;- 30\na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\np &lt;- seq(0, 1, length.out = 1000)\n\nprior &lt;- dbeta(p, a_prior, b_prior)\n# Scaled for visualisation\nlikelihood &lt;- dbinom(y, n, p) * 100  \nposterior &lt;- dbeta(p, a_post, b_post)\n\nplot_data &lt;- data.frame(\n  p = p,\n  Likelihood = likelihood,\n  Posterior = posterior,\n  Prior = prior\n)\ndata_long &lt;- reshape2::melt(plot_data, id = \"p\", variable.name = \"Distribution\", value.name = \"Density\")\nggplot(data_long, aes(x = p, y = Density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior (weakly informative), Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nWeakly informative priors are common in modern Bayesian modeling, where it balances interpretability, robustness, and computational efficiency. Even though weakly informative priors are designed to be robust, they still influence the posterior, especially in small-sample scenarios. What counts as weakly informative is context-dependent. For example, a \\(\\text{Normal}(0,10^2)\\) prior on a regression coefficient might be weakly informative in a standard model but too weak in a context where coefficients are typically small. We will explain more about the weakly informative prior when we will learn the Bayesian regression and hierarchical models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-language",
    "href": "M01_2.html#bayesian-language",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.6 Bayesian Language",
    "text": "2.6 Bayesian Language\n\n\n\nWe will learn a common language for illustrating and denoting the Bayesian models. This will help us to develop and write complex Bayesian models in a simpler way that we will learn later in this course.\nLet’s explain this using a Bernoulli model with parameter \\(\\theta\\). Let \\(x\\) be the random variable that follows Bernoulli distribution. If we have \\(n\\) number of independent observations \\((x_1,\\ldots,x_n)'\\), then denoting \\(y=\\sum_i^n x_i\\) we write the likelihood function as:\n\\[\n\\prod_i^n \\theta^{x_i} (1-\\theta)^{1-x_i} = \\theta^{\\sum_i^n x_i} (1-\\theta)^{\\sum_i^n (1-x_i)} = \\theta^y (1-\\theta)^{n-y}\n\\]\nwhich we can write in the form of a Binomial distribution:\n\\[\np(y|\\theta) \\propto   \\theta^y (1-\\theta)^{n-y}\n\\]\nNote that we replaced “=” with “\\(\\propto\\)” as the term \\(\\begin{pmatrix}n\\\\y \\end{pmatrix}\\) is a constant, which does not depend on the parameter \\(\\theta\\). Now, considering prior conjugacy, we assume that \\(\\theta\\) follows a Beta distribution with shape parameters \\(a\\) and \\(b\\) and we write \\(\\theta \\sim \\text{Beta}(a,b)\\) and define\n\\[\np(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\n\\]\nThus, the posterior distribution of \\(\\theta\\) can be written as \\(\\theta|y \\sim \\text{Beta}(a+y,b+n-y)\\) and defined as:\n\\[\np(\\theta|y) \\propto \\theta^y (1-\\theta)^{n-y}\\theta^{a-1}(1-\\theta)^{b-1} =\\theta^{y+a-1} (1-\\theta)^{n-y+b-1}\n\\]\n\\[\np(\\theta|y) \\propto \\theta^{y+a-1} (1-\\theta)^{n-y+b-1}\n\\]\nWe have again included the “\\(\\propto\\)” term, as we will learn in our next two lectures that the marginal distribution of the data, i.e., \\(p(y)\\) does not depend on the model parameter and can therefore be omitted when obtaining the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#background",
    "href": "M01_1.html#background",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.2 Background",
    "text": "1.2 Background\n\n\n\n\n\nThomas Bayes (The IMS Bulletin, 1988, vol-17(3), pp.276-278)\n\n\n\n\nThomas Bayes, who is remembered through the term “Bayesian,” passed away in 1761 without having the chance to formally present or publish his groundbreaking findings. Two years after his death, it was Richard Price who, in 1763, introduced Bayes’ extraordinary work to the Royal Statistical Society. Bayes had been developing a probabilistic framework to tackle inverse problems. Later, Richard Price (1723–1791) and Pierre-Simon Laplace (1749–1827) played crucial roles in advancing and applying this transformative idea to practical real-world scenarios.\nTo fully understand the Bayesian framework, it is essential to become familiar with several key terms commonly used in Bayesian discussions, such as Bayesian inference, prior, posterior, and Bayesian modeling. Throughout this course, we will gradually explore and learn these fundamental concepts.\nBefore that, let’s start understanding the Bayesian philosophy.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#concepts-classical-vs.-bayesian",
    "href": "M01_1.html#concepts-classical-vs.-bayesian",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.5 Concepts: Classical vs. Bayesian",
    "text": "1.5 Concepts: Classical vs. Bayesian\n\n\nThroughout this course, we will provide relative comparisons of frequentists and Bayesian statistical methods, using examples. Let us now explain some key conceptual aspects of these two approaches.\nHistory:\n\nThe origins of Bayesian statistical inference trace back to the late 18th century, predating many modern methodologies. Its use continued into the 19th century, but after World War I, statisticians like Sir Ronald Fisher, who opposed Bayesian concepts, contributed to its decline. Fisher’s 1925 statistical handbook briefly mentioned Bayesian analysis—then known as “inverse probability”—further pushing it to the margins of mainstream statistics. However, in the latter half of the 20th century, Bayesian methods gradually regained acceptance. This resurgence was particularly driven by advancements in computational technology during the 1990s, which greatly expanded their practical applications.\nData and Parameter:\n\nData represents known elements, whereas parameters are unknown quantities inferred from data. Within the Bayesian framework, this distinction becomes less clear; a variable may be either observed or unobserved, yet it is governed by the same distribution function. Consequently, an assumption can serve as a “likelihood” or a “prior” depending on the context, without altering the model. This connection between certainty (data) and uncertainty (parameters) facilitates the management of measurement errors and missing data in modeling.\nReliable Inference:\n\nThere exists a notion that a specific number of observations is necessary for reliable statistical estimates. For example, at least 30 observations are typically required for a Gaussian distribution. This notion is rooted in traditional statistical inference, where methods are validated for large sample sizes, a concept known as asymptotic behavior.\nConversely, Bayesian estimates remain valid regardless of sample size. While larger samples are advantageous, Bayesian methods provide meaningful results even with limited data. However, they necessitate a careful selection of the “prior,” which significantly influences the final inference. An improperly chosen prior can skew conclusions. Understanding the world demands thoughtful consideration, without resorting to shortcuts.\nRole of Data:\n\nThe distinctions between Bayesian and non-Bayesian methodologies are notable, yet these differences can sometimes overshadow their underlying commonalities. In many Bayesian and non-Bayesian models, the most critical assumptions typically concern the likelihood functions and their connections with the parameters. These assumptions guide the inferences drawn from each dataset. As the sample size grows, the significance of the likelihood increases. This shared emphasis on likelihood clarifies why Bayesian and non-Bayesian inferences frequently yield similar results.\nFurthermore, a common misunderstanding regarding Bayesian data analysis and inference is the belief that they are exclusively defined by Bayes’ theorem. Any inferential method employing probability theory incorporates Bayes’ theorem. Numerous examples labeled as “Bayesian” often lack distinctive attributes and instead rely on observed data frequencies, resembling non-Bayesian methods. The distinctiveness of Bayesian techniques lies in their application of Bayes’ theorem to measure the uncertainty associated with theoretical constructs not directly observable, such as parameters and models. Both methodologies can produce robust inferences, although they are grounded in different principles and entail unique trade-offs.\n\n\n\n1.5.1 Example:\nTo demonstrate where the Bayesian method is clearly more advantageous than the Frequentist method, let’s consider a scenario with limited data. The Bayesian approach can make use of prior knowledge, whereas the frequentist method relies purely on the data at hand. In situations with small sample sizes or limited data, the Bayesian method can give more insightful results.\nImagine a scenario where we have a small sample size from a clinical trial and we want to test whether a drug is effective in treating a rare disease. We have only 5 patients, and the treatment shows that 3 out of 5 patients recovered. For the control group 1 out of 5 patients recovered. The issue here is that the data is very sparse, so relying on a frequentist approach may lead to an unreliable conclusion because of the small sample size. The p-value might not be informative because small sample sizes lead to high variability. Whereas, Bayesian approach combines the sparse data with prior knowledge, offering more stable and informed results (even we use a non-informative prior).\nFor frequentist, the proportion test will provide a p-value indicating if the recovery rates are significantly different between the two groups. For this example, we get p-value =0.52. Whereas, the Bayesian approach will provide the posterior distributions for the treatment and placebo recovery rates. Additionally, you will get the probability that the treatment recovery rate is higher than the placebo recovery rate as 0.882 based on the posterior samples.\nNow, if we know control group has about 70% recovery rate, and considering this prior information in Bayesian setting, we get that the orobability of treatment recovery rate greater than the control rate is 0.58.\n\n\n\n\n\nUniform Prior\n\n\n\n\n\n\n\n\n\nInformed Prior\n\n\n\n\nIn brief, Bayesian Method can incorporate prior knowledge (such as known rates from similar treatments of the diseases), improving estimates even with small sample sizes. Instead of a single p-value, Bayesian analysis gives a full posterior distribution, providing a richer interpretation of the uncertainty in the treatment’s effectiveness. Finally, Bayesian approach is less affected by small sample sizes, as it uses prior distributions and provides more stable estimates.\nWe will discuss more on the distributional aspect in our next lecture. Before that we explain the Bayesian theorem using probabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-models",
    "href": "M01_2.html#bayesian-models",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Bayesian Models",
    "text": "2.3 Bayesian Models\n\nWe have explained Bayes’ rule in our previous lecture, now we will see how Bayes rule can be structured for model development using parameter and data. In a Bayesian model, a parameter is a quantity that we assume is uncertain and assign a probability distribution to it. Unlike in frequentist statistics, where parameters are fixed but unknown, Bayesian statistics treats parameters as random variables with their own probability distributions.\nLet us denote \\(\\theta\\) as the parameter and \\(D\\) as data. Hence, we write a model using the data likelihood \\(p(D|\\theta)\\), and prior distribution \\(p(\\theta)\\) of the model parameter \\(\\theta\\) (note that we have changed the notation from \\(Pr(.)\\) to \\(p(.)\\), where \\(Pr(.)\\) refers to probability and \\(p(.)\\) refers to probability distribution):\n\\[\np(D|\\theta) \\times p(\\theta)\n\\]\nHence, Bayes rule can be used to understand the parameter values, given the data,, i.e.,\n\\[\np(\\theta|D)\n\\]\nThus, using the Dual-Factor table explained in previous lecture, we can write\n\n\n\n\n\nData-Parameter; Kruschke (2014)\n\n\n\n\nWhere, each cell of the table holds the joint probability density of the specific combination of parameter value \\(\\theta\\) and data value \\(D\\), denoted \\(p(D, \\theta)\\), and which we know can be algebraically re-expressed as \\(p(D|\\theta)\\times p(\\theta)\\).\nThus, we write the Bayes rule for data and parameter model as:\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)\\times p(\\theta)}{p(D)};\n\\]\nwhere,\n\\[\\begin{align}\np(D) &= \\sum_{\\theta^*} p(D|\\theta^*) p(\\theta^*); \\quad \\text{ if discrete}; \\\\\np(D) &= \\int p(D|\\theta^*) p(\\theta^*) \\text{d}\\theta^*; \\quad \\text{ if continuous};\n\\end{align}\\]\nHere, \\(p(\\theta)\\) is the prior information about \\(\\theta\\) without observing data; \\(p(D|\\theta)\\) is the likelihood, i.e., data could be generated with model parameter \\(\\theta\\); and \\(p(D)\\) is the marginal likelihood obtained from data by averaging across all possible parameters.\nThe posterior distribution of \\(\\theta\\) is:\n\\[\np(\\theta|D) = \\text{ Credibility of }\\theta\\text{ based on data and evidence}\n\\]\nThe posterior probability distribution \\(p(\\theta|D)\\) is the main goal of Bayesian inference. The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value, and this can be obtained by collecting more data.\nWe will now explore with examples on obtaining posterior distributions of the model parameter \\(\\theta\\) for different data distributions (i.e., models), e.g., binomial, normal and poisson distributions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#binomial-model",
    "href": "M01_2.html#binomial-model",
    "title": "3  Bayesian Inference",
    "section": "3.5 Binomial Model",
    "text": "3.5 Binomial Model\n\nWe can write Binomial model with parameters \\(\\theta\\) and \\(n\\) trials as \\[\\begin{align}\np(y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\end{align}\\] If we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\), the write the distribution as: \\[\\begin{align}\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\end{align}\\] where, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write \\[\\begin{align}\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\end{align}\\] With some simple calculations, we can write the marginal likelihood as: \\[\\begin{align}\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\end{align}\\] Hence, we get the analytical form of the posterior distribution of \\(\\theta\\) as: \\[\\begin{align}\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\end{align}\\] which follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-odds",
    "href": "M01_2.html#bayesian-odds",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.5 Bayesian Odds",
    "text": "2.5 Bayesian Odds\n\n\nWe can also think of the Bayesian approach in terms of odds, such as what odds should I assign to an event or hypothesis. The simple definition of odds can be written as:\n\\[\n\\text{Odds of an event} = \\frac{Pr(\\text{event})}{1-Pr(\\text{event})}\n\\] which represents the ratio between the occurrence of an event and its non-occurrence.\nLet’s revisit the medical practitioner example from our first lecture to clarify this concept. Imagine the practitioner assessing a patient for diabetes. Initially, they have a prior belief about the patient’s likelihood of having the condition. After conducting a blood test that reveals elevated sugar levels, this new evidence increases the probability of diabetes. The practitioner then updates their belief accordingly, refining their assessment based on the test results. We wanted to know, given this experimental evidence, how sure are the medical practitioner that their guess about the diabetes is accurate?\nThus, to reflect the medical practitioner example by Bayesian odds, we write:\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = \\text{Odds}(\\text{G}) \\times \\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})\\) is the odds of the guess is correct given the evidence, and \\(\\text{Odds}(\\text{G})\\) is the odds of the guess that we define:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{Pr(\\text{G=[+]})}{Pr(\\text{G=[-]})}\n\\]\nand \\(\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\\) is the ratio of evidence under the guess \\(\\text{G}\\).\nThis reflects\n\\[\n\\text{posterior or updated odds} = \\text{prior or initial odds}\\times \\text{relative explanatory power}\n\\]\nThis explains that evidence (i.e., data/information) always changes the outcome, which could be probability, probability distributions or odds or any other outcome of interest.\nExample\nLet us explain this again with the type-2 diabetes example, where based on the patient’s age, family history, and some initial symptoms, the medical practitioner guessed that there’s a 20% chance the patient has diabetes. This belief is a prior probability. The odds from of this probability is:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{0.2}{0.8} = 0.25\n\\]\nSo, the prior odds of the patient having diabetes are 1:4 (one in four) guessed by the medical practitioner.\nThe blood test result shows elevated sugar levels. To assess how much this result affects our belief, we use the ratio of evidence under the guess \\(\\text{G}\\) (also known as the likelihood ratio).\nSuppose the medical practitioner has historically observed from boold test that 85% of diabetic patients have elevated sugar levels, while only 10% of non-diabetic patients do (e.g., due to other factors). Hence, we write\n\\[\n\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})} = \\frac{0.85}{0.10} = 8.5\n\\]\nThis means the test result (elevated sugar) is 8.5 times more likely in someone with diabetes than in someone without it.\nNow, the posterior odds\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = 0.25 \\times 8.5 = 2.125\n\\]\nSo, the updated odds is 2.125:1, i.e., the patient is 2.125 times more likely to have diabetes than non-diabetic individuals after considering the test result.\nUsing the well known relationship between odds and probability, we can also get back the posterior probability from the posterior odds as:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})}{1+\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})} = \\frac{2.125}{1+2.125} = 0.68\n\\]\nIn summary we write, before the test, the medical practitioner believed there was a 20% chance of diabetes. After seeing the elevated blood sugar result, the probability increased to 68% (compare the example in lecture 1), because the test result is 8.5 times more likely in diabetic than non-diabetic individuals. The practitioner may now recommend further tests (e.g., an HbA1c test) before confirming the diagnosis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-distributions",
    "href": "M02_1.html#prior-distributions",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.2 Prior Distributions",
    "text": "3.2 Prior Distributions\n\n\n\n\nGelman et al. (2013)\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst, let’s look at some real-world examples of how prior distributions play a crucial role, particularly in health and medical data.\nWe already got a flavour that prior distributions allow researchers to incorporate existing knowledge or expert opinions into their statistical models, improving the precision of their conclusions. For example, when designing treatments and interventions, prior knowledge helps tailor them to individual patients, enhancing both personalization and effectiveness.\nImagine historical data shows that a certain drug has a 70% success rate in patients with similar profiles. By using an informative prior distribution, we can incorporate this insight to estimate the likelihood of success for a new patient. If fresh data suggests an 80% effectiveness rate, Bayesian methods refine this estimate, leading to a more balanced probability—say, around 75%. This synthesis of prior knowledge with new evidence results in more reliable conclusions.\nPrior information is also invaluable when historical data is limited or when researching new treatments. In such cases, a non-informative prior—such as assuming an initial effectiveness probability of 0.5—can be used, gradually updating as more data becomes available.\nNow, let’s explore cases where we estimate posterior distributions using priors, focusing on statistical models that involve only a single parameter. We’ll discuss models where the posterior distribution has a closed-form solution, determined by both data and prior distributions. Interestingly, in some cases, choosing a particular type of prior results in a posterior that belongs to the same distribution family—a concept we’ve already encountered in our previous module.\nThe property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. This closed form offers easy probability calculations, simplifying updates with new data and contrasting with methods needing numerical approximations for precise inference, which we will explain more later in this lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#estimand-estimator-estimate",
    "href": "M02_1.html#estimand-estimator-estimate",
    "title": "4  Prior and Posterior Distributions",
    "section": "4.8 Estimand, Estimator & Estimate",
    "text": "4.8 Estimand, Estimator & Estimate\nasdf\nref: https://bookdown.org/paul/applied-causal-analysis/estimator.html\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\nFor example, suppose we are interested in the mean height of all male adults in the United States. Our estimand is “the mean height of all male adults in the United States”. A foolproof way to find this mean exactly would be to measure the height of each and every male adult in the United States and compute the mean. But that sounds too hard, so instead we decide to estimate the mean height by taking a random sample of male adults in the United States and measuring the height of each individual. Suppose we take a random sample of 100 adult men in the United States and measure their heights. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand.\nThe most obvious thing to do would be to compute the sample average of the heights. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average is 70 inches. Then 70 inches is the estimate of our estimand provided by the “sample average” estimator.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M03_1.html",
    "href": "M03_1.html",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "",
    "text": "5.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Understand Bayesian model and causality\n– Explain the terms Estimand, Estimator & Estimate\n– Understand the difference between Bayesian and classical Regression.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#causality-and-bayesian-model",
    "href": "M03_1.html#causality-and-bayesian-model",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.3 Causality and Bayesian Model",
    "text": "5.3 Causality and Bayesian Model\n\n\n\nWhen conducting causal inference, we must develop a causal model that is distinct from a Bayesian model, as observational data alone are insufficient. This principle is widely accepted across philosophical perspectives, though interpretations vary significantly.\nThe most cautious view holds that causation is fundamentally unprovable. A slightly less conservative stance suggests that we can infer causation only under strict conditions, such as randomisation and experimental control. However, many scientific questions cannot be addressed experimentally due to feasibility constraints or ethical concerns.\nIn fields like health and medicine, we often introduce various control variables into a statistical model, observe changes in estimates, and construct a causal narrative. This approach assumes that only omitted variables can distort causal conclusions, yet even included variables can introduce confusion.\nEven if we construct a causal model that appears to make accurate predictions, it may still misrepresent causation. If we rely on such a model to guide interventions, we risk producing unintended or misleading outcomes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#estimand-estimator-estimate",
    "href": "M03_1.html#estimand-estimator-estimate",
    "title": "5  Bayeswatch! Part - I",
    "section": "5.5 Estimand, Estimator & Estimate",
    "text": "5.5 Estimand, Estimator & Estimate\n\nThe estimand is the quantity of interest whose true value you want to know.\nAn estimator is a method for estimating the estimand.\nAn estimate is a numerical estimate of the estimand that results from the use of a particular estimator.\n\n5.5.1 Bayesian Context\nSuppose we are interested in the mean vaccine efficacy for a respiratory-related disease among children in Australia. Our estimand is “the mean vaccine efficacy for the respiratory-related disease among all children in Australia”, Now we take a random sample of 10,000 children in Australia and measure the vaccine’s efficacy in preventing the respiratory-related disease in each child. Using this data, we now have to choose an estimator that will provide us with an estimate of our estimand. The most obvious thing to do would be to compute the sample average of the vaccine efficacies. That is, “the sample average” is an estimator that provides an estimate of our estimand. Suppose the sample average indicates a vaccine efficacy of 85%. Then 85% is the estimate of our estimand provided by the “sample average” estimator.\nThe key link to Bayesian thinking is the use of prior information, the combination of prior beliefs with observed data, and the resulting posterior distribution that provides a more comprehensive understanding of the estimand and its uncertainty. In the context of this Bayesian example the estimand is the true, but unknown, mean vaccine efficacy for the respiratory-related disease among all children in Australia. This is the quantity we are ultimately interested in estimating. The estimator is the posterior distribution of the vaccine efficacy. This distribution is derived by combining the prior information with the likelihood of the observed data using Bayes’ theorem. A specific summary statistic of the posterior distribution, such as the posterior mean or posterior median, can also serve as an estimator. The estimate is the specific value or summary of the posterior distribution. For example, if the posterior mean vaccine efficacy is 85%, then 85% is the estimate of the estimand provided by the posterior mean estimator.\n\n\n5.5.2 Regression Context\nNow, let us explain this example in the context of regression problem. Suppose we are interested in understanding how vaccine efficacy for a respiratory-related disease among children in Australia is influenced by certain predictors, such as age, pre-existing health conditions, and socioeconomic status. In this case, our estimand is the set of true regression coefficients that describe the relationship between these predictors and vaccine efficacy.\nA foolproof way to determine these coefficients would be to measure vaccine efficacy and collect all relevant predictor data (e.g., age, health conditions, and socioeconomic status) for every child in Australia and then fit a regression model to the entire population data. However, this is infeasible. Instead, we decide to estimate the regression coefficients using a sample of children.\nHence, we take a random sample of 10,000 children in Australia and collect data on their vaccine efficacy and the relevant predictors. Using this data, we fit a regression model (e.g., a linear regression model) to estimate the relationship between the predictors and vaccine efficacy.\nIn the Bayesian framework, we approach this problem by starting with a prior distribution for each regression coefficient, reflecting our prior beliefs about the relationships. For instance, based on previous studies, we might believe that younger children have slightly lower vaccine efficacy and encode this belief into the prior.\nThe sample data provides the likelihood, representing the probability of observing the data given different values of the regression coefficients. By applying Bayes’ theorem, we combine the prior with the likelihood to produce a posterior distribution for each regression coefficient. The posterior distributions represent our updated beliefs about the coefficients after observing the data.\nFor example, if the posterior mean for the age coefficient is -0.5, it suggests that, on average, each additional year of age is associated with a 0.5% decrease in vaccine efficacy. If the posterior mean for the socioeconomic status coefficient is 2.0, it suggests that higher socioeconomic status is associated with a 2% increase in vaccine efficacy.\nHere, estimand is the true regression coefficients that describe the relationships between the predictors and vaccine efficacy. Estimator is the posterior distributions of the regression coefficients. These distributions summarize the uncertainty about the coefficients. And estimate is the specific value derived from the posterior distributions, such as the posterior mean, median, or mode for each coefficient.\nThis Bayesian approach allows us not only to estimate the coefficients but also to quantify our uncertainty about them, providing a more comprehensive understanding of the predictors’ influence on vaccine efficacy.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Part - I**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-development-using-dag",
    "href": "M03_1.html#model-development-using-dag",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.5 Model Development using DAG",
    "text": "5.5 Model Development using DAG\n\n\nWe have discussed about Directed Acyclic Graph (DAG) in one of our previous lectures. Today we will explain DAG for conceptualising and developing Bayesian regression models. It helps to visually represent causal relationships among variables and ensures proper adjustment for confounding factors.\nNow we explain this more with an example related to Bone Mineral Density (BMD). For example, we want to know, how does body mass index (BMI) impact bone mineral density (BMD)? What role does ‘age’ or ‘sex’ of the patient play in this relationship?\nLet’s focus on the relationship between BMD, BMI, age, and sex. As people age, their BMD naturally decreases over time, and age also influences factors like physical activity, which can impact BMI. Similarly, sex affects both BMI and BMD, with women being more likely to experience a decline in BMD, particularly in conditions like osteoporosis. These factors age and sex may act as confounders, influencing both BMI and BMD.\n\n\n\n\n\n graph LR\n    M(\"BMI\") --&gt; B(\"BMD\")\n    A(\"Age\") --&gt; M\n    S(\"Sex\") --&gt; M\n    A --&gt; B\n    S --&gt; B\n\n\n\n\n\n\nIn this case, the estimand is the specific causal effect of BMI on BMD, while accounting for the influence of age and sex as confounders. The goal is to isolate the effect of BMI on BMD after adjusting for these other variables.\nThe estimator we define here is the Bayesian model, i.e., the multiple linear regression model. This model adjusts for confounders like age and sex, helping us accurately estimate the causal effect of BMI on BMD.\nThe estimate is the actual numerical value derived from the data using the chosen estimator. For example, if the estimate is 0.03, this could represent the change in BMD associated with a one-unit increase in BMI, after accounting for the effects of age and sex.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html",
    "href": "M03_2.html",
    "title": "6  Bayeswatch! Part - II",
    "section": "",
    "text": "6.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Understand the Bayesian GLM\n– Understand the difference between Bayesian and classical GLM.\n– Formulate problems and solutions using Bayesian GLM.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-diagnostics",
    "href": "M03_1.html#model-diagnostics",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.8 Model Diagnostics",
    "text": "5.8 Model Diagnostics\nhttps://m-clark.github.io/easy-bayes/shinystan.html\nshinystan for model diag.\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#logistic-regression",
    "href": "M03_2.html#logistic-regression",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.3 Logistic Regression",
    "text": "6.3 Logistic Regression\n\n\nasdf",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#poisson-regression",
    "href": "M03_2.html#poisson-regression",
    "title": "6  Bayeswatch! Part - II",
    "section": "6.4 Poisson Regression",
    "text": "6.4 Poisson Regression\n\n\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html",
    "href": "M04_1.html",
    "title": "7  Clusterphobia? Part - I",
    "section": "",
    "text": "7.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Explain clusterd data.\n– Describe hierarchical or multilevel Models.\n– Fit Bayesian linear mixed models.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_2.html",
    "href": "M04_2.html",
    "title": "8  Clusterphobia? Part - II",
    "section": "",
    "text": "8.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Construct multilevel models for binary outcome.\n– Understand the difference between Bayesian and classical methods.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_1.html",
    "href": "M05_1.html",
    "title": "9  Size Matters! Part - I",
    "section": "",
    "text": "9.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_2.html",
    "href": "M05_2.html",
    "title": "10  Size Matters! Part - II",
    "section": "",
    "text": "10.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html",
    "href": "M06_1.html",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "",
    "text": "11.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_2.html",
    "href": "M06_2.html",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "",
    "text": "12.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#model-with-binary-variable",
    "href": "M01_2.html#model-with-binary-variable",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.4 Model with Binary Variable",
    "text": "2.4 Model with Binary Variable\n\nSuppose we have a binary observation i.e., can take values either 0 or 1, which follows Bernoulli distribution with parameter \\(\\theta\\). We already know that for \\(n&gt;1\\) number of trials the Bernoulli distribution yields a Binomial distribution. Considering \\(Y\\) as the random variable of number of successes in \\(n\\) trials for the Binomial distribution, we can write:\n\\[\np(Y=y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\]\nThis also represents the likelihood of a Bernoulli variable.\nNow, if we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\) (i.e., shape parameters of Beta distribution), then we can write the probability density function of the prior distribution as:\n\\[\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\]\nwhere, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write\n\\[\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\]\nWith some simple calculations, we can write the marginal likelihood as:\n\\[\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\]\nHence, we get the analytical form of the posterior distribution of \\(\\theta\\) as:\n\\[\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\]\nwhich follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).\nExample:\nLet us explain this with the type-2 diabetes example we discussed earlier. Now, the medical practitioner is trying to estimate the probability that a patient has type-2 diabetes \\(\\theta\\) based on both prior knowledge and a new diagnostic test result.\nBefore any test, the medical practitioner relies on existing medical data. Suppose past research suggests that for a certain risk group the probability of having type-2 diabetes is 0.5. We represent this belief using a \\(Beta(a=2,b=2)\\). This prior suggests that while any probability is possible, \\(\\theta\\) is likely to be around 0.5, with room for updating.\nNow, we assume the test result corresponds to 7 positive cases out of 10 tests, meaning, \\(n=10\\) and \\(y=7\\).\nHence, we get the posterior distribution of medical practitioner’s new belief about the probability of the patient having the disease as: \\(Beta(2+7,2+3)=Beta(9,5)\\).\nWe can see from the density plots, the posterior shifts toward higher probabilities of type-2 diabetes, meaning the medical practitioner is now more confident that the patient may have type-2 diabetes.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2   \nb_prior &lt;- 2   \nn &lt;- 10        \ny &lt;- 7         \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\ntheta &lt;- seq(0, 1, length.out = 100)\nprior_density &lt;- dbeta(theta, a_prior, b_prior)\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\nposterior_density &lt;- dbeta(theta, a_post, b_post)\ndata &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(prior_density, likelihood, posterior_density),\n  Distribution = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\nggplot(data, aes(x = theta, y = density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(title = \"Prior, Likelihood, and Posterior Distributions\",\n       x = expression(theta),\n       y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learning-outcomes",
    "href": "M01_2.html#learning-outcomes",
    "title": "2  The Big Dream",
    "section": "2.2 Learning Outcomes",
    "text": "2.2 Learning Outcomes\nLO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\nLO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**The Big Dream**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learning-outcomes",
    "href": "M02_2.html#learning-outcomes",
    "title": "4  Tools and Generative Models",
    "section": "4.3 Learning Outcomes",
    "text": "4.3 Learning Outcomes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Tools and Generative Models**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#solving-untraceability",
    "href": "M02_2.html#solving-untraceability",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.3 Solving Untraceability",
    "text": "4.3 Solving Untraceability\n\n\nWe can indentify an untraceable solution in Bayesian inference, where the posterior distribution cannot be expressed in a closed-form expression. This phenomenon occurs when the likelihood function and the prior distribution are incompatible, which results in complex integrals within Bayes’ theorem that are analytically intractable.\nThe opposite of untraceable solution is known as the traceable solution, which we have discussed in our previous lectures in the light of exact Bayesian inference. We already know that exact Bayesian inference means computing the posterior analytically, without approximations. And a tractable solution is one that can be computed exactly and efficiently, without requiring numerical approximations or complex sampling methods like Markov Chain Monte Carlo (MCMC). Thus traceable solution can be obtained when the prior distribution and the likelihood function are chosen such that the posterior distribution remains within a recognised family of probability distributions. For example, when a conjugate prior is used, the posterior has a known or a same functional form as the prior, i.e., for a Bernoulli model, that we have already discussed earlier in Lecture 2: \\(\\text{Prior: } \\theta \\sim \\text{Beta}(a,b)\\) and \\(\\text{Posterior: } \\theta|y \\sim \\text{Beta}(a+y,b+n-y)\\).\nUse of non-conjugate priors and often complex likelihood functions, such as those involving hierarchical models, mixture models, or high-dimensional data yields a posterior form of distribution with untraceable solutions, even if we consider conjugate priors for the model parameters.\nFor a non-Gaussian likelihood (i.e., it does not follow a normal distribution), choosing a uniform prior leads to a situation where the resulting posterior distribution cannot be easily determined or expressed in a simple mathematical form and also yields untraceable solution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning-outcomes",
    "href": "M02_1.html#learning-outcomes",
    "title": "3  Prior and Posterior Distributions",
    "section": "3.3 Learning Outcomes",
    "text": "3.3 Learning Outcomes",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior Distributions**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#criterion-and-shrinkage-based",
    "href": "M06_1.html#criterion-and-shrinkage-based",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.3 Criterion and Shrinkage Based",
    "text": "11.3 Criterion and Shrinkage Based\nasdf ref - lambert page 225, sec: 10.5 (AIC, DIC, WAIC, LOO-CV)\nasdf ref - … spike-slab priors (mixture-priors), Bayesian lasso",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#hypothesis-testing-with-bf",
    "href": "M06_1.html#hypothesis-testing-with-bf",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.4 Hypothesis Testing with BF",
    "text": "11.4 Hypothesis Testing with BF\nref: https://statswithr.github.io/book/hypothesis-testing-with-normal-populations.html",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-model-averaging",
    "href": "M06_1.html#bayesian-model-averaging",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "11.5 Bayesian Model Averaging",
    "text": "11.5 Bayesian Model Averaging\nref: https://statswithr.github.io/book/bayesian-model-choice.html#bayesian-model-averaging\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learning-outcomes",
    "href": "M01_1.html#learning-outcomes",
    "title": "1  The Big Dream",
    "section": "1.2 Learning Outcomes",
    "text": "1.2 Learning Outcomes\nLO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\nLO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**The Big Dream**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#problems-use-another-example",
    "href": "M01_1.html#problems-use-another-example",
    "title": "1  Belief-O-Meter: Navigating Evidence",
    "section": "1.8 Problems – use another example",
    "text": "1.8 Problems – use another example",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Belief-O-Meter: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze-logical-framework",
    "href": "M01_1.html#the-maze-logical-framework",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.4 The Maze: Logical Framework",
    "text": "1.4 The Maze: Logical Framework\n\nBayesian analysis is a logical framework that helps update our beliefs based on continuous new information. A helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works — it continuously updates our understanding as more evidence comes in.\nTo see this in practice, let’s consider an example explained below.\n\n1.4.1 Example:\nA medical practitioner had seen many cases of pneumonia before, but this one was tricky. A 55-year-old patient, had been admitted with high fever, cough, and shortness of breath. Based on his symptoms and an initial chest X-ray, the practitioner diagnosed him with bacterial pneumonia and started him on a standard antibiotic.\nAt this point, their belief was strong that the chosen antibiotic would work—this was their prior probability based on past experience.\nDay 2:\nAfter 24 hours, the patient wasn’t improving. Thier fever remained high, and their breathing was still labored.\nThe practitioner now had new evidence — the treatment wasn’t working as quickly as it should. Applying Bayesian reasoning, they adjusted their belief:\n\nThe probability that this was a typical bacterial pneumonia responding to first-line antibiotics decreased.\n\nThe probability that it was a resistant strain of bacteria or even a different type of infection increased.\n\nThey needed more information.\nDay 3:\nThe practitioner ordered a sputum culture to check for antibiotic-resistant bacteria. In the meantime, they updated the treatment, switching the patient to a broader-spectrum antibiotic.\n\nIf the new antibiotic worked, it would confirm that the initial one was ineffective, meaning resistant bacteria were likely the cause.\n\nIf the patient still didn’t improve, it could mean this wasn’t bacterial pneumonia at all—it might be a viral infection instead.\n\nAgain, their belief about the cause of the patient’s illness shifted based on new evidence.\nDay 4:\nThe test results came in: The patient’s infection was caused by a drug-resistant strain of bacteria. This confirmed that the initial choice of antibiotics was ineffective.\nWith this new evidence, the practitioner’s belief was now much stronger that the broader-spectrum antibiotic was the right choice.\nThe Lesson of Bayesian Thinking\nThe medical practitioner didn’t just rely on their initial belief. Instead, they continuously updated their understanding as new evidence emerged—just like someone navigating a maze learns from every wrong turn. This process demonstrates how Bayesian reasoning helps in making data-driven, logical decisions—not just by guessing, but by continuously refining our beliefs with new information, ultimately leading to the best possible decision.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#tutorial-exercises",
    "href": "M01_1.html#tutorial-exercises",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "1.10 Tutorial Exercises",
    "text": "1.10 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#directed-acyclic-graph-dag",
    "href": "M01_2.html#directed-acyclic-graph-dag",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.7 Directed Acyclic Graph (DAG)",
    "text": "2.7 Directed Acyclic Graph (DAG)\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\n\nBayesian models:\n\nIn the context of Bayesian modelling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the model with binary observations, we write a DAG as:\n\n\nCode\nlibrary(DiagrammeR)\n\ngrViz(\"\ndigraph flowchart {\n  graph [layout = dot, rankdir = LR]\n\n  node [shape = rectangle, style = filled, color = white]\n  \n  subgraph cluster_0 {\n    label = 'Hyper-parameter'\n    color = lightblue\n    node [color=lightblue]\n    a [label='a']\n    b [label='b']\n  }\n\n  subgraph cluster_1 {\n    label = 'Parameter'\n    color = lightgray\n    node [color=lightgray]\n    theta [label='θ']\n  }\n\n  subgraph cluster_2 {\n    label = 'Outcome'\n    color = lightsteelblue\n    node [color=lightsteelblue]\n    y [label='y']\n  }\n\n  edge[arrowhead=normal]\n\n  a -&gt; theta\n  b -&gt; theta\n  theta -&gt; y\n}\n\")\n\n\n\n\n\n\nThis is a simple graphical model, where \\(y\\) depends on \\(\\theta\\), with \\(\\theta\\) being a logical function of hyper-parameters \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#tutorial-exercises",
    "href": "M01_2.html#tutorial-exercises",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.11 Tutorial Exercises",
    "text": "2.11 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example-1",
    "href": "M01_2.html#example-1",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.10 Example",
    "text": "2.10 Example\n\n2.10.1 Decision Making:\n\nIn this example, we will see how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed. However, if you make the wrong decision, your research project is shut down.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): 10% prevalence \\(H_1\\): \\(&gt;10%\\) prevalence\np-value based on 5 samples: \\(Pr(k\\ge 1|n=5,p=0.10)=1-Pr(k= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\\)\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\] and\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of whether \\(H_0\\) or \\(H_1\\) is correct are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods as:\n\n\n\n\n\n\n\n\n\nObserved Data\nFrequentist ( Pr(y % ) )\nBayesian ( Pr(10% n, y) )\nBayesian ( Pr(20% n, y) )\n\n\n\n\n( n = 5, y = 1 )\n0.41\n0.45\n0.55\n\n\n( n = 10, y = 2 )\n0.26\n0.39\n0.61\n\n\n( n = 15, y = 3 )\n0.18\n0.34\n0.66\n\n\n( n = 20, y = 4 )\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where ( p = 0.20 ). As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as ( p = 0.20 ) and the alternative as ( p &lt; 0.20 )—we would have reached different conclusions. This highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.10.2 Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\)mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\)mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\n\n\nCode\n# Load necessary libraries\nlibrary(BayesFactor)  # For Bayesian t-test\nlibrary(ggplot2)      # For visualization\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Simulate data for two groups\nn_A &lt;- 50  # Sample size for Drug A\nn_B &lt;- 50  # Sample size for Drug B\n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(\"Frequentist t-test results:\")\n\n\n[1] \"Frequentist t-test results:\"\n\n\nCode\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). Cannot incorporate prior knowledge about the effectiveness of similar drugs. Requires a fixed sample size before testing.\nBayesian\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge. If previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", posterior_prob, \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.4124978 0.09383364 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method incorporates that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.\nThe Bayesian approach gives a richer, more flexible analysis by quantifying uncertainty and updating beliefs dynamically—ideal for real-world decision-making.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#inference",
    "href": "M01_2.html#inference",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.3 Inference",
    "text": "2.3 Inference\n\n\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote\\(Pr(H)\\) as the probability of initial belief about \\(H\\) before seeing data, we can write the updated beliefe about \\(H\\) given the data \\(D\\) as:\n\\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\]\nwhere, \\(Pr(D)\\) is the probability of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.\n\n2.3.1 Example - Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example-test-for-two-means",
    "href": "M01_2.html#example-test-for-two-means",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Example: Test for two means",
    "text": "2.9 Example: Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\) mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\) mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist Method\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\nWe get the frequentist t-test result:\n\n\nCode\n# For Bayesian t-test\nlibrary(BayesFactor)  \nlibrary(ggplot2)\n\nset.seed(123)\n\nn_A &lt;- 50  \nn_B &lt;- 50  \n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). We cannot incorporate any prior knowledge about the effectiveness of similar drugs. It also requires a fixed sample size before testing.\nBayesian Method\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge.\nIf previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\) or \\(Pr(\\mu_B &lt; \\mu_A)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", round(posterior_prob[1],2), \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.41 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method can incorporate that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---decision-making",
    "href": "M01_2.html#example---decision-making",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.7 Example - Decision Making:",
    "text": "2.7 Example - Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---test-for-two-means",
    "href": "M01_2.html#example---test-for-two-means",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.8 Example - Test for two means",
    "text": "2.8 Example - Test for two means\nA pharmaceutical company is testing a new drug (Drug B) to see if it lowers systolic blood pressure (SBP) more effectively than the standard treatment (Drug A).\nGroup A (Control - Standard Drug): \\(n_A=50\\), \\(\\bar{x}_A=140\\) mmHg, \\(\\sigma_A = 15\\).\nGroup A (Treatment - New Drug): \\(n_B=50\\), \\(\\bar{x}_B=135\\) mmHg, \\(\\sigma_A = 15\\).\nWe want to determine if Drug B significantly reduces SBP compared to Drug A.\nFrequentist Method\nIn the frequentist framework, we use a two-sample t-test to compare the means.\n\\(H_0:\\) The new drug has no effect, i.e., \\(\\mu_A=\\mu_B\\).\n\\(H_1:\\) The new drug lowers blood pressure, i.e., \\(\\mu_A\\) &gt; \\(\\mu_B\\)\nUsing a standard t-test we get p-value = 0.1149, and decision includes fail to reject \\(H_0\\).\nWe get the frequentist t-test result:\n\n\nCode\n# For Bayesian t-test\nlibrary(BayesFactor)  \nlibrary(ggplot2)\n\nset.seed(123)\n\nn_A &lt;- 50  \nn_B &lt;- 50  \n\n# Generate synthetic systolic blood pressure data\nsbp_A &lt;- rnorm(n_A, mean = 140, sd = 15)  # Standard drug\nsbp_B &lt;- rnorm(n_B, mean = 135, sd = 15)  # New drug\n\n# Frequentist t-test\nt_test_result &lt;- t.test(sbp_B, sbp_A, alternative = \"less\")  # One-tailed test\nprint(t_test_result)\n\n\n\n    Welch Two Sample t-test\n\ndata:  sbp_B and sbp_A\nt = -1.2085, df = 97.951, p-value = 0.1149\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n    -Inf 1.24187\nsample estimates:\nmean of x mean of y \n 137.1961  140.5161 \n\n\nThe p-value does not tell us the probability that \\(H_0\\) is true. It provides only a binary decision (reject/fail to reject). We cannot incorporate any prior knowledge about the effectiveness of similar drugs. It also requires a fixed sample size before testing.\nBayesian Method\nThe Bayesian method provides a probability distribution for the difference in means, incorporating prior knowledge.\nIf previous studies suggest that similar drugs lower SBP by about 5 mmHg, we can set priors accordingly. Hence, ket us consider the prior distributions for mean: \\(\\mu_A \\sim N(140,10)\\) and \\(\\mu_B \\sim N(135,10)\\); and for standard deviation \\(\\sigma_A,\\sigma_B \\sim \\text{Half-Cauchy}(10)\\).\nWe now get the data-likelihood: \\(x_A \\sim N(\\mu_A,\\sigma_A)\\) and \\(x_B\\sim N(\\mu_B,\\sigma_B)\\). Using Bayesian inference (e.g., Markov Chain Monte Carlo, MCMC), we estimate the posterior distribution of \\((\\mu_B-\\mu_A)\\).\nFrom the posterior distribution, we calculate 95% credible interval for \\((\\mu_B-\\mu_A)\\). And then compute \\(Pr(\\mu_A &gt; \\mu_B)\\) or \\(Pr(\\mu_B &lt; \\mu_A)\\), which is the probability that drug B lowers SBP more than drug A.\n\n\nCode\n# Bayesian t-test\nbayes_result &lt;- ttestBF(x = sbp_B, y = sbp_A, nullInterval = c(-Inf, 0))  # One-sided test\n#print(\"Bayesian t-test results:\")\n#print(bayes_result)\n\n# Convert Bayesian factor to posterior probability (optional)\nbf10 &lt;- extractBF(bayes_result)$bf\nposterior_prob &lt;- bf10 / (bf10 + 1)\ncat(\"Posterior probability that Drug B lowers BP more than Drug A:\", round(posterior_prob[1],2), \"\\n\")\n\n\nPosterior probability that Drug B lowers BP more than Drug A: 0.41 \n\n\nCode\n# Visualization: Plot the distributions\ndf &lt;- data.frame(\n  SBP = c(sbp_A, sbp_B),\n  Group = rep(c(\"Drug A\", \"Drug B\"), each = n_A)\n)\n\nggplot(df, aes(x = SBP, fill = Group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Blood Pressure Distributions for Drug A and B\", x = \"Systolic Blood Pressure (mmHg)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKey points\n\nInstead of just rejecting \\(H_0\\), we get \\(Pr(\\mu_A &gt; \\mu_B)\\), which is more interpretable for decision-making.\nIf past research suggests similar drugs reduce SBP, the Bayesian method can incorporate that information.\nThe Bayesian approach provides meaningful estimates even with limited data, while frequentist tests often require large samples.\nInstead of just saying “Drug B is statistically better,” the Bayesian approach provides probability estimates and expected effect sizes.\nThe frequentist t-test is useful for quick hypothesis testing but provides limited insights.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#example---bayesian-updating",
    "href": "M01_2.html#example---bayesian-updating",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.9 Example - Bayesian Updating",
    "text": "2.9 Example - Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior.\nGoing back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#examples",
    "href": "M01_2.html#examples",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.8 Examples:",
    "text": "2.8 Examples:\n\n2.8.1 Decision Making:\n\nFirst, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nWe can write this example using a DAG, where we can represent the relationships between the prior probabilities, likelihoods, and posterior probabilities.\n\nHypothesis (H₀ and H₁): These represent the two possible prevalence values (10% for H₀, 20% for H₁).\nData (y): The observed data (the number of successes in 5 samples, e.g., the presence of disease).\nLikelihoods (Pr(y=1|H₀) and Pr(y=1|H₁)): The likelihood of observing the data under each hypothesis.\nPrior Probabilities (Pr(H₀) and Pr(H₁)): The prior belief about the hypotheses (both have a prior probability of 0.5).\nPosterior Probabilities (Pr(H₀|y=1) and Pr(H₁|y=1)): The updated belief about the hypotheses after observing the data.\n\n\n\nCode\nlibrary(DiagrammeR)\n\n# Create a directed acyclic graph (DAG)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  H0 [label = 'H₀: 10% prevalence', width = 1.5]\n  H1 [label = 'H₁: 20% prevalence', width = 1.5]\n  y [label = 'y: Data (Successes in 5 samples)', width = 1.5]\n  PrH0 [label = 'Pr(H₀) = 0.5', width = 1.5]\n  PrH1 [label = 'Pr(H₁) = 0.5', width = 1.5]\n  LikelihoodH0 [label = 'Pr(y|H₀) ~ 0.33', width = 1.5]\n  LikelihoodH1 [label = 'Pr(y|H₁) ~ 0.41', width = 1.5]\n  PosteriorH0 [label = 'Pr(H₀|y=1) ~ 0.45', width = 1.5]\n  PosteriorH1 [label = 'Pr(H₁|y=1) ~ 0.55', width = 1.5]\n\n  # Define the edges (relationships)\n  PrH0 -&gt; LikelihoodH0\n  PrH1 -&gt; LikelihoodH1\n  H0 -&gt; LikelihoodH0\n  H1 -&gt; LikelihoodH1\n  LikelihoodH0 -&gt; y\n  LikelihoodH1 -&gt; y\n  y -&gt; PosteriorH0\n  y -&gt; PosteriorH1\n}\n\")\n\n# Render the DAG\ndag\n\n\n\n\n\n\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist: \\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian - 10%: \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nBayesian - 20%: \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\n\n\n\n\n\n\nObserved Data\np-value\nBayesian-10%\nBayesian-20%\n\n\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, and the alternative as \\(H_1\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.8.2 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  \n  # Prior node\n  Prior [label = 'Prior p(θ)', width = 1.5]\n  \n  # Data observations\n  D1 [label = 'D₁: Observation (YES)', width = 2]\n  Dots [label = '...', width = 0.5]\n  D6 [label = 'D₆: Observation (NO)', width = 2]\n  \n  # Posterior updates\n  Posterior_D1 [label = 'Posterior p(θ|D₁)', width = 2]\n  Posterior_D6 [label = 'Posterior p(θ|D₁, ..., D₆)', width = 2]\n\n  # Define the edges (relationships)\n  Prior -&gt; D1\n  D1 -&gt; Posterior_D1\n  Posterior_D1 -&gt; Dots\n  Dots -&gt; D6\n  D6 -&gt; Posterior_D6\n\n  # Layout: top to bottom style\n  rankdir = TB\n}\n\")\ndag\n\n\n\n\n\n\nInvariance to data-order\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior. Hence, going back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learnings",
    "href": "M01_2.html#learnings",
    "title": "2  Bayesian Dreams: Inference",
    "section": "",
    "text": "Outcomes\n\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learnings",
    "href": "M01_1.html#learnings",
    "title": "1  Bayesian Dreams: Navigating Evidence",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Bayesian Dreams: Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#more-examples",
    "href": "M01_2.html#more-examples",
    "title": "2  Bayesian Dreams: Inference",
    "section": "2.8 More Examples:",
    "text": "2.8 More Examples:\n\n2.8.1 Decision Making:\n\nHere, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nWe can write this example using a DAG, where we can represent the relationships between the prior probabilities, likelihoods, and posterior probabilities.\n\nHypothesis (H₀ and H₁): These represent the two possible prevalence values (10% for H₀, 20% for H₁).\nData (y): The observed data (the number of successes in 5 samples, e.g., the presence of disease).\nLikelihoods (Pr(y=1|H₀) and Pr(y=1|H₁)): The likelihood of observing the data under each hypothesis.\nPrior Probabilities (Pr(H₀) and Pr(H₁)): The prior belief about the hypotheses (both have a prior probability of 0.5).\nPosterior Probabilities (Pr(H₀|y=1) and Pr(H₁|y=1)): The updated belief about the hypotheses after observing the data.\n\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  H0 [label = 'H₀: 10% prevalence', width = 1.5]\n  H1 [label = 'H₁: 20% prevalence', width = 1.5]\n  y [label = 'y: Data (Successes in 5 samples)', width = 1.5]\n  PrH0 [label = 'Pr(H₀) = 0.5', width = 1.5]\n  PrH1 [label = 'Pr(H₁) = 0.5', width = 1.5]\n  LikelihoodH0 [label = 'Pr(y|H₀) ~ 0.33', width = 1.5]\n  LikelihoodH1 [label = 'Pr(y|H₁) ~ 0.41', width = 1.5]\n  PosteriorH0 [label = 'Pr(H₀|y=1) ~ 0.45', width = 1.5]\n  PosteriorH1 [label = 'Pr(H₁|y=1) ~ 0.55', width = 1.5]\n\n  # Define the edges (relationships)\n  PrH0 -&gt; LikelihoodH0\n  PrH1 -&gt; LikelihoodH1\n  H0 -&gt; LikelihoodH0\n  H1 -&gt; LikelihoodH1\n  LikelihoodH0 -&gt; y\n  LikelihoodH1 -&gt; y\n  y -&gt; PosteriorH0\n  y -&gt; PosteriorH1\n}\n\")\ndag\n\n\n\n\n\n\nSummary\nWe can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist:\n\\(H_0\\): 10% prevalence and \\(H_1\\): \\(&gt;10\\)% prevalence\n\\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian\n\\(H_0\\): 10% prevalence and \\(H_1\\): 20% prevalence\nPosterior for \\(H_0\\): \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nPosterior for \\(H_1\\): \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\n\n\n\nData\np-value\nPosterior\n\n\n\n\n\n\n\\(H_0\\): 10% prevalence\n\\(H_0\\): 10% prevalence\n\\(H_1\\): 20% prevalence\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently—setting the null hypothesis as \\(H_0\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.8.2 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  \n  # Prior node\n  Prior [label = 'Prior p(θ)', width = 1.5]\n  \n  # Data observations\n  D1 [label = 'D₁: Observation (YES)', width = 2]\n  Dots [label = '...', width = 0.5]\n  D6 [label = 'D₆: Observation (NO)', width = 2]\n  \n  # Posterior updates\n  Posterior_D1 [label = 'Posterior p(θ|D₁)', width = 2]\n  Posterior_D6 [label = 'Posterior p(θ|D₁, ..., D₆)', width = 2]\n\n  # Define the edges (relationships)\n  Prior -&gt; D1\n  D1 -&gt; Posterior_D1\n  Posterior_D1 -&gt; Dots\n  Dots -&gt; D6\n  D6 -&gt; Posterior_D6\n\n  # Layout: top to bottom style\n  rankdir = TB\n}\n\")\ndag\n\n\n\n\n\n\nInvariance to data-order\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior. Hence, going back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Dreams: Inference**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning",
    "href": "M02_1.html#learning",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#tutorial-exercises",
    "href": "M02_1.html#tutorial-exercises",
    "title": "3  Chaotics: Prior and Posterior",
    "section": "3.6 Tutorial Exercises",
    "text": "3.6 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Chaotics: Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learnings",
    "href": "M02_2.html#learnings",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#tutorial-exercises",
    "href": "M02_2.html#tutorial-exercises",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.10 Tutorial Exercises",
    "text": "4.10 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#preparation-for-week-5",
    "href": "M02_2.html#preparation-for-week-5",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.11 Preparation for Week 5",
    "text": "4.11 Preparation for Week 5\nIn week 5 you will be required to .\n\n\n\n\nBernardo, JM, MJ Bayarri, JO Berger, AP Dawid, D Heckerman, AFM Smith, and M West. 2007. “Generative or Discriminative? Getting the Best of Both Worlds.” Bayesian Statistics 8 (3): 3–24.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#algorithms",
    "href": "M02_2.html#algorithms",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.4 Algorithms",
    "text": "4.4 Algorithms\nDifferent types of sampling algorithms have been developed to tackle untraceable solutions, such as rejection sampling, Markov chain Monte Carlo (MCMC), variational inference, Laplace approximation etc. In this couse, we will learn how to use and impliment the MCMC algorithms to solve real-life problems. We refer Gelman et al. (2013) for details on this for those interested to explore more.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#markov-chain-monte-carlo-mcmc",
    "href": "M02_2.html#markov-chain-monte-carlo-mcmc",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.5 Markov chain Monte Carlo (MCMC)",
    "text": "4.5 Markov chain Monte Carlo (MCMC)\n\n\n\nIn this course, we will focus on learning Markov chain Monte Carlo (MCMC) algorithm, which is a sampling based approach to obtain the posterior distribution.\nA Markov chain is a stochastic process where the next state depends only on the current state, not on the sequence of states that preceded it. This property is called the Markovian or Markov property. The transition between states is defined by a transition probability matrix or kernel. On the other hand, Monte Carlo methods involve random sampling to estimate numerical quantities, such as integrals or expectations, to approximate the final solution. MCMC combines the Monte Carlo with Markov chains to generate samples.\nBasic concept and generic structure for MCMC can be explained as follows. Say we are interested in parameter \\(\\theta\\), then we state:\n\nSelecte \\(\\theta^{(0)}\\) at an arbitrary point\nAt iteration \\(t\\), sample from a transition distribution \\(\\theta^{(t)}|\\theta^{(t-1)}\\), i.e., to generate a new value \\(\\theta = \\theta^{(t)}\\) given the previous value \\(\\theta = \\theta^{(t-1)}\\).\nRepeat the previous step until a specified maximum number of iterations is reached, or until specified convergence criterion is satisfied.\n\nHence, the MCMC states, there exist a transition distribution that guarantee that\n\\[\np(\\theta\\in \\{\\theta^{(t)},\\theta^{(t+1)},...,\\theta^{(q)} \\}) \\rightarrow p(\\theta|\\text{data}); \\text{   as   } q\\rightarrow \\infty\n\\]\nThe function that determines the probability for selecting the next location, is called the transition distribution.\nNow, we will discuss some popular and common MCMC methods we use in practice to solve real-life applications.\n\nCommon MCMC methods\n\nSome common MCMC algorithms include Metropolis-Hastings (MH) algorithm, Gibbs sampling, Hamiltonian Monte Carlo (HMC) etc. MH is a general MCMC method that generates candidate samples from a proposal distribution. A candidate is accepted or rejected based on an acceptance probability, ensuring the chain converges to the target distribution. Whereas, Gibbs sampling is a special case of the Metropolis-Hastings algorithm. Updates one variable at a time by sampling from its conditional distribution while keeping other variables fixed. The Hamiltonian Monte Carlo (HMC) algorithm uses gradient information from the target distribution to propose new samples, making it more efficient for high-dimensional problems.\n\n\n4.5.1 Metropolis-Hastings (MH) Algorithm\nThe MH algorithm generates a sequence of samples that gradually approximates a target distribution say \\(p(\\theta)\\). It starts with an arbitrary value say \\(\\theta^{(0)}\\), and then uses a proposal distribution \\(q(\\theta^* | \\theta_t)\\) to propse a new value \\(\\theta^*\\). In the next step it accepts or rejects \\(\\theta^*\\) using an acceptance probability:\n\\[\nA = \\min \\left(1, \\frac{p(\\theta^*) q(\\theta_t | \\theta^*)}{p(\\theta_t) q(\\theta^* | \\theta_t)} \\right)\n\\]\nNow, if accepted, the we set \\(\\theta_{t+1} = \\theta^*\\), otherwise keep the current sample, i.e., \\(\\theta_{t+1} = \\theta_t\\). We then iterate this process to generate a sequence of samples, and over time, the samples approximate \\(p(\\theta)\\).\nExample\nSuppose, we want to sample from a standard normal distribution \\(N(0,1)\\) using the Metropolis-Hastings algorithm, starting from an arbitrary initial point. This allows us to observe how the MCMC chain gradually converges to the target distribution. We write the target density \\(\\theta \\sim N(0,1)\\) as:\n\\[\np(\\theta) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\theta^2}{2}\\right)\n\\]\n\n\nCode\nlibrary(coda)\nmetropolis_hastings &lt;- function(target_density, proposal_sd, n_iter, initial_value) {\n  chain &lt;- numeric(n_iter)\n  chain[1] &lt;- initial_value\n  \n  for (i in 2:n_iter) {\n    proposal &lt;- rnorm(1, mean = chain[i - 1], sd = proposal_sd)\n    acceptance_prob &lt;- min(1, target_density(proposal) / target_density(chain[i - 1]))\n    if (runif(1) &lt; acceptance_prob) {\n      chain[i] &lt;- proposal\n    } else {\n      chain[i] &lt;- chain[i - 1]\n    }\n  }\n  \n  return(chain)\n}\ntarget_density &lt;- function(x) dnorm(x, mean = 0, sd = 1)\n\nset.seed(123)\nn_iter &lt;- 10000\nn_chains &lt;- 3\nchains &lt;- list(\n  chain1 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 10),\n  chain2 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = -10),\n  chain3 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 5)\n)\n\nmcmc_chains &lt;- mcmc.list(\n  mcmc(chains$chain1),\n  mcmc(chains$chain2),\n  mcmc(chains$chain3)\n)\n\nsummary(mcmc_chains)\n\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n     -0.025039       1.066546       0.006158       0.020382 \n\n2. Quantiles for each variable:\n\n    2.5%      25%      50%      75%    97.5% \n-2.05216 -0.70284 -0.01213  0.65225  1.94265 \n\n\nCode\n#par(mfrow = c(1, 3))\n#for (i in 1:n_chains) {\n#  plot(mcmc_chains[[i]], type = \"l\", col = \"blue\", \n#       main = paste(\"Chain\", i), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       trace = TRUE, density = FALSE)\n#}\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_mh &lt;- mcmc_chains\n\n\n\n\n4.5.2 Gibbs Sampling\nThe Gibbs sampling algorithm is a special case of the Metropolis-Hastings (MH) algorithm and is particularly useful when we want to do sampling from high-dimensional joint distributions. Instead of sampling all variables at once, Gibbs sampling updates one variable at a time, conditioning on the others.\nSuppose we have a joint distribution \\(p(\\theta_1, \\theta_2)\\), and the algorithm starts with arbitrary initial values for all variables, i.e., \\(\\theta_1^{(0)}\\) and \\(\\theta_2^{(0)}\\). For each variable then we sample from its conditional distribution, i.e., for \\(\\theta_1\\) we use conditional distribution \\(p(\\theta_1|\\theta_2)\\) and then for \\(\\theta_2\\) we use \\(p(\\theta_2|\\theta_1)\\). This means we sample \\(\\theta_1\\) given all other current values, i.e., in our example this is \\(\\theta_2\\) and then sample \\(\\theta_2\\) given \\(\\theta_1\\). We then repeat the process for many iterations until the samples converge to the target distribution.\nExample\nLet’s use Gibbs Sampling to sample from a bivariate normal distribution where the marginal distributions of each variable are normal, but the two variables are correlated. We’ll then assess the convergence using trace plots, autocorrelation plots, and the Gelman-Rubin diagnostic.\nThe joint density is the bivariate normal distribution:\n\\[\np(x,y) = \\frac{1}{2\\pi\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left(x^2-2\\rho x y +y^2 \\right) \\right)\n\\]\nwhere \\(\\rho\\) is the correlation between \\(x\\) and \\(y\\).\n\n\nCode\nlibrary(coda)\ngibbs_sampling &lt;- function(n_iter, rho, initial_values) {\n  x &lt;- numeric(n_iter)\n  y &lt;- numeric(n_iter)\n  \n  x[1] &lt;- initial_values[1]\n  y[1] &lt;- initial_values[2]\n  \n  for (i in 2:n_iter) {\n    x[i] &lt;- rnorm(1, mean = rho * y[i - 1], sd = sqrt(1 - rho^2))\n    y[i] &lt;- rnorm(1, mean = rho * x[i], sd = sqrt(1 - rho^2))\n  }\n  \n  return(data.frame(theta_1 = x, theta_2 = y))\n}\n\nset.seed(123)         \nn_iter &lt;- 1000       \nrho &lt;- 0.8           \ninitial_values &lt;- c(0, 0)  \n\nchain1 &lt;- gibbs_sampling(n_iter, rho, c(0, 0))\nchain2 &lt;- gibbs_sampling(n_iter, rho, c(10, 10))\nchain3 &lt;- gibbs_sampling(n_iter, rho, c(-10, -10))\n\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(chain1)),\n  mcmc(as.matrix(chain2)),\n  mcmc(as.matrix(chain3))\n)\n\nsummary(mcmc_chains)\n\n\n\nIterations = 1:1000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean    SD Naive SE Time-series SE\ntheta_1 0.01841 1.026  0.01874        0.03854\ntheta_2 0.01097 1.018  0.01858        0.03912\n\n2. Quantiles for each variable:\n\n          2.5%     25%     50%    75% 97.5%\ntheta_1 -1.943 -0.6345 0.02087 0.6801 1.827\ntheta_2 -1.902 -0.6288 0.01558 0.6646 1.902\n\n\nCode\n#par(mfrow = c(2, 3))\n#for (i in 1:3) {\n#  plot(mcmc_chains[[i]][, \"x\"], type = \"l\", col = \"blue\",\n#       main = paste(\"Chain\", i, \"(x)\"), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       density = FALSE)\n#  plot(mcmc_chains[[i]][, \"y\"], type = \"l\", col = \"red\",\n#       main = paste(\"Chain\", i, \"(y)\"), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       density = FALSE)\n#}\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_gibbs &lt;- mcmc_chains\n\n\n\n\n4.5.3 Hamiltonian Monte Carlo (HMC)\nHamiltonian Monte Carlo (HMC) is a powerful MCMC algorithm that uses information about the gradient of the log-probability density to efficiently sample from complex distributions. HMC is inspired by Hamiltonian mechanics, which describes the motion of objects in a physical system. Here, we use a system in Hamiltonian mechanics and is defined by \\(H(\\theta,p)=L(\\theta)+K(p)\\), where \\(L(\\theta)\\) is the negative log of the target density and \\(K(p)\\) is a kinetic energy, which we usually model using a Gaussian distribution.\nThe sampling steps involves by initialising with a position \\(\\theta_t\\) and sample \\(p_t\\) from a Gaussian distribution. Then simulate Hamiltonian dynamics using gradient of \\(L(\\theta)\\) and hence update the position and momentum iteratively. After the simulation, we propose a new state \\((\\theta^*,p^*)\\) and accept or reject the proposed step using Metropolis criterion:\n\\[\nA = \\min \\left(1, \\frac{\\exp(-H(\\theta^*, p^*))}{\\exp(-H(\\theta_t, p_t))} \\right)\n\\]\nAnd, if accepted, move to \\(\\theta^*\\), and for rejection stay at \\(\\theta_t\\). We then repeat for many iterations to generate samples.\nExample\nBelow, we provide an example of implementing HMC for normal distriution with parameters \\(\\mu\\) and \\(\\sigma^2\\), using R with the rstan package, which includes a highly optimised implementation of HMC.\n\n\n\nCode\nlibrary(rstan)\nlibrary(bayesplot)\n\nset.seed(42)\ntrue_mu &lt;- 5.0\ntrue_sigma &lt;- 2.0\nn_samples &lt;- 100\ny &lt;- rnorm(n_samples, mean = true_mu, sd = true_sigma)\n\nhist(y, breaks = 20, col = \"lightblue\", main = \"Observed Data\", xlab = \"y\")\n\n\n\n\n\n\n\n\n\nCode\nstan_code &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;        // Number of observations\n  vector[N] y;           // Observed data\n}\nparameters {\n  real mu;               // Mean\n  real&lt;lower=0&gt; sigma;   // Standard deviation\n}\nmodel {\n  mu ~ normal(0, 10);    // Prior for mu\n  sigma ~ normal(0, 10); // Prior for sigma\n  y ~ normal(mu, sigma); // Likelihood\n}\n\"\nstan_data &lt;- list(\n  N = length(y),\n  y = y\n)\n\nfit &lt;- stan(\n  model_code = stan_code,\n  data = stan_data,\n  iter = 2000,      \n  warmup = 1000,    \n  chains = 3,       \n  seed = 1234         \n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 8.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.053 seconds (Warm-up)\nChain 1:                0.051 seconds (Sampling)\nChain 1:                0.104 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.089 seconds (Warm-up)\nChain 2:                0.047 seconds (Sampling)\nChain 2:                0.136 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.3e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.057 seconds (Warm-up)\nChain 3:                0.046 seconds (Sampling)\nChain 3:                0.103 seconds (Total)\nChain 3: \n\n\nCode\nprint(fit, pars = c(\"mu\", \"sigma\"))\n\n\nInference for Stan model: anon_model.\n3 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=3000.\n\n      mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat\nmu    5.06       0 0.21 4.65 4.92 5.06 5.20  5.49  2598    1\nsigma 2.11       0 0.16 1.83 2.00 2.10 2.21  2.45  2926    1\n\nSamples were drawn using NUTS(diag_e) at Sat Apr  5 11:53:52 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCode\n#library(bayesplot)\n#mcmc_trace(fit, pars = c(\"mu\", \"sigma\"))\n#mcmc_areas(fit, pars = c(\"mu\", \"sigma\"))\n#mcmc_acf_bar(fit, pars = c(\"mu\", \"sigma\"))\n\nlibrary(coda)\nposterior_samples &lt;- as.array(fit)\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(posterior_samples[,1,1:2])),\n  mcmc(as.matrix(posterior_samples[,2,1:2])),\n  mcmc(as.matrix(posterior_samples[,3,1:2]))\n)\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_hmc &lt;- mcmc_chains\n\n\n# use shinystan\n#library(shinystan)\n#launch_shinystan(fit)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#mcmc-diagnostics",
    "href": "M02_2.html#mcmc-diagnostics",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.6 MCMC diagnostics",
    "text": "4.6 MCMC diagnostics\n\n\nWhen we run Markov Chain Monte Carlo (MCMC) methods for Bayesian inference, we need to make sure our samples actually represent the true posterior distribution. MCMC doesn’t guarantee good results on its own, so we rely on MCMC diagnostics to check for issues like lack of convergence, autocorrelation, and poor mixing.\n\n4.6.1 Convergence\nWe first check whether the MCMC chain has actually converged to the posterior distribution. To check this we rely on methods such as: trace plots and Gelman-Rubin Diagnostic using R statistic.\nIf the trace plot looks like a “hairy caterpillar” without trends or long drifts, that’s a good sign. If we see big jumps or slow drifting, we might need a longer burn-in period or better tuning.\nIf we run multiple chains as indicated in the examples above, the we can compare their variance, which is also known as Gelman-Rubin Diagnostic and denote the estimate as \\(\\hat{R}\\). An \\(\\hat{R}\\) near 1 typically indicates convergence, i.e., all chains are settled into the same stationary distribution. It is also important to check the Gelman-Rubin plot, which usually show how \\(\\hat{R}\\) decreases over iterations.\n\n\n4.6.2 Autocorrelation\nWe can also use autocorrelation plots to check how correlated our MCMC samples are with previous ones. Ideally, the correlation should drop off quickly, if it lingers then we may need to adjust our proposal distribution for MH or thinning interval or run the chain for more iterations.\nAnother measurement diagnostic is the effective sample size (ESS). If ESS is low, it means we’re getting fewer independent samples than expected. Increasing the total iterations or improving sampling efficiency (e.g., using Hamiltonian Monte Carlo instead of Metropolis-Hastings) can help to increase the ESS.\n\n\n4.6.3 Mixing & Efficiency\nEven if our chain is converging, we want to make sure it’s exploring the full posterior efficiently. Poor mixing shows up when the chain gets stuck in one region for too long before jumping elsewhere. If we notice this, the we can tweak the sampling algorithm to improve mixing.\nFor Metropolis-Hastings, we aim for an acceptance rate between 20% and 50%. If it’s too low, our proposals might be too aggressive; if it’s too high, they might be too conservative.\nRunning MCMC isn’t just about pressing “go” and hoping for the best—we actively check these diagnostics to ensure our samples are reliable. If we run into problems, we adjust our burn-in period, reparameterize our model, or switch to a more advanced sampler like Hamiltonian Monte Carlo.\n\n\n4.6.4 Code for MH\n\n\nCode\n## MH\n#par(mfrow = c(1, 3))\n#for (i in 1:n_chains) {\n#  autocorr.plot(mcmc_chains_mh[[i]], main = #paste(\"Autocorrelation: Chain\", i), lag.max = 50)\n#}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_mh[[1]]) %&gt;% mutate(Chain = \"Chain 1\"),\n  extract_acf(mcmc_chains_mh[[2]]) %&gt;% mutate(Chain = \"Chain 2\"),\n  extract_acf(mcmc_chains_mh[[3]]) %&gt;% mutate(Chain = \"Chain 3\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of MCMC Chains - MH\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ngelman_diag &lt;- gelman.diag(mcmc_chains_mh)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]          1          1\n\n\nCode\ngelman.plot(mcmc_chains_mh)\n\n\n\n\n\n\n\n\n\n\n\n4.6.5 Code for Gibbs\n\n\nCode\n## gibbs\n#par(mfrow = c(2, 3))\n#for (i in 1:3) {\n#  autocorr.plot(mcmc_chains_gibbs[[i]][, \"x\"], main = paste(\"Autocorrelation: Chain\", i, \"(x)\"))\n#  autocorr.plot(mcmc_chains_gibbs[[i]][, \"y\"], main = paste(\"Autocorrelation: Chain\", i, \"(y)\"))\n#}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_gibbs[[1]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 1 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[1]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 1 (theta_2)\"),\n  extract_acf(mcmc_chains_gibbs[[2]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 2 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[2]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 2 (theta_2)\"),\n  extract_acf(mcmc_chains_gibbs[[3]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 3 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[3]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 3 (theta_2)\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of Gibbs Sampling Chains\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ngelman_diag &lt;- gelman.diag(mcmc_chains_gibbs)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\ntheta_1          1       1.02\ntheta_2          1       1.02\n\nMultivariate psrf\n\n1\n\n\nCode\ngelman.plot(mcmc_chains_gibbs)\n\n\n\n\n\n\n\n\n\n\n\n4.6.6 Code for HMC\n\n\nCode\n## HMC\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_hmc[[1]][, 1]) %&gt;% mutate(Chain = \"Chain 1 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[1]][, 2]) %&gt;% mutate(Chain = \"Chain 1 (Param 2)\"),\n  extract_acf(mcmc_chains_hmc[[2]][, 1]) %&gt;% mutate(Chain = \"Chain 2 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[2]][, 2]) %&gt;% mutate(Chain = \"Chain 2 (Param 2)\"),\n  extract_acf(mcmc_chains_hmc[[3]][, 1]) %&gt;% mutate(Chain = \"Chain 3 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[3]][, 2]) %&gt;% mutate(Chain = \"Chain 3 (Param 2)\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of HMC MCMC Samples\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ngelman_diag &lt;- gelman.diag(mcmc_chains_hmc)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu             1       1.00\nsigma          1       1.01\n\nMultivariate psrf\n\n1\n\n\nCode\ngelman.plot(mcmc_chains_hmc)\n\n\n\n\n\n\n\n\n\nCode\nrhats &lt;- rhat(fit)\nrhats\n\n\n       mu     sigma      lp__ \n0.9995676 0.9999119 1.0003116 \n\n\nCode\nmcmc_rhat(rhats) + yaxis_text(hjust = 1)\n\n\n\n\n\n\n\n\n\nCode\nratios_cp &lt;- neff_ratio(fit)\nprint(ratios_cp)\n\n\n       mu     sigma      lp__ \n0.8658714 0.9753797 0.4927674 \n\n\nCode\nmcmc_neff(ratios_cp, size = 2) + yaxis_text(hjust = 1)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#summary-1",
    "href": "M02_2.html#summary-1",
    "title": "4  Chaotics: Generative Models and Tools",
    "section": "4.8 Summary",
    "text": "4.8 Summary\nToday’s lecture focused on understanding generative models, and how we can use generative models to answer research questions using Bayesian methods. We learn when to use exact inference and MCMC based optimisations, together their types. Finally we illustrate the prior and posterior predictive checks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Chaotics: Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learnings",
    "href": "M03_1.html#learnings",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#estimand-estimator-estimate---bayesian-context",
    "href": "M03_1.html#estimand-estimator-estimate---bayesian-context",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.4 Estimand, Estimator & Estimate - Bayesian Context",
    "text": "5.4 Estimand, Estimator & Estimate - Bayesian Context\n\nWhen making causal inferences, we commonly use the terms estimand, estimator, and estimate. The estimand is the quantity of interest—the true value we seek to determine. We define an estimator as the method or procedure that we use to estimate the estimand. Finally, an estimate is the numerical result we obtain from applying a specific estimator to data. Now we will discuss how these terms can be used in Bayesian context.\n\nExample\n\nSuppose, we want to find out the average effectiveness of a vaccine for a respiratory disease among children in Australia. Our estimand is “the true average vaccine effectiveness for this disease among all children in Australia.”\nSince we can’t measure every child, we take a random sample of 10,000 children and record how well the vaccine protects them from the disease. Using this data, we now need to choose an estimator, which is a method to estimate our estimand.\nThe simplest approach is to calculate the average vaccine effectiveness in our sample. In this case, the sample average acts as our estimator, providing an estimate of the true vaccine effectiveness. If our sample average shows 85% effectiveness, then 85% is our estimate based on the sample average estimator.\nNow, in a Bayesian framework, the estimand remains the same, which is the true but unknown average vaccine effectiveness among all children in Australia. However, instead of just using the sample average, our estimator in the Bayesian context is the posterior distribution of vaccine effectiveness. And we already know that this distribution is derived by combining prior knowledge with the likelihood of the observed data using Bayes’ theorem.\nTo summarise this posterior distribution, we can use a specific value, such as the posterior mean or posterior median, as an estimator. The final estimate is the specific value from this distribution. For example, if the posterior mean suggests 85% effectiveness, then 85% is our estimate based on the posterior mean estimator.\n\n5.4.1 Modelling Context\nNow, let us explain this in the context of Bayesian regression problem. Suppose we are interested in understanding how vaccine efficacy for a respiratory-related disease among children in Australia is influenced by certain predictors, such as age, pre-existing health conditions, and socioeconomic status. In this case, our estimand is the set of true regression coefficients that describe the relationship between these predictors and vaccine efficacy.\nA perfect way to determine these coefficients would be to measure vaccine efficacy and collect all relevant predictor data (e.g., age, health conditions, and socioeconomic status) for every child in Australia and then fit a model to the entire population data. However, this is infeasible. Instead, we can estimate the regression coefficients using a sample observation, and we take a random sample of 10,000 children in Australia and collect data on their vaccine efficacy and the relevant predictors. Using this data, we fit a Bayesian model (e.g., a Bayesian linear regression model) to estimate the relationship between the predictors and vaccine efficacy.\nIn the Bayesian framework, we approach this problem by starting with a prior distribution for each regression coefficient, reflecting our prior beliefs about the relationships. For example, based on previous studies, we might believe that younger children have slightly lower vaccine efficacy and use this belief into the prior.\nThe sample data provides the likelihood, representing the probability of observing the data given different values of the regression coefficients. By applying Bayes’ theorem, we combine the prior with the likelihood to produce a posterior distribution for each regression coefficient. The posterior distributions represent our updated beliefs about the coefficients after observing the data.\nFor example, if the posterior mean for the age coefficient is -0.5, it suggests that, on average, each additional year of age is associated with a 0.5% decrease in vaccine efficacy. If the posterior mean for the socioeconomic status coefficient is 2.0, it suggests that higher socioeconomic status is associated with a 2% increase in vaccine efficacy.\nHere, estimand is the true regression coefficients that describe the relationships between the predictors and vaccine efficacy. Estimator is the posterior distributions of the regression coefficients. These distributions summarize the uncertainty about the coefficients. And estimate is the specific value derived from the posterior distributions, such as the posterior mean, median, or mode for each coefficient.\nThis Bayesian approach allows us not only to estimate the coefficients but also to quantify our uncertainty about them, providing a more comprehensive understanding of the predictors’ influence on vaccine efficacy.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learnings",
    "href": "M03_2.html#learnings",
    "title": "6  Bayeswatch! Part - II",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Bayeswatch! Part - II**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learnings",
    "href": "M04_1.html#learnings",
    "title": "7  Clusterphobia? Part - I",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learnings",
    "href": "M04_2.html#learnings",
    "title": "8  Clusterphobia? Part - II",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learnings",
    "href": "M05_1.html#learnings",
    "title": "9  Size Matters! Part - I",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Size Matters! Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learnings",
    "href": "M05_2.html#learnings",
    "title": "10  Size Matters! Part - II",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Size Matters! Part - II**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learnings",
    "href": "M06_1.html#learnings",
    "title": "11  Wander into the Wonder! Part - I",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Wander into the Wonder! Part - I**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learnings",
    "href": "M06_2.html#learnings",
    "title": "12  Wander into the Wonder! Part - II",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder! Part - II**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#prior-twites",
    "href": "M03_1.html#prior-twites",
    "title": "5  Bayeswatch! Causal Connections",
    "section": "5.7 Prior twites",
    "text": "5.7 Prior twites\nSimilarities between IG and students-t. Let’s explain this with Inverse-Gamma distributions with parameters (2,1), i.e., IG(2,1) and Student-t distributions that approximate the IG with parameters (3,0,1), i.e., Student-t(3, 0, 1), where Degrees of Freedom = 3, location = 0 (centered), and Scale = 1. Note that we’ll use the fact that the Inverse-Gamma distribution is the inverse of a Gamma distribution. This means that we can plot the Gamma distributions with appropriate parameters and then invert the axes to simulate the Inverse-Gamma behavior.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nCode\n# Function to plot Inverse-Gamma approximation (using the inverse of Gamma distribution)\nig_density &lt;- function(alpha, beta, x) {\n  return(dgamma(1 / x, shape = alpha, rate = beta) / (x^2))  # Inverse-Gamma as 1/Gamma(x)\n}\n\n# Plot Inverse-Gamma(2,1)\np1 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n  stat_function(fun = function(x) ig_density(2, 1, x), col = \"red\", lwd = 2) +\n  labs(y = \"Density\", x = expression(sigma), \n       title = \"Inverse-Gamma(2, 1)\") +\n  theme_minimal()\n\n# Plot Student-t(3, 0, 1)\np2 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n  stat_function(fun = function(x) dt(x / 1, df = 3) / 1, col = \"blue\", lwd = 2) +\n  labs(y = \"Density\", x = expression(sigma), \n       title = \"Student-t(3, 0, 1)\") +\n  theme_minimal()\n\n# Combine the plots side by side\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nThus if we\nWhy do we use Cauchy prior? What are the benefits? Is this weakly informative prior?\n\n\nCode\nbmd_model &lt;- brm(\n  formula = BMD ~ BMI + Age + Sex,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 1), class = \"b\"),       # Priors for slopes\n    prior(normal(0, 1), class = \"Intercept\"),\n    prior(cauchy(0, 1), class = \"sigma\")    # Prior for residual SD\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.244 seconds (Warm-up)\nChain 1:                0.147 seconds (Sampling)\nChain 1:                0.391 seconds (Total)\nChain 1: \n\n\nuse rstan, rstanarm or brms",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Bayeswatch! Causal Connections**</span>"
    ]
  }
]