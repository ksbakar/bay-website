[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistical Methods in Medicine & Health",
    "section": "",
    "text": "Preface\nThe application of Bayesian methods in medicine and health sciences has become increasingly vital as we strive to enhance our understanding of improve diagnostic accuracy, and personalise treatment plans. This course is designed to introduce students with a background in medicine and health sciences to the principles and practices of Bayesian statistics, providing a practical framework for applying these methods in their respective fields.",
    "crumbs": [
      "**Preface**"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Bayesian methods offer a unique approach to statistical analysis by incorporating prior knowledge and continuously updating the posterior probability as new evidence becomes available. This dynamic approach is particularly suited to the medical and health sciences, where new data is constantly emerging, and decisions often need to be made in the face of uncertainty.\nThe aim of this course is to explain Bayesian statistics and demonstrate its practical applications in medicine and health sciences. We will start with the foundational concepts, gradually building up to more advanced topics, ensuring a comprehensive understanding that is both accessible and relevant to medical professionals, researchers, and students. Each chapter includes real-world examples, case studies, and practical exercises to reinforce the concepts discussed and illustrate their application in clinical and research settings.\nThroughout the course, we will explore the following key areas:\n\nBayesian Dreams! Navigating Evidence and Inference: Understanding the basics of Bayesian philosophy and how it differs from traditional frequentist approaches. Learning how to update beliefs in light of new data using Bayes’ theorem. Exploring directed acyclic graph (DAG) in the Bayesian modelling context, with graphical representations of the probabilistic relationships between variables and parameters.\nChaotics? Prior Problems, Tools, and Computation: Exploring the role of prior information and how it influences posterior conclusions. Bayesian context of exact inference and computational techniques for approximating complex posterior distributions such as Markov chain Monte Carlo (MCMC). Generative models with prior and posterior predictive checks.\nBayeswatch! Keeping an Eye on Your Gaussian Model: Understanding causation and correlation and how it can be used in Bayesian context by drawing DAG. Nevigating Bayesian hierarchical models with continuous outcome or endpoint variable. Explore the choice for hyper-parameters of prior distributions for Gaussian model. Explore examples in clinical and health research.\nBayeswatch! Keeping an Eye on Your Non-Gaussian Model: Extending Bayesian models beyond normality assumptions, where outcome or endpoint variable is binary (i.e., generalised linear models under Bayesian hierarchy), and explanation with DAG. Explore key tactics on the choice of prior distributions.\nClusterphobia? Let Bayes Handle It!: Understanding and implementing hierarchical models for complex data structures common in health sciences. Learing the use of latent process modelling in Bayesian hierarchy (i.e., similar to mixed models in frequentist settings) with both normal and non-normal (e.g., binomial and Poisson) distributions.\nWander into the Wonder! Bayesian Secrets to the Right Sample: Bayesian sample size calculations, in particular to aid the sample size selection to design trials. Discussion of adaptations with relevant sample size calculations using Bayesian methods. Bayesian model choice (e.g., Bayes factor, deviance information criterion (DIC), Watanabe-Akaike information criterion (WAIC) and leave-one-out (LOO) cross-validation). Bayesian shrinkage, missing data analysis and measurement errors.\n\nThe field of medicine and health sciences is inherently multidisciplinary, and so too is this course. It is crafted to bridge the gap between statistical theory and medical practice, enabeling healthcare professionals to make more informed, data-driven decisions. Whether you are a student eager to learn about Bayesian statistics, or a biostatistician or clinician or a health professional looking to enhance your research skills, or a researcher aiming to apply Bayesian methods to your work, this course provides the tools and knowledge you need to succeed.\nWe hope that by the end of this journey, you will not only appreciate the power and flexibility of Bayesian methods but also feel confident in applying these techniques to improve patient outcomes and advance medical research.\nWelcome to the world of Bayesian methods in medicine and health sciences. Let’s begin.",
    "crumbs": [
      "**Introduction**"
    ]
  },
  {
    "objectID": "installation_guide.html",
    "href": "installation_guide.html",
    "title": "R and RStudio",
    "section": "",
    "text": "Have R and RStudio installed and working\nIt is important that everyone has R and RStudio installed and functional before any assignments are due.",
    "crumbs": [
      "**R and RStudio**"
    ]
  },
  {
    "objectID": "installation_guide.html#have-r-and-rstudio-installed-and-working",
    "href": "installation_guide.html#have-r-and-rstudio-installed-and-working",
    "title": "R and RStudio",
    "section": "",
    "text": "How to install R?\nThe latest version of R can be downloaded from the Comprehensive R Archive Network (CRAN):\n\nhttps://cran.r-project.org/\n\nTo install R on a PC click on “Download R for Windows”\n\nhttps://cran.r-project.org/bin/windows/base/\n\nand then “install R for the first time”. This will take you to a new window with the latest version of R. Click on “Download R 4.X.X for Windows” and follow the installation instructions. Default settings are OK. Note: At the time of writing, the current version of R was 4.2.2 but you can install whichever is the latest version, even if it differs from the one mentioned in the course notes.\nTo install R on a Mac click on “Download R for (Mac) OS X”\n\nhttps://cran.r-project.org/bin/macosx/\n\nand download the R binary under “Latest release”. The file will have an extension of .pkg, for example R-4.X.X.pkg. Click on this link and follow the instructions. Default settings are OK. Note: you can install whichever is the latest version, even if it differs from the one mentioned in these notes.\nOptional – Check that R has installed correctly (You can skip this step and proceed to installing RStudio. If RStudio is working then you know that base R was successfully installed.) Open R and type 1 + 2 into the command line (the command line is indicated with the “&gt;” symbol). After pressing Enter, you should get the following output:\n[1] 3\n\n\nHow to install RStudio?\nYou don’t need to download RStudio in order to use R, but RStudio provides a more user friendly interface and is commonly used by many R users. We will be using RStudio, so we strongly recommend that you install it too.\nFirst make sure you have downloaded base R and confirmed that it was successfully installed. After you have downloaded base R, you can download RStudio. RStudio can be downloaded from:\n\nhttps://posit.co/download/rstudio-desktop/#download\n\nScroll down and download the appropriate file for your operating system. Follow the prompts to install.\nTo confirm that RStudio has installed correctly, double click on the RStudio icon your computer to open the program\nIf you type 1 + 2 into the R Console and hit enter you should get 3 as the output.\nGood work! You have now successfully installed R and RStudio!",
    "crumbs": [
      "**R and RStudio**"
    ]
  },
  {
    "objectID": "installation_guide.html#how-to-install-compiler",
    "href": "installation_guide.html#how-to-install-compiler",
    "title": "R and RStudio",
    "section": "How to Install Compiler?",
    "text": "How to Install Compiler?\n\nInstall ‘Rtools’ (C++ Compiler) for Windows OS\nDownload Rtools from\n\nhttps://cran.r-project.org/bin/windows/Rtools/\n\nbased on the R version that you have already installed. Usually, for the latest version this should be RTools 4.4, i.e.,\n\nhttps://cran.r-project.org/bin/windows/Rtools/rtools44/rtools.html\n\nFor further detail on Rtools see:\n\nhttps://github.com/stan-dev/rstan/wiki/Configuring-C—Toolchain-for-Windows\n\n\n\nOption 1: Install ‘Rtools’ for Mac OS\nInstall ‘macrtools’ R package. This installer package was developed by James Joseph Balamuta, see details:\n\nhttps://mac.thecoatlessprofessor.com/macrtools/\n\nAccording to their webpage: “This package is designed to recreate the compiled code toolchain used to compile the official macOS R binary on CRAN by following the steps described on the r-project developer page for macOS tools (https://mac.r-project.org/tools/). The package is able to to setup the compilation toolchain on any Mac that meets the standards required to install the official CRAN R binary on macOS.”\nYou can install the development version of macrtools from GitHub using R console or using “Tools” menu.\nFirst install ‘remotes’ package (if not already installed)\n\n\nCode\ninstall.packages(\"remotes\")\n\n\nThen install ‘macrtools’ packages:\n\n\nCode\nremotes::install_github(\"coatless-mac/macrtools\")\n\n\nThen using ‘macrtools’ package install rtools as:\n\n\nCode\nmacrtools::macos_rtools_install()\n\n\nThis will install: (1) Xcode CLI (2) gfortran, and (3) R Development binaries from the Recipes project.\nFor further detail on installation see:\n\n\n\n\nOption 2: Install Compiler for Mac OS\nFirst, if you have the files ~/.R/Makevars and/or ~/.Renviron, save a copy in a different location (like your desktop) and delete them.\nIf you don’t know what these files are or if you have them, go to Finder &gt; Go &gt; Home, which takes you to your home directory, and press SHIFT + CMD + . to show hidden files (i.e. files starting with a full stop .) if you can’t see them already. Now search among the hidden files and if you see a folder named .R/ and/or a file .Renviron, copy them to your desktop and delete the original copies from your home directory.\nTo install the Xcode Command Line Tools, run the following in the Terminal (open Finder &gt; Applications &gt; Terminal, type in the following command and press ENTER):\n\nxcode-select –install\n\nmacOS will download and install the Xcode CLT (it will take a while, make sure you have a stable internet connection).\nIf your Mac has an Intel chip, you need to install gfortran v8.2 (for Mojave) independent of your macOS version. You can download the installer from\n\nhttps://github.com/fxcoudert/gfortran-for-macOS/releases/tag/8.2\n\nIf your Mac has an Apple M1 chip, you will need to install gfortran v11. You can download it from here:\n\nhttps://github.com/fxcoudert/gfortran-for-macOS/releases/tag/11-arm-alpha2\n\ndownload the .pkg package listed under Assets at the bottom of the page.",
    "crumbs": [
      "**R and RStudio**"
    ]
  },
  {
    "objectID": "installation_guide.html#install-rstan-and-brms-packages",
    "href": "installation_guide.html#install-rstan-and-brms-packages",
    "title": "R and RStudio",
    "section": "Install ‘rstan’ and ‘brms’ packages",
    "text": "Install ‘rstan’ and ‘brms’ packages\n‘rstan’ package\n– After installing Rtools (Windows and/or Mac OS), open RStudio and using R console or using “Tools” menu install ‘rstan’ package.\n\n\nCode\ninstall.packages(\"rstan\", dependencies = TRUE)\n\n\nFor detail on ‘rstan’ installation:\n\nhttps://github.com/stan-dev/rstan/wiki/RStan-Getting-Started\n\nNow, verify the installation by running:\n\n\nCode\nexample(stan_model, package = \"rstan\", run.dontrun = TRUE)\n\n\nin your R console.\n‘brms’ package\n– Then install ‘brms’ package:\n\n\nCode\ninstall.packages(\"brms\")\n\n\nGreat! Now you are ready to use Stan!",
    "crumbs": [
      "**R and RStudio**"
    ]
  },
  {
    "objectID": "brief_module_01.html",
    "href": "brief_module_01.html",
    "title": "Module 1: Bayesian Dreams",
    "section": "",
    "text": "In this module, we will learn the key principles and tools of Bayesian reasoning, a powerful framework for thinking about uncertainty, updating beliefs, and drawing inferences from data.\nWe begin by exploring Bayesian philosophy, which offers a fundamentally different view of probability compared to classical statistics. Rather than interpreting probability as the long-run frequency of events, we’ll learn to view it as a measure of belief, a way to quantify uncertainty based on both prior knowledge and observed data. This shift in perspective lays the foundation for all that follows.\nTo structure our reasoning, we introduce a logical framework — a kind of conceptual maze that guides our decision-making under uncertainty. Bayesian methods help us navigate this maze, using clear, consistent rules that allow us to revise our understanding as we encounter new situations and data.\nWe will then compare the concepts of classical and Bayesian approaches to statistical thinking. While classical methods treat parameters as fixed and unknown, we will learn how Bayesian methods treat parameters as uncertain, described by probability distributions. This distinction allows us to build more flexible and realistic models that better reflect the complexity of real-world problems.\nAt the heart of our learning is Bayes’ Theorem — the mathematical engine of Bayesian analysis. We’ll see how it allows us to update our beliefs in light of new evidence, producing what’s known as the posterior distribution. This process represents learning in action: our initial assumptions, or priors, are revised using the data, leading to updated beliefs.\nWith Bayes’ Theorem in hand, we’ll learn Bayesian inference, where we draw conclusions from data by interpreting full probability distributions instead of relying on single-point estimates. This approach gives us a deeper understanding of uncertainty in our conclusions.\nWe will also explore Bayesian odds as a way to compare competing hypotheses or models. By examining the ratio of their posterior probabilities, we learn how to judge which explanations are more plausible, based on both prior assumptions and current data. As we grow more familiar with the framework, we’ll begin to use Bayesian language — terms like priors, posteriors, likelihoods, and credible intervals — to articulate our reasoning.\nTo represent the relationships between variables/parameters, we will learn to use directed acyclic graphs, or DAGs. These graphical tools help us visualise assumptions, identify dependencies, and structure our models clearly.\nFinally, we’ll explain Bayesian updating, the idea that beliefs should evolve as new evidence is observed. This dynamic process mirrors how we learn in everyday life, and it ensures that our models remain responsive and reflective of the world around us.\nBy the end of this module, we will have developed a strong foundation in Bayesian thinking — learning the theory and methods, to apply them in real-world contexts where uncertainty and decision-making go hand in hand.",
    "crumbs": [
      "**Module 1: Bayesian Dreams**"
    ]
  },
  {
    "objectID": "M01_1.html",
    "href": "M01_1.html",
    "title": "1  Navigating Evidence",
    "section": "",
    "text": "1.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nIn today’s lecture we will:\n– Understand Bayesian philosophy.\n– Describe the motivation of doing Bayesian analysis.\n– Understand the difference between Bayesian and classical statistical methods.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#learnings",
    "href": "M01_1.html#learnings",
    "title": "1  Navigating Evidence",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#background",
    "href": "M01_1.html#background",
    "title": "1  Navigating Evidence",
    "section": "1.2 Background",
    "text": "1.2 Background\n\n\n\n\n\nThomas Bayes (The IMS Bulletin, 1988, vol-17(3), pp.276-278)\n\n\n\n\nThomas Bayes, who is remembered through the term “Bayesian,” passed away in 1761 without having the chance to formally present or publish his groundbreaking findings. Two years after his death, it was Richard Price who, in 1763, introduced Bayes’ extraordinary work to the Royal Statistical Society. Bayes had been developing a probabilistic framework to tackle inverse problems. Later, Richard Price (1723–1791) and Pierre-Simon Laplace (1749–1827) played crucial roles in advancing and applying this transformative idea to practical real-world scenarios.\nTo fully understand the Bayesian framework, it is essential to become familiar with several key terms commonly used in Bayesian discussions, such as Bayesian inference, prior, posterior, and Bayesian modeling. Throughout this course, we will gradually explore and learn these fundamental concepts.\nBefore that, let’s start understanding the Bayesian philosophy.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayesian-philosophy",
    "href": "M01_1.html#bayesian-philosophy",
    "title": "1  Navigating Evidence",
    "section": "1.3 Bayesian Philosophy",
    "text": "1.3 Bayesian Philosophy\n\n\nBayesian philosophy revolves around the concept of “degrees of belief” in scientific reasoning. But what does that actually mean? Simply put, it views probability as a measure of our confidence in an event, which updates as we gather new evidence. Unlike traditional frequentist statistics, which treat probability as an objective, fixed value, Bayesian thinking sees it as a dynamic, subjective measure that evolves with new data and insights.\nLet’s explain a bit more using examples:\n\n\n\n\n\nBayesian World (Philosophy)\n\n\n\n\nSuppose a medical practitioner is treating a patient who might have a particular illness, like type-2 diabetes. Initially, based on the patient’s age, family history, and some initial symptoms, the medical practitioner might believe there’s a 20% chance the patient has diabetes. This belief is a prior probability.\nNow, the medical practitioner orders a blood test to check the patient’s blood sugar levels. When the results come back, they show elevated sugar levels, which increase the likelihood of diabetes. The medical practitioner updates their belief based on this new evidence, which is called the posterior probability.\nSo, Bayesian philosophy evolves starting with an initial belief (prior), and then updating that belief as new data (like test results) comes in. In short, it’s a flexible way of thinking where beliefs are adjusted as information is acquired.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze-logical-framework",
    "href": "M01_1.html#the-maze-logical-framework",
    "title": "1  Navigating Evidence",
    "section": "1.4 The Maze: Logical Framework",
    "text": "1.4 The Maze: Logical Framework\n\nBayesian analysis is a logical framework that helps update our beliefs based on continuous new information. A helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works — it continuously updates our understanding as more evidence comes in.\nTo see this in practice, let’s consider an example explained below.\n\n1.4.1 Example:\nA medical practitioner had seen many cases of pneumonia before, but this one was tricky. A 55-year-old patient, had been admitted with high fever, cough, and shortness of breath. Based on his symptoms and an initial chest X-ray, the practitioner diagnosed him with bacterial pneumonia and started him on a standard antibiotic.\nAt this point, their belief was strong that the chosen antibiotic would work—this was their prior probability based on past experience.\nDay 2:\nAfter 24 hours, the patient wasn’t improving. Thier fever remained high, and their breathing was still labored.\nThe practitioner now had new evidence — the treatment wasn’t working as quickly as it should. Applying Bayesian reasoning, they adjusted their belief:\n\nThe probability that this was a typical bacterial pneumonia responding to first-line antibiotics decreased.\n\nThe probability that it was a resistant strain of bacteria or even a different type of infection increased.\n\nThey needed more information.\nDay 3:\nThe practitioner ordered a sputum culture to check for antibiotic-resistant bacteria. In the meantime, they updated the treatment, switching the patient to a broader-spectrum antibiotic.\n\nIf the new antibiotic worked, it would confirm that the initial one was ineffective, meaning resistant bacteria were likely the cause.\n\nIf the patient still didn’t improve, it could mean this wasn’t bacterial pneumonia at all—it might be a viral infection instead.\n\nAgain, their belief about the cause of the patient’s illness shifted based on new evidence.\nDay 4:\nThe test results came in: The patient’s infection was caused by a drug-resistant strain of bacteria. This confirmed that the initial choice of antibiotics was ineffective.\nWith this new evidence, the practitioner’s belief was now much stronger that the broader-spectrum antibiotic was the right choice.\nThe Lesson of Bayesian Thinking\nThe medical practitioner didn’t just rely on their initial belief. Instead, they continuously updated their understanding as new evidence emerged—just like someone navigating a maze learns from every wrong turn. This process demonstrates how Bayesian reasoning helps in making data-driven, logical decisions—not just by guessing, but by continuously refining our beliefs with new information, ultimately leading to the best possible decision.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#concepts-classical-vs.-bayesian",
    "href": "M01_1.html#concepts-classical-vs.-bayesian",
    "title": "1  Navigating Evidence",
    "section": "1.5 Concepts: Classical vs. Bayesian",
    "text": "1.5 Concepts: Classical vs. Bayesian\n\n\nThroughout this course, we will provide relative comparisons of frequentists and Bayesian statistical methods, using examples. Let us now explain some key conceptual aspects of these two approaches.\nHistory:\n\nThe origins of Bayesian statistical inference trace back to the late 18th century, predating many modern methodologies. Its use continued into the 19th century, but after World War I, statisticians like Sir Ronald Fisher, who opposed Bayesian concepts, contributed to its decline. Fisher’s 1925 statistical handbook briefly mentioned Bayesian analysis, then known as “inverse probability”, further pushing it to the margins of mainstream statistics. However, in the latter half of the 20th century, Bayesian methods gradually regained acceptance. This resurgence was particularly driven by advancements in computational technology during the 1990s, which greatly expanded their practical applications.\nData and Parameter:\n\nData represents known elements, whereas parameters are unknown quantities inferred from data. Within the Bayesian framework, this distinction becomes less clear; a variable may be either observed or unobserved, yet it is governed by the same distribution function. Consequently, an assumption can serve as a “likelihood” or a “prior” depending on the context, without altering the model. This connection between certainty (data) and uncertainty (parameters) facilitates the management of measurement errors and missing data in modeling.\nReliable Inference:\n\nThere exists a notion that a specific number of observations is necessary for reliable statistical estimates. For example, at least 30 observations are typically required for a Gaussian distribution. This notion is rooted in traditional statistical inference, where methods are validated for large sample sizes, a concept known as asymptotic behavior.\nConversely, Bayesian estimates remain valid regardless of sample size. While larger samples are advantageous, Bayesian methods provide meaningful results even with limited data. However, they necessitate a careful selection of the “prior,” which significantly influences the final inference. An improperly chosen prior can skew conclusions. Understanding the world demands thoughtful consideration, without resorting to shortcuts.\nRole of Data:\n\nThe distinctions between Bayesian and non-Bayesian methodologies are notable, yet these differences can sometimes overshadow their underlying commonalities. In many Bayesian and non-Bayesian models, the most critical assumptions typically concern the likelihood functions and their connections with the parameters. These assumptions guide the inferences drawn from each dataset. As the sample size grows, the significance of the likelihood increases. This shared emphasis on likelihood clarifies why Bayesian and non-Bayesian inferences frequently yield similar results.\nFurthermore, a common misunderstanding regarding Bayesian data analysis and inference is the belief that they are exclusively defined by Bayes’ theorem. Any inferential method employing probability theory incorporates Bayes’ theorem. Numerous examples labeled as “Bayesian” often lack distinctive attributes and instead rely on observed data frequencies, resembling non-Bayesian methods. The distinctiveness of Bayesian techniques lies in their application of Bayes’ theorem to measure the uncertainty associated with theoretical constructs not directly observable, such as parameters and models. Both methodologies can produce robust inferences, although they are grounded in different principles and entail unique trade-offs.\n\n\n\n1.5.1 Example:\nTo demonstrate where the Bayesian method is clearly more advantageous than the Frequentist method, let’s consider a scenario with limited data. The Bayesian approach can make use of prior knowledge, whereas the frequentist method relies purely on the data at hand. In situations with small sample sizes or limited data, the Bayesian method can give more insightful results.\nImagine a scenario where we have a small sample size from a clinical trial and we want to test whether a drug is effective in treating a rare disease. We have only 5 patients, and the treatment shows that 3 out of 5 patients recovered. For the control group 1 out of 5 patients recovered. The issue here is that the data is very sparse, so relying on a frequentist approach may lead to an unreliable conclusion because of the small sample size. The p-value might not be informative because small sample sizes lead to high variability. Whereas, Bayesian approach combines the sparse data with prior knowledge, offering more stable and informed results (even we use a non-informative prior, which we will discuss more later in this course).\nFor frequentist, the proportion test will provide a p-value indicating if the recovery rates are significantly different between the two groups. For this example, we get p-value =0.52. Whereas, the Bayesian approach will provide the posterior distributions for the treatment and placebo recovery rates. Additionally, you will get the probability that the treatment recovery rate is higher than the placebo recovery rate as 0.882 based on the posterior samples.\nNow, if we know control group has about 70% recovery rate, and considering this prior information in Bayesian setting, we get that the orobability of treatment recovery rate greater than the control rate is 0.58.\n\n\n\n\n\nUniform Prior\n\n\n\n\n\n\n\n\n\nInformed Prior\n\n\n\n\nIn brief, Bayesian Method can incorporate prior knowledge (such as known rates from similar treatments of the diseases), improving estimates even with small sample sizes. Instead of a single p-value, Bayesian analysis gives a full posterior distribution, providing a richer interpretation of the uncertainty in the treatment’s effectiveness. Finally, Bayesian approach is less affected by small sample sizes, as it uses prior distributions and provides more stable estimates.\nWe will discuss more on the distributional aspect in our next lecture. Before that we explain the Bayesian theorem using probabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#dual-factor-probabilities",
    "href": "M01_1.html#dual-factor-probabilities",
    "title": "1  Navigating Evidence",
    "section": "1.6 Dual-Factor Probabilities",
    "text": "1.6 Dual-Factor Probabilities\n\nKruschke (2014)\nBayesians do not imagine repetitions of an experiment in order to define and specify a probability. Probability is merely taken as a measure of certainty in a particular belief. This implies that the probability is used as a way to quantify how certain we are about a belief or an event happening. Before diving into Bayes’ theorem, let’s first understand some key concepts in probability distributions, which I assume you have already learned in the PSI unit.\nThere are many situations in which we are interested in the conjunction of two outcomes. As a specific example for developing these ideas, consider a situation where the probabilities of various combinations of people’s eye color and hair color. The data come from a particular convenience sample (Snee, 1974), and are not meant to be representative of any larger population.\n\n\n\n\n\nDual-Factor (Snee, 1974); Kruschke (2014)\n\n\n\n\nThe above Table considers four possible eye colors, listed in its rows, and four possible hair colors, listed across its columns. In each of its main cells, the table indicates the joint probability of particular combinations of eye color and hair color. For example, the top-left cell indicates that the joint probability of brown eyes and black hair is 0.11 (i.e., 11%). Notice that not all combinations of eye color and hair color are equally likely. For example, the joint probability of blue eyes and black hair is only 0.03 (i.e., 3%).\nWe may be interested in the probabilities of the eye colors overall, collapsed across hair colors. These probabilities are indicated in the right margin of the table, and they are therefore called marginal probabilities. They are computed simply by summing the joint probabilities in each row, to produce the row sums. For example, the marginal probability of green eyes, irrespective of hair color, is 0.11. The joint values indicated in the table do not all sum exactly to the displayed marginal values because of rounding error from the original data.\nWe often want to know the probability of one outcome, given that we know another outcome is true. For example, suppose I sample a person at random from the population. Suppose I tell you that this person has blue eyes. Conditional on that information, what is the probability that the person has blond hair (or any other particular hair color)? It is intuitively clear how to compute the answer: We see from the blue-eye row of the above Table that the total (i.e., marginal) amount of blue-eyed people is 0.36, and that 0.16 of the population has blue eyes and blond hair. Therefore, of the 0.36 with blue eyes, the fraction 0.16/0.36 has blond hair. In other words, of the blue-eyed people, 45% have blond hair.We also note that of the blue-eyed people, 0.03/0.36 = 8% have black hair.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#bayes-theorem",
    "href": "M01_1.html#bayes-theorem",
    "title": "1  Navigating Evidence",
    "section": "1.7 Bayes’ Theorem",
    "text": "1.7 Bayes’ Theorem\n\n\nLet’s now go back to the example related to type-2 diabetes, where, a medical practitioner hypothise based on patient’s background history that the patient has a chance of having diabetes.\nThus, we have two events:\n\nThe hypothesis that medical practitioner’s guess is correct \\((G=[+])\\).\nThe evidence: Blood test showing elevated sugar levels \\((E=[+])\\).\n\nNow, given this experimental evidence of elevated blood sugar, how sure are the medical practitioner that their guess about the diabetes is accurate?\n\\[\nPr(\\text{Guess is correct} | \\text{Positive evidence}) = \\text{ ?}\n\\]\nHence, using conditional probability expression we write:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]},\\text{E=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(\\text{G=[+]},\\text{E=[+]})\\) is the joint probabiity that both \\((G=[+])\\) and \\((E=[+])\\) occur. We can rearrange and write the joint probability as:\n\\[\nPr(\\text{G=[+]},\\text{E=[+]}) = Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})\n\\]\nHence, by substituting the joint probability the Bayes theorem states:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(E=[+])}\n\\]\nwhere, \\(Pr(E=[+])\\) is the marginal probability for the blood test showing high suger levels for all possible hypotheses, here, the possible hypotheses are: \\(G=[+]\\) and \\(G=[-]\\). Hence, we write \\(Pr(\\text{G=[+]}|\\text{E=[+]})\\) as:\n\\[\n\\frac{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{G=[+]})\\times Pr(\\text{E=[+]}|\\text{G=[+]})+Pr(\\text{G=[-]})\\times Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(Pr(\\text{G=[+]})\\) and \\(Pr(\\text{G=[-]})\\) are the probabilities of the medical practitioner’s guess is correct and incorrect respectively, thus we write \\(Pr(\\text{G=[-]}) = 1-Pr(\\text{G=[+]})\\) or vise versa.\nWe clearly see that the degree of belief probability after including the evidence is equal to the probability of guess before incorporating the evidence and probability of the evidence with the medical practitioner’s guess.\n\n1.7.1 Example\nTo explain the above example we write, \\(Pr(\\text{G=[+]})=0.2\\), as the medical practitioner guessed that there is a 20% chance the patient has diabetes. The complement, the probability that the patient does not have diabetes, is \\(Pr(\\text{G=[-]})=0.8\\).\nNow, let us define the test’s accuracy:\n\nSensitivity (True Positive Rate or Hit Rate): \\(Pr(\\text{E=[+]}|\\text{G=[+]})=0.85\\), i.e., 85% of diabetics test positive.\nSpecificity (True Negative Rate): \\(Pr(\\text{E=[-]}|\\text{G=[-]})=0.90\\), i.e., 90% of non-diabetics test negative.\nFalse Positive Rate (False Alarm): \\(Pr(\\text{E=[+]}|\\text{G=[-]})=1-Pr(\\text{E=[-]}|\\text{G=[-]})=1-0.9=0.10\\), i.e., 10% of non-diabetics test positive.\n\nThe question is: Given that the test result is positive, how sure is the medical practitioner that the patient truly has diabetes?\nThis is expressed as the posterior probability , which we compute using Bayes’ theorem:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{(0.2\\times 0.85)}{(0.2\\times 0.85) + (0.8\\times 0.1)} = 0.68\n\\]\nAfter observing a positive blood sugar test, the probability that the patient has diabetes increases from 20% to 68%. This means the medical practitioner is now 68% confident in their updated belief that the patient has diabetes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#summary",
    "href": "M01_1.html#summary",
    "title": "1  Navigating Evidence",
    "section": "1.8 Summary",
    "text": "1.8 Summary\nThe key concept of this week’s lecture is that Bayesian ways of thinking are inherently more suited to solving real-life problems compared to frequentist/classical approaches, as they allow for the inclusion of prior information in decision-making, providing a clear advantage in calculating inverse probability.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#live-tutorial-and-discussion",
    "href": "M01_1.html#live-tutorial-and-discussion",
    "title": "1  Navigating Evidence",
    "section": "1.9 Live tutorial and discussion",
    "text": "1.9 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#tutorial-exercises",
    "href": "M01_1.html#tutorial-exercises",
    "title": "1  Navigating Evidence",
    "section": "1.10 Tutorial Exercises",
    "text": "1.10 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_1.html#preparation-for-week-2",
    "href": "M01_1.html#preparation-for-week-2",
    "title": "1  Navigating Evidence",
    "section": "1.11 Preparation for Week 2",
    "text": "1.11 Preparation for Week 2\nIn week 2, we will start exploring Bayesian dreams and learn the fundamental concepts related to Bayesian inference and models.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M01_2.html",
    "href": "M01_2.html",
    "title": "2  Bayesian Inference",
    "section": "",
    "text": "2.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Describe Bayesian inference using probability distributions.\n– Understand Bayesian learning.\n– Draw DAG for Bayesian models.\n– Formulate examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#learnings",
    "href": "M01_2.html#learnings",
    "title": "2  Bayesian Inference",
    "section": "",
    "text": "Outcomes\n\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#inference",
    "href": "M01_2.html#inference",
    "title": "2  Bayesian Inference",
    "section": "2.2 Inference",
    "text": "2.2 Inference\n\n\n\nBayesian inference is a method of statistical inference that updates the probability of a hypothesis \\((H)\\) as more evidence or data \\((D)\\) becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote \\(Pr(H)\\) as the probability of initial belief about \\(H\\) before seeing data, we can write the updated belief about \\(H\\) given the data \\(D\\) as:\n\\[\nPr(H|D) = \\frac{Pr(D|H)\\times Pr(H)}{Pr(D)}\n\\]\nwhere, \\(Pr(D)\\) is the probability of the data under all possible hypotheses.\nIn today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-models",
    "href": "M01_2.html#bayesian-models",
    "title": "2  Bayesian Inference",
    "section": "2.3 Bayesian Models",
    "text": "2.3 Bayesian Models\n\nWe have explained Bayes’ rule in our previous lecture, now we will see how Bayes rule can be structured for model development using parameter and data. In a Bayesian model, a parameter is a quantity that we assume is uncertain and assign a probability distribution to it. Unlike in frequentist statistics, where parameters are fixed but unknown, Bayesian statistics treats parameters as random variables with their own probability distributions.\nLet us denote \\(\\theta\\) as the parameter and \\(D\\) as data. Hence, we write a model using the data likelihood \\(p(D|\\theta)\\), and prior distribution \\(p(\\theta)\\) of the model parameter \\(\\theta\\) (note that we have changed the notation from \\(Pr(.)\\) to \\(p(.)\\), where \\(Pr(.)\\) refers to probability and \\(p(.)\\) refers to probability distribution):\n\\[\np(D|\\theta) \\times p(\\theta)\n\\]\nHence, Bayes rule can be used to understand the parameter values, given the data,, i.e.,\n\\[\np(\\theta|D)\n\\]\nThus, using the Dual-Factor table explained in previous lecture, we can write\n\n\n\n\n\nData-Parameter; Kruschke (2014)\n\n\n\n\nWhere, each cell of the table holds the joint probability density of the specific combination of parameter value \\(\\theta\\) and data value \\(D\\), denoted \\(p(D, \\theta)\\), and which we know can be algebraically re-expressed as \\(p(D|\\theta)\\times p(\\theta)\\).\nThus, we write the Bayes rule for data and parameter model as:\n\\[\np(\\theta|D) = \\frac{p(D|\\theta)\\times p(\\theta)}{p(D)};\n\\]\nwhere,\n\\[\\begin{align}\np(D) &= \\sum_{\\theta^*} p(D|\\theta^*) p(\\theta^*); \\quad \\text{ if discrete}; \\\\\np(D) &= \\int p(D|\\theta^*) p(\\theta^*) \\text{d}\\theta^*; \\quad \\text{ if continuous};\n\\end{align}\\]\nHere, \\(p(\\theta)\\) is the prior information about \\(\\theta\\) without observing data; \\(p(D|\\theta)\\) is the likelihood, i.e., data could be generated with model parameter \\(\\theta\\); and \\(p(D)\\) is the marginal likelihood obtained from data by averaging across all possible parameters.\nThe posterior distribution of \\(\\theta\\) is:\n\\[\np(\\theta|D) = \\text{ Credibility of }\\theta\\text{ based on data and evidence}\n\\]\nThe posterior probability distribution \\(p(\\theta|D)\\) is the main goal of Bayesian inference. The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value, and this can be obtained by collecting more data.\nWe will now explore with examples on obtaining posterior distributions of the model parameter \\(\\theta\\) for different data distributions (i.e., models), e.g., binomial, normal and poisson distributions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#model-with-binary-variable",
    "href": "M01_2.html#model-with-binary-variable",
    "title": "2  Bayesian Inference",
    "section": "2.4 Model with Binary Variable",
    "text": "2.4 Model with Binary Variable\n\nSuppose we have a binary observation i.e., can take values either 0 or 1, which follows Bernoulli distribution with parameter \\(\\theta\\). We already know that for \\(n&gt;1\\) number of trials the Bernoulli distribution yields a Binomial distribution. Considering \\(Y\\) as the random variable of number of successes in \\(n\\) trials for the Binomial distribution, we can write:\n\\[\np(Y=y|\\theta) = \\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\n\\]\nThis also represents the likelihood of a Bernoulli variable.\nNow, if we consider a Beta prior distribution for \\(\\theta\\) with hyper-parameters \\(a\\) and \\(b\\) (i.e., shape parameters of Beta distribution), then we can write the probability density function of the prior distribution as:\n\\[\np(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a,b)}\n\\]\nwhere, \\(B(a,b)=\\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\) is the beta function. Thus, using Bayes theorem we write\n\\[\np(\\theta|y) = \\frac{\\begin{pmatrix}n\\\\y \\end{pmatrix} \\theta^y (1-\\theta)^{n-y}\\times \\theta^{a-1}(1-\\theta)^{b-1}}{p(y)\\times B(a,b)}\n\\]\nWith some simple calculations, we can write the marginal likelihood as:\n\\[\np(y) = \\begin{pmatrix}n\\\\y \\end{pmatrix}\\frac{B(y+a,n-y+b)}{B(a,b)}\n\\]\nHence, we get the analytical form of the posterior distribution of \\(\\theta\\) as:\n\\[\np(\\theta|y) = \\frac{\\theta^{y+a-1}(1-\\theta)^{n-y+b-1}}{B(y+a,n-y+b)}\n\\]\nwhich follows a Beta distribution with parameters \\((a+y)\\) and \\((b+n-y)\\).\nExample:\nLet us explain this with the type-2 diabetes example we discussed earlier. Now, the medical practitioner is trying to estimate the probability that a patient has type-2 diabetes \\(\\theta\\) based on both prior knowledge and a new diagnostic test result.\nBefore any test, the medical practitioner relies on existing medical data. Suppose past research suggests that for a certain risk group the probability of having type-2 diabetes is 0.5. We represent this belief using a \\(Beta(a=2,b=2)\\). This prior suggests that while any probability is possible, \\(\\theta\\) is likely to be around 0.5, with room for updating.\nNow, we assume the test result corresponds to 7 positive cases out of 10 tests, meaning, \\(n=10\\) and \\(y=7\\).\nHence, we get the posterior distribution of medical practitioner’s new belief about the probability of the patient having the disease as: \\(Beta(2+7,2+3)=Beta(9,5)\\).\nWe can see from the density plots, the posterior shifts toward higher probabilities of type-2 diabetes, meaning the medical practitioner is now more confident that the patient may have type-2 diabetes.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2   \nb_prior &lt;- 2   \nn &lt;- 10        \ny &lt;- 7         \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\ntheta &lt;- seq(0, 1, length.out = 100)\nprior_density &lt;- dbeta(theta, a_prior, b_prior)\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\nposterior_density &lt;- dbeta(theta, a_post, b_post)\ndata &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(prior_density, likelihood, posterior_density),\n  Distribution = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\nggplot(data, aes(x = theta, y = density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(title = \"Prior, Likelihood, and Posterior Distributions\",\n       x = expression(theta),\n       y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-odds",
    "href": "M01_2.html#bayesian-odds",
    "title": "2  Bayesian Inference",
    "section": "2.5 Bayesian Odds",
    "text": "2.5 Bayesian Odds\n\n\nWe can also think of the Bayesian approach in terms of odds, such as what odds should I assign to an event or hypothesis. The simple definition of odds can be written as:\n\\[\n\\text{Odds of an event} = \\frac{Pr(\\text{event})}{1-Pr(\\text{event})}\n\\] which represents the ratio between the occurrence of an event and its non-occurrence.\nLet’s revisit the medical practitioner example from our first lecture to clarify this concept. Imagine the practitioner assessing a patient for diabetes. Initially, they have a prior belief about the patient’s likelihood of having the condition. After conducting a blood test that reveals elevated sugar levels, this new evidence increases the probability of diabetes. The practitioner then updates their belief accordingly, refining their assessment based on the test results. We wanted to know, given this experimental evidence, how sure are the medical practitioner that their guess about the diabetes is accurate?\nThus, to reflect the medical practitioner example by Bayesian odds, we write:\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = \\text{Odds}(\\text{G}) \\times \\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\n\\]\nwhere, \\(\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})\\) is the odds of the guess is correct given the evidence, and \\(\\text{Odds}(\\text{G})\\) is the odds of the guess that we define:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{Pr(\\text{G=[+]})}{Pr(\\text{G=[-]})}\n\\]\nand \\(\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})}\\) is the ratio of evidence under the guess \\(\\text{G}\\).\nThis reflects\n\\[\n\\text{posterior or updated odds} = \\text{prior or initial odds}\\times \\text{relative explanatory power}\n\\]\nThis explains that evidence (i.e., data/information) always changes the outcome, which could be probability, probability distributions or odds or any other outcome of interest.\nExample\nLet us explain this again with the type-2 diabetes example, where based on the patient’s age, family history, and some initial symptoms, the medical practitioner guessed that there’s a 20% chance the patient has diabetes. This belief is a prior probability. The odds from of this probability is:\n\\[\n\\text{Odds}(\\text{G}) = \\frac{0.2}{0.8} = 0.25\n\\]\nSo, the prior odds of the patient having diabetes are 1:4 (one in four) guessed by the medical practitioner.\nThe blood test result shows elevated sugar levels. To assess how much this result affects our belief, we use the ratio of evidence under the guess \\(\\text{G}\\) (also known as the likelihood ratio).\nSuppose the medical practitioner has historically observed from boold test that 85% of diabetic patients have elevated sugar levels, while only 10% of non-diabetic patients do (e.g., due to other factors). Hence, we write\n\\[\n\\frac{Pr(\\text{E=[+]}|\\text{G=[+]})}{Pr(\\text{E=[+]}|\\text{G=[-]})} = \\frac{0.85}{0.10} = 8.5\n\\]\nThis means the test result (elevated sugar) is 8.5 times more likely in someone with diabetes than in someone without it.\nNow, the posterior odds\n\\[\n\\text{Odds}(\\text{G=[+]}|\\text{E=[+]}) = 0.25 \\times 8.5 = 2.125\n\\]\nSo, the updated odds is 2.125:1, i.e., the patient is 2.125 times more likely to have diabetes than non-diabetic individuals after considering the test result.\nUsing the well known relationship between odds and probability, we can also get back the posterior probability from the posterior odds as:\n\\[\nPr(\\text{G=[+]}|\\text{E=[+]}) = \\frac{\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})}{1+\\text{Odds}(\\text{G=[+]}|\\text{E=[+]})} = \\frac{2.125}{1+2.125} = 0.68\n\\]\nIn summary we write, before the test, the medical practitioner believed there was a 20% chance of diabetes. After seeing the elevated blood sugar result, the probability increased to 68% (compare the example in lecture 1), because the test result is 8.5 times more likely in diabetic than non-diabetic individuals. The practitioner may now recommend further tests (e.g., an HbA1c test) before confirming the diagnosis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-language",
    "href": "M01_2.html#bayesian-language",
    "title": "2  Bayesian Inference",
    "section": "2.6 Bayesian Language",
    "text": "2.6 Bayesian Language\n\n\n\nWe will learn a common language for illustrating and denoting the Bayesian models. This will help us to develop and write complex Bayesian models in a simpler way that we will learn later in this course.\nLet’s explain this using a Bernoulli model with parameter \\(\\theta\\). Let \\(x\\) be the random variable that follows Bernoulli distribution. If we have \\(n\\) number of independent observations \\((x_1,\\ldots,x_n)'\\), then denoting \\(y=\\sum_i^n x_i\\) we write the likelihood function as:\n\\[\n\\prod_i^n \\theta^{x_i} (1-\\theta)^{1-x_i} = \\theta^{\\sum_i^n x_i} (1-\\theta)^{\\sum_i^n (1-x_i)} = \\theta^y (1-\\theta)^{n-y}\n\\]\nwhich we can write in the form of a Binomial distribution:\n\\[\np(y|\\theta) \\propto   \\theta^y (1-\\theta)^{n-y}\n\\]\nNote that we replaced “=” with “\\(\\propto\\)” as the term \\(\\begin{pmatrix}n\\\\y \\end{pmatrix}\\) is a constant, which does not depend on the parameter \\(\\theta\\). Now, considering prior conjugacy, we assume that \\(\\theta\\) follows a Beta distribution with shape parameters \\(a\\) and \\(b\\) and we write \\(\\theta \\sim \\text{Beta}(a,b)\\) and define\n\\[\np(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\n\\]\nThus, the posterior distribution of \\(\\theta\\) can be written as \\(\\theta|y \\sim \\text{Beta}(a+y,b+n-y)\\) and defined as:\n\\[\np(\\theta|y) \\propto \\theta^y (1-\\theta)^{n-y}\\theta^{a-1}(1-\\theta)^{b-1}\n\\]\n\\[\np(\\theta|y) \\propto \\theta^{y+a-1} (1-\\theta)^{n-y+b-1}\n\\]\nWe have again included the “\\(\\propto\\)” term, as we will learn in our next two lectures that the marginal distribution of the data, i.e., \\(p(y)\\) does not depend on the model parameter and can therefore be omitted when obtaining the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#directed-acyclic-graph-dag",
    "href": "M01_2.html#directed-acyclic-graph-dag",
    "title": "2  Bayesian Inference",
    "section": "2.7 Directed Acyclic Graph (DAG)",
    "text": "2.7 Directed Acyclic Graph (DAG)\n\nThe directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.\nBayesian models\nIn the context of Bayesian modelling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.\nUsing the model with binary observations, we write a DAG as:\n\n\n\n\n\n\nThis is a simple graphical model, where \\(y\\) depends on \\(\\theta\\), with \\(\\theta\\) being a logical function of hyper-parameters \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#more-examples",
    "href": "M01_2.html#more-examples",
    "title": "2  Bayesian Inference",
    "section": "2.8 More Examples",
    "text": "2.8 More Examples\n\n2.8.1 Decision Making\n\nHere, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.\nLet us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.\nYou are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.\nHence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.\nThe cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.\nSuppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.\nFequentists Method\nBased on the scenario we write the null \\((H_0)\\) and alternative \\((H_1)\\) hypotheses as:\n\\(H_0\\): \\(10\\)% prevalence \\(H_1\\): \\(&gt;10\\)% prevalence\np-value based on 5 samples:\n\\[\nPr(y\\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\\approx 0.41\n\\]\nNote that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.\nTherefore, we fail to reject \\(H_0\\) and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.\nBayesian Method\nFrom Bayesian perspective we can write:\n\\(H_0\\): 10% prevalence \\(H_1\\): 20% prevalence\nWe can also assume that priors related to the hypothesis same and equal, i.e, \\(Pr(H_0)=Pr(H_1)=0.5\\).\nConsidering the scenario with 5 samples, we write the likelihood for \\(H_0\\) and \\(H_1\\) as:\n\\[\nPr(y=1|H_0) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.1 \\times 0.9^{4} \\approx 0.33\n\\]\n\\[\nPr(y=1|H_1) = \\begin{pmatrix} 5 \\\\ 1 \\end{pmatrix} \\times 0.2 \\times 0.8^{4} \\approx 0.41\n\\]\nWe get the posterior probability for \\(H_0\\) as:\n\\[\nPr(H_0|y=1) = \\frac{Pr(y=1|H_0)\\times Pr(H_0)}{Pr(y=1)}=\\frac{0.5\\times 0.33}{0.5\\times 0.33+0.5\\times 0.41} \\approx 0.45\n\\]\nand for \\(H_1\\) as:\n\\[\nPr(H_1|y=1) = 1- 0.45 = 0.55\n\\]\nThe posterior probabilities of \\(H_0\\) and \\(H_1\\) are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, \\(H_1\\) has a higher posterior probability than \\(H_0\\), so if we had to make a decision at this point, we should choose \\(H_1\\), meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.\nWe can write this example using a DAG, where we can represent the relationships between the prior probabilities, likelihoods, and posterior probabilities.\nHypothesis (H₀ and H₁): These represent the two possible prevalence values (10% for H₀, 20% for H₁).\nData (y): The observed data (the number of successes in 5 samples, e.g., the presence of disease).\nLikelihoods (Pr(y=1|H₀) and Pr(y=1|H₁)): The likelihood of observing the data under each hypothesis.\nPrior Probabilities (Pr(H₀) and Pr(H₁)): The prior belief about the hypotheses (both have a prior probability of 0.5).\nPosterior Probabilities (Pr(H₀|y=1) and Pr(H₁|y=1)): The updated belief about the hypotheses after observing the data.\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  H0 [label = 'H₀: 10% prevalence', width = 1.5]\n  H1 [label = 'H₁: 20% prevalence', width = 1.5]\n  y [label = 'y: Data (Successes in 5 samples)', width = 1.5]\n  PrH0 [label = 'Pr(H₀) = 0.5', width = 1.5]\n  PrH1 [label = 'Pr(H₁) = 0.5', width = 1.5]\n  LikelihoodH0 [label = 'Pr(y|H₀) ~ 0.33', width = 1.5]\n  LikelihoodH1 [label = 'Pr(y|H₁) ~ 0.41', width = 1.5]\n  PosteriorH0 [label = 'Pr(H₀|y=1) ~ 0.45', width = 1.5]\n  PosteriorH1 [label = 'Pr(H₁|y=1) ~ 0.55', width = 1.5]\n\n  # Define the edges (relationships)\n  PrH0 -&gt; LikelihoodH0\n  PrH1 -&gt; LikelihoodH1\n  H0 -&gt; LikelihoodH0\n  H1 -&gt; LikelihoodH1\n  LikelihoodH0 -&gt; y\n  LikelihoodH1 -&gt; y\n  y -&gt; PosteriorH0\n  y -&gt; PosteriorH1\n}\n\")\ndag\n\n\n\n\n\n\nNow, we can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where\nFrequentist\n\\(H_0\\): 10% prevalence and \\(H_1\\): \\(&gt;10\\)% prevalence\n\\(Pr(y \\text{ or more} \\mid 10\\% \\text{ prevalence})\\) = p-value\nBayesian\n\\(H_0\\): 10% prevalence and \\(H_1\\): 20% prevalence\nPosterior for \\(H_0\\): \\(Pr(10\\% \\text{ prevalence} \\mid n, y)\\)\nPosterior for \\(H_1\\): \\(Pr(20\\% \\text{ prevalence} \\mid n, y)\\)\nAnd the results we get:\n\n\n\nData\np-value\nPosterior\n\n\n\n\n\n\n\\(H_0\\): 10% prevalence\n\\(H_0\\): 10% prevalence\n\\(H_1\\): 20% prevalence\n\n\nn = 5, y = 1\n0.41\n0.45\n0.55\n\n\nn = 10, y = 2\n0.26\n0.39\n0.61\n\n\nn = 15, y = 3\n0.18\n0.34\n0.66\n\n\nn = 20, y = 4\n0.13\n0.29\n0.71\n\n\n\nIn each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.\nHowever, if we had structured the frequentist approach differently, say setting the null hypothesis as \\(H_0\\): 20% prevalence, we would have reached different conclusions.\nThis highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.\n\n\n2.8.2 Comparison of Two Means\nNow, let us explain another example, where we want to find out if a new drug lowers systolic blood pressure (SBP) compared to standard of care (SOC).\nThe study involves two groups of patients: Group A (treatment group), where 10 patients are given the new medication, and Group B (control group), where 10 patients receive the standard of care (SOC), which includes existing medication for SBP.\nAfter a period of four weeks, the SBP of all participants is recorded for analysis.\nNow, we will use both the frequentist and Bayesian approaches to determine whether there are any differences between the treatment and SOC.\nFrequentist\nFrom the frequentist perspective, we wil test:\n\\(H_0\\): There is no difference in mean SBP between the two groups.\n\\(H_1\\): The treatment group has a different mean SBP than the SOC group.\nConsidering equal variance assumption, we use t-test as follows:\n\n\nCode\ngroup_A &lt;- c(120, 118, 122, 115, 119, 117, 121, 116, 118, 119)\ngroup_B &lt;- c(130, 128, 135, 132, 129, 131, 134, 133, 137, 130)\nt.test(group_A, group_B, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  group_A and group_B\nt = -11.834, df = 18, p-value = 6.315e-10\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -15.77898 -11.02102\nsample estimates:\nmean of x mean of y \n    118.5     131.9 \n\n\nWe can see that the p-value is extremely small (much less than 0.05), which means we reject the null hypothesis. Si, there is strong evidence that the new drug significantly reduces systolic blood pressure compared to the placebo.\nBayesian\nNow, we will use Bayesian approach to estimate the posterior probability distribution of the difference in mean systolic blood pressure between the treatment and SOC groups, and extract a 95% credible interval.\nIn most scenarios, we do not have prior information regarding the effectiveness of the new drug. However, sometimes we do have prior knowledge about the effectiveness of the SOC. Let us assume that, from a past study with 15 patients, for the SOC group, after a period of four weeks, the average SBP is around 110 mmHg with a variance of 25. This constitutes our prior knowledge about the control/SOC group.\nNow, using these information we can get the posterior distributions for both groups and then compare their differences. Note that our variable of interest in this example is in continuous scale (SBP measured in mmHg), hence, we will use normal distributions for the SBP.\nHere, we have observe data from 10 individuals for each groups. The posterior mean and variance calculation involves combining prior and observed data for the SOC (control) group, i.e., Group B. Whereas, for the treatment group we do not have any prior knowledge, i.e., the posterior for this group will reflect the observed data. Then we calculate the posterior mean and variance for the difference in means and extract the 95% credible interval for the difference.\nWe can write this mathematically as follows:\n\n\\(\\mu_A\\): True mean SBP of treatment group\n\\(\\mu_B\\): True mean SBP of SOC group\n\\(\\delta = \\mu_A - \\mu_B\\): Difference in means, this is our parameter of interest\n\nFor observed data, Groups A (treatment) and B (SOC) with observed sample sizes \\(n_A = n_B = 10\\), we get observed means \\(\\bar{x}_A\\), \\(\\bar{x}_B\\), and variances \\(s_A^2\\), \\(s_B^2\\).\nWe will model SBP as Normally distributed:\n\n\\(X_A \\sim N(\\mu_A, \\sigma^2_A)\\)\n\\(X_B \\sim N(\\mu_B, \\sigma^2_B)\\)\n\nNow, prior information on Group B, that we get from a previous study, where \\(\\mu_{B,0} = 110\\), and prior variance \\(\\sigma^2_{B,0} = 25\\) from sample size \\(n_{B,0} = 15\\).\nFor the treatment group (i.e., A), we get the posterior distribution as:\n\\[\n\\mu_A \\mid \\text{data} \\sim N\\left( \\bar{x}_A, \\frac{s_A^2}{n_A} \\right)\n\\]\nNow, for the SOC group (i.e., B) we write the prior\n\\[\n\\mu_B \\sim N\\left( \\mu_{B,0}, \\frac{\\sigma_{B,0}^2}{n_{B,0}} \\right)\n\\]\nHence, with observed data \\(\\bar{x}_B\\) from \\(n_B = 10\\) samples, the posterior becomes:\n\\[\n\\mu_B \\mid \\text{data} \\sim N\\left( \\mu_{B,\\text{post}}, \\sigma^2_{B,\\text{post}} \\right)\n\\]\nWhere with simple calculation we write:\n\\[\n\\mu_{B,\\text{post}} = \\frac{ \\frac{n_{B,0}}{\\sigma^2_{B,0}} \\mu_{B,0} + \\frac{n_B}{s_B^2} \\bar{x}_B }{ \\frac{n_{B,0}}{\\sigma^2_{B,0}} + \\frac{n_B}{s_B^2} }\n\\]\nand\n\\[\n\\sigma^2_{B,\\text{post}} = \\left( \\frac{n_{B,0}}{\\sigma^2_{B,0}} + \\frac{n_B}{s_B^2} \\right)^{-1}\n\\]\nNow, we get the posterior for difference in means assuming independence between \\(\\mu_A\\) and \\(\\mu_B\\) as:\n\\[\n\\delta = \\mu_A - \\mu_B \\sim N(\\mu_{\\delta}, \\sigma^2_{\\delta})\n\\]\nWhere,\n\\[\n\\mu_{\\delta} = \\mu_{A,\\text{post}} - \\mu_{B,\\text{post}} = \\bar{x}_A - \\mu_{B,\\text{post}}\n\\]\nand\n\\[\n\\sigma^2_{\\delta} = \\sigma^2_{A,\\text{post}} + \\sigma^2_{B,\\text{post}} = \\frac{s_A^2}{n_A} + \\sigma^2_{B,\\text{post}}\n\\]\nFinally, we can calculate the 95% credible interval of \\(\\delta\\) from its posterior distribution.\n\n\nCode\nmu_prior_B &lt;- 110    \nvar_prior_B &lt;- 25    \nn_prior_B &lt;- 15       \nn_B &lt;- length(group_B)\nmean_B &lt;- mean(group_B)\nvar_B &lt;- var(group_B)\nn_A &lt;- length(group_A)\nmean_A &lt;- mean(group_A)\nvar_A &lt;- var(group_A)\nmu_post_B &lt;- (n_B * mean_B + n_prior_B * mu_prior_B) / (n_B + n_prior_B)\nvar_post_B &lt;- var_B / n_B\nmu_post_A &lt;- mean_A\nvar_post_A &lt;- var_A / n_A\nmean_diff &lt;- mu_post_A - mu_post_B\nvar_diff &lt;- var_post_A + var_post_B\nsd_diff &lt;- sqrt(var_diff)\ncredible_interval &lt;- c(mean_diff - 1.96 * sd_diff, mean_diff + 1.96 * sd_diff)\ncat(\"Posterior mean difference in SBP:\", round(mean_diff,2), \"\\n\")\n\n\nPosterior mean difference in SBP: -0.26 \n\n\nCode\ncat(\"95% credible interval for difference in SBP:\", round(credible_interval,2), \"\\n\")\n\n\n95% credible interval for difference in SBP: -2.48 1.96 \n\n\nThe results shows, on average, the treatment group has a slightly lower SBP than the SOC group, just 0.26 mmHg lower, which is a very small difference. We can also see the 95% credible interval spans both negative and positive values, including zero, we can’t say with confidence whether the treatment lowers, increases, or has no effect on SBP.\nThis result from Bayesian analysis again contradicts with the frequentist method due to the consideration of prior information related to the SOC in the analysis.\nWe will explore more about how different prior information might influence our results throughout the course.\nNote that in this example, we incorporate prior information as past data and thus update the posterior, which is in line with the Bayesian philosophy. It is also important to note that we might arrive at the same conclusion using a frequentist method, if we consider these historical data from \\(n_{B,0}\\) samples.\nIn the following section, we discuss more on this type of Bayesian update accordingly.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#bayesian-updating",
    "href": "M01_2.html#bayesian-updating",
    "title": "2  Bayesian Inference",
    "section": "2.9 Bayesian Updating",
    "text": "2.9 Bayesian Updating\n\nSuppose we observe some data \\(D_1\\) and update our posterior belief \\(p(\\theta|D_1)\\) based on prior \\(p(\\theta)\\). Now, if we observe some more data, say \\(D_2\\), then can update our belief from \\(p(\\theta|D_1)\\) to \\(p(\\theta|D_1,D_2)\\). We can explain the Bayesian updating using a step-by-step process.\nFor example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.\n\n\n\n\n\nBayesian Learning, McElreath (2020)\n\n\n\n\nThis figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.\nIn the first plot (n = 1, YES), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (n = 2, NO), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.\nAs more data points are collected (n = 3, YES and n = 4, YES), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By n = 5 (YES), the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in n = 6 (NO), the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.\n\n\nCode\nlibrary(DiagrammeR)\ndag &lt;- grViz(\"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]\n  \n  # Prior node\n  Prior [label = 'Prior p(θ)', width = 1.5]\n  \n  # Data observations\n  D1 [label = 'D₁: Observation (YES)', width = 2]\n  Dots [label = '...', width = 0.5]\n  D6 [label = 'D₆: Observation (NO)', width = 2]\n  \n  # Posterior updates\n  Posterior_D1 [label = 'Posterior p(θ|D₁)', width = 2]\n  Posterior_D6 [label = 'Posterior p(θ|D₁, ..., D₆)', width = 2]\n\n  # Define the edges (relationships)\n  Prior -&gt; D1\n  D1 -&gt; Posterior_D1\n  Posterior_D1 -&gt; Dots\n  Dots -&gt; D6\n  D6 -&gt; Posterior_D6\n\n  # Layout: top to bottom style\n  rankdir = TB\n}\n\")\ndag\n\n\n\n\n\n\nInvariance to data-order\nThis Bayesian learning process for \\(\\theta\\) is very intuitive, where we can write\n\\[\\begin{align}\np(\\theta|D_1,D_2) = \\frac{p(D_1,D_2|\\theta)\\times p(\\theta)}{\\sum_{\\theta^*}p(D_1,D_2|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\] If we consider \\(D_1\\) and \\(D_2\\) are independent, then \\[\\begin{align}\np(D_1,D_2|\\theta)=p(D_1|\\theta)p(D_2|\\theta)\n\\end{align}\\] This leads to a very simple formation of considering \\[\\begin{align}\np(\\theta|D_2,D_1) = \\frac{p(D_2|\\theta)\\times p(\\theta|D_1)}{\\sum_{\\theta^*}p(D_2,D_1|\\theta^*)\\times p(\\theta^*)}\n\\end{align}\\]\nThis implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior. Hence, going back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#summary",
    "href": "M01_2.html#summary",
    "title": "2  Bayesian Inference",
    "section": "2.10 Summary",
    "text": "2.10 Summary\nToday’s lecture explored Bayesian inference, focusing on how to derive it analytically, we also learn Bayesian updating, posterior odds and Directed Acyclic Graphs (DAGs).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#live-tutorial-and-discussion",
    "href": "M01_2.html#live-tutorial-and-discussion",
    "title": "2  Bayesian Inference",
    "section": "2.11 Live tutorial and discussion",
    "text": "2.11 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#tutorial-exercises",
    "href": "M01_2.html#tutorial-exercises",
    "title": "2  Bayesian Inference",
    "section": "2.12 Tutorial Exercises",
    "text": "2.12 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "M01_2.html#preparation-for-week-3",
    "href": "M01_2.html#preparation-for-week-3",
    "title": "2  Bayesian Inference",
    "section": "2.13 Preparation for Week 3",
    "text": "2.13 Preparation for Week 3\nNext week we will start Module 02 of this unit, where our main focus will be to understand different types of prior distributions and how they influence the posteriors.\n\n\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Bayesian Inference**</span>"
    ]
  },
  {
    "objectID": "brief_module_02.html",
    "href": "brief_module_02.html",
    "title": "Module 2: Chaotics",
    "section": "",
    "text": "In this part, we will be strengthening our understanding of Bayesian analysis by exploring how we represent, summarise, and work with probability distributions. We begin by examining what prior and posterior distributions are and how they function in the Bayesian framework.\nNext, we dig deeper into prior distributions. We will learn to distinguish between informative, non-informative, and weakly informative priors. Informative priors reflect strong existing knowledge or expert opinion. Non-informative priors attempt to contribute as little information as possible, and weakly informative priors strike a balance, offering gentle regularisation without overwhelming the data. By understanding these types, we can make principled choices when defining priors in our models.\nWe will learn how to interpret and communicate Bayesian results using posterior summary, i.e., using means, medians, credible intervals, and other descriptive statistics.\nWe will also look at exact inference — the process of analytically computing posterior distributions when mathematical forms are tractable. While exact solutions are ideal, they are not always possible, which is why much of Bayesian analysis relies on computational methods.\nWe then explore generative models — a fundamental concept in Bayesian thinking where we define a complete data-generating process based on assumptions and parameters. These models help us simulate new data and test whether our assumptions are realistic.\nAs we build more complex models, we face the challenge of untraceability, where we can no longer compute posterior distributions analytically. To solve this, we turn to powerful computational methods — in particular, Markov chain Monte Carlo (MCMC) techniques. These methods allow us to approximate posterior distributions through simulation, enabling inference in otherwise intractable models.\nWe will learn about key MCMC algorithms, starting with the Metropolis-Hastings algorithm, which generates samples by proposing changes and accepting them with a probability that ensures proper convergence. We then study Gibbs sampling, a special case that works efficiently when we can sample from conditional distributions directly. Finally, we introduce Hamiltonian Monte Carlo (HMC), an advanced method that uses concepts from physics to sample more efficiently in high-dimensional spaces.\nTo ensure the reliability of our results, we also focus on MCMC diagnostics. We’ll learn to assess whether our MCMC algorithms have converged and whether the samples we’ve drawn are sufficient to represent the true posterior. This step is crucial for validating the quality of our inference.\nLastly, we explore prior and posterior predictive checks. These techniques allow us to test whether our models make reasonable predictions — both before and after observing the data. Predictive checks help us evaluate how well our model fits and whether our assumptions hold in practice.\nBy the end of this section, we will have gained practical and theoretical tools to build, refine, and evaluate Bayesian models using both exact and approximate inference. These skills will prepare us to handle a wide range of problems where uncertainty and complexity demand more than just point estimates.",
    "crumbs": [
      "**Module 2: Chaotics**"
    ]
  },
  {
    "objectID": "M02_1.html",
    "href": "M02_1.html",
    "title": "3  Prior and Posterior",
    "section": "",
    "text": "3.1 Learning\n– L02: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– L04: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.\nBy the end of this week you should be able to:\n– Understand the importance of prior distributions.\n– Calculate posterior using Bayesian exact inference.\n– Distinguish between different types of Prior distributions\n– Formulate examples.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#learning",
    "href": "M02_1.html#learning",
    "title": "3  Prior and Posterior",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-and-posterior-distributions",
    "href": "M02_1.html#prior-and-posterior-distributions",
    "title": "3  Prior and Posterior",
    "section": "3.2 Prior and Posterior Distributions",
    "text": "3.2 Prior and Posterior Distributions\n\n\n\n\nGelman et al. (2013)\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst, let’s look at some real-world examples of how prior distributions play a crucial role, particularly in health and medical data.\nWe already got a flavour that prior distributions allow researchers to incorporate existing knowledge or expert opinions into their statistical models, improving the precision of their conclusions. For example, when designing treatments/interventions, prior knowledge helps tailor them to individual patients, enhancing both personalisation and effectiveness.\nImagine historical data shows that a certain drug has a 70% success rate in patients with similar profiles. By using an informative prior distribution, we can incorporate this insight to estimate the likelihood of success for a new patient. If fresh data suggests an 80% effectiveness rate, Bayesian methods refine this estimate, leading to a more balanced probability—say, around 75%. This synthesis of prior knowledge with new evidence results in more reliable conclusions.\nPrior information is also invaluable when historical data is limited or when researching new treatments. In such cases, a non-informative prior—such as assuming an initial effectiveness probability of 0.5—can be used, gradually updating as more data becomes available.\n\n3.2.1 Posterior Summary\n\nThe posterior distribution is a valid probability distribution obtained through Bayesian inference, representing the updated beliefs about a parameter after incorporating prior knowledge and observed data. While the full posterior distribution provides a comprehensive summary of uncertainty, policymakers often require point estimates to facilitate decision-making. Common Bayesian point estimates include the posterior mean, posterior median, and maximum a posteriori (MAP) estimate. Among these, the posterior mean and median are generally preferred over the MAP estimate because MAP focuses solely on the mode of the posterior density, ignoring the overall distribution’s shape and probability mass. This can lead to misleading inferences, especially when the posterior distribution is skewed or multimodal. Moreover, since MAP is a mode, it may lie far from the regions of high probability mass, making it a less robust estimator compared to the mean or median.\n\n\n\n\n\nPosterior Point Estimates; Lambert (2018)\n\n\n\n\nBeyond point estimates, it is also important to quantify uncertainty, which is where credible intervals come into play. A credible interval provides an interval within which the true parameter value is likely to lie with a specified probability (e.g., 95%). Unlike frequentist confidence intervals, credible intervals have a direct probabilistic interpretation: if a 95% credible interval for a parameter is \\([a, b]\\), we can say there is a 95% probability that the parameter lies within this range, given the observed data and prior information. This makes credible intervals particularly useful for policy decisions, as they provide a natural way to express uncertainty in estimates, allowing decision-makers to weigh risks and benefits accordingly.\nExample\nConsider a policymaker estimating the proportion of a population that supports a new public health initiative. Suppose they collect survey data from 1,000 people, where 600 respondents express support. A Bayesian approach models this as a binomial likelihood with a Beta prior (a common conjugate prior for proportions). If the prior is \\(\\text{Beta}(2,2)\\), which represents a weak prior belief that the proportion is roughly uniform between 0 and 1, the posterior distribution is updated using the observed data:\n\\[\n\\theta | \\text{data} \\sim \\text{Beta}(2 + 600, 2 + 400) = \\text{Beta}(602, 402)\n\\]\nFrom this posterior, the policymaker can derive different point estimates:\n\nPosterior Mean: Given a \\(\\text{Beta}(a, b)\\) distribution, the mean is $ $, which in this case is:\n\n\\[\n\\frac{602}{602 + 402} = 0.60\n\\]\nThis suggests that, on average, the Bayesian model estimates 60% of the population supports the initiative.\n\nPosterior Median: This is the value that splits the posterior probability into two equal halves. For a Beta distribution, the median can be approximated numerically, where we can write the median approximately\n\n\\[\n\\frac{a-1/3}{a+b-2/3} = \\frac{602-1/3}{602+402-2/3} \\approx 0.6\n\\] and in this case, it is close to 0.6.\n\nMaximum a Posteriori (MAP): The MAP estimate is the mode of the Beta distribution, which for \\(\\text{Beta}(\\alpha, \\beta)\\) is:\n\n\\[\n\\frac{a - 1}{a + b - 2} = \\frac{601}{1000} = 0.601\n\\]\nWhile close to the posterior mean, the MAP estimate can be problematic in other cases, particularly with skewed distributions, since it focuses only on the density’s peak rather than the overall probability mass.\n\nCredible Interval: To express uncertainty, the policymaker can compute a 95% credible interval, which provides a range where the true proportion likely falls. For the \\(\\text{Beta}(602, 402)\\) distribution, the central 95% credible interval (obtained numerically) is approximately \\((0.576, 0.623)\\).\n\nThis means that, given the data and prior, there is a 95% probability that the true proportion of public support lies between 57.6% and 62.3%. This interval gives a clearer sense of uncertainty than a single point estimate and helps policymakers make informed decisions while considering potential variations in public opinion.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\na &lt;- 602  \nb &lt;- 402  \n\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nposterior_density &lt;- dbeta(theta_vals, a, b)\n\nposterior_mean &lt;- a / (a + b)\nposterior_median &lt;- qbeta(0.5, a, b)\nposterior_map &lt;- (a - 1) / (a + b - 2)\ncredible_interval &lt;- qbeta(c(0.025, 0.975), a, b)\n\nposterior_df &lt;- data.frame(theta = theta_vals, density = posterior_density)\n\np = ggplot(posterior_df, aes(x = theta, y = density)) +\n  geom_line(color = \"blue\", size = 1) +\n  \n  geom_vline(xintercept = posterior_mean, color = \"red\", linetype = \"dashed\", size = 1) +\n  \n  geom_vline(xintercept = posterior_median, color = \"green\", linetype = \"dotted\", size = 1) +\n  \n  geom_vline(xintercept = posterior_map, color = \"purple\", linetype = \"dotdash\", size = 1) +\n  \n  geom_ribbon(aes(ymin = 0, ymax = density), \n              data = subset(posterior_df, theta &gt;= credible_interval[1] & theta &lt;= credible_interval[2]),\n              fill = \"gray\", alpha = 0.3) +\n  \n  geom_vline(xintercept = credible_interval[1], color = \"gray\", linetype = \"solid\", size = 1) +\n  geom_vline(xintercept = credible_interval[2], color = \"gray\", linetype = \"solid\", size = 1) +\n  \n  labs(title = \"Posterior Distribution of θ\",\n       x = \"θ (Proportion)\",\n       y = \"Density\",\n       caption = \"Red: Mean, Green: Median, Purple: MAP, Gray: 95% Credible Interval\") +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank())\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\n\n\n\n3.2.2 Exact Inference\n\n\nThe exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given prior distribution and data likelihood.\nWe have already seen from the Bernoullie distribution example that, choosing a particular type of prior distribution results in a posterior that belongs to the same distribution family. This property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. In the Bernoulli model example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nBelow we present some common pairs of likelihoods and priors related to conjugacy:\n\n\n\n\n\n\n\n\nLikelihood\nConjugate Prior\nPosterior Distribution\n\n\n\n\n\\(\\text{Bernoulli}(\\theta)\\)\n\\(\\text{Beta}(a, b)\\)\n\\(\\text{Beta}(a + y, b + n-y)\\)\n\n\n\\(\\text{Poisson}(\\lambda)\\)\n\\(\\text{Gamma}(a, b)\\)\n\\(\\text{Gamma}(a + y, b + n)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Known variance)\n\\(\\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\\(\\mathcal{N}(\\mu_n, \\sigma_n^2)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Unknown variance)\nNormal-Gamma \\((\\mu_0, \\lambda_0, \\alpha, \\beta)\\)\nNormal-Gamma \\((\\mu_n, \\lambda_n, \\alpha_n, \\beta_n)\\)\n\n\n\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging, if we want to.\nIn this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in our next lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#more-insights-into-prior-distribution",
    "href": "M02_1.html#more-insights-into-prior-distribution",
    "title": "3  Prior and Posterior",
    "section": "3.3 More Insights into Prior Distribution",
    "text": "3.3 More Insights into Prior Distribution\n\nUnderstanding the appropriate selection of prior distributions in modeling is crucial. Prior distributions can be categorised as informative, non-informative, weakly informative, or based on expert judgment. This section explores into these various types of prior distributions, examining their applicability and relevance.\n\n3.3.1 Informative Prior Distribution\n\n\n\nAn informative prior is a type of prior distribution that is based on information that provides significant idea about the parameters being estimated. Since informative priors reflect more certainty, they tend to be more concentrated around a certain value. The informative prior has a strong influence on the posterior distribution, especially when the data is limited or noisy. In cases with substantial data, the posterior may still be mostly driven by the observed data, but the prior will still play a role in shaping the final outcome.\nTo explain it more, suppose, we want to know the efficacy rate of a certain vaccine in patients with similar profiles. Let’s consider that the efficacy rate of the vaccine range from 70% to 90%, which we know from literature. Now from a pilot study we observe 16 successes out of 20 trials, i.e., the efficacy rate is still 80%. Hence, we can easily get the posterior distribution of the efficacy rate from \\(\\text{Beta}(24, 6)\\) distribution, if we consider the prior average success rate of 80%, which is calculated from the range 70% to 90%. Numerically, we can plot the prior and posterior distributions as:\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 8\nb_prior &lt;- 2\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(8,2)], i.e., 80% vs Posterior Distributions [Beta(24,6)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 9\nb_prior &lt;- 4\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(9,4)], i.e., 70% vs Posterior Distributions [Beta(25,8)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 10\nb_prior &lt;- 1\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(10,1)], i.e., 90% vs Posterior Distributions [Beta(26,5)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nThe informative prior in this example allows you to start with a reasonable expectation (from historical data) and update it with observed results. This is especially useful when the sample size is small or the observed data alone might not be robust enough to guide decision-making.\n\n\n\n3.3.2 Non-informative Prior Distribution\n\n\n\nA non-informative prior (also known as an uninformative prior or objective prior or diffuse prior) is a type of prior distribution used in Bayesian statistics that is intended to have minimal influence on the posterior distribution. It reflects a lack of specific prior knowledge about the parameter of interest, allowing the data to drive the inference as much as possible.\nNon-informative priors are often used when the goal is to let the observed data dominate the analysis. These are useful in cases where objectivity is critical or where prior knowledge is genuinely unavailable, but they may not always be appropriate when prior information exists.\nNon-informative priors often reflect a high degree of uncertainty about the parameter’s value, and might end up with parameter estimates similar to the estimates obtained from frequentist approach.\nBefore going into details, let’s explain some prior distribution concepts:\nImproper Priors: Prior distributions that do not integrate to 1 and therefore are not valid probability distributions but can still be useful for inference if they lead to proper posterior distributions. For instance, \\(p(\\theta) \\propto 1/\\theta\\) for scale parameters.\nFlat Priors: Priors that are constant over the range of the parameter (often used for parameters with bounded support).\nNow, we will discuss some common approaches to defining non-informative priors:\n\nUniform Priors:\n\nUniform priors assign equal probability across all possible values of a parameter, assuming no preference for any particular value (e.g., \\(p(\\theta) \\propto 1\\), where for a probability parameter \\(\\theta\\) in a Bernoulli model, a uniform prior on \\(\\text{Unif}[0, 1]\\) implies no prior belief about the likelihood of success. From the plot below we cannot visualize the likelihood function (scaled), as the posterior distribution and likelihood functions are same.\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100       \ntrue_theta &lt;- 0.8  \ndata &lt;- rbinom(n, size = 1, prob = true_theta)  \nsuccesses &lt;- sum(data)  \nfailures &lt;- n - successes\n# Uniform prior: P(theta) ∝ 1 on [0, 1]\n# The uniform prior is equivalent to Beta(1, 1).\na_prior &lt;- 1  \nb_prior &lt;- 1  \na_post &lt;- a_prior + successes\nb_post &lt;- b_prior + failures\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(successes, size = n, prob = theta_vals)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nprior_density &lt;- dbeta(theta_vals, a_prior, b_prior)\nposterior_density &lt;- dbeta(theta_vals, a_post, b_post)\n# likelihood - scaled\nlikelihood_scaled &lt;- likelihood / max(likelihood) * max(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, posterior_density, likelihood_scaled),\n  type = rep(c(\"Prior (Uniform)\", \"Posterior\", \"Likelihood (Scaled)\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior, Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))\n\n\n\n\n\n\n\n\n\n\nJeffreys’ Priors:\n\nJeffreys’ prior is a non-informative prior derived based on the Fisher information matrix, ensuring invariance under reparameterisation. This prior is proportional to the square root of the determinant of the Fisher information: \\(p(\\theta) \\propto \\sqrt{|I(\\theta)|}\\), where \\(I(\\theta)\\) is the Fisher information.\nJeffreys’ prior is invariant under reparameterisation means that if you change the parameterization of a model (i.e., if you make a transformation of the parameters), the form of the Jeffreys’ prior does not change.\nBinomial distribution\nLet us now explain this using Binomial distribution, where we observe 16 successes out of 20 trials, i.e., the efficacy rate is 80% observed from a pilot survey.\nNow, we write the Fisher information matrix as: \\(I(\\theta)=\\frac{n}{\\theta(1-\\theta)}\\). Hence, we get Jeffreys prior for \\(\\theta\\) as:\n\\[\np(\\theta) \\propto \\sqrt{\\left| \\frac{n}{\\theta(1-\\theta)}\\right|} \\propto \\frac{1}{\\sqrt{\\theta(1-\\theta)}}\n\\]\nwhere, we can ignore \\(\\sqrt{n}\\) using the proportional sign, as it is free from the model parameter \\(\\theta\\). Hence, we can plot the distributions as:\n\n\nCode\nlibrary(ggplot2)\njeffreys_prior &lt;- function(theta) {\n  return(1 / sqrt(theta * (1 - theta)))  \n}\nlikelihood &lt;- function(theta, k, n) {\n  return(choose(n, k) * theta^k * (1 - theta)^(n - k))  \n}\nn &lt;- 20  \nk &lt;- 16 \ntheta_vals &lt;- seq(0.01, 0.99, length.out = 1000)  \nprior_density &lt;- jeffreys_prior(theta_vals)\nlikelihood_density &lt;- likelihood(theta_vals, k, n)\nposterior_density &lt;- likelihood_density * prior_density\nprior_density &lt;- prior_density / sum(prior_density)\nlikelihood_density &lt;- likelihood_density / sum(likelihood_density)\nposterior_density &lt;- posterior_density / sum(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood\", \"Posterior\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Binomial Model\",\n    x = expression(theta),\n    y = \"Scaled Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nNormal Distribution\nLet’s consider a normal distribution with known variance \\(\\sigma^2\\). We write the Fisher information for the mean parameter \\(\\mu\\) as \\(I(\\mu) =\\frac{n}{\\sigma^2}\\), where \\(n\\) is the sample size. Hence, we write the Jeffreys prior for \\(\\mu\\) as the proportional to the square root of the Fisher information, i.e.,\n\\[\np(\\mu) \\propto \\sqrt{|I(\\mu)|} = \\sqrt{\\frac{n}{\\sigma^2}}\n\\]\nSince, \\(\\sigma^2\\) is a constant, hence for the mean of a normal distribution, it’s constant, i.e., Jeffreys prior is \\(p(\\mu) \\propto 1\\), and \\(-\\infty \\le \\mu \\le \\infty\\).\nThus, the prior is uniform over the parameter space. We write the posterior for \\(\\mu\\) follows normal distribution with mean \\(\\bar{y}\\) (sample mean) and variance \\(\\sigma^2/n\\).\nNow let us explain with an eample. Suppose a new antihypertensive drug is tested in a clinical trial, and researchers measure the reduction in systolic blood pressure (in mmHg) among patients. Where, most patients experience a blood pressure reduction of around 5 mmHg, but there is natural variability, which is about 2 standard deviation. Now considering Jeffreys non-informative prior, we can get the posterior distribution of the systolic blood pressure.\nFollowing this we draw the density plots using R code as follows:\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100        \ntrue_mu &lt;- 5    \nsigma &lt;- 2      \ndata &lt;- rnorm(n, mean = true_mu, sd = sigma)  \n# Fisher information for the mean is: I(mu) = n / sigma^2\nfisher_info &lt;- n / sigma^2 \n# Jeffreys prior is proportional to sqrt(I(mu)). For the mean of a normal distribution, it's constant, i.e., uniform over the parameter space\njeffreys_prior &lt;- function(mu) {\n  return(rep(1, length(mu)))  \n}\nsample_mean &lt;- mean(data)\nposterior_mean &lt;- sample_mean\nposterior_sd &lt;- sigma / sqrt(n)\n\nlikelihood &lt;- function(mu) {\n  return(dnorm(mu, mean = sample_mean, sd = sigma / sqrt(n)))\n}\n\nmu_vals &lt;- seq(true_mu - 3 * sigma, true_mu + 3 * sigma, length.out = 1000)\n\nprior_density &lt;- jeffreys_prior(mu_vals)\nlikelihood_density &lt;- likelihood(mu_vals)\nposterior_density &lt;- dnorm(mu_vals, mean = posterior_mean, sd = posterior_sd)\n\nlikelihood_density &lt;- likelihood_density / max(likelihood_density) * max(posterior_density)\n\nplot_data &lt;- data.frame(\n  mu = rep(mu_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood (Scaled)\", \"Posterior\"), each = length(mu_vals))\n)\nggplot(plot_data, aes(x = mu, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Normal Model\",\n    x = expression(mu),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nFurther Notes\nDespite being called “non-informative,” their choice can still involve subjective decisions. Some priors, like uniform priors, may appear non-informative in one parameterisation but informative in another (e.g., uniform in \\(\\theta\\) vs. \\(\\log(\\theta)\\)).\nTo explain this, consider a the case where we defined a uniform prior for \\(\\theta\\), i.e., \\(p(\\theta) = \\text{constant}\\), implies that all values of \\(\\theta\\) are equally likely. Now, suppose we reparameterise the problem using a new variable, say logit transformation:\n\\[\n\\phi = \\log \\frac{\\theta}{1 - \\theta}\n\\]\nIf \\(\\theta\\) follows a \\(\\text{Unif}[0, 1]\\) prior, what does this imply about \\(\\phi\\)? Using the change of variables formula for probability densities:\n\\[\np(\\phi) = p(\\theta) \\left| \\frac{d\\theta}{d\\phi} \\right|\n\\]\nSince \\(\\theta = \\frac{e^\\phi}{1 + e^\\phi}\\), its derivative is:\n\\[\n\\frac{d\\theta}{d\\phi} = \\frac{e^\\phi}{(1 + e^\\phi)^2}\n\\]\nSubstituting this into the density transformation:\n\\[\np(\\phi) \\propto \\frac{\\exp(\\phi)}{(1 + \\exp(\\phi))^2}\n\\]\nwhich is the logistic distribution rather than a uniform distribution. This shows that a uniform prior on \\(\\theta\\) induces a highly structured prior on \\(\\phi\\), meaning that the prior is no longer flat in the transformed space. We will learning more about this in hierarchical modelling.\nThis concept is crucial in Bayesian statistics, as it shows that non-informative priors are not always truly non-informative; their informativeness depends on the chosen parameter space.\n\n\n3.3.3 Weakly Informative Prior Distribution\n\n\n\nA weakly informative prior distribution in Bayesian statistics is characterised as proper, yet it is designed to provide information that is intentionally less robust than the actual prior knowledge available.\nLet’s explain this with the example of efficacy rate of the vaccine. If we consider a \\(\\text{Beta}(1,1)\\) prior for the parameter \\(\\theta\\), then we have already discussed that the prior is a flat line, which represents a non-informative situation. Now, considering a \\(\\text{Beta}(0.5,0.5)\\) prior might lead to a distribution similar to Jefferys’ prior. Whereas, if we consider a \\(\\text{Beta}(2,2)\\) prior, then it favours a middle value (0.5) but still flexible. This prior avoids extreme values (near 0 or 1) unless strongly supported by the data. Below, we can plot all these three different priors.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nbeta_1_1 &lt;- dbeta(theta_vals, 1, 1)    # Uniform prior\nbeta_0_5_0_5 &lt;- dbeta(theta_vals, 0.5, 0.5)  # Jeffreys' prior\nbeta_2_2 &lt;- dbeta(theta_vals, 2, 2)    # Weakly informative prior\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(beta_1_1, beta_0_5_0_5, beta_2_2),\n  type = rep(c(\"Beta(1,1) - Uniform\", \"Beta(0.5,0.5) - Jeffreys\", \"Beta(2,2) - Weakly Informative\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(title = \"Comparison of Different Beta Priors\",\n       x = expression(theta), \n       y = \"Density\", \n       color = \"Distribution\") +\n  ylim(0,3) +\n  theme_minimal() +\n  scale_color_viridis_d(option = \"cvidis\")\n\n\n\n\n\n\n\n\n\nNow assume that the success rate of the vaccine is about 50%, and we can consider the prior distribution as \\(\\text{Beta}(2,2)\\). This symmetric pattern favours the efficacy rate around 0.5 but also allows a wide range of plausible values. Now, suppose 30 trials out of \\(n = 50\\) shows success. Hence, we get the posterior distribution as \\(\\text{Beta}(32,22)\\). Below you can see the density plots of the distributions.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2\nb_prior &lt;- 2\nn &lt;- 50\ny &lt;- 30\na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\np &lt;- seq(0, 1, length.out = 1000)\n\nprior &lt;- dbeta(p, a_prior, b_prior)\n# Scaled for visualisation\nlikelihood &lt;- dbinom(y, n, p) * 100  \nposterior &lt;- dbeta(p, a_post, b_post)\n\nplot_data &lt;- data.frame(\n  p = p,\n  Likelihood = likelihood,\n  Posterior = posterior,\n  Prior = prior\n)\ndata_long &lt;- reshape2::melt(plot_data, id = \"p\", variable.name = \"Distribution\", value.name = \"Density\")\nggplot(data_long, aes(x = p, y = Density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior (weakly informative), Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nWeakly informative priors are common in modern Bayesian modeling, where it balances interpretability, robustness, and computational efficiency. Even though weakly informative priors are designed to be robust, they still influence the posterior, especially in small-sample scenarios. What counts as weakly informative is context-dependent. For example, a \\(\\text{Normal}(0,10^2)\\) prior on a regression coefficient might be weakly informative in a standard model but too weak in a context where coefficients are typically small. We will explain more about the weakly informative prior when we will learn the Bayesian regression and hierarchical models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#summary",
    "href": "M02_1.html#summary",
    "title": "3  Prior and Posterior",
    "section": "3.4 Summary",
    "text": "3.4 Summary\nToday’s lecture focused on understanding different types of prior distributions and their role in deriving the posterior distribution.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#live-tutorial-and-discussion",
    "href": "M02_1.html#live-tutorial-and-discussion",
    "title": "3  Prior and Posterior",
    "section": "3.5 Live tutorial and discussion",
    "text": "3.5 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#tutorial-exercises",
    "href": "M02_1.html#tutorial-exercises",
    "title": "3  Prior and Posterior",
    "section": "3.6 Tutorial Exercises",
    "text": "3.6 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#preparation-for-week-4",
    "href": "M02_1.html#preparation-for-week-4",
    "title": "3  Prior and Posterior",
    "section": "3.7 Preparation for Week 4",
    "text": "3.7 Preparation for Week 4\nIn week 4 you will be required to .\n\n\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.\n\n\nLambert, Ben. 2018. A Student’s Guide to Bayesian Statistics. SAGE Publications Ltd.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_2.html",
    "href": "M02_2.html",
    "title": "4  Generative Models and Tools",
    "section": "",
    "text": "4.1 Learnings\nL03: Explain how these generative models can be used for inference, prediction and model criticism.\nL04: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.\nBy the end of this week you should be able to:\n– Create generative models\n– Understand traceable and untraceable solutions\n– Explain the convergence of MCMC.\n– Conduct prior predictive check.\n– Conduct posterior predictive check.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#learnings",
    "href": "M02_2.html#learnings",
    "title": "4  Generative Models and Tools",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#generative-models",
    "href": "M02_2.html#generative-models",
    "title": "4  Generative Models and Tools",
    "section": "4.2 Generative Models",
    "text": "4.2 Generative Models\n\n\nA generative model is designed to generate new data points by capturing the intricate probability distributions of existing datasets. By learning these distributions, the model can produce data that reflects the characteristics of original datasets, simulating realistic examples. A generative model can also be used to understand how a set of observed data could have arisen from a set of underlying causes, which we will discuss more later in this course.\nIn Bayesian modelling, generative models are particularly useful as they provide a framework for estimating the likelihood of data under different hypotheses. This capability enhances Bayesian inference processes, allowing for more effective prior and posterior distribution updates. The flexibility of generative models in simulating various scenarios can also improve the robustness and accuracy of Bayesian models, and refines the decision-making and predictive capabilities.\nNote that, in this course, we use “generative model” broadly to consider the origins of a particular dataset. However, this term also has a more specific definition, especially as it contrasts with “discriminative models”, for details see Bernardo et al. (2007).\n\nExample\nLet’s explain this using the example we discussed earlier related to the vaccine efficacy rate. Let use assume that we know the true vaccine effectiveness rate, which is \\(0.8\\), and given this information we can recreate the data.\n\nData generation:\n\nIn a generative modelling context, we simulate data say for 100 individuals by considering success probability \\(\\theta = 0.8\\).\n\n\nCode\nn &lt;- 100\ntheta &lt;- 0.8  \nsize &lt;- 1  \nset.seed(1234)  \ndata &lt;- rbinom(size, n, theta)\npaste(\"Number of success: \",data,\" out of \",n, \"individuals\")\n\n\n[1] \"Number of success:  85  out of  100 individuals\"\n\n\nWe can see that our simulation using one replication yields probability 0.85, whereas, actual data shows \\(\\theta = 0.8\\). Hence, to reflect actual data we need to replicate the data simulation for multiple times, which yields an average value for \\(\\theta \\approx 0.8\\) and upper and lower 95% credible interval (0.72,0.88). This is very simple example of how we can generate data when the model parameter is known. We will utilise this concept later in this course to simulate data and use Bayesian models to provide results based on disitions.\n\n\nCode\nlibrary(ggplot2)\n\nn &lt;- 100     \ntheta &lt;- 0.8    \nsize &lt;- 1000  \n\nset.seed(123)  \ndata &lt;- rbinom(size, n, theta)\nci &lt;- quantile(data, probs = c(0.025, 0.975))\ndf &lt;- data.frame(Successes = data)\np = ggplot(df, aes(x = Successes)) +\n  geom_histogram(\n    breaks = seq(-0.5, n + 0.5, by = 1),\n    fill = \"skyblue\",\n    color = \"black\",\n    boundary = -0.5\n  ) +\n  scale_x_continuous(\n    breaks = NULL,  \n    name = NULL     \n  ) +\n  labs(\n    title = paste(\"Histogram of Simulated Binomial Data (n =\", n, \", θ =\", theta, \")\"),\n    y = \"Frequency\"\n  ) +\n  geom_vline(xintercept = ci[1], linetype = \"dashed\", color = \"red\", size = 1) +\n  geom_vline(xintercept = ci[2], linetype = \"dashed\", color = \"red\", size = 1) +\n  annotate(\"text\", x = ci[1], y = max(table(data)) * 0.9, label = paste0(\"2.5%: \", ci[1]), color = \"red\", angle = 90, vjust = -0.5) +\n  annotate(\"text\", x = ci[2], y = max(table(data)) * 0.9, label = paste0(\"97.5%: \", ci[2]), color = \"red\", angle = 90, vjust = -0.5) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_blank(),  \n    axis.ticks.x = element_blank()  \n  )\nlibrary(plotly)\nggplotly(p)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#solving-untraceability",
    "href": "M02_2.html#solving-untraceability",
    "title": "4  Generative Models and Tools",
    "section": "4.3 Solving Untraceability",
    "text": "4.3 Solving Untraceability\n\n\nWe can indentify an untraceable solution in Bayesian inference, where the posterior distribution cannot be expressed in a closed-form expression. This phenomenon occurs when the likelihood function and the prior distribution are incompatible, which results in complex integrals within Bayes’ theorem that are analytically intractable.\nThe opposite of untraceable solution is known as the traceable solution, which we have discussed in our previous lectures in the light of exact Bayesian inference. We already know that exact Bayesian inference means computing the posterior analytically, without approximations. And a tractable solution is one that can be computed exactly and efficiently, without requiring numerical approximations or complex sampling methods like Markov Chain Monte Carlo (MCMC). Thus traceable solution can be obtained when the prior distribution and the likelihood function are chosen such that the posterior distribution remains within a recognised family of probability distributions. For example, when a conjugate prior is used, the posterior has a known or a same functional form as the prior, i.e., for a Bernoulli model, that we have already discussed earlier in Lecture 2: \\(\\text{Prior: } \\theta \\sim \\text{Beta}(a,b)\\) and \\(\\text{Posterior: } \\theta|y \\sim \\text{Beta}(a+y,b+n-y)\\).\nUse of non-conjugate priors and often complex likelihood functions, such as those involving hierarchical models, mixture models, or high-dimensional data yields a posterior form of distribution with untraceable solutions, even if we consider conjugate priors for the model parameters.\nFor a non-Gaussian likelihood (i.e., it does not follow a normal distribution), choosing a uniform prior leads to a situation where the resulting posterior distribution cannot be easily determined or expressed in a simple mathematical form and also yields untraceable solution.\n\n\n4.3.1 Algorithms\nDifferent types of sampling algorithms have been developed to tackle untraceable solutions, such as rejection sampling, variational inference, Laplace approximation, sequential Monte Carlo, Markov chain Monte Carlo (MCMC) etc. In this couse, we will learn how to use and implement the MCMC algorithms to solve real-life problems. We refer Gelman et al. (2013) for details on this for those interested to explore more.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#markov-chain-monte-carlo-mcmc",
    "href": "M02_2.html#markov-chain-monte-carlo-mcmc",
    "title": "4  Generative Models and Tools",
    "section": "4.4 Markov chain Monte Carlo (MCMC)",
    "text": "4.4 Markov chain Monte Carlo (MCMC)\n\n\n\nIn this course, we will focus on learning Markov chain Monte Carlo (MCMC) algorithm, which is a sampling based approach to obtain the posterior distribution.\nA Markov chain is a stochastic process where the next state depends only on the current state, not on the sequence of states that preceded it. This property is called the Markovian or Markov property. The transition between states is defined by a transition probability matrix or kernel. On the other hand, Monte Carlo methods involve random sampling to estimate numerical quantities, such as integrals or expectations, to approximate the final solution. MCMC combines the Monte Carlo with Markov chains to generate samples.\nBasic concept and generic structure for MCMC can be explained as follows. Say we are interested in parameter \\(\\theta\\), then we state:\n\nSelect \\(\\theta^{(0)}\\) at an arbitrary point\nAt iteration \\(t\\), sample from a transition distribution \\(\\theta^{(t)}|\\theta^{(t-1)}\\), i.e., to generate a new value \\(\\theta = \\theta^{(t)}\\) given the previous value \\(\\theta = \\theta^{(t-1)}\\).\nRepeat the previous step until a specified maximum number of iterations is reached, or until specified convergence criterion is satisfied.\n\nHence, the MCMC states, there exist a transition distribution that guarantee that\n\\[\np(\\theta\\in \\{\\theta^{(t)},\\theta^{(t+1)},...,\\theta^{(q)} \\}) \\rightarrow p(\\theta|\\text{data}); \\text{   as   } q\\rightarrow \\infty\n\\]\nThe function that determines the probability for selecting the next location, is called the transition distribution.\n\n\nCode\n#set.seed(42)\n#n_iter &lt;- 10\n#theta &lt;- numeric(n_iter)\n#theta[1] &lt;- 0\n#sigma &lt;- 1\n#for (t in 2:n_iter) {\n#  theta[t] &lt;- rnorm(1, mean = theta[t - 1], sd = sigma)\n#}\n#x_vals &lt;- theta[1:(n_iter - 1)]\n#y_vals &lt;- theta[2:n_iter]\n#plot(x_vals, y_vals, type = \"b\", pch = 19, col = \"blue\",\n#     xlab = expression(theta[t-1]),\n#     ylab = expression(theta[t]),\n#     main = expression(paste(\"Transition plot: \", theta[t-1], \" vs \", theta[t])))\n#for (i in 1:(n_iter - 2)) {\n#  arrows(x_vals[i], y_vals[i], x_vals[i + 1], y_vals[i + 1],\n#         length = 0.1, col = \"darkgreen\", lwd = 2)\n#}\n#text(x_vals, y_vals, labels = paste0(\"t=\", 2:n_iter), pos = 3, cex = 0.8)\n\n#library(ggplot2)\n#library(ggrepel)\n#set.seed(007)\n#n_iter &lt;- 10\n#theta &lt;- numeric(n_iter)\n#theta[1] &lt;- 0\n#sigma &lt;- 1\n#for (t in 2:n_iter) {\n#  theta[t] &lt;- rnorm(1, mean = theta[t - 1], sd = sigma)\n#}\n#df &lt;- data.frame(\n#  x = theta[1:(n_iter - 1)],\n#  y = theta[2:n_iter],\n#  theta_label = round(theta[2:n_iter], 2)\n#)\n#df$arrows_xend &lt;- c(df$x[-1], NA)\n#df$arrows_yend &lt;- c(df$y[-1], NA)\n#df_arrows &lt;- df[1:(nrow(df) - 1), ]\n#p1 &lt;- ggplot(df, aes(x = x, y = y)) +\n#  geom_path(color = \"steelblue\", linewidth = 1, alpha = 0.6) +\n#  geom_segment(data = df_arrows,\n#               aes(xend = arrows_xend, yend = arrows_yend),\n#               arrow = arrow(length = unit(0.3, \"cm\"), type = \"closed\"),\n#               color = \"firebrick\", linewidth = 1.5, linetype = \"dashed\") +\n#  geom_point(color = \"blue\", size = 3) +\n#  geom_text_repel(aes(label = theta_label), size = 3) +\n#  labs(\n#    x = expression(theta[t-1]),\n#    y = expression(theta[t]),\n#    title = expression(paste(\"Transition plot: \", theta[t-1], \" vs \", theta[t]))\n#  ) +\n#  theme_minimal()\n\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(plotly)\nset.seed(007)\nn_iter &lt;- 10\ntheta &lt;- numeric(n_iter)\ntheta[1] &lt;- 0\nsigma &lt;- 1\nfor (t in 2:n_iter) {\n  theta[t] &lt;- rnorm(1, mean = theta[t - 1], sd = sigma)\n}\ndf &lt;- data.frame(\n  x = theta[1:(n_iter - 1)],\n  y = theta[2:n_iter],\n  z = 2:n_iter,\n  theta_label = round(theta[2:n_iter], 2)\n)\np2 &lt;- plot_ly(df, x = ~x, y = ~y, z = ~z, type = 'scatter3d', mode = 'lines+markers+text',\n        line = list(color = 'firebrick', width = 5, dash = 'dash'),\n        marker = list(size = 5, color = 'blue'),\n        text = ~theta_label,\n        textposition = 'top right') %&gt;%\n  layout(\n    scene = list(\n      xaxis = list(title = \"theta[t-1]\"),\n      yaxis = list(title = \"theta[t]\"),\n      zaxis = list(title = \"t\")\n    ),\n    title = \"Transition Plot of θ (in 3D)\"\n  )\np2\n\n\n\n\n\n\nNow, we will discuss some popular and common MCMC methods we use in practice to solve real-life applications.\n\nCommon MCMC methods\n\nSome common MCMC algorithms include Metropolis-Hastings (MH) algorithm, Gibbs sampling, Hamiltonian Monte Carlo (HMC) etc. MH is a general MCMC method that generates candidate samples from a proposal distribution. A candidate is accepted or rejected based on an acceptance probability, ensuring the chain converges to the target distribution. Whereas, Gibbs sampling is a special case of the Metropolis-Hastings algorithm. Updates one variable at a time by sampling from its conditional distribution while keeping other variables fixed. The Hamiltonian Monte Carlo (HMC) algorithm uses gradient information from the target distribution to propose new samples, making it more efficient for high-dimensional problems.\n\n\n4.4.1 Metropolis-Hastings (MH) Algorithm\nThe MH algorithm generates a sequence of samples that gradually approximates a target distribution say \\(p(\\theta)\\). It starts with an arbitrary value say \\(\\theta^{(0)}\\), and then uses a proposal distribution \\(q(\\theta^* | \\theta_t)\\) to propose a new value \\(\\theta^*\\). In the next step it accepts or rejects \\(\\theta^*\\) using an acceptance probability:\n\\[\nA = \\min \\left(1, \\frac{p(\\theta^*) q(\\theta_t | \\theta^*)}{p(\\theta_t) q(\\theta^* | \\theta_t)} \\right)\n\\]\nNow, we generate a random number \\(u\\) (say) from uniform distribution with (0,1), and when \\(u &lt; A\\), we accept the new point. That is, if accepted, then we set \\(\\theta_{t+1} = \\theta^*\\), otherwise keep the current sample, i.e., \\(\\theta_{t+1} = \\theta_t\\). We then iterate this process to generate a sequence of samples, and over time, the samples approximate \\(p(\\theta)\\).\nMetropolis Algorithm\nA simpler version and special case of the MH algorithm is the Metropolis algorithm, where the proposal distribution is symmetric, i.e., \\(q(\\theta^* | \\theta_t) = q(\\theta_t | \\theta^*)\\). Hence, in this case, we write the acceptance probability as:\n\\[\nA = \\min \\left(1, \\frac{p(\\theta^*) }{p(\\theta_t) } \\right)\n\\]\nHere, we can see as the proposal distribution is symmetric and it cancles out.\nExample\nSuppose, we want to sample from a standard normal distribution \\(N(0,1)\\) using the Metropolis-Hastings algorithm, starting from an arbitrary initial point. This allows us to observe how the MCMC chain gradually converges to the target distribution. We write the target density \\(\\theta \\sim N(0,1)\\) as:\n\\[\np(\\theta) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\theta^2}{2}\\right)\n\\]\n\n\nCode\nlibrary(coda)\nmetropolis_hastings &lt;- function(target_density, proposal_sd, n_iter, initial_value) {\n  chain &lt;- numeric(n_iter)\n  chain[1] &lt;- initial_value\n  \n  for (i in 2:n_iter) {\n    proposal &lt;- rnorm(1, mean = chain[i - 1], sd = proposal_sd)\n    acceptance_prob &lt;- min(1, target_density(proposal) / target_density(chain[i - 1]))\n    if (runif(1) &lt; acceptance_prob) {\n      chain[i] &lt;- proposal\n    } else {\n      chain[i] &lt;- chain[i - 1]\n    }\n  }\n  \n  return(chain)\n}\ntarget_density &lt;- function(x) dnorm(x, mean = 0, sd = 1)\n\nset.seed(123)\nn_iter &lt;- 10000\nn_chains &lt;- 3\nchains &lt;- list(\n  chain1 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 10),\n  chain2 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = -10),\n  chain3 = metropolis_hastings(target_density, proposal_sd = 1, n_iter, initial_value = 5)\n)\n\nmcmc_chains &lt;- mcmc.list(\n  mcmc(chains$chain1),\n  mcmc(chains$chain2),\n  mcmc(chains$chain3)\n)\n\nsummary(mcmc_chains)\n\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n     -0.025039       1.066546       0.006158       0.020382 \n\n2. Quantiles for each variable:\n\n    2.5%      25%      50%      75%    97.5% \n-2.05216 -0.70284 -0.01213  0.65225  1.94265 \n\n\nCode\n#par(mfrow = c(1, 3))\n#for (i in 1:n_chains) {\n#  plot(mcmc_chains[[i]], type = \"l\", col = \"blue\", \n#       main = paste(\"Chain\", i), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       trace = TRUE, density = FALSE)\n#}\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_mh &lt;- mcmc_chains\n\n\n\n\n4.4.2 Gibbs Sampling\nThe Gibbs sampling algorithm is a special case of the Metropolis-Hastings (MH) algorithm and is particularly useful when we want to do sampling from high-dimensional joint distributions. Instead of sampling all variables at once, Gibbs sampling updates one variable at a time, conditioning on the others.\nSuppose we have a joint distribution \\(p(\\theta_1, \\theta_2)\\), and the algorithm starts with arbitrary initial values for all variables, i.e., \\(\\theta_1^{(0)}\\) and \\(\\theta_2^{(0)}\\). For each variable then we sample from its conditional distribution, i.e., for \\(\\theta_1\\) we use conditional distribution \\(p(\\theta_1|\\theta_2)\\) and then for \\(\\theta_2\\) we use \\(p(\\theta_2|\\theta_1)\\). This means we sample \\(\\theta_1\\) given all other current values, i.e., in our example this is \\(\\theta_2\\) and then sample \\(\\theta_2\\) given \\(\\theta_1\\). We then repeat the process for many iterations until the samples converge to the target distribution.\nWe write the algorithm for \\(n\\) number of parameters, where we want to sample from a joint distribution over parameters \\(p(\\theta_1, \\theta_2, \\dots, \\theta_n)\\).\nInitialisation by choosing starting values: \\(\\left(\\theta_1^{(0)}, \\theta_2^{(0)}, \\dots, \\theta_n^{(0)}\\right)'\\)\nThen iterate for $t = 1, 2, $, and update each parameter one at a time using its conditional distribution:\n\\[\\begin{align*}\n\\theta_1^{(t)} &\\sim p(\\theta_1 \\mid \\theta_2^{(t-1)}, \\dots, \\theta_n^{(t-1)}) \\\\\n\\theta_2^{(t)} &\\sim p(\\theta_2 \\mid \\theta_1^{(t)}, \\theta_3^{(t-1)}, \\dots, \\theta_n^{(t-1)}) \\\\\n&\\vdots \\\\\n\\theta_n^{(t)} &\\sim p(\\theta_n \\mid \\theta_1^{(t)}, \\dots, \\theta_{n-1}^{(t)})\n\\end{align*}\\]\nHence, the samples approximate the target distribution \\(p(\\theta_1, \\dots, \\theta_n)\\).\nExample\nLet’s use Gibbs Sampling to sample from a bivariate normal distribution where the marginal distributions of each variable are normal, but the two variables are correlated. We’ll then assess the convergence using trace plots, autocorrelation plots, and the Gelman-Rubin diagnostic.\nThe joint density is the bivariate normal distribution:\n\\[\np(\\theta_1,\\theta_2) = \\frac{1}{2\\pi\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left(\\theta_1^2-2\\rho \\theta_1 \\theta_2 +\\theta_2^2 \\right) \\right)\n\\]\nwhere \\(\\rho\\) is the correlation between \\(\\theta_1\\) and \\(\\theta_2\\).\n\n\nCode\nlibrary(coda)\ngibbs_sampling &lt;- function(n_iter, rho, initial_values) {\n  x &lt;- numeric(n_iter)\n  y &lt;- numeric(n_iter)\n  \n  x[1] &lt;- initial_values[1]\n  y[1] &lt;- initial_values[2]\n  \n  for (i in 2:n_iter) {\n    x[i] &lt;- rnorm(1, mean = rho * y[i - 1], sd = sqrt(1 - rho^2))\n    y[i] &lt;- rnorm(1, mean = rho * x[i], sd = sqrt(1 - rho^2))\n  }\n  \n  return(data.frame(theta_2 = x, theta_1 = y))\n}\n\nset.seed(123)         \nn_iter &lt;- 1000       \nrho &lt;- 0.8           \ninitial_values &lt;- c(0, 0)  \n\nchain1 &lt;- gibbs_sampling(n_iter, rho, c(0, 0))\nchain2 &lt;- gibbs_sampling(n_iter, rho, c(10, 10))\nchain3 &lt;- gibbs_sampling(n_iter, rho, c(-10, -10))\n\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(chain1)),\n  mcmc(as.matrix(chain2)),\n  mcmc(as.matrix(chain3))\n)\n\nsummary(mcmc_chains)\n\n\n\nIterations = 1:1000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean    SD Naive SE Time-series SE\ntheta_2 0.01841 1.026  0.01874        0.03854\ntheta_1 0.01097 1.018  0.01858        0.03912\n\n2. Quantiles for each variable:\n\n          2.5%     25%     50%    75% 97.5%\ntheta_2 -1.943 -0.6345 0.02087 0.6801 1.827\ntheta_1 -1.902 -0.6288 0.01558 0.6646 1.902\n\n\nCode\n#par(mfrow = c(2, 3))\n#for (i in 1:3) {\n#  plot(mcmc_chains[[i]][, \"x\"], type = \"l\", col = \"blue\",\n#       main = paste(\"Chain\", i, \"(x)\"), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       density = FALSE)\n#  plot(mcmc_chains[[i]][, \"y\"], type = \"l\", col = \"red\",\n#       main = paste(\"Chain\", i, \"(y)\"), \n#       xlab = \"Iteration\", ylab = \"Value\",\n#       density = FALSE)\n#}\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_gibbs &lt;- mcmc_chains\n\n\n\n\n4.4.3 Hamiltonian Monte Carlo (HMC)\nHamiltonian Monte Carlo (HMC) is a powerful MCMC algorithm that uses information about the gradient of the log-probability density to efficiently sample from complex distributions. HMC is inspired by Hamiltonian mechanics, which describes the motion of objects in a physical system. Here, we use a system in Hamiltonian mechanics and is defined by \\(H(\\theta,p)=L(\\theta)+K(p)\\), where \\(L(\\theta)\\) is the negative log of the target density and \\(K(p)\\) is a kinetic energy, which we usually model using a Gaussian distribution.\nThe sampling steps involves by initialising with a position \\(\\theta_t\\) and sample \\(p_t\\) from a Gaussian distribution. Then simulate Hamiltonian dynamics using gradient of \\(L(\\theta)\\) and hence update the position and momentum iteratively. After the simulation, we propose a new state \\((\\theta^*,p^*)\\) and accept or reject the proposed step using Metropolis criterion:\n\\[\nA = \\min \\left(1, \\frac{\\exp(-H(\\theta^*, p^*))}{\\exp(-H(\\theta_t, p_t))} \\right)\n\\]\nAnd, if accepted, move to \\(\\theta^*\\), and for rejection stay at \\(\\theta_t\\). We then repeat for many iterations to generate samples.\nThere is an adaptive version of HMC that automatically tunes trajectory lengths, which is also known as the No-U-Turn Sampler (NUTS). In this course, we will use Stan compiler, which uses NUTS to obtain posterior distributions of the Bayesian model parameters.\nExample\nBelow, we provide an example of implementing HMC for normal distribution with parameters \\(\\mu\\) and \\(\\sigma^2\\), using R with the rstan package, which includes a highly optimised implementation of HMC.\n\n\n\nCode\nlibrary(rstan)\nlibrary(bayesplot)\n\nset.seed(42)\ntrue_mu &lt;- 5.0\ntrue_sigma &lt;- 2.0\nn_samples &lt;- 100\ny &lt;- rnorm(n_samples, mean = true_mu, sd = true_sigma)\n\nhist(y, breaks = 20, col = \"lightblue\", main = \"Observed Data\", xlab = \"y\")\n\n\n\n\n\n\n\n\n\nCode\nstan_code &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;        // Number of observations\n  vector[N] y;           // Observed data\n}\nparameters {\n  real mu;               // Mean\n  real&lt;lower=0&gt; sigma;   // Standard deviation\n}\nmodel {\n  mu ~ normal(0, 10);    // Prior for mu\n  sigma ~ normal(0, 10); // Prior for sigma\n  y ~ normal(mu, sigma); // Likelihood\n}\n\"\nstan_data &lt;- list(\n  N = length(y),\n  y = y\n)\n\nfit &lt;- stan(\n  model_code = stan_code,\n  data = stan_data,\n  iter = 2000,      \n  warmup = 1000,    \n  chains = 3,       \n  seed = 1234         \n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.017 seconds (Warm-up)\nChain 1:                0.017 seconds (Sampling)\nChain 1:                0.034 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.026 seconds (Warm-up)\nChain 2:                0.015 seconds (Sampling)\nChain 2:                0.041 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 6e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.018 seconds (Warm-up)\nChain 3:                0.019 seconds (Sampling)\nChain 3:                0.037 seconds (Total)\nChain 3: \n\n\nCode\nprint(fit, pars = c(\"mu\", \"sigma\"))\n\n\nInference for Stan model: anon_model.\n3 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=3000.\n\n      mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat\nmu    5.06       0 0.21 4.65 4.92 5.06 5.20  5.49  2598    1\nsigma 2.11       0 0.16 1.83 2.00 2.10 2.21  2.45  2926    1\n\nSamples were drawn using NUTS(diag_e) at Fri May  9 11:05:33 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCode\n#library(bayesplot)\n#mcmc_trace(fit, pars = c(\"mu\", \"sigma\"))\n#mcmc_areas(fit, pars = c(\"mu\", \"sigma\"))\n#mcmc_acf_bar(fit, pars = c(\"mu\", \"sigma\"))\n\nlibrary(coda)\nposterior_samples &lt;- as.array(fit)\nmcmc_chains &lt;- mcmc.list(\n  mcmc(as.matrix(posterior_samples[,1,1:2])),\n  mcmc(as.matrix(posterior_samples[,2,1:2])),\n  mcmc(as.matrix(posterior_samples[,3,1:2]))\n)\n\nlibrary(lattice)\nxyplot(mcmc_chains, col=c(\"blue\", \"red\", \"green\"), lwd=1.5)\n\n\n\n\n\n\n\n\n\nCode\nmcmc_chains_hmc &lt;- mcmc_chains\n\n\n# use shinystan\n#library(shinystan)\n#launch_shinystan(fit)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#mcmc-diagnostics",
    "href": "M02_2.html#mcmc-diagnostics",
    "title": "4  Generative Models and Tools",
    "section": "4.5 MCMC diagnostics",
    "text": "4.5 MCMC diagnostics\n\n\nWhen we run Markov Chain Monte Carlo (MCMC) methods for Bayesian inference, we need to make sure our samples actually represent the true posterior distribution. MCMC doesn’t guarantee good results on its own, so we rely on MCMC diagnostics to check for issues like lack of convergence, autocorrelation, and poor mixing.\nNote that there are two major schools of thought regarding MCMC diagnostics: one prefers running a single chain for a longer number of iterations, while the other prefers running multiple chains for relatively shorter iterations. We also need to understand “burn-in” and “thinning” of the MCMC samples. A burn-in refers to discard early samples to allow the chain to reach the stationary distribution. Typical burn-in might be 10–50% of the chain. The thinning approach is related to reduce autocorrelation. Thinning means keeping only every \\(n\\)th sample from your MCMC chain and discarding the rest. For example, if you thin by 10, you keep sample 10, 20, 30, etc., and discard the rest.\nNow, let’s discuss more on the MCMC diagnostics below:\n\n4.5.1 Convergence\nWe first check whether the MCMC chain has actually converged to the posterior distribution. To check this we rely mainly on visual method: trace plots. If the trace plot looks like a “hairy caterpillar” without trends or long drifts, that’s a good sign. If we see big jumps or slow drifting, we might need a longer burn-in period or better tuning.\nIf we run multiple chains as indicated in the examples above, the we can compare their variance, which is also known as Gelman-Rubin Diagnostic and denote the estimate as \\(\\hat{R}\\). An \\(\\hat{R}\\) near 1 (or less than 1.1) typically indicates convergence, i.e., all chains are settled into the same stationary distribution. It is also important to check the Gelman-Rubin plot, which usually show how \\(\\hat{R}\\) decreases over iterations.\n\n\n4.5.2 Autocorrelation\nWe can also use autocorrelation plots to check how correlated our MCMC samples are with previous ones. Ideally, the correlation should drop off quickly, if it lingers then we may need to adjust our proposal distribution for MH or thinning interval or run the chain for more iterations.\nAnother measurement diagnostic is the effective sample size (ESS). If ESS is low, it means we’re getting fewer independent samples than expected. Increasing the total iterations or improving sampling efficiency (e.g., using Hamiltonian Monte Carlo instead of Metropolis-Hastings) can help to increase the ESS. Usually, ESS &lt; 100 might not be a good indicator, which might lead the posterior estimates unreliable. ESS &gt; 400 is generally considered good, where you can get reasonably accurate estimates of posterior means, variances, and quantiles (like credible intervals).\n\n\n4.5.3 Mixing & Efficiency\nFor MCMC algorithms such as Metropolis or Metropolis-Hastings, even if our chain is converging, we want to make sure it’s exploring the full posterior efficiently. Poor mixing shows up when the chain gets stuck in one region for too long before jumping elsewhere. If we notice this, the we can tweak the sampling algorithm to improve mixing.\nFor such algorithms, we aim for an acceptance rate between 20% and 50%. If it’s too low, our proposals might be too aggressive; if it’s too high, they might be too conservative. Advanced algorithms, such as NUTS does not need such coareful considerations.\nHence, in this course, we will mainly use the HMC-NUTS algorithm to obtain posterior distributions from the Bayesian models and check for MCMC diagnostics related to this algorithm.\n\n\n4.5.4 Code for MH\n\n\nCode\n## MH\n#par(mfrow = c(1, 3))\n#for (i in 1:n_chains) {\n#  autocorr.plot(mcmc_chains_mh[[i]], main = #paste(\"Autocorrelation: Chain\", i), lag.max = 50)\n#}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_mh[[1]]) %&gt;% mutate(Chain = \"Chain 1\"),\n  extract_acf(mcmc_chains_mh[[2]]) %&gt;% mutate(Chain = \"Chain 2\"),\n  extract_acf(mcmc_chains_mh[[3]]) %&gt;% mutate(Chain = \"Chain 3\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of MCMC Chains - MH\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ngelman_diag &lt;- gelman.diag(mcmc_chains_mh)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n     Point est. Upper C.I.\n[1,]          1          1\n\n\nCode\ngelman.plot(mcmc_chains_mh)\n\n\n\n\n\n\n\n\n\n\n\n4.5.5 Code for Gibbs\n\n\nCode\n## gibbs\n#par(mfrow = c(2, 3))\n#for (i in 1:3) {\n#  autocorr.plot(mcmc_chains_gibbs[[i]][, \"x\"], main = paste(\"Autocorrelation: Chain\", i, \"(x)\"))\n#  autocorr.plot(mcmc_chains_gibbs[[i]][, \"y\"], main = paste(\"Autocorrelation: Chain\", i, \"(y)\"))\n#}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_gibbs[[1]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 1 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[1]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 1 (theta_2)\"),\n  extract_acf(mcmc_chains_gibbs[[2]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 2 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[2]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 2 (theta_2)\"),\n  extract_acf(mcmc_chains_gibbs[[3]][, \"theta_1\"]) %&gt;% mutate(Chain = \"Chain 3 (theta_1)\"),\n  extract_acf(mcmc_chains_gibbs[[3]][, \"theta_2\"]) %&gt;% mutate(Chain = \"Chain 3 (theta_2)\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of Gibbs Sampling Chains\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nlibrary(coda)\ngelman_diag &lt;- gelman.diag(mcmc_chains_gibbs)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n        Point est. Upper C.I.\ntheta_2          1       1.02\ntheta_1          1       1.02\n\nMultivariate psrf\n\n1\n\n\nCode\ngelman.plot(mcmc_chains_gibbs)\n\n\n\n\n\n\n\n\n\n\n\n4.5.6 Code for HMC\n\n\nCode\n## HMC\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nextract_acf &lt;- function(chain, lag.max = 40) {\n  acf_values &lt;- acf(chain, plot = FALSE, lag.max = lag.max)\n  data.frame(Lag = acf_values$lag, ACF = acf_values$acf)\n}\nacf_data &lt;- bind_rows(\n  extract_acf(mcmc_chains_hmc[[1]][, 1]) %&gt;% mutate(Chain = \"Chain 1 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[1]][, 2]) %&gt;% mutate(Chain = \"Chain 1 (Param 2)\"),\n  extract_acf(mcmc_chains_hmc[[2]][, 1]) %&gt;% mutate(Chain = \"Chain 2 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[2]][, 2]) %&gt;% mutate(Chain = \"Chain 2 (Param 2)\"),\n  extract_acf(mcmc_chains_hmc[[3]][, 1]) %&gt;% mutate(Chain = \"Chain 3 (Param 1)\"),\n  extract_acf(mcmc_chains_hmc[[3]][, 2]) %&gt;% mutate(Chain = \"Chain 3 (Param 2)\")\n)\nggplot(acf_data, aes(x = Lag, y = ACF, fill = Chain)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Autocorrelation of HMC MCMC Samples\", x = \"Lag\", y = \"Autocorrelation\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\ngelman_diag &lt;- gelman.diag(mcmc_chains_hmc)\nprint(gelman_diag)\n\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nmu             1       1.00\nsigma          1       1.01\n\nMultivariate psrf\n\n1\n\n\nCode\ngelman.plot(mcmc_chains_hmc)\n\n\n\n\n\n\n\n\n\nCode\n#rhats &lt;- rhat(fit)\n#rhats\n#mcmc_rhat(rhats) + yaxis_text(hjust = 1)\n#ratios_cp &lt;- neff_ratio(fit)\n#print(ratios_cp)\n#mcmc_neff(ratios_cp, size = 2) + yaxis_text(hjust = 1)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#prior-and-posterior-predictive-checks",
    "href": "M02_2.html#prior-and-posterior-predictive-checks",
    "title": "4  Generative Models and Tools",
    "section": "4.6 Prior and Posterior Predictive Checks",
    "text": "4.6 Prior and Posterior Predictive Checks\n\n\n\n\n4.6.1 Prior Predictive Checks\nPrior predictive checks involve simulating data from the model before observing real data to assess whether the chosen prior distribution is reasonable. Then we compare this simulated data with the actual observation, if available. This step helps to ensure that our prior assumptions align with the real-world outcomes.\nPrior predictive check is important in Bayesian simulations. We can use this to understand the influence of prior on possible outcomes. It can also help us to avoid overly informed prior, which might lead to a strong influence on the posterior distribution. For example, if a prior on disease prevalence suggests 90% probability when we know it’s closer to 5%, then the prior is not reasonable. Thus, for implausible simulated data, we can say that the prior is too vague, too strong, or poorly chosen.\n\nSteps to perform prior predictive check\n\nBefore collecting data, choose a prior for the parameter, say \\(\\theta\\), if we are modelling a Bernoulli process, where assume the prior follows Beta distribution, i.e., \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\).\nFor instance, let’s assume:\n\\[\n\\theta \\sim \\text{Beta}(1, 1) \\quad \\text{(Uniform prior, meaning all values are equally likely).}\n\\]\nNow, we generate or simulate data from the prior distribution, i.e., first sample \\(\\theta\\) from the prior and then generate data \\(y\\) using a defined model.\nFor example, if we are modelling the efficacy rate of a certain vaccine in patients with similar profiles, then\n\nSample \\(\\theta^{sim} \\sim \\text{Beta}(1,1)\\).\nSimulate \\(y^{sim} \\sim \\text{Bernoulli}(\\theta^{sim})\\) for \\(n\\) trials.\n\nThis gives us a distribution of possible datasets before seeing real data.\nIn the next step, we compare the simulated data with what we would expect or any available data. This can be done by plotting histograms or summary statistics of the simulated data. We can then check if the range and spread of simulated values make sense.\nFor example, if we assume a Beta(2, 2) prior, we expect \\(\\theta\\) to be centered around 0.5. Whereas, for Beta(1, 1) (i.e., Uniform prior), simulated values will be more spread out. If we assume Beta(100, 5), then most values will be very high (\\(\\theta\\) close to 1).\nNow, if simulated data looks unrealistic, the prior may need adjusting. This step prevents misleading results and improves Bayesian inference quality.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n#prior_predictive_check &lt;- function(alpha, beta, n_trials = 10, n_sim = 1000) {\n#  theta_samples &lt;- rbeta(n_sim, alpha, beta)\n#  bernoulli_samples &lt;- rbinom(n_sim, size = n_trials, prob = theta_samples)\n#  df &lt;- data.frame(Theta = theta_samples, Successes = bernoulli_samples)\n#  p1 &lt;- ggplot(df, aes(x = Theta)) +\n#    geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n#    labs(title = paste(\"Prior Distribution: Beta(\", alpha, \",\", beta, \")\"),\n#         x = expression(theta), y = \"Frequency\") +\n#    theme_minimal()\n#  p2 &lt;- ggplot(df, aes(x = Successes)) +\n#    geom_bar(fill = \"coral\", color = \"black\", alpha = 0.7) +\n#    labs(title = paste(\"Simulated Successes (n =\", n_trials, \")\"),\n#         x = \"Number of Successes\", y = \"Frequency\") +\n#    theme_minimal()\n#  gridExtra::grid.arrange(p1,p2,ncol=2)\n#}\nprior_predictive_check &lt;- function(alpha, beta, n_trials = 10, n_sim = 1000, observed_successes = NULL) {\n  \n  theta_samples &lt;- rbeta(n_sim, alpha, beta)\n  simulated_successes &lt;- rbinom(n_sim, size = n_trials, prob = theta_samples)\n  df &lt;- data.frame(Theta = theta_samples, Successes = simulated_successes)\n  p1 &lt;- ggplot(df, aes(x = Theta)) +\n    geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n    labs(title = bquote(\"Prior Distribution: Beta(\"~.(alpha)*\",\"~.(beta)~\")\"),\n         x = expression(theta), y = \"Frequency\") +\n    theme_minimal() +\n    xlim(0, 1)\n  p2 &lt;- ggplot(df, aes(x = Successes)) +\n    geom_bar(fill = \"coral\", color = \"black\", alpha = 0.7) +\n    labs(title = paste(\"Simulated Successes (n =\", n_trials, \")\"),\n         x = \"Number of Successes\", y = \"Frequency\") +\n    theme_minimal() +\n    scale_x_continuous(limits = c(0, n_trials), breaks = 0:n_trials)\n  if (!is.null(observed_successes)) {\n    p2 &lt;- p2 + \n      geom_vline(xintercept = as.numeric(observed_successes), \n                 color = \"blue\", linetype = \"dashed\", linewidth = 1.2) +\n      annotate(\"text\", \n               x = as.numeric(observed_successes), \n               y = max(table(df$Successes)) * 0.45, \n               label = paste(\"Observed Success:\", observed_successes), \n               color = \"blue\", angle = 90, vjust = -0.5, hjust = -0.1)\n  }\n  gridExtra::grid.arrange(p1, p2, ncol = 2)\n}\n\n\n# Without observed data\n#prior_predictive_check(alpha = 2, beta = 2, n_trials = 10)\n# With observed number of successes\n#prior_predictive_check(alpha = 2, beta = 2, n_trials = 10, observed_successes = 7)\n# Example 1: Uniform Prior (Beta(1,1)) - No strong belief\n#prior_predictive_check(alpha = 1, beta = 1)\n# Example 2: Informative Prior (Beta(2,2)) - Believes success rate around 50%\n#prior_predictive_check(alpha = 2, beta = 2)\n# Example 3: Strong Prior (Beta(100,5)) - Believes success rate is high\n#prior_predictive_check(alpha = 100, beta = 5)\n# Example 4: Weak Prior (Beta(0.5, 0.5)) - Encourages extreme values (0 or 1)\n#prior_predictive_check(alpha = 0.5, beta = 0.5)\n\n\nLet’s now look at two examples in a health and medical context:\n\nPerfect Example: Estimating the probability of a successful treatment for a specific medical condition based on prior knowledge.\n\nSuppose, a new drug treatment has been tested on patients with a specific medical condition. Previous studies indicate that the drug has a 70% success rate in patients with similar characteristics. We are uncertain about the exact probability of success, but the previous studies give us a reasonable prior belief about the success rate.\nThe Beta(7,3) prior reflects our belief that the treatment has a 70% success rate on average. This prior configuration is centered around 0.7, with a reasonable spread, allowing for some variation while keeping the treatment’s effectiveness as a reasonable estimate.\n\n\nCode\nprior_predictive_check(alpha = 7, beta = 3, n_trials = 10, n_sim = 1000, observed_successes = 7)\n\n\n\n\n\n\n\n\n\nHistogram of \\(\\theta\\) shows most of the values around 0.7, reflecting the prior belief that the drug has a 70% success rate. For the simulated data we can see out of 10 trials, on average, 7 out of 10 patients are expected to succeed, but some variability (e.g., 6, 8 successes) is expected due to the spread of the prior.\n\nImperfect Example: Assuming a unreasonably high success rate for a new treatment without proper evidence.\n\nNow, assume a new drug for treating a condition has been introduced, but no clinical trials have been conducted yet. Despite this lack of data, the manufacturer assumes an overly optimistic success rate of 90% based on limited anecdotal evidence.\nBeta(90,10) prior assumes a very high success rate (about 90%), which is unrealistic without substantial evidence. This prior leads to a very narrow distribution, with values almost always close to 0.9, indicating extremely high success rates.\n\n\nCode\nprior_predictive_check(alpha = 90, beta = 10, n_trials = 10, n_sim = 1000, observed_successes = 7)\n\n\n\n\n\n\n\n\n\nHere, histogram of \\(\\theta\\) shows that most values are close to 0.9, and similarly, simulations result show an unrealistic scenario for a new drug with little evidence backing the success rate.\n\n\n4.6.2 Posterior Predictive Checks\nA posterior predictive check is a technique used in Bayesian statistics to assess how well a fitted model explains the observed data. It involves generating or simulating new data from the posterior predictive distribution and comparing it to the observed data to check for discrepancies. If the generated data looks similar to the observed data, the model is considered a good fit; if not, the model may be inadequate.\nUse of posterior predictive checks help to detect model misspecification, can provide intuitive, visual validation of the model’s performance.\n\nSteps to perform posterior predictive check\n\nWe first estimate the posterior distribution of the model parameters, say \\(\\theta\\) given the observed data \\(y\\). Then draw samples from the posterior predictive distribution (say \\(p(\\tilde{y}|y)\\), where \\(\\tilde{y}\\) is the predicted data), which represents hypothetical new data (\\(\\tilde{y}\\)) generated by the model.\nHence, use visualisations (e.g., histograms, density plots, scatter plots) or statistical summaries (e.g., mean, variance) to compare the simulated data to the actual observed data.\nIf the simulated data deviates significantly from the observed data, it suggests the model may be misspecified.\nLet’s consider a Bernoulli model, where suppose we have a dataset of \\(n\\) observations. Hence, the posterior predictive distribution for new data \\(\\tilde{y}\\) is:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta\n\\]\nTo check if our model fits well, we generate new (simulated) data \\(\\tilde{y}^{(sim)}\\), and the compare \\(\\tilde{y}^{(sim)}\\) to observed data \\(y\\).\nIf simulated data is similar to observed data, the model is reasonable. Whereas, if there is a mismatch, the model might be misspecified (e.g., wrong prior, incorrect likelihood assumption).\nExample\nSuppose we want to estimate the probability of a successful treatment for a specific medical condition using Bayesian inference. The model assumes that each patient’s treatment outcome follows a Bernoulli distribution, and we use a Beta prior to express our prior beliefs about the success rate. We then perform a posterior predictive check to assess the model fit by simulating new data and comparing it to observed outcomes.\nAssume that we collected data from 30 patients who underwent treatment, of which 18 patients recovered (successes), while 12 did not recover (failures). Considering a uniform prior for \\(\\theta\\), i.e., \\(\\theta \\sim \\text{Beta}(1,1)\\), we can get the following plots for posterior distribution, and posterior predictive checks.\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(bayesplot)\nposterior_predictive_check &lt;- function(a, b, n_trials, successes, n_sim = 1000) {\n  posterior_alpha &lt;- a + successes\n  posterior_beta &lt;- b + (n_trials - successes)\n  theta_samples &lt;- rbeta(n_sim, posterior_alpha, posterior_beta)\n  bernoulli_samples &lt;- rbinom(n_sim, size = n_trials, prob = theta_samples)\n  df &lt;- data.frame(Theta = theta_samples, Successes = bernoulli_samples)\n  p1 &lt;- ggplot(df, aes(x = Theta)) +\n    geom_density(fill = \"skyblue\", alpha = 0.7) +\n    labs(title = paste(\"Posterior Distribution: Beta(\", posterior_alpha, \",\", posterior_beta, \")\"),\n         x = expression(theta), y = \"Density\") +\n    theme_minimal() + xlim(0,1)\n  p2 &lt;- ggplot(df, aes(x = Successes)) +\n    geom_bar(fill = \"coral\", color = \"black\", alpha = 0.7) +\n    geom_vline(xintercept = successes, color = \"red\", linetype = \"dashed\", size = 1) +\n    labs(title = paste(\"Posterior Predictive Check (n =\", n_trials, \")\"),\n         x = \"Number of Successful Treatments\", y = \"Frequency\") +\n    theme_minimal()\n  #\n  y_rep &lt;- t(replicate(n_sim*0.01, rbeta(n_sim, posterior_alpha, posterior_beta)))\n  color_scheme_set(\"blue\")\n  p3 = ppc_dens_overlay(theta_samples, y_rep) # +    labs(title=\"Posterior Predictive Check: Density Overlay\")\n  #\n  gridExtra::grid.arrange(p1, p2, p3, ncol = 2)\n}\n# n=30 patients, y=18 successful treatments, Beta(1,1) prior\nposterior_predictive_check(a = 1, b = 1, n_trials = 30, successes = 18)\n\n\n\n\n\n\n\n\n\nWe can see that the observed number of successful treatments (18) falls within the distribution of simulated outcomes, which implies that the model is consistent with the data.\nOn the other hand, if the observed value significantly deviates, it may indicate model misspecification, requiring adjustments to the prior or likelihood assumptions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#summary",
    "href": "M02_2.html#summary",
    "title": "4  Generative Models and Tools",
    "section": "4.7 Summary",
    "text": "4.7 Summary\nToday’s lecture focused on understanding generative models, and how we can use generative models to answer research questions using Bayesian methods. We learn when to use exact inference and MCMC based optimisations, together their types. Finally we illustrate the prior and posterior predictive checks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#live-tutorial-and-discussion",
    "href": "M02_2.html#live-tutorial-and-discussion",
    "title": "4  Generative Models and Tools",
    "section": "4.8 Live tutorial and discussion",
    "text": "4.8 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#tutorial-exercises",
    "href": "M02_2.html#tutorial-exercises",
    "title": "4  Generative Models and Tools",
    "section": "4.9 Tutorial Exercises",
    "text": "4.9 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "M02_2.html#preparation-for-week-5",
    "href": "M02_2.html#preparation-for-week-5",
    "title": "4  Generative Models and Tools",
    "section": "4.10 Preparation for Week 5",
    "text": "4.10 Preparation for Week 5\nIn week 5 you will be required to .\n\n\n\n\nBernardo, JM, MJ Bayarri, JO Berger, AP Dawid, D Heckerman, AFM Smith, and M West. 2007. “Generative or Discriminative? Getting the Best of Both Worlds.” Bayesian Statistics 8 (3): 3–24.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**Generative Models and Tools**</span>"
    ]
  },
  {
    "objectID": "brief_module_03.html",
    "href": "brief_module_03.html",
    "title": "Module 3: Bayeswatch - Gaussian",
    "section": "",
    "text": "In this module, we will start learning about how Bayesian methods can help us understand cause-and-effect relationships, not just patterns in the data. To do this, we’ll begin by understanding three important ideas such as the estimand, estimator, and estimate.\nWe will then look closely at a common type of Bayesian model: linear regression where the outcome is normally (or Gaussian) distributed. We’ll learn how to build this model step by step, i.e., choosing priors, fitting the model with data, and interpreting the results. We’ll also talk about what kinds of posterior summaries we can get from these models, like mean, median and credible intervals.\nTo see how this compares to more traditional statistics, we’ll take a look at frequentist regression, the kind you have already learned in basic statistics courses. Both Bayesian and frequentist methods can give similar answers, but the Bayesian approach gives us more flexibility by including prior knowledge and showing results as full probability distributions instead of just single estimates and p-values.\nAfter that, we’ll focus on how to choose priors for the model, especially for the part that measures how much the data varies (the variance). Many traditional models use something called the inverse gamma prior, but it can sometimes lead to unrealistic results. Instead, we’ll try more modern and reliable options like the half-Cauchy or exponential priors, which often lead to better results and easier interpretation.\nWe’ll also explore what happens when we use different types of priors for the regression coefficients. A weakly informative prior is a gentle way of guiding the model, where it doesn’t push the results too strongly, but helps prevent extreme values. On the other hand, an informative prior gives the model stronger guidance based on expert knowledge or previous studies. We’ll compare both types and see how they affect the results.\nFinally, we’ll bring everything together by comparing Bayesian regression with informative priors to frequentist regression. We’ll see how Bayesian methods allow us to build models that learn not just from the data in front of us, but also from what we already know, something that can be very helpful in real-world problems with limited data.\nBy the end of this module, you’ll be more comfortable with building and interpreting Bayesian models, thinking about cause-and-effect, and making thoughtful choices about prior information. This will give you a strong foundation for analysing complex problems in a clear and reliable way.",
    "crumbs": [
      "**Module 3: Bayeswatch - Gaussian**"
    ]
  },
  {
    "objectID": "M03_1.html",
    "href": "M03_1.html",
    "title": "5  Logical Connections",
    "section": "",
    "text": "5.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Understand Bayesian model and causality\n– Explain the terms Estimand, Estimator & Estimate\n– Understand the difference between Bayesian and classical Regression.\n– Interpret real-life problems in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#learnings",
    "href": "M03_1.html#learnings",
    "title": "5  Logical Connections",
    "section": "",
    "text": "Outcomes\n\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#causality-and-bayesian-inference",
    "href": "M03_1.html#causality-and-bayesian-inference",
    "title": "5  Logical Connections",
    "section": "5.2 Causality and Bayesian Inference",
    "text": "5.2 Causality and Bayesian Inference\n\n\n\nA causal inference is a conclusion about a cause-and-effect relationship between two or more things. In simple terms, it’s answering the question: “Did X cause Y?” For example, if a study finds that people who drink more water tend to have better skin, causal inference would be the process of figuring out whether drinking water actually causes better skin or if that’s just a coincidence, or maybe due to some other factor (like diet or lifestyle). On the other hand, a correlation is when two things tend to happen together. It shows a relationship, but not necessarily a cause-and-effect one.\nLet’s explore with another example. We might think, people who carry lighters are more likely to get lung cancer. This means that there is an association between carrying lighters and lung cancer, but it doesn’t imply that carrying a lighter causes lung cancer. Other factors, like smoking, could be the actual cause.\n\n\n\n\n\nConcept of correlation and causation\n\n\n\n\nNow, when we conduct causal inference, we must first develop a causal model that is separate from a purely Bayesian (or statistical) model, because observational data by itself is not enough to establish causality. This idea is widely accepted across different philosophical traditions, even though interpretations of how to approach it can vary greatly.\nThe most cautious view holds that causation is fundamentally unprovable. We can take a slightly less conservative view, which holds that we are able to infer causation, but only under strict and carefully defined conditions, such as randomisation and experimental control. However, many scientific questions cannot be addressed experimentally due to feasibility constraints or ethical concerns.\nIn fields like health and medicine, we often introduce various control variables into a statistical model, observe changes in estimates, and construct a causal narrative. This approach assumes that only omitted variables can bias causal conclusions, yet even included variables can introduce confusion.\nEven if we construct a causal model that appears to make accurate predictions, it may still misrepresent causation. If we rely on such a model to guide interventions, we risk producing unintended or misleading outcomes.\nIn this course, we will not discuss causal modelling in details, and for interested readers we refer books by Pearl, Glymour, and Jewell (2016) and Hernán and Robins (2025).\n\n5.2.1 Estimand, Estimator & Estimate\n\nNow, let us learn the terms estimand, estimator, and estimate. The estimand is the quantity of interest, i.e., the true value we seek to determine. We define an estimator as the method or procedure that we impliment to mimic/get the estimand. Finally, an estimate is the result (e.g., numerical value) we obtain from applying a specific estimator to data.\nSuppose, we want to find out the average effectiveness of a vaccine for a respiratory disease among children in Australia. Our estimand is “the true average vaccine effectiveness for this respiratory disease among all children in Australia.”\nSince we can’t measure every child, we take a random sample of 10,000 children (say) and record how well the vaccine protects them from the disease. Using this data, we now need to choose an estimator, which is a method to estimate our estimand.\nThe simplest approach that we can take is to calculate the average vaccine effectiveness in our sample. In this case, the sample average acts as our estimator, providing an estimate of the true vaccine effectiveness. If our sample average shows 85% effectiveness, then 85% is our estimate based on the sample average estimator.\nNow, in a Bayesian framework, the estimand remains the same, which is the true but unknown average vaccine effectiveness among all children in Australia, that we can obtain from the true distribution of the vaccine effectiveness. However, instead of just using the sample average calculated from the 10,000 respondents/children, our estimator in the Bayesian context is the method of obtaining the posterior distribution of vaccine effectiveness. And we already know that this distribution is derived by combining prior knowledge with the likelihood of the observed data using Bayes theorem.\n\n\n5.2.2 Bayesian Regression Context\nNow, let us explain this in the context of Bayesian model, or regression problem. Considering the example explained earlier, suppose we are interested in understanding how vaccine efficacy for a respiratory-related disease among children in Australia is influenced by certain predictors, such as age, pre-existing health conditions, and socioeconomic status. In this case, our estimand is the set of true regression coefficients that describe the relationship between these predictors and vaccine efficacy.\nA perfect way to determine these coefficients would be to measure vaccine efficacy and collect all relevant predictor data (e.g., age, health conditions, and socioeconomic status) for every child in Australia and then fit a model to the entire population data. However, this is practically infeasible. Instead, we can estimate the regression coefficients using a sample observation, and as we have already mentioned, we can take a random sample of 10,000 children in Australia and collect data on their vaccine efficacy and the relevant predictors. Using this data, we fit a Bayesian model (e.g., a Bayesian linear regression model) to estimate the relationship between the predictors and vaccine efficacy.\nIn the Bayesian framework, we approach this problem by starting with a prior distribution for each regression coefficient, reflecting our prior beliefs about the relationships. For example, based on previous studies, we might believe that younger children have slightly lower vaccine efficacy and use this belief into the prior.\nThe sample data provides the likelihood, representing the probability of observing the data given different values of the regression coefficients. By applying Bayes theorem, we combine the prior with the likelihood to produce a posterior distribution for each regression coefficient. The posterior distributions represent our updated beliefs about the coefficients after observing the data.\nFor example, when considering the outcome variable on a continuous scale (i.e., without any transformation), if the posterior mean for the age coefficient is -0.5, it suggests that, on average, each additional year of age is associated with a 0.5 percentage point decrease in vaccine efficacy. Similarly, if the posterior mean for the socioeconomic status coefficient is 2.0, it suggests that higher socioeconomic status is associated with a 2 percentage point increase in vaccine efficacy.\nHere, estimand is the true regression coefficients that describe the relationships between the predictors and vaccine efficacy. Estimator is the posterior distributions of the regression coefficients that we get based on the Bayesian model. These distributions summarise the uncertainty about the coefficients. And estimate is the specific value derived from the posterior distributions, such as the posterior mean, median, or mode for each coefficient.\nThis Bayesian approach allows us not only to estimate the coefficients but to quantify our uncertainty about them, providing a more comprehensive understanding of the predictor influences on vaccine efficacy.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-development---gaussian-context",
    "href": "M03_1.html#model-development---gaussian-context",
    "title": "5  Logical Connections",
    "section": "5.3 Model Development - Gaussian Context",
    "text": "5.3 Model Development - Gaussian Context\n\n\nWe have discussed about Directed Acyclic Graph (DAG) in one of our previous lectures. Today we will explain DAG for conceptualising and developing Bayesian regression models. It also helps to visually represent any potetntial causal relationships among variables and ensures proper adjustment for confounding factors.\nNow we explain this more with an example related to Bone Mineral Density (BMD) measured in \\(g/cm^2\\). For example, we want to know, how does body mass index (BMI) impact bone mineral density (BMD)?\nHere, we are trying to model the relationship between BMI (independent or exposure variable) and BMD (dependent or outcome or endpoint variable). Thus can draw the DAG as:\n\n\n\n\n\n\nIn a Bayesian context, we need to define the likelihood of observing the data given certain parameters and then combine that with a prior belief about those parameters.\n\n5.3.1 Likelihood, Prior and Posterior\nLet’s identify the likelihood and priors for the example:\nBMD is modeled as a random variable that follows a normal distribution:\n\\[\n\\text{BMD} \\sim N(\\mu, \\sigma^2)\n\\]\nThis notation means that for each observed value of BMD, the values are assumed to come from a normal distribution with mean \\(\\mu\\), which is the location of the distribution and variance \\(\\sigma^2\\), which indicates the spread or uncertainty around the mean.\nWe can now model the mean of the BMD as a function of the exposure variable, BMI. That is, the mean \\(\\mu\\) of BMD is determined by a linear relationship with BMI:\n\\[\n\\mu = \\beta_0 + \\beta_1 \\cdot \\text{BMI}\n\\]\nwhere, \\(\\beta_0\\) is the intercept term, which is the expected BMD when BMI is zero, and \\(\\beta_1\\) is the slope term, which indicates the change in BMD per unit change in BMI.\nSo, the likelihood function tells us how probable it is to observe the given BMD data, given specific values for the parameters \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2\\).\nNow, let’s define the prior distributions for the model parameters:\n\\[\n\\beta_0 \\sim N(\\mu_0, \\sigma_0^2)\n\\]\nThis states that \\(\\beta_0\\) follows a normal distribution with mean \\(\\mu_0\\) and variance \\(\\sigma_0^2\\). The prior for \\(\\beta_0\\) could represent our belief about the intercept term before observing the data. For instance, if we think that \\(\\beta_0\\) (the baseline BMD when BMI is 0) should be close to 0, then we would choose \\(\\mu_0 = 0\\), with some reasonable uncertainty \\(\\sigma_0^2\\).\n\\[\n\\beta_1 \\sim N(\\mu_1, \\sigma_1^2)\n\\]\nThis states that \\(\\beta_1\\), the effect of BMI on BMD, is also normally distributed with a mean of \\(\\mu_1\\) and variance \\(\\sigma_1^2\\). In this case, \\(\\mu_1\\) reflects our prior belief about the effect of BMI on BMD, and \\(\\sigma_1^2\\) reflects the uncertainty about that effect.\n\\[\n\\sigma^2 \\sim \\text{IG}(a, b)\n\\]\nThis represents the prior belief about the variance of the error terms (the variability in BMD not explained by BMI). It is modeled using an Inverse Gamma distribution, which is a conjugate prior distribution and denoted as $ (a, b)$, where: \\(a\\) is a shape parameter, and \\(b\\) is a scale parameter.\nThe inverse gamma distribution is commonly used for modelling variance parameters because it is from a conjugate family and produces positive values and can model both large and small variances.\nOnce we have the likelihood (how the data are distributed given the parameters) and the priors (our initial beliefs about the parameters), we can easily get the posterior distribution and in this case, the posterior distribution for the parameters \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2\\). This is proportional to:\n\\[\np(\\beta_0, \\beta_1, \\sigma^2 | \\text{BMD}, \\text{BMI}) \\propto p(\\text{BMD} | \\beta_0, \\beta_1, \\sigma^2) \\cdot p(\\beta_0) \\cdot p(\\beta_1) \\cdot p(\\sigma^2)\n\\]\nGiven the joint posterior distribution, we can write the full conditional distributions for parameters \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma^2\\) as:\n\\[\np(\\beta_0 \\mid \\beta_1, \\sigma^2, \\text{BMD}, \\text{BMI}) \\propto N(\\text{BMD} \\mid \\beta_0 + \\beta_1 \\cdot \\text{BMI}, \\sigma^2) \\cdot N(\\beta_0 \\mid \\mu_0, \\sigma_0^2)\n\\]\nThis is the product of a likelihood and a normal prior, so the conditional posterior is also normal:\n\\[\n\\beta_0 \\mid \\cdot \\sim N(\\mu_{\\beta_0}^*, \\sigma_{\\beta_0}^{2*})\n\\]\nWhere:\n\\[\n\\sigma_{\\beta_0}^{2*} = \\left( \\frac{n}{\\sigma^2} + \\frac{1}{\\sigma_0^2} \\right)^{-1}; \\quad \\mu_{\\beta_0}^* = \\sigma_{\\beta_0}^{2*} \\left( \\frac{1}{\\sigma^2} \\sum_{i=1}^n (\\text{BMD}_i - \\beta_1 \\text{BMI}_i) + \\frac{\\mu_0}{\\sigma_0^2} \\right)\n\\]\nNow, the conditional distribution for \\(\\beta_1\\):\n\\[\np(\\beta_1 \\mid \\beta_0, \\sigma^2, \\text{BMD}, \\text{BMI}) \\propto N(\\text{BMD} \\mid \\beta_0 + \\beta_1 \\cdot \\text{BMI}, \\sigma^2) \\cdot N(\\beta_1 \\mid \\mu_1, \\sigma_1^2)\n\\]\nHence, the full conditional is normal:\n\\[\n\\beta_1 \\mid \\cdot \\sim N(\\mu_{\\beta_1}^*, \\sigma_{\\beta_1}^{2*})\n\\]\nWhere:\n\\[\n\\sigma_{\\beta_1}^{2*} = \\left( \\frac{\\sum \\text{BMI}_i^2}{\\sigma^2} + \\frac{1}{\\sigma_1^2} \\right)^{-1}; \\quad \\mu_{\\beta_1}^* = \\sigma_{\\beta_1}^{2*} \\left( \\frac{1}{\\sigma^2} \\sum \\text{BMI}_i (\\text{BMD}_i - \\beta_0) + \\frac{\\mu_1}{\\sigma_1^2} \\right)\n\\]\nNow, we can write the Conditional distribution for \\(\\sigma^2\\) as:\n\\[\np(\\sigma^2 \\mid \\beta_0, \\beta_1, \\text{BMD}, \\text{BMI}) \\propto N(\\text{BMD} \\mid \\beta_0 + \\beta_1 \\cdot \\text{BMI}, \\sigma^2) \\cdot \\text{IG}(a, b)\n\\]\nCombining the likelihood (Gaussian) and Inverse Gamma prior, the full conditional is also Inverse Gamma:\n\\[\n\\sigma^2 \\mid \\cdot \\sim \\text{IG} \\left(a + \\frac{n}{2},\\ b + \\frac{1}{2} \\sum_{i=1}^n (\\text{BMD}_i - \\beta_0 - \\beta_1 \\text{BMI}_i)^2 \\right)\n\\]\n\n\n5.3.2 Bayesian DAG\nBy using these information in the above example, we write DAG for the Bayesian model as:\n\n\n\n\n\n\nHere, circles represent variables, while squares denote model parameters and hyperparameters. We can also present the DAG in a more visually informative form below, including the hyperparameters along with their corresponding distributions.\n\n\n\n\n\n\nNow, let’s break down the concepts of estimand, estimator, and estimate using the Bayesian model represented by the DAG. In this example, the estimand is the quantity or parameter that we aim to estimate from the data, i.e., here the estimands are the parameters we want to infer, \\(\\beta_0\\) (intercept), \\(\\beta_1\\) (slope), and \\(\\sigma^2\\) (variance). Now, estimator is the method we are using, i.e., the Bayesian model with MCMC method to get the posterior distributions of the parameters \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma^2\\). In this Bayesian modelling framework, the estimates are the specific values derived from the posterior distributions of the parameters. For example, the mean or median of the posterior distribution of \\(\\beta_0\\) could be an estimate of the intercept. Similarly, the mean or median of the posterior distribution of \\(\\beta_1\\) could be an estimate of the slope.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#model-baesd-results",
    "href": "M03_1.html#model-baesd-results",
    "title": "5  Logical Connections",
    "section": "5.4 Model-Baesd Results",
    "text": "5.4 Model-Baesd Results\n\n\n\n5.4.1 Priors\nWe consider the following prior distributions for the model parameters. Say, we do not know any previous information at the baseline for BMD ( i.e., intercept). Suppose, we do not have any knowledge about the effect of BMI on BMD. Hence, we can consider \\(\\beta_0,\\beta_1 \\sim N(0, 10^2)\\). Furthermore, let us assume the the variance parameter follows inverse-gamma distribution with hyper-parameters \\(a=2\\) and \\(b=1\\).\nThe prior structure we use follows a pattern of weakly informative priors. These help with regularisation by gently pulling parameter estimates toward zero, unless the data provide strong evidence for a large effect. This also helps avoid overestimating effects, a problem sometimes known as the winner’s curse.\nHence, following this structure, we can draw the prior distributions as follows:\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(invgamma)  \n\nx_norm &lt;- seq(-40, 40, length.out = 500)\nnormal_density &lt;- dnorm(x_norm, mean = 0, sd = 10)\ndf_beta &lt;- tibble(\n  x = x_norm,\n  density = normal_density\n)\np1 &lt;- ggplot(df_beta, aes(x, density)) +\n  geom_line(color = \"steelblue\", size = 1.2) +\n  labs(\n    title = expression(\"Prior for \" ~ beta[0]),\n    x = expression(beta[0]),\n    y = \"Density\"\n  ) +\n  theme_minimal()\np2 &lt;- ggplot(df_beta, aes(x, density)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  labs(\n    title = expression(\"Prior for \" ~ beta[1]),\n    x = expression(beta[1]),\n    y = \"Density\"\n  ) +\n  theme_minimal()\nx_sigma2 &lt;- seq(0.001, 5, length.out = 500)\nsigma2_density &lt;- dinvgamma(x_sigma2, shape = 2, rate = 1)\ndf_sigma2 &lt;- tibble(\n  x = x_sigma2,\n  density = sigma2_density\n)\np3 &lt;- ggplot(df_sigma2, aes(x, density)) +\n  geom_line(color = \"firebrick\", size = 1.2) +\n  labs(\n    title = expression(\"Prior for \" ~ sigma^2),\n    x = expression(sigma^2),\n    y = \"Density\"\n  ) +\n  theme_minimal()\n# Combine all three plots\n(p1 | p2 | p3) + plot_annotation(title = \"Prior Distributions\")\n\n\n\n\n\n\n\n\n\nNow, we use these prior distributions to obtain the posterior distributions for the model parameters. We use R package “brms” to impliment the Bayesian model.\nNote that not all R packages (such as brms) have the option to use the inverse Gamma distribution directly in the R front-end function. We could avoid using Bayesian R packages and write individual Stan code to include the Inverse Gamma prior, but at this stage, that is beyond the scope of this course. Writing in Stan requires a strong understanding of mathematical coding, which may not be suitable for the general audience or students taking this course. Having said that, we encourage interested readers or students to stay in touch with the course coordinator for a deeper dive into writing core Stan code.\nNow, a simple solution related to the issue of inverse Gamma distribution is to use a distribution that approximates the inverse Gamma, and here Student’s t-distribution can be a good candidate for such distribution. While they are not equivalent, under certain conditions they can be closely approximated. Now, if\n\\[\n\\sigma^2 \\sim \\text{IG}(a, b), \\quad x \\mid \\sigma^2 \\sim N(0, \\sigma^2)\n\\]\nthen marginally,\n\\[\nx \\sim \\text{Student-}t_{(\\nu = 2a)}\\left(0, \\sqrt{\\frac{b}{a}}\\right)\n\\]\nThat is, we can approximate by considering:\n\nDegrees of freedom: \\(\\nu = 2a\\)\nLocation: \\(\\mu=0\\) (for variance parameter we restrict it to the \\(\\mathbb{R}^+\\))\nScale: \\(\\sqrt{\\frac{b}{a}}\\)\n\nNow, for \\(\\text{IG}(a=2,b=1)\\), we get the approximation as: \\(\\text{Student-t}(4,0,0.7)\\). Although, in practice, we have seen that for \\(\\sigma\\), use of \\(\\text{Student-t}(3,0,1)\\) is often a popular choice for the prior.\nHence, in this course, we will use Student-t distribution instead of the inverse Gamma to represnt the prior distribution for the Bayesian regression coefficient. Note that, in our next lecture, we will also discuss some other possible candidates for the prior distributions.\nNow, we can draw the prior distribution plots for inverse Gamma and Student-t distributions with different hyper-parmaters as follows:\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nig_density &lt;- function(alpha, beta, x) {\n  return(dgamma(1 / x, shape = alpha, rate = beta) / (x^2))  \n}\np1 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n  stat_function(fun = function(x) ig_density(2, 1, x), col = \"red\", lwd = 2) +\n  labs(y = \"Density\", x = expression(sigma), \n       title = \"Inverse-Gamma(2, 1)\") +\n  theme_minimal()\np2 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n     stat_function(fun = function(x) ig_density(1.5, 1.5, x), col = \"red\", lwd = 2) +\n     labs(y = \"Density\", x = expression(sigma), \n          title = \"Inverse-Gamma(1.5, 1.5)\") +\n     theme_minimal()\np3 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n  stat_function(fun = function(x) dt(x / 0.707, df = 4) / 1, col = \"blue\", lwd = 2) +\n  labs(y = \"Density\", x = expression(sigma), \n       title = \"Student-t(4, 0, 0.707)\") +\n  theme_minimal()\np4 &lt;- ggplot(data.frame(x = seq(0.001, 20, length.out = 1000)), aes(x = x)) +\n  stat_function(fun = function(x) dt(x / 1, df = 3) / 1, col = \"blue\", lwd = 2) +\n  labs(y = \"Density\", x = expression(sigma), \n       title = \"Student-t(3, 0, 1)\") +\n  theme_minimal()\ngrid.arrange(p1, p2, p3, p4, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n5.4.2 Posteriors\nWe fit the model using the brms package with a single MCMC chain and 2000 iterations. While this example uses one chain, multiple chains can also be specified. Note that for \\(\\sigma\\), we use Student-t prior distribution with degrees of freedom \\(\\nu = 3\\) and scale 1. Finally, we obtain a summary of the posterior distributions for the model parameters as follows:\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_restricted.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data &lt;- tibble(\n  BMD = bmd_data$bmd,\n  BMI = bmd_data$bmi,\n)\n# model\nbmd_model &lt;- brm(\n  formula = BMD ~ BMI,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"BMI\"),   # N(mean, sd) Slope priors\n    prior(normal(0, 10), class = \"Intercept\"),   # N(mean, sd) Intercept prior\n    prior(student_t(3, 0, 1), class = \"sigma\")  \n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.039 seconds (Warm-up)\nChain 1:                0.024 seconds (Sampling)\nChain 1:                0.063 seconds (Total)\nChain 1: \n\n\nCode\nsummary(bmd_model)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI \n   Data: bmd_data (Number of observations: 169) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.42      0.07     0.29     0.55 1.00     1302      852\nBMI           0.01      0.00     0.01     0.02 1.00     1317      852\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.16      0.01     0.14     0.17 1.00      719      614\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\n#posterior_summary(bmd_model)\n#plot(bmd_model)\n\n\nThe Bayesian model output indicates that the estimated intercept is 0.42, representing the expected BMD when BMI is zero, a value that isn’t realistic but is standard when interpreting linear models. The coefficient for BMI is 0.01, suggesting that for every one-unit increase in BMI, BMD increases by approximately 0.01 units on average. The 95% credible interval for this estimate ranges from 0.01 to 0.02, providing strong evidence that the effect of BMI on BMD is positive. The residual standard deviation (noise not explained by BMI) is estimated at 0.16 with a tight credible interval.\n\n\n5.4.3 MCMC Diagnostics\nWe see that the convergence diagnostics are excellent, with Rhat values equal to 1.00, showing that the MCMC chains have mixed well. Additionally, the Bulk Effective Sample Size (Bulk_ESS) and Tail Effective Sample Size (Tail_ESS) are both comfortably above 500. ESS values should ideally be over 400–500 for each parameter. Lower ESS suggests that the model might need more iterations or better mixing. The results indicate that the posterior estimates are based on a sufficient number of effective samples and can be considered stable and reliable.\nBelow we provide the histogram and trace plots related to the posterior distributions of the model parameters. We also provide the autocorrelation plot and posterior predictive check based on the posterior distributions.\n\n\nCode\nplot(bmd_model)\n\n\n\n\n\n\n\n\n\nCode\npost_samples &lt;- as.array(bmd_model)\n#acf(post_samples[, , \"b_Intercept\"], main = \"Autocorrelation: Intercept\")\nacf(post_samples[, , \"b_BMI\"], main = \"Autocorrelation: BMI\")\n\n\n\n\n\n\n\n\n\nCode\npp_check(bmd_model)\n\n\n\n\n\n\n\n\n\nThe trace plots show a well-mixed pattern for the MCMC samples. Similarly, we can see that the autocorrelation is low after a few iterations, i.e., the chains are well-mixed. Finally, the posterior predictive check provides further indication that the distribution match with the replications.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#bayesian-vs.-frequentist-comparisons",
    "href": "M03_1.html#bayesian-vs.-frequentist-comparisons",
    "title": "5  Logical Connections",
    "section": "5.5 Bayesian vs. Frequentist Comparisons",
    "text": "5.5 Bayesian vs. Frequentist Comparisons\n\n\nNow, let us compare the posterior distributions we obtained from the Bayesian model with the estimates from frequentist linear regression model.\n\n\nCode\nlibrary(jtools)\nlm_model &lt;- lm(BMD ~ BMI, data = bmd_data)\njtools::summ(lm_model)\n\n\nMODEL INFO:\nObservations: 169\nDependent Variable: BMD\nType: OLS linear regression \n\nMODEL FIT:\nF(1,167) = 27.98, p = 0.00\nR² = 0.14\nAdj. R² = 0.14 \n\nStandard errors:OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.42   0.07     6.11   0.00\nBMI                 0.01   0.00     5.29   0.00\n-----------------------------------------------\n\n\nCode\nlm_coef &lt;- coef(summary(lm_model))\nbmi_est &lt;- lm_coef[\"BMI\", \"Estimate\"]\nbmi_se &lt;- lm_coef[\"BMI\", \"Std. Error\"]\nci_low &lt;- bmi_est - 1.96 * bmi_se\nci_high &lt;- bmi_est + 1.96 * bmi_se\n\npost &lt;- as_draws_df(bmd_model)\npost_bmi &lt;- post$b_BMI\nbayes_mean &lt;- mean(post_bmi)\nbayes_ci &lt;- quantile(post_bmi, probs = c(0.025, 0.975))\n\np &lt;- ggplot() +\n  geom_density(aes(x = post_bmi), fill = \"skyblue\", alpha = 0.5, color = NA) +\n  geom_vline(xintercept = bmi_est, color = \"red\", size = 1) +\n  geom_vline(xintercept = ci_low, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = ci_high, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = bayes_mean, color = \"blue\", size = 1) +\n  geom_vline(xintercept = bayes_ci[1], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  geom_vline(xintercept = bayes_ci[2], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  labs(\n    title = \"Bayesian vs Frequentist Estimate of BMI\",\n    subtitle = \"Red: Frequentist (Mean & 95% Confidence Interval)\\nBlue: Bayesian (Posterior Mean & 95% Credible Interval)\",\n    x = \"Coefficient for BMI\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        plot.subtitle = element_text(size = 12))\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\n\nThe graph compares our Bayesian and frequentist estimates of the BMI coefficient. The x-axis shows the BMI coefficient, and the y-axis shows the density. For the Bayesian estimate, we use a blue shaded area, with a solid blue vertical line representing the posterior mean, and the shaded area showing the 95% credible interval. For the frequentist estimate, we use two red dashed vertical lines to mark the maximum likelihood estimate (MLE) and the 95% confidence interval. This comparison helps us see the differences in how we estimate the BMI coefficient and the uncertainty in each method.\nIn our next lecture, we will look at how different types of prior distributions affect the posterior in a Bayesian hierarchical model, and how these results differ from those in the frequentist approach.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#summary",
    "href": "M03_1.html#summary",
    "title": "5  Logical Connections",
    "section": "5.6 Summary",
    "text": "5.6 Summary\nToday’s lecture focused on understanding the relationship between causality and Bayesian inference, and how we can clearly distinguish between estimators, estimands, and estimates. We explored Bayesian linear regression in detail, highlighting its key differences compared to frequentist regression.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#live-tutorial-and-discussion",
    "href": "M03_1.html#live-tutorial-and-discussion",
    "title": "5  Logical Connections",
    "section": "5.7 Live tutorial and discussion",
    "text": "5.7 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#tutorial-exercises",
    "href": "M03_1.html#tutorial-exercises",
    "title": "5  Logical Connections",
    "section": "5.8 Tutorial Exercises",
    "text": "5.8 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#preparation-for-week-6",
    "href": "M03_1.html#preparation-for-week-6",
    "title": "5  Logical Connections",
    "section": "5.9 Preparation for Week 6",
    "text": "5.9 Preparation for Week 6\nIn week 5 you will be required to .\n\n\n\n\nHernán, M, and J Robins. 2025. Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P Jewell. 2016. Causal Inference in Statistics: A Primer. John Wiley & Sons.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M03_2.html",
    "href": "M03_2.html",
    "title": "6  Prior Tweaks and More",
    "section": "",
    "text": "6.1 Learnings\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.\n– LO4: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Understand different aspects of prior distributions for variance parameter.\n– Explain which prior to use for Bayesian model with multiple variables.\n– Compare Bayesian and frequentist models.\n– Interpret real-life problems in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#learnings",
    "href": "M03_2.html#learnings",
    "title": "6  Prior Tweaks and More",
    "section": "",
    "text": "Outcomes\n\n\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#prior-options",
    "href": "M03_2.html#prior-options",
    "title": "6  Prior Tweaks and More",
    "section": "6.2 Prior Options",
    "text": "6.2 Prior Options\nIn our previous lecture, using Bayesian model, we explained the effect of body mass index (BMI) on bone mineral density (BMD). We used weakly informative prior, and we discussed in one of our previous lectures that use of weakly informative priors are common in modern Bayesian modeling, as it balances interpretability and robustness of the posterior distribution. Now, we will explain how different types of prior distributions can be used for the model variance and slope parameters.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#bayesian-vs.-frequentist-comparisons",
    "href": "M03_2.html#bayesian-vs.-frequentist-comparisons",
    "title": "6  Prior Tweaks and More",
    "section": "6.3 Bayesian vs. Frequentist Comparisons",
    "text": "6.3 Bayesian vs. Frequentist Comparisons\n\n\nNow we explain and compare the Bayesian and frequentist estimates, where we use informative prior distribution, i.e., \\(\\beta_1\\sim N(0.05,0.01)\\).\n\n\nCode\nlibrary(jtools)\nlm_model &lt;- lm(BMD ~ BMI, data = bmd_data)\njtools::summ(lm_model)\n\n\nMODEL INFO:\nObservations: 169\nDependent Variable: BMD\nType: OLS linear regression \n\nMODEL FIT:\nF(1,167) = 27.98, p = 0.00\nR² = 0.14\nAdj. R² = 0.14 \n\nStandard errors:OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.42   0.07     6.11   0.00\nBMI                 0.01   0.00     5.29   0.00\n-----------------------------------------------\n\n\nCode\nlm_coef &lt;- coef(summary(lm_model))\nbmi_est &lt;- lm_coef[\"BMI\", \"Estimate\"]\nbmi_se &lt;- lm_coef[\"BMI\", \"Std. Error\"]\nci_low &lt;- bmi_est - 1.96 * bmi_se\nci_high &lt;- bmi_est + 1.96 * bmi_se\n\npost &lt;- as_draws_df(bmd_model_inform)\npost_bmi &lt;- post$b_BMI\nbayes_mean &lt;- mean(post_bmi)\nbayes_ci &lt;- quantile(post_bmi, probs = c(0.025, 0.975))\n\nggplot() +\n  geom_density(aes(x = post_bmi), fill = \"skyblue\", alpha = 0.5, color = NA) +\n  geom_vline(xintercept = bmi_est, color = \"red\", size = 1) +\n  geom_vline(xintercept = ci_low, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = ci_high, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = bayes_mean, color = \"blue\", size = 1) +\n  geom_vline(xintercept = bayes_ci[1], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  geom_vline(xintercept = bayes_ci[2], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  labs(\n    title = \"Bayesian (informative) vs Frequentist Estimate of BMI\",\n    subtitle = \"Red: Frequentist (Mean & 95% Confidence Interval)\\nBlue: Bayesian (Posterior Mean & 95% Credible Interval)\",\n    x = \"Coefficient for BMI\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        plot.subtitle = element_text(size = 12))\n\n\n\n\n\n\n\n\n\nThe above plot shows the estimates of the BMI coefficient (\\(\\beta_1\\)) for BMD using both frequentist and Bayesian methods. On the x-axis, we see the coefficient for BMI, ranging from approximately 0.008 to 0.024, while the y-axis represents density, showing the distribution of the estimates.\nIn Bayesian inference, the blue shaded area represents our posterior distribution of \\(\\beta_1\\), which incorporates both prior information and observed data. The vertical blue solid line indicates our Bayesian posterior mean, and the vertical blue dashed lines show the 95% credible interval. This interval represents the range within which \\(\\beta_1\\) lies with 95% probability, given our prior and the data. The Bayesian approach provides a more nuanced estimate that reflects both our prior beliefs and the observed data, resulting in a posterior distribution that can be more or less spread out depending on the prior and the data.\nWhereas, the frequentist approach relies solely on the observed data to provide point estimates and confidence intervals. The vertical red solid line represents our Frequentist maximum likelihood estimate (MLE) of \\(\\beta_1\\), and the vertical red dashed lines show the 95% confidence interval. This interval represents the range within which \\(\\beta_1\\) would lie in 95% of repeated samples, assuming the true value is fixed. The Frequentist estimate does not incorporate any prior information and is based solely on the variability in the observed data.\nThe key difference highlighted by this plot is how each method estimates and interprets \\(\\beta_1\\). Our Bayesian credible interval can be narrower due to the influence of the informative prior, suggesting that prior information has influenced the estimate. In contrast, the Frequentist confidence interval is based only on the observed data and may be wider or narrower depending on the sample size and variability. This plot emphasizes our Bayesian approach’s ability to incorporate prior knowledge, resulting in a more informed and potentially more precise estimate of \\(\\beta_1\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#further-model-development---gaussian-context",
    "href": "M03_2.html#further-model-development---gaussian-context",
    "title": "6  Prior Tweaks and More",
    "section": "6.4 Further Model Development - Gaussian Context",
    "text": "6.4 Further Model Development - Gaussian Context\n\n\nFollowing the BMD example, where we explore the influence of BMI on BMD. Now, we might want to ask: What role does ‘Age’ or ‘Sex’ of the patient play in this relationship?\nAs people age, their BMD naturally decreases over time, and age also influences factors like BMI. Similarly, sex affects both BMI and BMD, with women being more likely to experience a decline in BMD, particularly in conditions like osteoporosis. These factors age and sex may act as confounders, influencing both BMI and BMD. Hence, we write the DAG using these variables:\n\n\n\n\n\n\n\nIn this case, the estimand is the specific effect of BMI on BMD, while accounting for the influence of age and sex as confounders. The goal is to isolate the effect of BMI on BMD after adjusting for these other variables.\nThe estimator we define here is the Bayesian model, i.e., the Bayesian multiple linear regression model with posterior distributions for the model parameters. This model adjusts for confounders like age and sex, helping us to estimate the causal effect of BMI on BMD.\nThe estimate is the numerical value, such as mean or median derived from the posterior distribution using the chosen estimator. For example, if the posterior mean estimate is 0.03, this could represent the change in BMD associated with a one-unit increase in BMI, after accounting for the effects of age and sex.\n\n6.4.1 Bayesian Model Development\nWe now develop the Bayesian model with all these four variables. Hence, we write the Bayesian model as:\n\\[\n\\text{BMD}_i \\sim N(\\beta_0 + \\beta_1 \\cdot \\text{BMI}_i + \\beta_2 \\cdot \\text{Age}_i + \\beta_3 \\cdot \\text{Sex}_i, \\sigma^2)\n\\]\nWhere, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the coefficient for BMI, \\(\\beta_2\\) is the coefficient for Age, \\(\\beta_3\\) is the coefficient for Sex (with a reference category; for example, if Sex is binary, it could be “Male” vs. “Female”). This model also includes the variance \\(\\sigma^2\\) of the error term. Now, assuming weakly informative prior we write:\n\n\\(\\beta_0 \\sim N(0, 10^2)\\)\n\\(\\beta_1 \\sim N(0, 10^2)\\)\n\\(\\beta_2 \\sim N(0, 10^2)\\)\n\\(\\beta_3 \\sim N(0, 10^2)\\)\n\\(\\sigma^2 \\sim \\text{Half-Cauchy}(0, 1)\\)\n\nNote that the model equation can be also written as:\n\\[\n\\text{BMD}_i = \\beta_0 + \\beta_1 \\cdot \\text{BMI}_i + \\beta_2 \\cdot \\text{Age}_i + \\beta_3 \\cdot \\text{Sex}_i + \\epsilon_i\n\\]\nwhere, \\(\\epsilon_i\\) is the error term of the model.\nHence, we draw the DAG for this Bayesian model with prior and hyper-prior parameters as:\n\n\n\n\n\n\n\n\n6.4.2 R Code Example\nNow, we implement the Bayesian hierarchical model for this DAG, where we use weakly-informative priors for the model parameters.\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_restricted.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data &lt;- tibble(\n  BMD = bmd_data$bmd,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\nbmd_model_multi &lt;- brm(\n  formula = BMD ~ BMI + Age + Sex,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"BMI\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"b\", coef = \"Age\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"b\", coef = \"SexM\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"Intercept\"), # N(mean, sd)\n    prior(cauchy(0, 1), class = \"sigma\")  # Half-Cauchy prior for sigma\n    ),  \n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.57 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.135 seconds (Warm-up)\nChain 1:                0.093 seconds (Sampling)\nChain 1:                0.228 seconds (Total)\nChain 1: \n\n\nCode\n#prior_summary(bmd_model_multi, all = FALSE)\nprint(prior_summary(bmd_model_multi, all = FALSE), show_df = FALSE)\n\n\nb_Age ~ normal(0, 10)\nb_BMI ~ normal(0, 10)\nb_SexM ~ normal(0, 10)\nIntercept ~ normal(0, 10)\n&lt;lower=0&gt; sigma ~ cauchy(0, 1)\n\n\nCode\nprint(summary(bmd_model_multi), digits=3)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI + Age + Sex \n   Data: bmd_data (Number of observations: 169) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nIntercept    0.604     0.083    0.441    0.765 1.001     1168      803\nBMI          0.016     0.002    0.011    0.020 1.001     1071      536\nAge         -0.004     0.001   -0.006   -0.003 1.004     1128      692\nSexM         0.095     0.021    0.054    0.134 1.003      654      613\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nsigma    0.139     0.008    0.125    0.155 1.001      574      579\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe can exlain the posterior estimates of the model parameters from the Bayesian model as follows:\n\n\n\n\n\n\n\n\n\nPredictor\nMean (95% Credible Interval)\nRhat\nExplanation\n\n\n\n\nBMI\n0.016 (0.010, 0.021)\n1.003\nA 1-unit increase in BMI is associated with a 0.016 unit increase in BMD, holding other variables constant. This is a small but credible positive effect.\n\n\nAge\n-0.004 (-0.006, -0.003)\n1.002\nEach additional year of age is associated with a 0.004 unit decrease in BMD, suggesting a consistent age-related decline.\n\n\nSex (Male)\n0.095 (0.050, 0.139)\n1.002\nMales have on average 0.095 units higher BMD than females, adjusting for BMI and age. This reflects a moderate and credible sex difference in BMD.\n\n\n\\(\\sigma\\)\n0.139 (0.124, 0.154)\n0.999\nRepresents residual variability in BMD not explained by BMI, age, or sex. The relatively small value suggests a good overall model fit.\n\n\n\nWe can also observe that all \\(\\hat{R}\\) values are \\(\\approx\\) 1.00, i.e., convergence is excellent. The Bulk and Tail ESS values are all \\(&gt;600\\), i.e., sufficient posterior sample size and good mixing of chains.\nTrace Plots\n\n\nCode\nplot(bmd_model_multi)\n\n\n\n\n\n\n\n\n\nCode\n#library(bayesplot)\n#library(brms)\n#posterior &lt;- as_draws_df(bmd_model_multi)\n#mcmc_areas(\n#  posterior,\n#  pars = c(\"b_BMI\", \"b_Age\", \"b_SexM\"),\n#  prob = 0.95  # 95% credible intervals\n#)\n#mcmc_trace(\n#  posterior,\n#  pars = c(\"b_Intercept\", \"b_BMI\", \"b_Age\", \"b_SexM\")\n#)\n\n\nTrace plots for the MCMC samples also shows a nice mixing and density (histogram) plots also shows a normal distributional shape, confirms a good MCMC mixing for the model parameters.\nConditional Effects\nWe can also plot the conditional effects of the predictor variables BMI, Age and Sex. Here, conditional effects refer to the effect of say BMI on BMD considering other variables (i.e., Age and Sex) fixed and so on for Age and Sex.\n\n\nCode\n#plot(conditional_effects(bmd_model_multi, effects = \"BMI\"), points = TRUE)\n#plot(conditional_effects(bmd_model_multi, effects = \"Age\"), points = TRUE)\n#plot(conditional_effects(bmd_model_multi, effects = \"Sex\"))\n\nce &lt;- conditional_effects(bmd_model_multi)\np1 &lt;- plot(ce, effects = \"BMI\", plot = FALSE, points = TRUE)[[1]]\np2 &lt;- plot(ce, effects = \"Age\", plot = FALSE, points = TRUE)[[2]]\np3 &lt;- plot(ce, effects = \"Sex\", plot = FALSE)[[3]]\n#library(patchwork)\n#combined_plot &lt;- p1 + p2 + p3  # 1 row # OR use / to stack vertically: combined_plot &lt;- p1 / p2 / p3\n#combined_plot\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, ncol = 3)\n\n\n\n\n\n\n\n\n\nIn the first plot, we see a positive trend, as BMI increases, BMD also tends to go up. The shaded area around the line shows the uncertainty, or the range where the true trend is likely to fall. The second plot shows a negative trend with Age, meaning that as people get older, their BMD tends to decrease. In the third plot, we compare BMD between males and females. We can see that males tend to have higher BMD than females. The vertical lines (error bars) show how much BMD varies within each group.\npredictive checks\nWe can also look at the posterior predictive plot to see how well the model fits the data. As we have discussed in one of the previous lectures, if the plot looks similar to the actual data, that means the model is doing a good job. But if the predicted values are too spread out, too narrow, or miss important patterns, we might need to adjust the model by adding better predictors, transforming variables, or trying a different type of model.\n\n\nCode\n# Posterior predictive check\n#pp_check(bmd_model_multi)\n#pp_check(bmd_model_multi, type = \"hist\")\n#pp_check(bmd_model_multi, type = \"boxplot\")\n#pp_check(bmd_model_multi, type = \"scatter_avg\")\n#pp_check(bmd_model_multi, type = \"ecdf_overlay\")\n\n#library(patchwork)\np1 &lt;- pp_check(bmd_model_multi)\np2 &lt;- pp_check(bmd_model_multi, type = \"ecdf_overlay\")\n#combined_plot &lt;- p1 + p2 \n#combined_plot\nlibrary(gridExtra)\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nFrom the above plots, we can see that the replications in the posterior predictive plot of BMD match the actual observed BMD.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#summary",
    "href": "M03_2.html#summary",
    "title": "6  Prior Tweaks and More",
    "section": "6.7 Summary",
    "text": "6.7 Summary\nToday’s lecture focused on understanding priors in Bayesian regression, specifically for variance and the coefficients. We discussed weakly-informative and informative priors for \\(\\beta_1\\), and their implications in modeling. A comparison between Bayesian and frequentist approaches was made, particularly in the context of using an informative prior for \\(\\beta_1\\). Finally, we explored how to further develop the model to better understand exposure and confounders, and how these can be incorporated into a Bayesian regression framework.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#live-tutorial-and-discussion",
    "href": "M03_2.html#live-tutorial-and-discussion",
    "title": "6  Prior Tweaks and More",
    "section": "6.8 Live tutorial and discussion",
    "text": "6.8 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#tutorial-exercises",
    "href": "M03_2.html#tutorial-exercises",
    "title": "6  Prior Tweaks and More",
    "section": "6.9 Tutorial Exercises",
    "text": "6.9 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#preparation-for-week-7",
    "href": "M03_2.html#preparation-for-week-7",
    "title": "6  Prior Tweaks and More",
    "section": "6.10 Preparation for Week 7",
    "text": "6.10 Preparation for Week 7\nIn week 7 you will be required to .",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "brief_module_04.html",
    "href": "brief_module_04.html",
    "title": "Module 4: Non-Gaussian Bayeswatch",
    "section": "",
    "text": "ASDF",
    "crumbs": [
      "**Module 4: Non-Gaussian Bayeswatch**"
    ]
  },
  {
    "objectID": "M04_1.html",
    "href": "M04_1.html",
    "title": "7  Non-Gaussian",
    "section": "",
    "text": "7.1 Learnings\nNOT READY YET\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Understand non-Gaussian Bayesian model with binary outcome\n– Understand the difference between Bayesian and classical models.\n– Formulate problems and solutions.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#learnings",
    "href": "M04_1.html#learnings",
    "title": "7  Non-Gaussian",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#non-gaussian-bayesian-model",
    "href": "M04_1.html#non-gaussian-bayesian-model",
    "title": "7  Non-Gaussian",
    "section": "7.2 Non-Gaussian Bayesian Model",
    "text": "7.2 Non-Gaussian Bayesian Model\nA non-Gaussian Bayesian model is any Bayesian model where the likelihood, i.e., the model for the observed data is not based on the normal distribution. In many real-world situations, the assumptions of the normal distribution do not hold. The response variable might be binary, a count, a proportion, or restricted to positive values. In such cases, it is more appropriate to use a different distribution that better matches the data.\nMany of these alternative distributions come from what is known as the exponential family of distributions. This family includes a wide range of commonly used distributions such as:\n\nBernoulli for binary outcomes\n\nPoisson for count data\n\nExponential and gamma for positive continuous data\n\nCategorical and multinomial for discrete choices\n\nThese distributions have a shared mathematical form, which makes them convenient for modeling. Specifically, they can be written in a way that separates the data from the parameters in a structured form. This makes them suitable for use in generalised linear models and their Bayesian extensions.\nNon-Gaussian Bayesian models are especially useful because they allow us to model a wider range of data types, incorporate prior knowledge, and fully represent uncertainty. By using distributions from the exponential family, we take advantage of mathematical properties that simplify inference and make modeling more robust.\nIn this module, we will explore Bayesian models to tackle binary and count data and in today’s lecture we will learn models with binary outcome.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#understanding-binary-outcomes",
    "href": "M04_1.html#understanding-binary-outcomes",
    "title": "7  Non-Gaussian",
    "section": "7.3 Understanding Binary Outcomes",
    "text": "7.3 Understanding Binary Outcomes\nBinary variables may seem simple at first, just yes or no, 1 or 0, success or failure. But there’s often more happening behind the scenes, especially when the outcome depends on other factors. For instance, how likely is a patient to recover depending on their treatment and medical history?\nTo study questions like this, we use regression models designed for binary outcomes. These models help us explore how different variables influence the likelihood of a particular result. Two common types are logistic regression and probit regression. Logistic regression models the log-odds of success, while probit regression uses the cumulative normal distribution to relate predictors to outcome probabilities.\nWhen we take a Bayesian approach, we build on this foundation in an important way, as we have already lean that instead of estimating fixed values for model parameters, we treat those parameters as uncertain and describe them using probability distributions. We start with prior distributions that reflect our beliefs or assumptions and then, we update these beliefs in light of the observed data using Bayes theorem, resulting in posterior distributions.\nTo make this more concrete, imagine we’re modelling the probability that a patient recovers, where recovery is coded as 1 and no recovery as 0. We might model this probability as a function of whether the patient received a particular treatment. Once we observe data, we update priors to get posterior distributions for the treatment effect. From these, we can calculate probabilities, make predictions, and evaluate the uncertainty in our conclusions.\nBelow we provide a more detailed example related to the bone mineral density (BMD) data we discussed in previous lectures. Here, our research aim is now to understand the effect of BMD on the fracture status of the bone (‘Status’), where we assume no-fracture refers to zero (reference category) and fracture refers to one.\n\n7.3.1 Bone Mineral Density Data\n\n\nBelow, we provide a descrptive summary of the variables that we want to use to develop the model. We observe that the dataset, named bmd_data, comprises 169 rows and 5 columns. Among these columns, two are categorical (factors) and three are numerical.\nFor the categorical variables, we have ‘Status’ and ‘Sex’. The ‘Status’ variable has no missing values and includes two unique categories: “No” (i.e., no fracture) and “Fra” (i.e., fracture) with counts of 119 and 50, respectively. This indicates that the majority of the observations fall under the no fracture category. Similarly, the Sex variable also has no missing values and includes two categories: “F” (female) and “M” (male), with counts of 86 and 83, respectively. We can also see that the mean BMD is 0.78, with a standard deviation of 0.17, indicating some variability around the mean. The mean BMI is 25.2, with a standard deviation of 4.41, suggesting a moderate variability. Lastly, we ca see that the mean age is 63.6 years, with a standard deviation of 12.4 years, indicating a relatively older population with some age variability. The age ranges from a minimum of 36 to a maximum of 89 years.\n\n\nCode\nlibrary(tidyverse)\nlibrary(skimr)\nbmd_data &lt;- read.csv(\"bmd_restricted.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data$fracture_status &lt;- factor(bmd_data$fracture)\nbmd_data$fracture_status &lt;- relevel(bmd_data$fracture_status, ref = \"no fracture\")\nbmd_data &lt;- tibble(\n  Status = bmd_data$fracture_status,\n  BMD = bmd_data$bmd,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\nskimr:::skim_without_charts(bmd_data)\n\n\n\nData summary\n\n\nName\nbmd_data\n\n\nNumber of rows\n169\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nStatus\n0\n1\nFALSE\n2\nno : 119, fra: 50\n\n\nSex\n0\n1\nFALSE\n2\nM: 86, F: 83\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\nBMD\n0\n1\n0.78\n0.17\n0.41\n0.67\n0.79\n0.89\n1.36\n\n\nBMI\n0\n1\n25.20\n4.41\n15.43\n22.15\n24.96\n27.55\n38.54\n\n\nAge\n0\n1\n63.63\n12.36\n35.81\n54.42\n63.49\n72.08\n88.75\n\n\n\n\n\nNow, based on out research aim, i.e., understanding the effect of BMD on the fracture status of the bone (‘Status’), we can develop the Bayesian model as follows.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#bayesian-model-development",
    "href": "M04_1.html#bayesian-model-development",
    "title": "7  Non-Gaussian",
    "section": "7.4 Bayesian Model Development",
    "text": "7.4 Bayesian Model Development\n\n7.4.1 DAG\nLet’s start by explaining the example using a DAG. In our research, we’re trying to understand how Bone Mineral Density (BMD) total (\\(g/cm^2\\)) measure in spine affects whether a bone breaks or not. We group fracture status into two categories: no fracture (0) and fracture (1).\nIn this case, BMD total in spine is our main variable of interest, this is the exposure variable, because we want to see how changes in BMD are linked to the risk of fractures. At the same time, we also look at Body Mass Index (BMI), Age, and Sex. These are the confounders, which means they can influence both BMD and the risk of having a fracture. If we don’t take them into account, we might get the wrong idea about how strongly BMD is related to fractures.\nSo, we’re using this setup to better understand how all these factors: BMD, BMI, age, and sex, work together and affect whether someone has a bone fracture or not. Each factor follows a certain pattern, and by studying these patterns, we can make better predictions about bone health.\n\n\n\n\n\n\nHere, we’re modeling how BMD affects the probability of a bone fracture, while adjusting for the confounding effects of BMI, Age, and Sex. Let’s build a Bayesian hierarchical model:\n\n\n7.4.2 Bayesian model\nLet, \\(\\text{Status}_i \\in \\{0,1\\}\\): fracture status for individual \\(i\\), i.e, 0 = no fracture and 1 = fracture. Using \\(\\text{BMD}_i\\), \\(\\text{BMI}_i\\), \\(\\text{Age}_i\\), and _i$, we write the probability of fracture \\(P(\\text{Status}_i = 1 \\mid \\cdot)\\) as:\n\\[\nP(\\text{Status}_i = 1 \\mid \\text{BMD}_i, \\text{BMI}_i, \\text{Age}_i, \\text{Sex}_i) = \\text{logit}^{-1}(\\eta_i)\n\\]\n\\[\n\\eta_i = \\beta_0 + \\beta_1 \\cdot \\text{BMD}_i + \\beta_2 \\cdot \\text{BMI}_i + \\beta_3 \\cdot \\text{Age}_i + \\beta_4 \\cdot \\text{Sex}_i\n\\]\nNow, we define the priors as:\n\\[\n\\beta_j \\sim \\mathcal{N}(\\mu_j, \\sigma^2_j) \\quad \\text{for } j = 0, 1, 2, 3, 4\n\\]\nHence, denoting \\(\\mathbf{y}_i = \\text{Status}_i\\) and \\(\\bf{x}_i =(\\text{BMD}_i, \\text{BMI}_i, \\text{Age}_i, \\text{Sex}_i)'\\), we write the posterior distribution in matrix and vector notations as:\n\\[\np(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{x}) \\propto p(\\mathbf{y} \\mid \\mathbf{x}, \\boldsymbol{\\beta}) \\cdot p(\\boldsymbol{\\beta})\n\\]\nWhere, \\(\\boldsymbol{\\beta} = (\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4)'\\).\nThis model lets us estimate the posterior distribution of the effect of BMD on fractures, while adjusting for BMI, Age, and Sex.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#prior-distributions",
    "href": "M04_1.html#prior-distributions",
    "title": "7  Non-Gaussian",
    "section": "7.5 Prior Distributions",
    "text": "7.5 Prior Distributions\nConsideration of a non-informative prior for logistic regression can yiled a wide range or variability for the odds ratio. For example, a \\(N(0,10^{2})\\) will provide a standard deviation in the odds ratio scale as \\(\\exp(\\sqrt{100})\\approx 22,000\\), which is a very large number, and consideration of such large number can cause issues with identifiability and numerical stability, as the link function of the logistic regression can explode with large coefficients. Whereas, weakly informative priors balance flexibility and regularisation for the logistic regression scenario. They prevent extreme parameter estimates, improve convergence, and produce more realistic predictions. A paper by Andrew Gelman et al. (Gelman et al. (2008)) addresses some of these key challenges.\nTo model fracture status, let us consider weakly informative prior distributions for \\(\\boldsymbol{\\beta}\\). Now, defining a weakly informative prior is often tricky in such a situation, as it needs to be robust in nature for explaining the predictors. Several options can be considered, and in this unit, we will discuss some of them.\n\n\n7.5.1 Normal Distribution with Small Variance\nOne of the approaches that we can take is to consider a normal prior distribution for \\(\\beta\\) parameter with mean zero and a small variance. Say, \\(\\beta_{(.)} \\sim N(0, 3^2)\\) to define the weakly informative prior for the log-odds ratio. This will give provide the prior range for the model coeficients (i.e., parameters) with hyper-parameter standard deviation as: \\(\\exp(3)\\approx 20\\) in odds ratio scale. Note that, unlike Bayesian model we discussed in our previous lection for continuous variable (i.e., Gaussian distribution); we do not have any variance parameter for the logistic model.\nFor this Bayesian model with small hyper parametr for the prior variance, we can hence write a simpler DAG (only for visualisation, as we will be using the full model in our analysis) using only one predictor variable BMD as below. Note that we use small variance hyper parameter only for \\(\\beta_1\\), as usually we recommend to use large variance for the intercept term of the model (i.e., \\(\\beta_0 \\sim N(0, 10^2)\\)), such that we can get a flexible posterior distribution for the intrcept.\n\n\n\n\n\n\n\n\n7.5.2 Cauchy Distribution\nAnother suggestion for the weakly informative prior distribution for \\(\\beta\\) parameters in logistic regression is the Cauchy prior with mean zero and scale 2.5 (Gelman et al. (2008)). The suggestion is to assign the Cauchy prior to each of the coefficients in the logistic regression except the intercept (i.e., \\(\\beta_0\\)) term. Furthermore, it is recommended to standardise continuous predictor variables when using a Cauchy prior—specifically, \\(\\text{Cauchy}(\\mu = 0, \\tau = 2.5)\\), because this helps ensure that the resulting change in the log-odds (logit scale) remains within a reasonable range, typically less than 5, when the predictor moves from one standard deviation below the mean to one standard deviation above.\nWe can draw DAG based on the Cauchy prior for only one predictor variable BMD as follows. Similarly, we can see that for the intercept \\(\\beta_0\\) we consider a normal prior distribution with a relatively wider variance.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#posterior-results",
    "href": "M04_1.html#posterior-results",
    "title": "7  Non-Gaussian",
    "section": "7.6 Posterior Results",
    "text": "7.6 Posterior Results\nWe will now obtain the posterior distribution of the model parameters we developed for the fracture and BMD example. Here, we will use both exposure (i.e, BMD) and confounders (e.g., BMI, Age and Sex) to generate model-based results. In this section, we will use normal prior for the \\(\\beta\\) parameters, where the weakly informative influence of the prior will be demonstrated using the small-variance example we discussed earlier. Note that we will perform a sensitivity analysis of the prior distributions in our next lecture, where we will compare both normal and Cauchy prior distributions.\nRecall, we want to obtain posterior distribution of the model parameters from the joint posterior distribution:\n\\[\\begin{align}\np(\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4 \\mid y, \\text{BMD}, \\text{BMI}, \\text{Age}, \\text{Sex}) &\\propto p(y \\mid \\text{BMD}, \\text{BMI}, \\text{Age}, \\text{Sex},\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4) \\times \\\\\n& p(\\beta_0) \\cdot p(\\beta_1) \\cdot p(\\beta_2) \\cdot p(\\beta_3) \\cdot p(\\beta_4)\n\\end{align}\\]\nAssuming weakly informative prior as:\n\n\\(\\beta_1,\\beta_2,\\beta_3,\\beta_4 \\sim N(0, 3^2)\\)\n\nAnd for intercept we write:\n\n\\(\\beta_0 \\sim N(0, 10^2)\\)\n\nWe impliment the model using ‘brm’ function from ‘brms’ R package as follows:\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_drug.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data$fracture &lt;- factor(bmd_data$fracture)\nbmd_data$fracture &lt;- relevel(bmd_data$fracture, ref = \"no fracture\")\nbmd_data &lt;- tibble(\n  Status = bmd_data$fracture,\n  BMD = bmd_data$bmdtot_spine,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\n\npriors_normal &lt;- c(\n  prior(normal(0, 3), class = \"b\", coef = \"BMI\"), # N(mean, sd)\n  prior(normal(0, 3), class = \"b\", coef = \"Age\"), # N(mean, sd)\n  prior(normal(0, 3), class = \"b\", coef = \"SexM\"), # N(mean, sd)\n  prior(normal(0, 10), class = \"Intercept\") # N(mean, sd)\n)\n\nfracture_model_normal_prior &lt;- brm(\n  formula = Status ~ BMD + BMI + Age + Sex,\n  data = bmd_data,\n  family = bernoulli(link = \"logit\"),\n  prior = priors_normal,\n  chains = 1,\n  iter = 2000,\n  warmup = 1000,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.66 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.726 seconds (Warm-up)\nChain 1:                0.46 seconds (Sampling)\nChain 1:                1.186 seconds (Total)\nChain 1: \n\n\nTo get the prior distributions and related hyper parameters that we implemented in the model, we can use ‘prior_summary’ function, which gives us the following output:\n\n\nCode\nprint(prior_summary(fracture_model_normal_prior, all = FALSE), show_df = FALSE)\n\n\nb_Age ~ normal(0, 3)\nb_BMI ~ normal(0, 3)\nb_SexM ~ normal(0, 3)\nIntercept ~ normal(0, 10)\n\n\nThe posterior summaries and MCMC chain plots for the model parameters can be obtained as follows:\n\n\nCode\nsummary(fracture_model_normal_prior)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Status ~ BMD + BMI + Age + Sex \n   Data: bmd_data (Number of observations: 1077) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.35      1.63    -3.45     2.77 1.00     1126      715\nBMD          -2.55      1.07    -4.69    -0.34 1.00      800      663\nBMI          -0.22      0.05    -0.32    -0.13 1.00      805      588\nAge           0.08      0.02     0.05     0.11 1.00      717      531\nSexM         -0.05      0.32    -0.72     0.61 1.00      770      658\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nplot(fracture_model_normal_prior)\n\n\n\n\n\n\n\n\n\nNote that by deafult the ‘brm’ model output provides mean estimates for the model parameters. To get the summary statistics in odds ratios, we need to follow the R code below:\n\n\nCode\n#posterior_summary &lt;- posterior_summary(fracture_model_normal_prior)\n#odds_ratios &lt;- exp(posterior_summary[grep(\"^b_\", rownames(posterior_summary)), ])\n\nlibrary(bayesplot)\nposterior &lt;- as_draws_df(fracture_model_normal_prior)\nposterior_or &lt;- posterior %&gt;%\n  dplyr::select(starts_with(\"b_\")) %&gt;%\n  dplyr::mutate(across(everything(), exp))\n# drop intercept from the estimate\n#posterior_or &lt;- posterior_or[,-1]\n\n#mcmc_areas(\n#  posterior_or,\n#  pars = colnames(posterior_or),\n#  prob = 0.95  # 95% credible interval\n#) +\n#  ggplot2::labs(title = \"Posterior Distributions of Odds Ratios\")\n\nmcmc_trace(\n  posterior_or,\n  pars = c(\"b_BMD\",\"b_BMI\", \"b_Age\", \"b_SexM\")\n) +\n  ggplot2::labs(title = \"Posterior Trace Plots of Odds Ratios\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#summary",
    "href": "M04_1.html#summary",
    "title": "7  Non-Gaussian",
    "section": "7.7 Summary",
    "text": "7.7 Summary\nToday’s lecture focused on understanding priors in Bayesian regression, specifically for variance and the coefficients. We discussed weakly-informative and informative priors for \\(\\beta_1\\), and their implications in modeling. A comparison between Bayesian and frequentist approaches was made, particularly in the context of using an informative prior for \\(\\beta_1\\). Finally, we explored how to further develop the model to better understand exposure and confounders, and how these can be incorporated into a Bayesian regression framework.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#live-tutorial-and-discussion",
    "href": "M04_1.html#live-tutorial-and-discussion",
    "title": "7  Non-Gaussian",
    "section": "7.8 Live tutorial and discussion",
    "text": "7.8 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#tutorial-exercises",
    "href": "M04_1.html#tutorial-exercises",
    "title": "7  Non-Gaussian",
    "section": "7.9 Tutorial Exercises",
    "text": "7.9 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_1.html#preparation-for-week-8",
    "href": "M04_1.html#preparation-for-week-8",
    "title": "7  Non-Gaussian",
    "section": "7.10 Preparation for Week 8",
    "text": "7.10 Preparation for Week 8\nIn week 8 you will be required to .\n\n\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” The Annals of Applied Statistics 2 (4): 1360–83.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_2.html",
    "href": "M04_2.html",
    "title": "8  More on Non-Gaussian",
    "section": "",
    "text": "8.1 Learnings\nNOT READY YET\n– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.\n– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.\nBy the end of this week you should be able to:\n– Perform sensitivity analysis for non-Gaussian Bayesian model\n– Understand non-Gaussian Bayesian model with count outcome\n– Understand the difference between Bayesian and classical models.\n– Formulate problems and solutions.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#learnings",
    "href": "M04_2.html#learnings",
    "title": "8  More on Non-Gaussian",
    "section": "",
    "text": "Outcomes\n\n\n\n\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#sensitivity-analysis",
    "href": "M04_2.html#sensitivity-analysis",
    "title": "8  More on Non-Gaussian",
    "section": "8.2 Sensitivity Analysis",
    "text": "8.2 Sensitivity Analysis\n\n\nRecall, in our last lecture we demonstrated how to use Bayesian approach to model binary outcome variable, i.e., logistic regression. We also explained how we can define weakly informative prior distribution for the coefficients of the predictor variables in the model.\nNow, in today’s lecture, we will explain and compare the posterior results using normal distribution with small variance and Cauchy prior distribution. We will also explore how sensitive is the results based on the prior distribution assumptions.\n\n8.2.1 Prior Density Plots\nBelow, we draw two prior density plots based on the \\(\\text{Cauchy}(0, 2.5)\\) and \\(N(0, 3^2)\\) distributions. The Cauchy distribution is represented by the blue curve. We can see, as discussed, one of the key features of the Cauchy distribution is its heavy tails. This means that it allows for more extreme values compared to other distributions like the Normal distribution. In practical terms, this implies that the Cauchy distribution is more flexible and can accommodate larger deviations from the mean. The normal distribution, showed by the red curve, has a mean of 0 and a standard deviation of 3. Unlike the Cauchy distribution, the Normal distribution is more concentrated around the mean. This means that it assumes values of \\(\\beta\\) are more likely to be close to the mean, with fewer extreme values. The tails of the Normal distribution are lighter, indicating that it is less likely to produce outliers compared to the Cauchy distribution.\nThe choice between these two distributions sometimes can significantly impact the results of a Bayesian analysis. The Cauchy distribution, with its heavy tails, is more robust to outliers and can handle more extreme values. This can be advantageous in situations where you expect the parameter \\(\\beta\\) to have a wide range of possible values. Whereas, the normal distribution, with its lighter tails, is more suitable when you have strong prior beliefs that the parameter values will be close to the mean zero.\n\n\nCode\nlibrary(ggplot2)\nx &lt;- seq(-20, 20, length.out = 1000)\nnormal_density &lt;- dnorm(x, mean = 0, sd = 3)\ncauchy_density &lt;- dcauchy(x, location = 0, scale = 2.5)\npriors_df &lt;- data.frame(\n  x = rep(x, 2),\n  density = c(normal_density, cauchy_density),\n  distribution = factor(rep(c(\"Normal (mean = 0, sd = 3)\", \"Cauchy (mean = 0, scale = 2.5)\"), each = length(x)))\n)\nggplot(priors_df, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Comparison of Prior Distributions\",\n       x = expression(beta),\n       y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"steelblue\", \"firebrick\")) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n8.2.2 Posterior Comparison\nfor normal\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_drug.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data$fracture &lt;- factor(bmd_data$fracture)\nbmd_data$fracture &lt;- relevel(bmd_data$fracture, ref = \"no fracture\")\nbmd_data &lt;- tibble(\n  Status = bmd_data$fracture,\n  BMD = bmd_data$bmdtot_spine,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\n\npriors_normal &lt;- c(\n  prior(normal(0, 3), class = \"b\", coef = \"BMI\"), # N(mean, sd)\n  prior(normal(0, 3), class = \"b\", coef = \"Age\"), # N(mean, sd)\n  prior(normal(0, 3), class = \"b\", coef = \"SexM\"), # N(mean, sd)\n  prior(normal(0, 10), class = \"Intercept\") # N(mean, sd)\n)\n\nfracture_model_normal_prior &lt;- brm(\n  formula = Status ~ BMD + BMI + Age + Sex,\n  data = bmd_data,\n  family = bernoulli(link = \"logit\"),\n  prior = priors_normal,\n  chains = 1,\n  iter = 2000,\n  warmup = 1000,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 8.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.901 seconds (Warm-up)\nChain 1:                0.589 seconds (Sampling)\nChain 1:                1.49 seconds (Total)\nChain 1: \n\n\nCode\n#summary(fracture_model_normal_prior)\n#plot(fracture_model_normal_prior)\n\nprint(prior_summary(fracture_model_normal_prior, all = FALSE), show_df = FALSE)\n\n\nb_Age ~ normal(0, 3)\nb_BMI ~ normal(0, 3)\nb_SexM ~ normal(0, 3)\nIntercept ~ normal(0, 10)\n\n\nfor cauchy\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_drug.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data$fracture &lt;- factor(bmd_data$fracture)\nbmd_data$fracture &lt;- relevel(bmd_data$fracture, ref = \"no fracture\")\nbmd_data &lt;- tibble(\n  Status = bmd_data$fracture,\n  BMD = bmd_data$bmdtot_spine,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\n\npriors_cauchy &lt;- c(\n  prior(cauchy(0, 2.5), class = \"b\", coef = \"BMI\"), # N(mean, sd)\n  prior(cauchy(0, 2.5), class = \"b\", coef = \"Age\"), # N(mean, sd)\n  prior(cauchy(0, 2.5), class = \"b\", coef = \"SexM\"), # N(mean, sd)\n  prior(normal(0, 10), class = \"Intercept\") # N(mean, sd)\n)\n\nfracture_model_cauchy_prior &lt;- brm(\n  formula = Status ~ BMD + BMI + Age + Sex,\n  data = bmd_data,\n  family = bernoulli(link = \"logit\"),\n  prior = priors_cauchy,\n  chains = 1,\n  iter = 2000,\n  warmup = 1000,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000139 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.39 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.214 seconds (Warm-up)\nChain 1:                0.877 seconds (Sampling)\nChain 1:                2.091 seconds (Total)\nChain 1: \n\n\nCode\n#summary(fracture_model_cauchy_prior)\n#plot(fracture_model_cauchy_prior)\nprint(prior_summary(fracture_model_cauchy_prior, all = FALSE), show_df = FALSE)\n\n\nb_Age ~ cauchy(0, 2.5)\nb_BMI ~ cauchy(0, 2.5)\nb_SexM ~ cauchy(0, 2.5)\nIntercept ~ normal(0, 10)\n\n\n\n\nCode\n# Compare posterior summaries\nsummary(fracture_model_normal_prior)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Status ~ BMD + BMI + Age + Sex \n   Data: bmd_data (Number of observations: 1077) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.35      1.63    -3.45     2.77 1.00     1126      715\nBMD          -2.55      1.07    -4.69    -0.34 1.00      800      663\nBMI          -0.22      0.05    -0.32    -0.13 1.00      805      588\nAge           0.08      0.02     0.05     0.11 1.00      717      531\nSexM         -0.05      0.32    -0.72     0.61 1.00      770      658\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nsummary(fracture_model_cauchy_prior)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Status ~ BMD + BMI + Age + Sex \n   Data: bmd_data (Number of observations: 1077) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -0.44      1.65    -3.70     2.52 1.01      952      747\nBMD          -2.48      1.10    -4.76    -0.38 1.00      966      834\nBMI          -0.22      0.05    -0.32    -0.13 1.00      842      793\nAge           0.08      0.02     0.05     0.10 1.01      860      694\nSexM         -0.04      0.32    -0.64     0.56 1.00      945      643\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\n# Combine posterior samples for comparison\nposterior_normal &lt;- as_draws_df(fracture_model_normal_prior)\nposterior_cauchy &lt;- as_draws_df(fracture_model_cauchy_prior)\n\n# Plot comparisons\nlibrary(bayesplot)\n#mcmc_areas(\n#  list(Normal = posterior_normal,\n#       Cauchy = posterior_cauchy),\n#  pars = c(\"b_BMI\", \"b_Age\", \"b_SexM\", \"b_BMD\"),\n#  prob = 0.95\n#) + ggtitle(\"Posterior Distributions: Normal vs. Cauchy Priors\")\n\n\n# Trace plots\nmcmc_trace(as_draws_array(fracture_model_normal_prior), \n           pars = c(\"b_BMI\", \"b_Age\", \"b_SexM\", \"b_BMD\")) + \n  ggtitle(\"Trace Plots: Normal Priors\")\n\n\n\n\n\n\n\n\n\nCode\nmcmc_trace(as_draws_array(fracture_model_cauchy_prior), \n           pars = c(\"b_BMI\", \"b_Age\", \"b_SexM\", \"b_BMD\")) + \n  ggtitle(\"Trace Plots: Cauchy Priors\")\n\n\n\n\n\n\n\n\n\nCode\n# LOO model comparison\n#loo_normal &lt;- loo(fracture_model_normal_prior)\n#loo_cauchy &lt;- loo(fracture_model_cauchy_prior)\n#loo_compare(loo_normal, loo_cauchy)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#prior-hierarchy",
    "href": "M04_2.html#prior-hierarchy",
    "title": "8  More on Non-Gaussian",
    "section": "8.3 Prior Hierarchy",
    "text": "8.3 Prior Hierarchy\n\n\nAnother approach that we can take in Bayesian logistic modeling is to incorporate a hierarchy of prior distributions. This hierarchical setup allows for more flexibility and adaptability in capturing the underlying uncertainty and scale of model parameters. One way to implement this is by introducing multiple hierarchical structures based on different types of priors. Specifically, we can explore two distinct hierarchical formulations for the coefficients in a Bayesian logistic regression, that we have already discussed:\n\nusing a normal prior with an exponential hyperprior on its scale parameter \\(\\sigma\\), and\nusing a Cauchy prior with an exponential hyperprior on its scale parameter \\(\\tau\\).\n\n\n8.3.1 Normal-Exponential Hierarchy\nIn the first setup, i.e., normal-exponential hierarchy, each regression coefficient is assumed to follow a normal distribution, such that \\(\\beta \\sim N(0, \\sigma^2)\\). Instead of fixing \\(\\sigma\\), we place an exponential hyperprior on it: \\(\\sigma \\sim \\text{Exp}(\\lambda)\\), and we consider the hyper-hyper parameter \\(\\lambda=1\\). This allows the model to learn an appropriate scale from the data, shrinking coefficients more aggressively when \\(\\sigma\\) is small and allowing more flexibility when \\(\\sigma\\) is large. This structure introduces a level of adaptivity that can help prevent overfitting while still permitting the model to express sufficient complexity when warranted by the data.\n\n\nCode\nlibrary(brms)\nstanvars &lt;- stanvar(scode = \"real&lt;lower=0&gt; sigma;\", block = \"parameters\") +\n            stanvar(scode = \"sigma ~ exponential(1);\", block = \"model\")\npriors &lt;- c(\n  prior(normal(0, sigma), class = \"b\"),\n  prior(normal(0, 10), class = \"Intercept\")\n)\nfracture_model_normal_hierarchy &lt;- brm(\n  formula = Status ~ BMD + BMI + Age + Sex,\n  data = bmd_data,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  stanvars = stanvars,\n  chains = 1,\n  iter = 2000,\n  warmup = 1000,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.0001 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.347 seconds (Warm-up)\nChain 1:                0.805 seconds (Sampling)\nChain 1:                2.152 seconds (Total)\nChain 1: \n\n\nCode\nprint(prior_summary(fracture_model_normal_hierarchy, all = FALSE), show_df = FALSE)\n\n\nb ~ normal(0, sigma)\nIntercept ~ normal(0, 10)\n\n\nCode\nsummary(fracture_model_normal_hierarchy)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Status ~ BMD + BMI + Age + Sex \n   Data: bmd_data (Number of observations: 1077) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -1.92      1.53    -5.00     0.98 1.00      492      566\nBMD          -0.28      0.50    -1.74     0.30 1.00      302      221\nBMI          -0.24      0.04    -0.34    -0.15 1.00      420      444\nAge           0.08      0.01     0.05     0.11 1.00      580      574\nSexM         -0.08      0.20    -0.51     0.28 1.00      620      580\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nTo check the stancode behined this we write:\n\n\nCode\nlibrary(brms)\nstancode(fracture_model_normal_hierarchy)\n\n\n// generated with brms 2.22.0\nfunctions {\n}\ndata {\n  int&lt;lower=1&gt; N;  // total number of observations\n  array[N] int Y;  // response variable\n  int&lt;lower=1&gt; K;  // number of population-level effects\n  matrix[N, K] X;  // population-level design matrix\n  int&lt;lower=1&gt; Kc;  // number of population-level effects after centering\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n  matrix[N, Kc] Xc;  // centered version of X without an intercept\n  vector[Kc] means_X;  // column means of X before centering\n  for (i in 2:K) {\n    means_X[i - 1] = mean(X[, i]);\n    Xc[, i - 1] = X[, i] - means_X[i - 1];\n  }\n}\nparameters {\n  vector[Kc] b;  // regression coefficients\n  real Intercept;  // temporary intercept for centered predictors\n  real&lt;lower=0&gt; sigma;\n}\ntransformed parameters {\n  real lprior = 0;  // prior contributions to the log posterior\n  lprior += normal_lpdf(b | 0, sigma);\n  lprior += normal_lpdf(Intercept | 0, 10);\n}\nmodel {\n  sigma ~ exponential(1);\n  // likelihood including constants\n  if (!prior_only) {\n    target += bernoulli_logit_glm_lpmf(Y | Xc, Intercept, b);\n  }\n  // priors including constants\n  target += lprior;\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept - dot_product(means_X, b);\n}\n\n\n\n\n8.3.2 Cauchy-Exponential Hierarchy\nIn the second hierarchical approach, i.e., Cauchy-exponential hierarchy, we adopt a heavy-tailed Cauchy prior for each coefficient: \\(\\beta \\sim \\text{Cauchy}(0, \\tau)\\). An then to regulate the scale \\(\\tau\\), we again place an exponential hyperprior: \\(\\tau \\sim \\text{Exp}(\\lambda)\\). This configuration allows the model to dynamically adapt the amount of shrinkage, with the heavy tails of the Cauchy helping to preserve large coefficients when needed, while the exponential hyperprior controls global shrinkage.\n\n\nCode\nlibrary(brms)\nstanvars &lt;- stanvar(scode = \"real&lt;lower=0&gt; tau;\", block = \"parameters\") +\n            stanvar(scode = \"tau ~ exponential(1);\", block = \"model\")\npriors &lt;- c(\n  prior(cauchy(0, tau), class = \"b\"),\n  prior(normal(0, 10), class = \"Intercept\")\n)\nfracture_model_cauchy_hierarchy &lt;- brm(\n  formula = Status ~ BMD + BMI + Age + Sex,\n  data = bmd_data,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  stanvars = stanvars,\n  chains = 1,\n  iter = 2000,\n  warmup = 1000,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000106 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.06 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.576 seconds (Warm-up)\nChain 1:                1.176 seconds (Sampling)\nChain 1:                2.752 seconds (Total)\nChain 1: \n\n\nCode\nprint(prior_summary(fracture_model_cauchy_hierarchy, all = FALSE), show_df = FALSE)\n\n\nb ~ cauchy(0, tau)\nIntercept ~ normal(0, 10)\n\n\nCode\nsummary(fracture_model_cauchy_hierarchy)\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Status ~ BMD + BMI + Age + Sex \n   Data: bmd_data (Number of observations: 1077) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -1.52      1.65    -4.44     1.60 1.00      453      598\nBMD          -0.92      1.03    -3.39     0.20 1.00      369      640\nBMI          -0.23      0.05    -0.33    -0.14 1.00      461      498\nAge           0.08      0.01     0.05     0.11 1.00      463      501\nSexM         -0.06      0.21    -0.55     0.34 1.01      643      486\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nTo check the stancode behined this we write:\n\n\nCode\nlibrary(brms)\nstancode(fracture_model_cauchy_hierarchy)\n\n\n// generated with brms 2.22.0\nfunctions {\n}\ndata {\n  int&lt;lower=1&gt; N;  // total number of observations\n  array[N] int Y;  // response variable\n  int&lt;lower=1&gt; K;  // number of population-level effects\n  matrix[N, K] X;  // population-level design matrix\n  int&lt;lower=1&gt; Kc;  // number of population-level effects after centering\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n  matrix[N, Kc] Xc;  // centered version of X without an intercept\n  vector[Kc] means_X;  // column means of X before centering\n  for (i in 2:K) {\n    means_X[i - 1] = mean(X[, i]);\n    Xc[, i - 1] = X[, i] - means_X[i - 1];\n  }\n}\nparameters {\n  vector[Kc] b;  // regression coefficients\n  real Intercept;  // temporary intercept for centered predictors\n  real&lt;lower=0&gt; tau;\n}\ntransformed parameters {\n  real lprior = 0;  // prior contributions to the log posterior\n  lprior += cauchy_lpdf(b | 0, tau);\n  lprior += normal_lpdf(Intercept | 0, 10);\n}\nmodel {\n  tau ~ exponential(1);\n  // likelihood including constants\n  if (!prior_only) {\n    target += bernoulli_logit_glm_lpmf(Y | Xc, Intercept, b);\n  }\n  // priors including constants\n  target += lprior;\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept - dot_product(means_X, b);\n}\n\n\nThese two hierarchical strategies offer different trade-offs in terms of regularization and flexibility. The normal-exponential hierarchy tends to be more conservative and is often preferred for more stable, well-behaved datasets, while the Cauchy-exponential hierarchy provides robustness and flexibility in the presence of outliers or sparse, large signals. Comparing these hierarchical approaches in practice can reveal which formulation better suits a given problem, depending on the structure and noisiness of the data.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#count-outcome",
    "href": "M04_2.html#count-outcome",
    "title": "8  More on Non-Gaussian",
    "section": "8.4 Count Outcome",
    "text": "8.4 Count Outcome\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nicu_data &lt;- read.csv(\"icu_days.csv\")\nicu_data &lt;- tibble(\n  Ndays = icu_data$ndays,\n  Sex = factor(icu_data$sex),\n  Admission = factor(icu_data$admtype),\n  Age = icu_data$Age,\n  PRISM = icu_data$PRISM\n)\n\n# model\nicu_model &lt;- brm(\n  formula = Ndays ~ Sex + Admission + Age + PRISM,\n  data = icu_data,\n  family = poisson(),\n  prior = c(\n    prior(normal(0, 3), class = \"b\"), \n    prior(normal(0, 10), class = \"Intercept\")\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000109 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.09 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 2.194 seconds (Warm-up)\nChain 1:                2.071 seconds (Sampling)\nChain 1:                4.265 seconds (Total)\nChain 1: \n\n\nCode\nsummary(icu_model)\n\n\n Family: poisson \n  Links: mu = log \nFormula: Ndays ~ Sex + Admission + Age + PRISM \n   Data: icu_data (Number of observations: 398) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept            1.89      0.05     1.79     1.98 1.00      832      704\nSexMale             -0.11      0.04    -0.19    -0.04 1.00      762      489\nAdmissionPlanned    -0.73      0.05    -0.83    -0.63 1.00      507      610\nAge                 -0.00      0.00    -0.00    -0.00 1.00      960      843\nPRISM                0.04      0.00     0.04     0.05 1.00      878      661\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nplot(icu_model)\n\n\n\n\n\n\n\n\n\nCode\nlibrary(bayesplot)\nposterior &lt;- as_draws_df(icu_model)\nposterior_rr &lt;- posterior %&gt;%\n  dplyr::select(starts_with(\"b_\")) %&gt;%\n  dplyr::mutate(across(everything(), exp))\nmcmc_trace(\n  posterior_rr,\n  pars = c(\"b_SexMale\",\"b_AdmissionPlanned\", \"b_Age\", \"b_PRISM\")\n) +\n  ggplot2::labs(title = \"Posterior Trace Plots of Risk Ratios\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  },
  {
    "objectID": "brief_module_05.html",
    "href": "brief_module_05.html",
    "title": "Module 5: Clusterphobia",
    "section": "",
    "text": "ASDF",
    "crumbs": [
      "**Module 5: Clusterphobia**"
    ]
  },
  {
    "objectID": "M05_1.html",
    "href": "M05_1.html",
    "title": "9  Clusterphobia? Part - I",
    "section": "",
    "text": "9.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Explain clusterd data.\n– Describe Bayesian hierarchical (or multilevel) models.\n– Compare with classical models for clustered data\n– Interpret real-life problems in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#learnings",
    "href": "M05_1.html#learnings",
    "title": "9  Clusterphobia? Part - I",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#clustered-data",
    "href": "M05_1.html#clustered-data",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.2 Clustered Data",
    "text": "9.2 Clustered Data\nClustered data refers to observations that are grouped into clusters, where data points within the same cluster tend to be more similar to each other than to those in other clusters. This structure often arises naturally in health and medical research, where measurements are taken on individuals who share a common setting, treatment provider, or geographic location. A common example in healthcare is data collected from multiple patients treated within the same hospital or clinic. Patients within a single hospital may receive similar types of care, be exposed to the same medical practitioner, and follow similar protocols. As a result, their outcomes, such as recovery time or treatment success often are more alike compared to patients from different hospitals. Another example occurs in longitudinal studies, where repeated measurements are taken from the same individual over time. Here, each individual forms a cluster of observations. For instance, a study tracking blood pressure readings in hypertensive patients over several months will generate multiple observations per patient, and these readings are naturally correlated.\n\n\n\n\n\nExample of Clustered Data\n\n\n\n\nIn both cases, recognising and correctly handling clustered data ensures more accurate inferences and better decision-making in health and medical research. A Bayesian hierarchical model (also known as Bayesian multilevel model) can handle this types of complexity by introducing levels of variation (hierarchies) and latent processes that influence the observed data.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#bayesian-hierarchical-multilevel-model",
    "href": "M05_1.html#bayesian-hierarchical-multilevel-model",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.3 Bayesian Hierarchical (Multilevel) Model",
    "text": "9.3 Bayesian Hierarchical (Multilevel) Model\ncomplete pooling, no pooling and partially pooling",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#clustered-data-multilevel-modles",
    "href": "M05_1.html#clustered-data-multilevel-modles",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.4 Clustered Data & Multilevel Modles",
    "text": "9.4 Clustered Data & Multilevel Modles\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#varying-intercept-model",
    "href": "M05_1.html#varying-intercept-model",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.5 Varying Intercept Model",
    "text": "9.5 Varying Intercept Model\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#varying-slope-model",
    "href": "M05_1.html#varying-slope-model",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.6 Varying Slope Model",
    "text": "9.6 Varying Slope Model\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#exercises",
    "href": "M05_1.html#exercises",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#live-tutorial-and-discussion",
    "href": "M05_1.html#live-tutorial-and-discussion",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.8 Live tutorial and discussion",
    "text": "9.8 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#summary",
    "href": "M05_1.html#summary",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.9 Summary",
    "text": "9.9 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_1.html#preparation-for-week-2",
    "href": "M05_1.html#preparation-for-week-2",
    "title": "9  Clusterphobia? Part - I",
    "section": "9.10 Preparation for Week 2",
    "text": "9.10 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Clusterphobia? Part - I**</span>"
    ]
  },
  {
    "objectID": "M05_2.html",
    "href": "M05_2.html",
    "title": "10  Clusterphobia? Part - II",
    "section": "",
    "text": "10.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n– Construct multilevel models for binary outcome.\n– Understand the difference between Bayesian and classical methods.\n– Interpret a real-life problem in Bayesian context.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#learnings",
    "href": "M05_2.html#learnings",
    "title": "10  Clusterphobia? Part - II",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#introduction",
    "href": "M05_2.html#introduction",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.2 Introduction",
    "text": "10.2 Introduction\nasdafs\nMarginal effects:\nref: https://joshuawiley.com/brmsmargins/articles/fixed-effects-marginaleffects.html\nref: https://cran.r-project.org/web/packages/brmsmargins/vignettes/mixed-effects-marginaleffects.html",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#conditional-and-marginal-models",
    "href": "M05_2.html#conditional-and-marginal-models",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.3 Conditional and Marginal Models",
    "text": "10.3 Conditional and Marginal Models\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#comparison-with-classical-approach",
    "href": "M05_2.html#comparison-with-classical-approach",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.4 Comparison with Classical Approach",
    "text": "10.4 Comparison with Classical Approach\nasdf\nVedio\n…\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#exercises",
    "href": "M05_2.html#exercises",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.5 Exercises",
    "text": "10.5 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#live-tutorial-and-discussion",
    "href": "M05_2.html#live-tutorial-and-discussion",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.6 Live tutorial and discussion",
    "text": "10.6 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#summary",
    "href": "M05_2.html#summary",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.7 Summary",
    "text": "10.7 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "M05_2.html#preparation-for-week-2",
    "href": "M05_2.html#preparation-for-week-2",
    "title": "10  Clusterphobia? Part - II",
    "section": "10.8 Preparation for Week 2",
    "text": "10.8 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>**Clusterphobia? Part - II**</span>"
    ]
  },
  {
    "objectID": "brief_module_06.html",
    "href": "brief_module_06.html",
    "title": "Module 6: Wander into the Wonder!",
    "section": "",
    "text": "ASDF",
    "crumbs": [
      "**Module 6: Wander into the Wonder!**"
    ]
  },
  {
    "objectID": "M06_1.html",
    "href": "M06_1.html",
    "title": "11  Size Matters!",
    "section": "",
    "text": "11.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#learnings",
    "href": "M06_1.html#learnings",
    "title": "11  Size Matters!",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-sample-size",
    "href": "M06_1.html#bayesian-sample-size",
    "title": "11  Size Matters!",
    "section": "11.2 Bayesian Sample Size",
    "text": "11.2 Bayesian Sample Size\n\n\nBayesian sample size selection is a method used in the design of experiments or studies—especially clinical trials—that determines how many subjects or data points are needed, based on Bayesian statistical principles.\nRather than relying on traditional frequentist criteria (like fixed power and significance levels), Bayesian sample size selection incorporates prior knowledge (in the form of a prior distribution) and focuses on decision-making under uncertainty.\nFor example, from frequentist view we can ask: “How many participants do I need to have an 80% chance of detecting a true effect if it exists?” Whereas, in Bayesian thoughts, we ask: “How many participants do I need so that, after seeing the data, I’m likely to have strong enough evidence to make a good decision?”\nIn Bayesian sample size determination, we choose a sample size that meets a predefined decision or utility criterion, based on the posterior distribution.\nFor example, let’s say we’re testing a new drug and we think there’s a fair chance it might work. To figure out how many people we need in the study, we simulate data using different sample sizes. For each one, we check how likely it is, after seeing the data, that the drug has a positive effect. We then choose the smallest sample size where, in 90% (say) of the simulations, that chance is greater than say 95%.\nThe Bayesian sample size seletion is very flexible in decision making and not tied to fixed p-values such as we see in frequentist method. It is also more natural for thinking adaptive ways of doing trials using interim analysis.\nThis types of sample size selection, however is computationally intensive (often simulation-based) and often less familiar to regulatory bodies in some fields.\nLet us discuss this with specific terms starting with explaining randomised control trials (RCTs) briefly.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#rcts-where-size-really-matters",
    "href": "M06_1.html#rcts-where-size-really-matters",
    "title": "11  Size Matters!",
    "section": "11.3 RCTs: Where Size Really Matters",
    "text": "11.3 RCTs: Where Size Really Matters\nAn RCT is a type of scientific study we use to find out whether a treatment, intervention, or program actually works. RCTs are considered one of the most reliable ways to prove cause and effect.\nIn an RCT, we start by selecting a group of participants, usualy with common baseline characteristics. We then randomly assign them into two or more groups. One group receives the treatment we are testing, while the other group receives either a placebo, which looks like the treatment but has no real effect, or the usual standard treatment. Randomisation helps make sure the groups are similar at the beginning of the study. This way, if there is a difference in outcomes at the end, we can be more confident that it is because of the treatment and not because of other factors.\nBefore the study begins, we decide what we want to measure. This is called the outcome. Depending on what we are testing, outcomes can include things like changes in symptoms, blood pressure, infection rates, or even school test scores. Measuring the right outcomes is key to understanding whether the treatment worked.\nFrom statistical perspective, outcome can be represented using distributions. For example, if outcome is continuous then we can use normal distribution and if it is binary then use bernoulli distribution.\nWhen we do an RCT, we are setting up a fair and careful design to see if something really works. Sample size determination plays a crucial role here by ensuring that the study has enough statistical power to detect a true effect if one exists. It helps to estimate the minimum number of participants needed to achieve reliable and valid results, while minimising the risk of Type I (false positive) and Type II (false negative) errors.\nA well calculated sample size allows for accurate comparisons between treatment groups, ensuring that the study can confidently evaluate the intervention’s efficacy. It also helps optimise resources by preventing over-recruitment, which can be costly and unnecessary, or under-recruitment, which can lead to inconclusive or biased results.\nIn this lecture, we will learn how we can utilise Bayesian methods to calculate sample size for an RCT design. We will also discuss the flexibility of Bayesian methods in conducting adaptive trials. Additionally, we will see that the Bayesian approach provides a more nuanced understanding of uncertainty, potentially leading to more efficient trial designs and better resource allocation, making it an attractive option in situations where prior data or expert opinion is available.\nBefore discussing more on this, let us explain the Bayesian decision rules.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-decision-criteria",
    "href": "M06_1.html#bayesian-decision-criteria",
    "title": "11  Size Matters!",
    "section": "11.4 Bayesian Decision Criteria",
    "text": "11.4 Bayesian Decision Criteria\nBerry et al. (2010)\n\n\nDecision criteria can provide a flexible understanding of the choice of sample size. There are multiple options available to define the decision rules. For example, we can set a decision criterion to aim for a high probability threshold, based on the data that the treatment actually works. Sometimes, we might also try to ensure our decisions are worthwhile by considering factors like cost and benefit.\nThere are different Bayesian decision rules, below, we provide a brief discussion of some of the criteria.\nPosterior Probability Decision Rule\nThis decision rule is based on the posterior probability that a treatment effect is either greater or less than a specified threshold (e.g., a clinically meaningful effect). In Bayesian terms, the posterior distribution of the treatment effect is updated as data accumulate.\nBayesian Predictive Probability\nBayesian predictive probability calculates the probability of achieving a successful outcome (e.g., a significant treatment effect) based on the data already collected and the prior knowledge (prior distribution) about the treatment. This decision rule is similar to the posterior probability decision rule, however instead using posterior probability we use posterior predictive probability to make the decision.\nCredible Intervals for Treatment Effects\nWe already know the credible interval of parameter estimated from the posterior distributions, and now we use this credible interval for treatment effects to define the decision rule. Here, we consider a credible interval threshold say 95%, and check this range of values within which the true treatment effect lies with a given probability.\nUtility-Based Decision Rules\nIn some cases, the decision to continue or stop a trial is based on a utility function that combines the benefits (e.g., treatment efficacy) and the costs (e.g., patient safety, cost of the trial). Bayesian methods allow for the specification of a utility function that can be used to guide decisions.\nIn this course, we will explore and discuss examples using decision criterion based on posterior probability decision rules only. We will also compare the Bayesian approach of the sample size calculations with the approach based on frequentist methods.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-power",
    "href": "M06_1.html#bayesian-power",
    "title": "11  Size Matters!",
    "section": "11.5 Bayesian Power",
    "text": "11.5 Bayesian Power\n\n\nIn frequentist statistics, power is the probability of correctly rejecting the null hypothesis when the alternative is true, i.e., detecting an effect if there truly is one.\nBut in Bayesian statistics, we think a bit differently. A Bayesian analogue of power is the probability that, under the assumed true effect, our decision rule leads us to the correct conclusion, such as declaring the treatment effective when it actually is.\nLet’s say, we define success as the posterior probability that treatment effect is greater than the threshold (say, 0) is at least 95%. So our decision rule is to declare treatment effective if\n\\[\nPr(\\text{effect} &gt; 0 \\mid \\text{data}) \\geq 0.95\n\\]\nThen, we can simulate many trials assuming the treatment actually works, and compute how often our posterior crosses the 0.95 threshold. This result, how often the rule leads to the right conclusion is our Bayesian power.\nNow, if under the assumed true effect, 80% of simulated trials lead us to declare the treatment effective using our decision rule, then we say the design has 80% power. This is conceptually similar to the frequentist idea, where we aim for 80% power as a common benchmark to ensure a reasonably high chance of detecting a true effect. Note that consideration of 80% power is seen as a good trade-off in many health science. However, it’s not a rule, just a convention, and different fields or high-stakes studies might set higher bars for the power.\nIn more advanced Bayesian decision theory, power is just one part of the equation. We can optimise sample size based on expected utility (e.g., benefit of correct decision - cost of study), where power feeds into the expected gain of making the right call. In this course, however, we will only discuss Bayesian power related to the posterior probability decision rule.\nNow, let’s explain this more with an example below, which reflects the power using posterior probability decision rule.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#example-pediatric-antibiotic-trial",
    "href": "M06_1.html#example-pediatric-antibiotic-trial",
    "title": "11  Size Matters!",
    "section": "11.6 Example: Pediatric Antibiotic Trial",
    "text": "11.6 Example: Pediatric Antibiotic Trial\nSuppose, we aim to evaluate whether a new antibiotic (treatment group) is safer than the current standard of care (control group) for treating bacterial respiratory infections in children under 5 years of age.\nOur target population includes children aged 6 months to 5 years who are diagnosed with bacterial pneumonia.\nThe primary endpoint (or the outcome variable) is binary: defined as the absence of drug-related adverse events (e.g., rash, diarrhea, allergic reaction) within 10 days of starting treatment.\nWe are interested to conduct 1:1 allocations for the treatment and control groups.\nSuppose, the standard of care has an estimated safety rate of approximately 60%. As the safety data for the new antibiotic in this age group is still limited, we assume equal prior beliefs for both groups. Hence, we can model the safety probabilities using Beta prior distributions as: \\(\\text{Beta}(2, 2)\\).\n\n11.6.1 Decision Rule\nAs indicated earlier, we use the Bayesian posterior probability decision rule to test whether the treatment is superior in safety compared to the control. Let us denote \\(\\theta\\) be the safety or success rate and we declare the new antibiotic superior if:\n\\[\nPr(\\theta_{\\text{trt}} - \\theta_{\\text{crt}} &gt; 0 \\mid \\text{data}) \\geq 0.95\n\\]\nThat is, we require at least 95% posterior probability that the new antibiotic has a higher safety rate than the control group (even if the improvement is small). This approach points out any level of safety improvement, provided we are confident in the result.\n\n\n11.6.2 Sample Size\nLet’s say we want to plan/design the sample size such that, assuming the expected data for the safety (or success) rates are 75% for treatment (i.e., \\(\\theta_{\\text{trt}}=0.75\\)) and 60% for control (i.e., \\(\\theta_{\\text{crt}}=0.6\\)), and the posterior probability that the treatment is better than control (superiority trial), in at least 95% of simulated trials. Changes between treatment and control success rates can be also indicated as 15% point differece, i.e., from 60% to 75%.\nNote that in this example we are assuming equal prior beliefs for both treatment and control groups, which follows a \\(\\text{Beta}(1,1)\\) distribution. This prior reflects a non-informative situation, where the safety rates can take any values from 0 to 100%.\nBased on the information, we run simulations to generate data. Then, using simulated data from, say, 50 to 150 samples per group, we calculate the Bayesian power. Next, we identify the minimum sample size per group that achieves 80% power.\nNow, from the simulation we can see the minimum sample size per group for 80% power as:\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nsimulate_safety_trial &lt;- function(n_per_group, \n                                  true_control = 0.60, \n                                  true_treatment = 0.75,\n                                  prior_control = c(1, 1), \n                                  prior_treatment = c(1, 1),\n                                  prob_cutoff = 0.95,\n                                  threshold = 0) {\n  \n  success_c &lt;- rbinom(1, n_per_group, true_control)\n  success_t &lt;- rbinom(1, n_per_group, true_treatment)\n  post_c &lt;- prior_control + c(success_c, n_per_group - success_c)\n  post_t &lt;- prior_treatment + c(success_t, n_per_group - success_t)\n  n_samples &lt;- 10\n  p_c_post &lt;- rbeta(n_samples, post_c[1], post_c[2])\n  p_t_post &lt;- rbeta(n_samples, post_t[1], post_t[2])\n  prob_superior &lt;- mean((p_t_post - p_c_post) &gt; threshold)\n  return(prob_superior &gt;= prob_cutoff)\n}\nestimate_safety_power &lt;- function(n_per_group, n_sim = 20000) {\n  mean(replicate(n_sim, simulate_safety_trial(n_per_group)))\n}\nsample_sizes &lt;- seq(50, 150, by = 5)\nset.seed(0001)\npower_results &lt;- tibble(\n  SampleSize = sample_sizes,\n  Power = map_dbl(sample_sizes, estimate_safety_power)\n)\nmin_n &lt;- round(power_results,2) %&gt;% filter(Power &gt;= 0.80) %&gt;% slice(1)\nprint(paste(\"Bayesian: Minimun sample size per group for 80% power: \", min_n$SampleSize))\n\n\n[1] \"Bayesian: Minimun sample size per group for 80% power:  120\"\n\n\nNow, let us compare this with frequentist sample size calculation.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#frequentist-comparison",
    "href": "M06_1.html#frequentist-comparison",
    "title": "11  Size Matters!",
    "section": "11.7 Frequentist Comparison",
    "text": "11.7 Frequentist Comparison\n\n\nHere, we want to determine the minimum sample size per group required to detect a treatment effect (from 60% to 75%) with 80% power, using a frequentist approach. Thus, we consider null hypothesis as: no improvement or the treatment is not better than the control, i.e., \\(H_0: \\theta_\\text{trt}\\leq \\theta_\\text{crt}\\). The alternative hypothesis we consider as: the treatment is better than the control (i.e., higher success rate), i.e., \\(H_1: \\theta_\\text{trt}&gt; \\theta_\\text{crt}\\).\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\np1 &lt;- ggplot(power_results, aes(x = SampleSize, y = Power)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_point(color = \"#D55E00\", size = 2) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = min_n$SampleSize, linetype = \"dashed\", color = \"darkgreen\") +\n  labs(\n    title = \"Bayesian\",\n    x = \"Sample Size per Group\",\n    y = \"Power\"\n  ) +\n  ylim(0,1) +\n  theme_minimal(base_size = 14)\n\n# frequentist way\n\ntrue_control &lt;- 0.60  \ntrue_treatment &lt;- 0.75  \nalpha &lt;- 0.05  \nn_range &lt;- seq(50, 150, by = 5)  \npower_values &lt;- numeric(length(n_range))\nfor (i in seq_along(n_range)) {\n  result &lt;- power.prop.test(n = n_range[i],\n                            p1 = true_control,\n                            p2 = true_treatment,\n                            sig.level = alpha,\n                            alternative = \"one.sided\")\n  power_values[i] &lt;- result$power\n}\ndf &lt;- data.frame(SampleSize = n_range, Power = power_values)\nmin_n &lt;- df %&gt;% filter(Power &gt;= 0.80) %&gt;% slice(1)\nprint(paste(\"Frequentist: Minimun sample size per group for 80% power: \", min_n$SampleSize))\n\n\n[1] \"Frequentist: Minimun sample size per group for 80% power:  120\"\n\n\nCode\np2 &lt;- ggplot(df, aes(x = SampleSize, y = Power)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_point(color = \"blue\", size = 2) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = min_n$SampleSize, linetype = \"dashed\", color = \"darkgreen\") +  \n  labs(\n    title = \"Frequentist\",\n    x = \"Sample Size per Group\",\n    y = \"Power\"\n  ) +\n  ylim(0,1) +  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n\ngridExtra::grid.arrange(p1,p2,ncol=2)\n\n\n\n\n\n\n\n\n\nThe above plots provide power curves for both Bayesian and frequentist methods for sample sizes 50 to 150. We can see both plots show the power increases with the sample size and we can achieve 80% power at sample size 120 for both methods. This reflects under \\(\\text{Beta}(2,2)\\) prior we get same results for both Bayesian and frequentist methods.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#when-they-are-different",
    "href": "M06_1.html#when-they-are-different",
    "title": "11  Size Matters!",
    "section": "11.8 When they are different?",
    "text": "11.8 When they are different?\nNow, we will explore Bayesian sample size calculations by implementing sensitivity analyses. First, we will examine how the sample size changes with variations in the prior distribution. We will also explore sensitivity related to the choice of the cutoff threshold, ranging from 90% to 99%.\n\n11.8.1 Prior Sensitivity\nIn real-world situations, we often don’t have much prior knowledge about how well a new treatment will work, so we can’t build a strong prior belief for it. However, for the standard treatment (SOC), there may be existing data or studies that provide useful information. In a Bayesian framework, this existing information about the SOC can help us design the study more efficiently, potentially reducing the number of participants needed.\nLet’s explain this using the Pediatric Antibiotic Trial example. Suppose, we find from a study that the minimum safety (or success) rate for the SOC, i.e., the control group is about 40% (i.e., this is an informative prior). So, we can write this prior using Beta distribution with shape parameters 4 and 6, i.e., \\(\\text{Beta}(4,6)\\).\nRecall that, in the example we considered the true success rate for the SOC is about 60%. This information is an assumption related to the observe data, which is different compared to the prior assumption for the SOC group.\nNow we might want to ask: if we already believe safety is around 40% (prior), why assume it’s 60%? Is there any need to use the 60% safety rate to design the trial?\nThe short answer for this question is yes, both the prior (40%) and the assumed “true” rate (60%) can be useful, but for different purposes in trial design. When we design a trial, especially using simulations, we need to ask if the true success rate is 60%, how likely is our trial to detect it? Here, the 60% value is a design assumption — a scenario we’re testing. We might say, if the true SOC rate is actually better than we thought, will our trial design pick that up? And the prior (40% safety) is our starting belief about the SOC success rate before the trial. When we get data, we will update this prior with new evidence to get the posterior distribution.\nWe can definitely see a key challenge in interpreting trial results in these types of situations. Here, the same data can lead to vastly different conclusions depending on the prior beliefs brought into the analysis. Therefore, the use of informative priors should be chosen very carefully, ideally motivated by strong prior clinical trial data and agreed upon in consultation with regulatory bodies such as the Therapeutic Goods Administration (TGA), the Food and Drug Administration (FDA), and others.\nTo learn and explore more regarding this we refer to JAMA article by Quintana, Viele, and Lewis (2017).\nNow, let us assume that we have strong prior knowledge, and for the above example it is 40%, and hence, we plot the prior density function using \\(\\text{Beta}(4,6)\\) and true safety as:\n\n\nCode\nlibrary(ggplot2)\nx_vals &lt;- seq(0, 1, length.out = 1000)\nbeta_df &lt;- data.frame(\n  x = x_vals,\n  density = dbeta(x_vals, shape1 = 4, shape2 = 6)\n)\nggplot(beta_df, aes(x = x, y = density)) +\n  geom_area(fill = \"skyblue\", alpha = 0.5) +\n  geom_line(color = \"steelblue\", linewidth = 1.2) +\n  geom_vline(xintercept = 0.6, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  annotate(\"text\", x = 0.61, y = max(beta_df$density)*0.8, label = \"True Safety = 0.6\", \n           vjust = -0.5, hjust = 0, color = \"red\", size = 4) +\n  labs(\n    title = \"Beta(4, 6) Prior with True Safety\",\n    x = expression(theta),\n    y = \"Density\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nConsidering this informative prior we get the minimum sample size per group for 80% power as:\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nset.seed(0001)\nestimate_safety_power_pr &lt;- function(n_per_group, n_sim = 20000) {\n  mean(replicate(n_sim, simulate_safety_trial(n_per_group,\n                                              prior_control = c(4, 6),\n                                              prior_treatment = c(2, 2))))\n}\nsample_sizes &lt;- seq(50, 150, by = 5)\npower_results_pr &lt;- tibble(\n  SampleSize = sample_sizes,\n  Power = map_dbl(.x = sample_sizes, .f = estimate_safety_power_pr, .progress = TRUE)\n)\nmin_n &lt;- power_results_pr %&gt;% filter(Power &gt;= 0.80) %&gt;% slice(1)\nprint(paste(\"Bayesian: Minimun sample size per group for 80% power: \", min_n$SampleSize))\n\n\n[1] \"Bayesian: Minimun sample size per group for 80% power:  100\"\n\n\nCode\nggplot(power_results_pr, aes(x = SampleSize, y = Power)) +\n  geom_line(color = \"#0072B2\", size = 1.2) +\n  geom_point(color = \"#D55E00\", size = 2) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = min_n$SampleSize, linetype = \"dashed\", color = \"darkgreen\") +\n  labs(\n    title = \"Bayesian - Beta(4,6) Prior\",\n    x = \"Sample Size per Group\",\n    y = \"Power\"\n  ) +\n  ylim(0,1) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n\n11.8.2 Cutoff Sensitivity\nIn this section, we conduct a sensitivity analysis to examine how varying posterior probability cutoffs (0.90 vs 0.99) influence the estimated power across a range of sample sizes per group. We use data repeated across multiple simulations to estimate power for each scenario.\n\n\nCode\nlibrary(tidyverse)\nestimate_safety_power_cutoff &lt;- function(n_per_group, prob_cutoff, n_sim = 20000) {\n  mean(replicate(n_sim, simulate_safety_trial(n_per_group, prob_cutoff = prob_cutoff)))\n}\nsample_sizes &lt;- seq(50, 150, by = 5)\ncutoffs &lt;- c(0.90, 0.99)\nset.seed(0001)\npower_results_all &lt;- expand_grid(\n  SampleSize = sample_sizes,\n  Cutoff = cutoffs\n) %&gt;%\n  mutate(\n    Power = map2_dbl(SampleSize, Cutoff, ~estimate_safety_power_cutoff(.x, .y), .progress = TRUE)\n  )\nggplot(power_results_all, aes(x = SampleSize, y = Power, color = factor(Cutoff))) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  geom_hline(yintercept = 0.80, linetype = \"dashed\", color = \"gray40\") +\n  labs(\n    title = \"Different Posterior Probability Cutoffs\",\n    x = \"Sample Size per Group\",\n    y = \"Power\",\n    color = \"Cutoff\"\n  ) +\n  ylim(0, 1) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\nThe plot illustrates the relationship between posterior probability cutoffs and the statistical power of a safety trial, as the sample size increases. Specifically, it shows that using a lower cutoff value (e.g., 0.90) results in higher power more quickly compared to a higher cutoff (e.g., 0.99).\nThis means that when we set a cutoff of 0.90, we are requiring less evidence from the data to conclude that the treatment is safe. As a result, it’s easier to meet this criterion, and we reach acceptable power levels (e.g., 80%) with fewer participants.\nOn the other hand, with a stricter cutoff of 0.99, we are demanding more certainty before declaring safety. This makes it harder to reach the decision threshold, so the power of the test increases more slowly. To achieve the same level of power as with the 0.90 cutoff, we need a larger sample size to accumulate enough evidence.\nIn practical terms, this reflects a trade-off between statistical rigor and resource requirements:\n\nA lower cutoff may be more efficient in terms of sample size and cost but might increase the risk of falsely declaring a treatment safe.\nA higher cutoff increases the level of confidence in the safety conclusion but demands more data, which could be more expensive or time-consuming to collect.\n\nThus, this sensitivity analysis helps guide decision-making around trial design, balancing efficiency in safety evaluations.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#bayesian-type-i-error",
    "href": "M06_1.html#bayesian-type-i-error",
    "title": "11  Size Matters!",
    "section": "11.9 Bayesian Type-I Error",
    "text": "11.9 Bayesian Type-I Error\n\n\nBayesian Type-I error is a concept that mirrors the classical (frequentist) Type-I error. In a frequentist hypothesis test, type-I error refers to the probability of rejecting the null hypothesis when it is actually true. For example, with statistical level of significance \\(\\alpha=0.05\\), we are accepting a 5% chance of falsely declaring a treatment effective when it’s not.\nIn Bayesian analysis, we don’t really reject null in the traditional way. Instead, we compute the posterior probability that the treatment is better than control, given the data.\nSo in a Bayesian superiority trial, as we have already explain earlier, we might want to declare treatment superior if the posterior probability that treatment is better than control exceeds some threshold (e.g., 95%). Here, Bayesian Type-I Error is the probability that we incorrectly declare superiority, when the treatment is not actually better (e.g., when there’s no difference, or control is better).\nNow, how do we estimate Bayesian Type-I Error (in practice)? We simulate many trials under the null hypothesis, and see how often our Bayesian decision rule declares a false positive.\n\nAssume null is true: i.e., treatment = control = 60% success.\nSimulate N trials (e.g., 10,000).\nFor each trial:\n\nCompute posterior probability that treatment is better than control.\nIf it exceeds your decision threshold (e.g., 95%), declare “superior.”\n\nCount how many of those trials wrongly declare superiority.\nThat proportion is our Bayesian Type-I Error rate.\n\nNow, even in a Bayesian framework, especially in regulated environments (e.g., clinical trials), controlling type-I error is critical for ethical, financial, and regulatory reasons.\nWhile Bayesian methods don’t inherently control \\(\\alpha\\) like frequentist ones do, regulators often require simulations to show that the Type-I error is controlled.\nExample:\nIf our decision rule is to declare treatment superior if posterior P(treatment &gt; control) &gt; 0.95; then we might find:\n\nUnder the null (treatment = control), this rule gives a false positive 5% of the time, i.e, Type-I error is approximately 0.05\nIf it gives greater than 5% of the time, then Type-I error is too high and we may need to adjust the cutoff, sample size, or prior.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nsimulate_safety_trial &lt;- function(n_per_group, \n                                  true_control = 0.60, \n                                  true_treatment = 0.60,\n                                  prior_control = c(1, 1), \n                                  prior_treatment = c(1, 1),\n                                  prob_cutoff = 0.95,\n                                  threshold = 0) {\n  \n  success_c &lt;- rbinom(1, n_per_group, true_control)\n  success_t &lt;- rbinom(1, n_per_group, true_treatment)\n  \n  post_c &lt;- prior_control + c(success_c, n_per_group - success_c)\n  post_t &lt;- prior_treatment + c(success_t, n_per_group - success_t)\n  \n  n_samples &lt;- 500\n  p_c_post &lt;- rbeta(n_samples, post_c[1], post_c[2])\n  p_t_post &lt;- rbeta(n_samples, post_t[1], post_t[2])\n  \n  prob_superior &lt;- mean((p_t_post - p_c_post) &gt; threshold)\n  \n  return(prob_superior &gt;= prob_cutoff)\n}\nestimate_safety_power &lt;- function(n_per_group, prob_cutoff_val, n_sim = 10000) {\n  mean(replicate(n_sim, simulate_safety_trial(n_per_group, \n                                               prob_cutoff = prob_cutoff_val)))\n}\nsample_sizes &lt;- seq(50, 150, by = 5)\ncutoff_values &lt;- c(0.95) #c(0.95, 0.99)\npower_results_type1 &lt;- expand_grid(SampleSize = sample_sizes,\n                             ProbCutoff = cutoff_values) %&gt;%\n  mutate(Type1_Error = map2_dbl(SampleSize, ProbCutoff, estimate_safety_power, .progress = TRUE))\nggplot(power_results_type1, aes(x = SampleSize, y = Type1_Error, color = factor(ProbCutoff))) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Bayesian Type-I Error\",\n    x = \"Sample Size per Group\",\n    y = \"Type-I Error Rate\",\n    color = \"Cutoff\"\n  ) +\n  ylim(0, 0.20) +\n  theme_minimal(base_size = 14)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#adaptivity-and-bayesian-sample-size",
    "href": "M06_1.html#adaptivity-and-bayesian-sample-size",
    "title": "11  Size Matters!",
    "section": "11.10 Adaptivity and Bayesian Sample Size",
    "text": "11.10 Adaptivity and Bayesian Sample Size\n\n\nIn this course, we will introduce the fundamental conpects of Bayesian adaptive design. For interested readers to learn more, we refer to the book by Berry et al. (2010).\nAdaptive designs are an increasingly popular approach in clinical trials, offering flexibility to modify trial procedures based on accumulating data without undermining the study’s integrity or validity. One powerful framework for implementing adaptive designs is through Bayesian methods, which provide a natural way to incorporate prior information and update beliefs as new data become available.\n\n\n\n\n\n\nAdaptive trials are designed with flexibility built in from the start. This means we can pre-plan adjustments to key elements like treatment types (dose, frequency, combinations), how patients are assigned to different treatments, which patient groups to include, and even how many participants are needed.\nWhat makes this approach powerful is its ability to learn as it goes. As data rolls in, the trial can start to focus more on the treatment arms that are showing promise. That allows us to begin with a broader range of options—maybe testing 8 doses instead of just 3—and still use fewer participants overall.\nA well-designed adaptive trial doesn’t just benefit researchers. Patients may get better treatments, regulators get more informative results, and the entire development process becomes more streamlined.\nThat said, the flip side is that adaptive designs take more effort to build. They require careful planning and trial simulations to make sure they perform well and stand up to regulatory standards. This means close collaboration—statisticians, clinicians, regulatory teams, operations, supply chain, and more all need to be in sync. When done right, though, the payoff is a trial design that’s not only smarter, but truly better for everyone involved.\n\n\n\n11.10.1 Bayesian Adaptive Design: Antibiotic Safety Trial\nLet’s expain the adaptivity and realted sample size calculation based on the antibiotic safety trila we discussed earlier, where we want to evaluate if a new antibiotic is safer than the standard treatment for bacterial pneumonia in children aged 6 months to 5 years.\nDesign Features\n\nRandomisation: 1:1 (New Antibiotic vs. Standard of Care)\nPrior Beliefs: Non-informative priors for both arms (e.g., Beta(1,1) for safety rates)\nControl Safety Rate: Estimated at 60%\nTreatment Safety Rate: Estimated at 70% (say, about 10% point difference)\nPlanned Sample Size: Let’s assume 200 total (100 per group)\nInterim Analyses: After 50, 100, and 150 participants have been followed\n\nDecision Rule\n\nIf \\(Pr(\\theta_{trt} &gt; \\theta_{crt}) &gt; 0.95\\) then consider early success\nIf \\(Pr(\\theta_{trt} &lt; \\theta_{crt}) &gt; 0.95\\) then consider futility (stop for harm)\nElse continue to next interim or if in the final interim then either it is inconclusive or conclude as no added benefit.\n\nInterim Steps\nAt the first interim, conducted after enrolling 50 participants (25 in each group), suppose we observed that 17 children in the treatment group (i.e., \\(\\approx\\) 70%) and 15 in the control group experienced no adverse events (i.e., 60%). Starting with weakly-informative \\(\\text{Beta}(2,2)\\) priors, we updated the posterior distributions based on this data. For the treatment group, this yielded a \\(\\text{Beta}(19, 10)\\) distribution, and for the control group, a \\(\\text{Beta}(17, 12)\\). We then calculated the posterior probability that the new antibiotic is safer than the standard treatment—specifically, $ Pr({} &gt; {})$. According to our decision rules, if this probability exceeds 0.95, we would consider stopping the trial early for efficacy. Conversely, if the probability that the treatment is worse exceeds 0.95, we would stop for futility. Since neither condition was met, we proceeded to the next interim analysis.\nDuring the second interim analysis, conducted after 100 participants had been followed (50 per group), our cumulative data showed that 36 out of 50 participants in the treatment group and 29 out of 50 in the control group had no adverse events. We updated the posterior distributions accordingly: \\(\\text{Beta}(38, 16)\\) for the treatment group and \\(\\text{Beta}(31, 23)\\) for the control group. Once again, we computed the posterior probability of treatment superiority. If this probability had exceeded our predefined threshold (greater than 0.95), we would have stopped the trial early for success. Since the threshold was not reached, we decided to continue to the final planned interim.\nThe third interim analysis took place after 150 participants had been enrolled and followed (75 per group). At this point, 57 participants in the treatment arm and 45 in the control arm experienced no adverse events. These data produced updated posterior distributions: \\(\\text{Beta}(59, 20)\\) for the treatment and \\(\\text{Beta}(47, 32)\\) for the control. We calculated the final posterior probability that the treatment is safer than the control, and we also reported the corresponding credible intervals and full posterior distributions. If the final probability exceeded 0.95, we planned to declare the trial a success and conclude that the new antibiotic is statistically superior in terms of safety. Otherwise, we would interpret the result as either inconclusive or indicative of no added benefit.\nWe write R code for this analysis as follows that also provides us the power and decision for each interim steps.\n\n\nCode\nlibrary(ggplot2)\nposterior_prob_superiority &lt;- function(success_treat, total_treat, success_control, total_control, alpha_prior = 2, beta_prior = 2, n_sim = 5000) {\n  alpha_treat &lt;- alpha_prior + success_treat\n  beta_treat  &lt;- beta_prior + (total_treat - success_treat)\n  alpha_control &lt;- alpha_prior + success_control\n  beta_control  &lt;- beta_prior + (total_control - success_control)\n  p_treat_samples &lt;- rbeta(n_sim, alpha_treat, beta_treat)\n  p_control_samples &lt;- rbeta(n_sim, alpha_control, beta_control)\n  prob_superior &lt;- mean(p_treat_samples &gt; p_control_samples)\n  list(\n    prob_superior = prob_superior,\n    treat_posterior = c(alpha = alpha_treat, beta = beta_treat),\n    control_posterior = c(alpha = alpha_control, beta = beta_control),\n    samples = data.frame(p_treat = p_treat_samples, p_control = p_control_samples)\n  )\n}\ninterims &lt;- list(\n  interim1 = list(treat = c(success = 17, total = 25), control = c(success = 15, total = 25)),\n  interim2 = list(treat = c(success = 36, total = 50), control = c(success = 29, total = 50)),\n  interim3 = list(treat = c(success = 57, total = 75), control = c(success = 45, total = 75))\n)\nefficacy_thresh &lt;- 0.95\nfutility_thresh &lt;- 0.05\nfinal_success_thresh &lt;- 0.95\nfor (i in seq_along(interims)) {\n  \n  data &lt;- interims[[i]]\n  cat(paste(\"Interim: \", i,\" -- Sample Size: \", data$treat[2],\"\\n\"))\n\n  result &lt;- posterior_prob_superiority(\n    success_treat = data$treat[\"success\"],\n    total_treat = data$treat[\"total\"],\n    success_control = data$control[\"success\"],\n    total_control = data$control[\"total\"]\n  )\n  \n  cat(\"Posterior Pr(treat &gt; control):\", round(result$prob_superior, 4), \"\\n\")\n  \n  if (result$prob_superior &gt; efficacy_thresh) {\n    cat(\"Stop: Evidence for treatment superiority\\n\")\n    break\n  } else if (result$prob_superior &lt; (1 - efficacy_thresh)) {\n    cat(\"Stop: Futility (treatment worse)\\n\")\n    break\n  } else {\n    cat(\"Continue to next interim\\n\")\n  }\n}\n\n\nInterim:  1  -- Sample Size:  25 \nPosterior Pr(treat &gt; control): 0.7154 \nContinue to next interim\nInterim:  2  -- Sample Size:  50 \nPosterior Pr(treat &gt; control): 0.9304 \nContinue to next interim\nInterim:  3  -- Sample Size:  75 \nPosterior Pr(treat &gt; control): 0.9816 \nStop: Evidence for treatment superiority\n\n\nCode\nfinal_samples &lt;- result$samples\nggplot(final_samples, aes(x = p_treat - p_control)) +\n  geom_density(fill = \"steelblue\", alpha = 0.5) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Posterior Distribution of Difference: Pr(Treatment) - Pr(Control)\",\n    x = \"Difference in Safety Probabilities\",\n    y = \"Density\"\n  )\n\n\n\n\n\n\n\n\n\nIt is also possible to do Bayesian power analyses for each intrem steps at the desing stage to identify the sample size required based on the decision rule.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#why-to-use-bayesian-sample-size",
    "href": "M06_1.html#why-to-use-bayesian-sample-size",
    "title": "11  Size Matters!",
    "section": "11.11 Why to use Bayesian Sample Size",
    "text": "11.11 Why to use Bayesian Sample Size\nWith non-informative priors, Bayesian and frequentist designs often converge on similar results, especially for things like power and sample size. So then, why bother with Bayesian design at all?\nEven when power and sample sizes look similar, Bayesian methods offer several unique advantages that go beyond what frequentist designs provide.\nFor example,\nInterpretability of Results\nIn frequentist approach, we use p-value, which tells us the probability of observing data as extreme as ours, assuming the null hypothesis is true. Whereas, in Bayesian, we can directly compute the probability that a treatment works, given the data — which is often what clinicians and patients care about. For example, we might find that there is a 92% probability that the treatment improves outcomes.\nFlexible Decision-Making\nBayesian designs inherently support adaptive trials, where sample sizes can change mid-trial, arms can be dropped early, and interim decisions are based on posterior probabilities. On the other hand, frequentist designs often require pre-specified stopping rules and can’t adapt as naturally to new information during the trial.\nIncorporation of Prior Knowledge\nEven when we start with a non-informative prior, we can incorporate informative priors in future trials to borrow strength from earlier studies, reduce sample size for rare diseases or pediatric populations, and leverage previous data to guide our current study design.\nBetter Handling of Uncertainty\nBayesian models quantify uncertainty more naturally. We obtain a full posterior distribution, rather than just a point estimate and confidence interval. This is especially useful in early-phase trials or small-sample settings, where uncertainty is higher.\nA More Holistic View of Evidence\nFrequentist results are dichotomous, i.e., significant or not? Whereas, Bayesian results provide a more gradual understanding — showing degrees of belief supported by the data.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#summary",
    "href": "M06_1.html#summary",
    "title": "11  Size Matters!",
    "section": "11.12 Summary",
    "text": "11.12 Summary\n…",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#live-tutorial-and-discussion",
    "href": "M06_1.html#live-tutorial-and-discussion",
    "title": "11  Size Matters!",
    "section": "11.13 Live tutorial and discussion",
    "text": "11.13 Live tutorial and discussion\nThe final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#tutorial-exercises",
    "href": "M06_1.html#tutorial-exercises",
    "title": "11  Size Matters!",
    "section": "11.14 Tutorial Exercises",
    "text": "11.14 Tutorial Exercises\nSolutions will be provided later after the tutorial.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_1.html#preparation-for-week-12",
    "href": "M06_1.html#preparation-for-week-12",
    "title": "11  Size Matters!",
    "section": "11.15 Preparation for Week 12",
    "text": "11.15 Preparation for Week 12\nIn week 12 you will be required to .\n\n\n\n\nBerry, Scott M, Bradley P Carlin, J Jack Lee, and Peter Muller. 2010. Bayesian Adaptive Methods for Clinical Trials. CRC press.\n\n\nQuintana, Melanie, Kert Viele, and Roger J Lewis. 2017. “Bayesian Analysis: Using Prior Information to Interpret the Results of Clinical Trials.” JAMA 318 (16): 1605–6.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>**Size Matters!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html",
    "href": "M06_2.html",
    "title": "12  Wander into the Wonder!",
    "section": "",
    "text": "12.1 Learnings\nNOT READY YET\nBy the end of this week you should be able to:\n…\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#learnings",
    "href": "M06_2.html#learnings",
    "title": "12  Wander into the Wonder!",
    "section": "",
    "text": "Outcomes\nObjectives",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#exercises",
    "href": "M06_2.html#exercises",
    "title": "12  Wander into the Wonder!",
    "section": "12.2 Exercises",
    "text": "12.2 Exercises\nsdfads",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#live-tutorial-and-discussion",
    "href": "M06_2.html#live-tutorial-and-discussion",
    "title": "12  Wander into the Wonder!",
    "section": "12.3 Live tutorial and discussion",
    "text": "12.3 Live tutorial and discussion\nasdfa",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#summary",
    "href": "M06_2.html#summary",
    "title": "12  Wander into the Wonder!",
    "section": "12.4 Summary",
    "text": "12.4 Summary\nasdf",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "M06_2.html#preparation-for-week-2",
    "href": "M06_2.html#preparation-for-week-2",
    "title": "12  Wander into the Wonder!",
    "section": "12.5 Preparation for Week 2",
    "text": "12.5 Preparation for Week 2\nIn week 2 you will be required to collaboratively complete some exercises. To do this, in week 1 you will be allocated into groups of 3-4 and you are encouraged to meet with your group in week 2 by zoom at a mutually beneficial time. Each group has their own discussion board, which you can use to help organise a meet up time. Interacting, discussing, and working through problems with your peers is an important skill for any biostatistician. This is also nice activity to get to know your peers in this online course.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>**Wander into the Wonder!**</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "13  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n\nCode\n1 + 1\n\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bernardo, JM, MJ Bayarri, JO Berger, AP Dawid, D Heckerman, AFM Smith,\nand M West. 2007. “Generative or Discriminative? Getting the Best\nof Both Worlds.” Bayesian Statistics 8 (3): 3–24.\n\n\nBerry, Scott M, Bradley P Carlin, J Jack Lee, and Peter Muller. 2010.\nBayesian Adaptive Methods for Clinical Trials. CRC press.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari,\nand Donald B Rubin. 2013. Bayesian Data Analysis (3rd Edition).\nChapman; Hall/CRC.\n\n\nGelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su.\n2008. “A Weakly Informative Default Prior Distribution for\nLogistic and Other Regression Models.” The Annals of Applied\nStatistics 2 (4): 1360–83.\n\n\nHernán, M, and J Robins. 2025. Causal Inference: What If. Boca\nRaton: Chapman & Hall/CRC.\n\n\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with r,\nJAGS, and Stan. Academic Press.\n\n\nLambert, Ben. 2018. A Student’s Guide to Bayesian Statistics.\nSAGE Publications Ltd.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in r and Stan (2nd Edition). Chapman; Hall/CRC.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P Jewell. 2016. Causal\nInference in Statistics: A Primer. John Wiley & Sons.\n\n\nQuintana, Melanie, Kert Viele, and Roger J Lewis. 2017. “Bayesian\nAnalysis: Using Prior Information to Interpret the Results of Clinical\nTrials.” JAMA 318 (16): 1605–6.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "M01_1.html#the-maze",
    "href": "M01_1.html#the-maze",
    "title": "1  Navigating Evidence",
    "section": "1.4 The Maze",
    "text": "1.4 The Maze\n\nBayesian analysis is a logical framework that helps update our beliefs based on continuous new information. A helpful analogy is navigating a maze with an incomplete map. Each step provides new clues, and with every clue, your understanding of the maze improves. By continuously updating your knowledge with new information, you eventually find the exit. This is how Bayesian analysis works, it continuously updates our understanding as more evidence comes in.\nTo see this in practice, let’s consider an example explained below.\n\n1.4.1 Example:\nA medical practitioner had seen many cases of pneumonia before, but this one was tricky. A 55-year-old patient, had been admitted with high fever, cough, and shortness of breath. Based on his symptoms and an initial chest X-ray, the practitioner diagnosed him with bacterial pneumonia and started him on a standard antibiotic.\nAt this point, their belief was strong that the chosen antibiotic would work, this was their prior probability based on past experience.\nDay 2:\nAfter 24 hours, the patient wasn’t improving. Thier fever remained high, and their breathing was still labored.\nThe practitioner now had new evidence, the treatment wasn’t working as quickly as it should. Applying Bayesian reasoning, they adjusted their belief:\n\nThe probability that this was a typical bacterial pneumonia responding to first-line antibiotics decreased.\nThe probability that it was a resistant strain of bacteria or even a different type of infection increased.\n\nThey needed more information.\nDay 3:\nThe practitioner ordered a sputum culture to check for antibiotic-resistant bacteria. In the meantime, they updated the treatment, switching the patient to a broader-spectrum antibiotic.\n\nIf the new antibiotic worked, it would confirm that the initial one was ineffective, meaning resistant bacteria were likely the cause.\nIf the patient still didn’t improve, it could mean this wasn’t bacterial pneumonia at all, it might be a viral infection instead.\n\nAgain, their belief about the cause of the patient’s illness shifted based on new evidence.\nDay 4:\nThe test results came in: The patient’s infection was caused by a drug-resistant strain of bacteria. This confirmed that the initial choice of antibiotics was ineffective.\nWith this new evidence, the practitioner’s belief was now much stronger that the broader-spectrum antibiotic was the right choice.\nThe Lesson of Bayesian Thinking\nThe medical practitioner didn’t just rely on their initial belief. Instead, they continuously updated their understanding as new evidence emerged, just like someone navigating a maze learns from every wrong turn. This process demonstrates how Bayesian reasoning helps in making data-driven, logical decisions, not just by guessing, but by continuously refining our beliefs with new information, ultimately leading to the best possible decision.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>**Navigating Evidence**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#prior-to-posterior-distribution",
    "href": "M02_1.html#prior-to-posterior-distribution",
    "title": "3  Prior and Posterior",
    "section": "3.2 Prior to Posterior Distribution",
    "text": "3.2 Prior to Posterior Distribution\n\n\n\n\nGelman et al. (2013)\n\\[\\begin{align}\n\\text{initial belief} \\xrightarrow[]{\\text{Bayes rule + data}} \\text{new belief}\n\\end{align}\\]\nFirst, let’s look at some real-world examples of how prior distributions play a crucial role, particularly in health and medical data.\nWe already got a flavour that prior distributions allow researchers to incorporate existing knowledge or expert opinions into their statistical models, improving the precision of their conclusions. For example, when designing treatments/interventions, prior knowledge helps tailor them to individual patients, enhancing both personalisation and effectiveness.\nImagine historical data shows that a certain drug has a 70% success rate in patients with similar profiles. By using an informative prior distribution, we can incorporate this insight to estimate the likelihood of success for a new patient. If fresh data suggests an 80% effectiveness rate, Bayesian methods refine this estimate, leading to a more balanced probability—say, around 75%. This synthesis of prior knowledge with new evidence results in more reliable conclusions.\nPrior information is also invaluable when historical data is limited or when researching new treatments. In such cases, a non-informative prior—such as assuming an initial effectiveness probability of 0.5—can be used, gradually updating as more data becomes available.\n\n3.2.1 Posterior Summary\n\nThe posterior distribution is a valid probability distribution obtained through Bayesian inference, representing the updated beliefs about a parameter after incorporating prior knowledge and observed data. While the full posterior distribution provides a comprehensive summary of uncertainty, policymakers often require point estimates to facilitate decision-making. Common Bayesian point estimates include the posterior mean, posterior median, and maximum a posteriori (MAP) estimate. Among these, the posterior mean and median are generally preferred over the MAP estimate because MAP focuses solely on the mode of the posterior density, ignoring the overall distribution’s shape and probability mass. This can lead to misleading inferences, especially when the posterior distribution is skewed or multimodal. Moreover, since MAP is a mode, it may lie far from the regions of high probability mass, making it a less robust estimator compared to the mean or median.\n\n\n\n\n\nPosterior Point Estimates; Lambert (2018)\n\n\n\n\nBeyond point estimates, it is also important to quantify uncertainty, which is where credible intervals come into play. A credible interval provides an interval within which the true parameter value is likely to lie with a specified probability (e.g., 95%). Unlike frequentist confidence intervals, credible intervals have a direct probabilistic interpretation: if a 95% credible interval for a parameter is \\([a, b]\\), we can say there is a 95% probability that the parameter lies within this range, given the observed data and prior information. This makes credible intervals particularly useful for policy decisions, as they provide a natural way to express uncertainty in estimates, allowing decision-makers to weigh risks and benefits accordingly.\nExample\nConsider a policymaker estimating the proportion of a population that supports a new public health initiative. Suppose they collect survey data from 1,000 people, where 600 respondents express support. A Bayesian approach models this as a binomial likelihood with a Beta prior (a common conjugate prior for proportions). If the prior is \\(\\text{Beta}(2,2)\\), which represents a weak prior belief that the proportion is roughly uniform between 0 and 1, the posterior distribution is updated using the observed data:\n\\[\n\\theta | \\text{data} \\sim \\text{Beta}(2 + 600, 2 + 400) = \\text{Beta}(602, 402)\n\\]\nFrom this posterior, the policymaker can derive different point estimates:\n\nPosterior Mean: Given a \\(\\text{Beta}(a, b)\\) distribution, the mean is $ $, which in this case is:\n\n\\[\n\\frac{602}{602 + 402} = 0.60\n\\]\nThis suggests that, on average, the Bayesian model estimates 60% of the population supports the initiative.\n\nPosterior Median: This is the value that splits the posterior probability into two equal halves. For a Beta distribution, the median can be approximated numerically, where we can write the median approximately\n\n\\[\n\\frac{a-1/3}{a+b-2/3} = \\frac{602-1/3}{602+402-2/3} \\approx 0.6\n\\] and in this case, it is close to 0.6.\n\nMaximum a Posteriori (MAP): The MAP estimate is the mode of the Beta distribution, which for \\(\\text{Beta}(\\alpha, \\beta)\\) is:\n\n\\[\n\\frac{a - 1}{a + b - 2} = \\frac{601}{1000} = 0.601\n\\]\nWhile close to the posterior mean, the MAP estimate can be problematic in other cases, particularly with skewed distributions, since it focuses only on the density’s peak rather than the overall probability mass.\n\nCredible Interval: To express uncertainty, the policymaker can compute a 95% credible interval, which provides a range where the true proportion likely falls. For the \\(\\text{Beta}(602, 402)\\) distribution, the central 95% credible interval (obtained numerically) is approximately \\((0.576, 0.623)\\).\n\nThis means that, given the data and prior, there is a 95% probability that the true proportion of public support lies between 57.6% and 62.3%. This interval gives a clearer sense of uncertainty than a single point estimate and helps policymakers make informed decisions while considering potential variations in public opinion.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\na &lt;- 602  \nb &lt;- 402  \n\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nposterior_density &lt;- dbeta(theta_vals, a, b)\n\nposterior_mean &lt;- a / (a + b)\nposterior_median &lt;- qbeta(0.5, a, b)\nposterior_map &lt;- (a - 1) / (a + b - 2)\ncredible_interval &lt;- qbeta(c(0.025, 0.975), a, b)\n\nposterior_df &lt;- data.frame(theta = theta_vals, density = posterior_density)\n\np = ggplot(posterior_df, aes(x = theta, y = density)) +\n  geom_line(color = \"blue\", size = 1) +\n  \n  geom_vline(xintercept = posterior_mean, color = \"red\", linetype = \"dashed\", size = 1) +\n  \n  geom_vline(xintercept = posterior_median, color = \"green\", linetype = \"dotted\", size = 1) +\n  \n  geom_vline(xintercept = posterior_map, color = \"purple\", linetype = \"dotdash\", size = 1) +\n  \n  geom_ribbon(aes(ymin = 0, ymax = density), \n              data = subset(posterior_df, theta &gt;= credible_interval[1] & theta &lt;= credible_interval[2]),\n              fill = \"gray\", alpha = 0.3) +\n  \n  geom_vline(xintercept = credible_interval[1], color = \"gray\", linetype = \"solid\", size = 1) +\n  geom_vline(xintercept = credible_interval[2], color = \"gray\", linetype = \"solid\", size = 1) +\n  \n  labs(title = \"Posterior Distribution of θ\",\n       x = \"θ (Proportion)\",\n       y = \"Density\",\n       caption = \"Red: Mean, Green: Median, Purple: MAP, Gray: 95% Credible Interval\") +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank())\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\n\n\n\n3.2.2 Exact Inference\n\n\nThe exact inference in Bayesian modeling refers to the precise calculation of posteriors. It involves the direct calculation of the posterior distribution by applying Bayes’ theorem considering the given prior distribution and data likelihood.\nWe have already seen from the Bernoullie distribution example that, choosing a particular type of prior distribution results in a posterior that belongs to the same distribution family. This property that posterior distribution has the same functional form as the prior distribution is called conjugacy. Priors that have this feature are called conjugate priors. In the Bernoulli model example, the conjugate nature of the Beta prior ensures that the posterior distribution remains a Beta distribution, which provides analytical tractability.\nBelow we present some common pairs of likelihoods and priors related to conjugacy:\n\n\n\n\n\n\n\n\nLikelihood\nConjugate Prior\nPosterior Distribution\n\n\n\n\n\\(\\text{Bernoulli}(\\theta)\\)\n\\(\\text{Beta}(a, b)\\)\n\\(\\text{Beta}(a + y, b + n-y)\\)\n\n\n\\(\\text{Poisson}(\\lambda)\\)\n\\(\\text{Gamma}(a, b)\\)\n\\(\\text{Gamma}(a + y, b + n)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Known variance)\n\\(\\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\\(\\mathcal{N}(\\mu_n, \\sigma_n^2)\\)\n\n\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\) (Unknown variance)\nNormal-Gamma \\((\\mu_0, \\lambda_0, \\alpha, \\beta)\\)\nNormal-Gamma \\((\\mu_n, \\lambda_n, \\alpha_n, \\beta_n)\\)\n\n\n\nThe method is computationally feasible only when the models involved are simple or when they allow for analytical solutions. Bayesian exact inference can be challenging with complex models. Furthermore, if we opt to use a non-conjugate prior, the posterior distribution cannot be easily simplified into a common distribution form and derivation of marginal likelihood will be challenging, if we want to.\nIn this case, to obtain the posterior distribution we need numerical methods or approximations, as analytical solutions are no longer straightforward or feasible. This complexity of the calculations requires the use of advanced computational techniques such as Markov chain Monte Carlo (MCMC) techniques. We will discuss more on the solutions for these types of situations in our next lecture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M02_1.html#more-insights-into-prior",
    "href": "M02_1.html#more-insights-into-prior",
    "title": "3  Prior and Posterior",
    "section": "3.3 More Insights into Prior",
    "text": "3.3 More Insights into Prior\n\nUnderstanding the appropriate selection of prior distributions in modeling is crucial. Prior distributions can be categorised as informative, non-informative, weakly informative, or based on expert judgment. This section explores into these various types of prior distributions, examining their applicability and relevance.\n\n3.3.1 Informative Prior\n\n\n\nAn informative prior is a type of prior distribution that is based on information that provides significant idea about the parameters being estimated. Since informative priors reflect more certainty, they tend to be more concentrated around a certain value. The informative prior has a strong influence on the posterior distribution, especially when the data is limited or noisy. In cases with substantial data, the posterior may still be mostly driven by the observed data, but the prior will still play a role in shaping the final outcome.\nTo explain it more, suppose, we want to know the efficacy rate of a certain vaccine in patients with similar profiles. Let’s consider that the efficacy rate of the vaccine range from 70% to 90%, which we know from literature. Now from a pilot study we observe 16 successes out of 20 trials, i.e., the efficacy rate is still 80%. Hence, we can easily get the posterior distribution of the efficacy rate from \\(\\text{Beta}(24, 6)\\) distribution, if we consider the prior average success rate of 80%, which is calculated from the range 70% to 90%. Numerically, we can plot the prior and posterior distributions as:\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 8\nb_prior &lt;- 2\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(8,2)], i.e., 80% vs Posterior Distributions [Beta(24,6)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 9\nb_prior &lt;- 4\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(9,4)], i.e., 70% vs Posterior Distributions [Beta(25,8)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nCode\n#\na_prior &lt;- 10\nb_prior &lt;- 1\nn &lt;- 20  \ny &lt;- 16  \na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\npr_values &lt;- seq(0, 1, length.out = 1000)  \nprior &lt;- dbeta(pr_values, a_prior, b_prior) \nposterior &lt;- dbeta(pr_values, a_post, b_post)\ndata &lt;- data.frame(\n  p = rep(pr_values, 2),\n  density = c(prior, posterior),\n  Distribution = rep(c(\"Prior\", \"Posterior\"), each = length(pr_values))\n)\nggplot(data, aes(x = p, y = density, color = Distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Prior [Beta(10,1)], i.e., 90% vs Posterior Distributions [Beta(26,5)]\",\n    x = \"Efficacy Rate\",\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\"))\n\n\n\n\n\n\n\n\n\nThe informative prior in this example allows you to start with a reasonable expectation (from historical data) and update it with observed results. This is especially useful when the sample size is small or the observed data alone might not be robust enough to guide decision-making.\n\n\n\n3.3.2 Non-informative Prior\n\n\n\nA non-informative prior (also known as an uninformative prior or objective prior or diffuse prior) is a type of prior distribution used in Bayesian statistics that is intended to have minimal influence on the posterior distribution. It reflects a lack of specific prior knowledge about the parameter of interest, allowing the data to drive the inference as much as possible.\nNon-informative priors are often used when the goal is to let the observed data dominate the analysis. These are useful in cases where objectivity is critical or where prior knowledge is genuinely unavailable, but they may not always be appropriate when prior information exists.\nNon-informative priors often reflect a high degree of uncertainty about the parameter’s value, and might end up with parameter estimates similar to the estimates obtained from frequentist approach.\nBefore going into details, let’s explain some prior distribution concepts:\nImproper Priors: Prior distributions that do not integrate to 1 and therefore are not valid probability distributions but can still be useful for inference if they lead to proper posterior distributions. For instance, \\(p(\\theta) \\propto 1/\\theta\\) for scale parameters.\nFlat Priors: Priors that are constant over the range of the parameter (often used for parameters with bounded support).\nNow, we will discuss some common approaches to defining non-informative priors:\n\nUniform Priors:\n\nUniform priors assign equal probability across all possible values of a parameter, assuming no preference for any particular value (e.g., \\(p(\\theta) \\propto 1\\), where for a probability parameter \\(\\theta\\) in a Bernoulli model, a uniform prior on \\(\\text{Unif}[0, 1]\\) implies no prior belief about the likelihood of success. From the plot below we cannot visualize the likelihood function (scaled), as the posterior distribution and likelihood functions are same.\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100       \ntrue_theta &lt;- 0.8  \ndata &lt;- rbinom(n, size = 1, prob = true_theta)  \nsuccesses &lt;- sum(data)  \nfailures &lt;- n - successes\n# Uniform prior: P(theta) ∝ 1 on [0, 1]\n# The uniform prior is equivalent to Beta(1, 1).\na_prior &lt;- 1  \nb_prior &lt;- 1  \na_post &lt;- a_prior + successes\nb_post &lt;- b_prior + failures\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(successes, size = n, prob = theta_vals)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nprior_density &lt;- dbeta(theta_vals, a_prior, b_prior)\nposterior_density &lt;- dbeta(theta_vals, a_post, b_post)\n# likelihood - scaled\nlikelihood_scaled &lt;- likelihood / max(likelihood) * max(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, posterior_density, likelihood_scaled),\n  type = rep(c(\"Prior (Uniform)\", \"Posterior\", \"Likelihood (Scaled)\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior, Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\",\"red\",\"blue\"))\n\n\n\n\n\n\n\n\n\n\nJeffreys’ Priors:\n\nJeffreys’ prior is a non-informative prior derived based on the Fisher information matrix, ensuring invariance under reparameterisation. This prior is proportional to the square root of the determinant of the Fisher information: \\(p(\\theta) \\propto \\sqrt{|I(\\theta)|}\\), where \\(I(\\theta)\\) is the Fisher information.\nJeffreys’ prior is invariant under reparameterisation means that if you change the parameterization of a model (i.e., if you make a transformation of the parameters), the form of the Jeffreys’ prior does not change.\nBinomial distribution\nLet us now explain this using Binomial distribution, where we observe 16 successes out of 20 trials, i.e., the efficacy rate is 80% observed from a pilot survey.\nNow, we write the Fisher information matrix as: \\(I(\\theta)=\\frac{n}{\\theta(1-\\theta)}\\). Hence, we get Jeffreys prior for \\(\\theta\\) as:\n\\[\np(\\theta) \\propto \\sqrt{\\left| \\frac{n}{\\theta(1-\\theta)}\\right|} \\propto \\frac{1}{\\sqrt{\\theta(1-\\theta)}}\n\\]\nwhere, we can ignore \\(\\sqrt{n}\\) using the proportional sign, as it is free from the model parameter \\(\\theta\\). Hence, we can plot the distributions as:\n\n\nCode\nlibrary(ggplot2)\njeffreys_prior &lt;- function(theta) {\n  return(1 / sqrt(theta * (1 - theta)))  \n}\nlikelihood &lt;- function(theta, k, n) {\n  return(choose(n, k) * theta^k * (1 - theta)^(n - k))  \n}\nn &lt;- 20  \nk &lt;- 16 \ntheta_vals &lt;- seq(0.01, 0.99, length.out = 1000)  \nprior_density &lt;- jeffreys_prior(theta_vals)\nlikelihood_density &lt;- likelihood(theta_vals, k, n)\nposterior_density &lt;- likelihood_density * prior_density\nprior_density &lt;- prior_density / sum(prior_density)\nlikelihood_density &lt;- likelihood_density / sum(likelihood_density)\nposterior_density &lt;- posterior_density / sum(posterior_density)\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood\", \"Posterior\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Binomial Model\",\n    x = expression(theta),\n    y = \"Scaled Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nNormal Distribution\nLet’s consider a normal distribution with known variance \\(\\sigma^2\\). We write the Fisher information for the mean parameter \\(\\mu\\) as \\(I(\\mu) =\\frac{n}{\\sigma^2}\\), where \\(n\\) is the sample size. Hence, we write the Jeffreys prior for \\(\\mu\\) as the proportional to the square root of the Fisher information, i.e.,\n\\[\np(\\mu) \\propto \\sqrt{|I(\\mu)|} = \\sqrt{\\frac{n}{\\sigma^2}}\n\\]\nSince, \\(\\sigma^2\\) is a constant, hence for the mean of a normal distribution, it’s constant, i.e., Jeffreys prior is \\(p(\\mu) \\propto 1\\), and \\(-\\infty \\le \\mu \\le \\infty\\).\nThus, the prior is uniform over the parameter space. We write the posterior for \\(\\mu\\) follows normal distribution with mean \\(\\bar{y}\\) (sample mean) and variance \\(\\sigma^2/n\\).\nNow let us explain with an eample. Suppose a new antihypertensive drug is tested in a clinical trial, and researchers measure the reduction in systolic blood pressure (in mmHg) among patients. Where, most patients experience a blood pressure reduction of around 5 mmHg, but there is natural variability, which is about 2 standard deviation. Now considering Jeffreys non-informative prior, we can get the posterior distribution of the systolic blood pressure.\nFollowing this we draw the density plots using R code as follows:\n\n\nCode\nlibrary(ggplot2)\nset.seed(123)  \nn &lt;- 100        \ntrue_mu &lt;- 5    \nsigma &lt;- 2      \ndata &lt;- rnorm(n, mean = true_mu, sd = sigma)  \n# Fisher information for the mean is: I(mu) = n / sigma^2\nfisher_info &lt;- n / sigma^2 \n# Jeffreys prior is proportional to sqrt(I(mu)). For the mean of a normal distribution, it's constant, i.e., uniform over the parameter space\njeffreys_prior &lt;- function(mu) {\n  return(rep(1, length(mu)))  \n}\nsample_mean &lt;- mean(data)\nposterior_mean &lt;- sample_mean\nposterior_sd &lt;- sigma / sqrt(n)\n\nlikelihood &lt;- function(mu) {\n  return(dnorm(mu, mean = sample_mean, sd = sigma / sqrt(n)))\n}\n\nmu_vals &lt;- seq(true_mu - 3 * sigma, true_mu + 3 * sigma, length.out = 1000)\n\nprior_density &lt;- jeffreys_prior(mu_vals)\nlikelihood_density &lt;- likelihood(mu_vals)\nposterior_density &lt;- dnorm(mu_vals, mean = posterior_mean, sd = posterior_sd)\n\nlikelihood_density &lt;- likelihood_density / max(likelihood_density) * max(posterior_density)\n\nplot_data &lt;- data.frame(\n  mu = rep(mu_vals, 3),\n  density = c(prior_density, likelihood_density, posterior_density),\n  type = rep(c(\"Prior (Jeffreys)\", \"Likelihood (Scaled)\", \"Posterior\"), each = length(mu_vals))\n)\nggplot(plot_data, aes(x = mu, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Jeffreys Prior, Likelihood, and Posterior for Normal Model\",\n    x = expression(mu),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nFurther Notes\nDespite being called “non-informative,” their choice can still involve subjective decisions. Some priors, like uniform priors, may appear non-informative in one parameterisation but informative in another (e.g., uniform in \\(\\theta\\) vs. \\(\\log(\\theta)\\)).\nTo explain this, consider a the case where we defined a uniform prior for \\(\\theta\\), i.e., \\(p(\\theta) = \\text{constant}\\), implies that all values of \\(\\theta\\) are equally likely. Now, suppose we reparameterise the problem using a new variable, say logit transformation:\n\\[\n\\phi = \\log \\frac{\\theta}{1 - \\theta}\n\\]\nIf \\(\\theta\\) follows a \\(\\text{Unif}[0, 1]\\) prior, what does this imply about \\(\\phi\\)? Using the change of variables formula for probability densities:\n\\[\np(\\phi) = p(\\theta) \\left| \\frac{d\\theta}{d\\phi} \\right|\n\\]\nSince \\(\\theta = \\frac{e^\\phi}{1 + e^\\phi}\\), its derivative is:\n\\[\n\\frac{d\\theta}{d\\phi} = \\frac{e^\\phi}{(1 + e^\\phi)^2}\n\\]\nSubstituting this into the density transformation:\n\\[\np(\\phi) \\propto \\frac{\\exp(\\phi)}{(1 + \\exp(\\phi))^2}\n\\]\nwhich is the logistic distribution rather than a uniform distribution. This shows that a uniform prior on \\(\\theta\\) induces a highly structured prior on \\(\\phi\\), meaning that the prior is no longer flat in the transformed space. We will learning more about this in hierarchical modelling.\nThis concept is crucial in Bayesian statistics, as it shows that non-informative priors are not always truly non-informative; their informativeness depends on the chosen parameter space.\n\n\n3.3.3 Weakly Informative Prior\n\n\n\nA weakly informative prior distribution in Bayesian statistics is characterised as proper, yet it is designed to provide information that is intentionally less robust than the actual prior knowledge available.\nLet’s explain this with the example of efficacy rate of the vaccine. If we consider a \\(\\text{Beta}(1,1)\\) prior for the parameter \\(\\theta\\), then we have already discussed that the prior is a flat line, which represents a non-informative situation. Now, considering a \\(\\text{Beta}(0.5,0.5)\\) prior might lead to a distribution similar to Jefferys’ prior. Whereas, if we consider a \\(\\text{Beta}(2,2)\\) prior, then it favours a middle value (0.5) but still flexible. This prior avoids extreme values (near 0 or 1) unless strongly supported by the data. Below, we can plot all these three different priors.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\ntheta_vals &lt;- seq(0, 1, length.out = 1000)\nbeta_1_1 &lt;- dbeta(theta_vals, 1, 1)    # Uniform prior\nbeta_0_5_0_5 &lt;- dbeta(theta_vals, 0.5, 0.5)  # Jeffreys' prior\nbeta_2_2 &lt;- dbeta(theta_vals, 2, 2)    # Weakly informative prior\nplot_data &lt;- data.frame(\n  theta = rep(theta_vals, 3),\n  density = c(beta_1_1, beta_0_5_0_5, beta_2_2),\n  type = rep(c(\"Beta(1,1) - Uniform\", \"Beta(0.5,0.5) - Jeffreys\", \"Beta(2,2) - Weakly Informative\"), each = length(theta_vals))\n)\nggplot(plot_data, aes(x = theta, y = density, color = type)) +\n  geom_line(size = 1) +\n  labs(title = \"Comparison of Different Beta Priors\",\n       x = expression(theta), \n       y = \"Density\", \n       color = \"Distribution\") +\n  ylim(0,3) +\n  theme_minimal() +\n  scale_color_viridis_d(option = \"cvidis\")\n\n\n\n\n\n\n\n\n\nNow assume that the success rate of the vaccine is about 50%, and we can consider the prior distribution as \\(\\text{Beta}(2,2)\\). This symmetric pattern favours the efficacy rate around 0.5 but also allows a wide range of plausible values. Now, suppose 30 trials out of \\(n = 50\\) shows success. Hence, we get the posterior distribution as \\(\\text{Beta}(32,22)\\). Below you can see the density plots of the distributions.\n\n\nCode\nlibrary(ggplot2)\na_prior &lt;- 2\nb_prior &lt;- 2\nn &lt;- 50\ny &lt;- 30\na_post &lt;- a_prior + y\nb_post &lt;- b_prior + (n - y)\np &lt;- seq(0, 1, length.out = 1000)\n\nprior &lt;- dbeta(p, a_prior, b_prior)\n# Scaled for visualisation\nlikelihood &lt;- dbinom(y, n, p) * 100  \nposterior &lt;- dbeta(p, a_post, b_post)\n\nplot_data &lt;- data.frame(\n  p = p,\n  Likelihood = likelihood,\n  Posterior = posterior,\n  Prior = prior\n)\ndata_long &lt;- reshape2::melt(plot_data, id = \"p\", variable.name = \"Distribution\", value.name = \"Density\")\nggplot(data_long, aes(x = p, y = Density, color = Distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Prior (weakly informative), Likelihood, and Posterior Distributions\",\n    x = expression(theta),\n    y = \"Density\",\n    color = \"Distribution\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"green\", \"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\nWeakly informative priors are common in modern Bayesian modeling, where it balances interpretability, robustness, and computational efficiency. Even though weakly informative priors are designed to be robust, they still influence the posterior, especially in small-sample scenarios. What counts as weakly informative is context-dependent. For example, a \\(\\text{Normal}(0,10^2)\\) prior on a regression coefficient might be weakly informative in a standard model but too weak in a context where coefficients are typically small. We will explain more about the weakly informative prior when we will learn the Bayesian regression and hierarchical models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**Prior and Posterior**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#prior-for-variability",
    "href": "M03_2.html#prior-for-variability",
    "title": "6  Prior Tweaks and More",
    "section": "6.3 Prior for Variability",
    "text": "6.3 Prior for Variability\n\n\nHistorically, Bayesian models used Inverse-Gamma priors for variability parameters, because it has support on positive values and has nice mathematical properties (conjugate prior for the normal distribution). However, in Bayesian model (e.g., Bayesian regression), this might cause problems. For example, to represent non-informativeness, we can consider \\(\\text{IG}(a=0.001,b=0.001)\\), which uses very small values for the hyperparameters of the distribution. Even though \\(\\text{IG}(a=0.001,b=0.001)\\) appears non-informative, it biases the model toward very small variance values. It is “too informative” in a negative way, not because it is strong, but because it pretends to be weak while still influencing the outcome. Furthermore, the use of \\(\\text{IG}(a,b)\\) often favours small variances, which can lead to underestimating uncertainty in group-level effects. In addition, in regression settings, if the model is complex, the use of \\(\\text{IG}(a,b)\\) can make it difficult to achieve convergence in the MCMC sampling for the variance parameter, as the distribution can become spiky near zero, leading to unstable behavior during inference.\nWe have already discussed in our previous lecture that we can approximate the inverse Gamma prior with Student-t distribution. Still this will not aid some of the issues that we mentioned, such as not having a heavy tail. In today’s lecture will learn about some other distributions that can provide reasonable solutions.\n\n6.3.1 Half-Cauchy Prior\nTo avoid the issues with inverse Gamma distribution, the half-Cauchy distribution (i.e., a Cauchy distribution restricted to positive values) is popularly used. Half-Cauchy also behaves as weakly informative prior and provides better inference (depending on the choice of hyper paramters).\nWe prefer using the half-Cauchy prior for the parameter \\(\\sigma\\) because it has several useful properties. It has heavy tails, which means it allows for large values of \\(\\sigma\\) when the data support it, rather than cutting them off or overly constraining them. Unlike the Inverse Gamma prior, it is less informative near zero and does not push the variance toward small values, which can be especially important in hierarchical models. It also provides a form of regularisation by gently pulling estimates toward smaller values without being too aggressive, allowing the data to guide the estimates more naturally.\nOne of the issues may arise for Half-Cauchy \\(\\sigma\\) prior in hierarchical Bayesian model relates to the non-conjugacy. However, use of cleaver MCMC sampling algorithm such as HMC-NUTS can provide a solution to this problem.\nNow, we can rewrite the DAG we provided in our last lecture related to the BMD model, where we replace the Inverse Gamma prior by the Half-Cauchy.\n\n\n\n\n\n\nHere, we use the Half-Cauchy prior distribution separately for the variance parameter instead of the Inverse Gamma distribution, while keeping the priors for \\(\\beta_0\\) and \\(\\beta_1\\), as normal distributions \\(N(0,10^2)\\), which gives us the following prior distributions:\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyverse)\n\nx_norm &lt;- seq(-40, 40, length.out = 500)\n\nnormal_density &lt;- dnorm(x_norm, mean = 0, sd = 10)\ndf_beta &lt;- tibble(\n  x = x_norm,\n  density = normal_density\n)\np1 &lt;- ggplot(df_beta, aes(x, density)) +\n  geom_line(color = \"steelblue\", size = 1.2) +\n  labs(\n    title = expression(\"Prior for \" ~ beta[0]),\n    x = expression(beta[0]),\n    y = \"Density\"\n  ) +\n  theme_minimal()\np2 &lt;- ggplot(df_beta, aes(x, density)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  labs(\n    title = expression(\"Priors for \" ~ beta[1] * \" and \" * beta[0]),\n    x = expression(beta[1]),\n    y = \"Density\"\n  ) +\n  theme_minimal()\nx_sigma &lt;- seq(0.001, 5, length.out = 500)\nhalf_cauchy_density &lt;- dcauchy(x_sigma, location = 0, scale = 1)  # Half-Cauchy with scale = 1\ndf_sigma &lt;- tibble(\n  x = x_sigma,\n  density = half_cauchy_density\n)\np3 &lt;- ggplot(df_sigma, aes(x, density)) +\n  geom_line(color = \"firebrick\", size = 1.2) +\n  labs(\n    title = expression(\"Half-Cauchy Prior for \" ~ sigma),\n    x = expression(sigma),\n    y = \"Density\"\n  ) +\n  theme_minimal()\n#library(patchwork)\n#(p1 | p2 | p3) + plot_annotation(title = \"Prior Distributions\")\nlibrary(gridExtra)\ngrid.arrange(p2,p3,ncol=2)\n\n\n\n\n\n\n\n\n\nHence, we get the posterior summaries based on the Half-Cauchy prior distribution with hyper-parmater one as follows. Note that for ‘brms’ R package, we define the prior distributions for \\(\\sigma\\) instead of \\(\\sigma^2\\), which we write:\n\nprior(cauchy(0, 1), class = “sigma”)\n\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_restricted.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data &lt;- tibble(\n  BMD = bmd_data$bmd,\n  BMI = bmd_data$bmi,\n)\n\n# model\nbmd_model &lt;- brm(\n  formula = BMD ~ BMI,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"BMI\"),   # N(mean, sd) Slope priors\n    prior(normal(0, 10), class = \"Intercept\"),   # N(mean, sd) Intercept prior\n    prior(cauchy(0, 1), class = \"sigma\")  # Half-Cauchy prior for sigma\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 1:                0.028 seconds (Sampling)\nChain 1:                0.072 seconds (Total)\nChain 1: \n\n\nCode\nsummary(bmd_model)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI \n   Data: bmd_data (Number of observations: 169) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.42      0.07     0.29     0.57 1.00     1273      773\nBMI           0.01      0.00     0.01     0.02 1.00     1233      872\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.16      0.01     0.14     0.17 1.00      700      608\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\n#posterior_summary(bmd_model)\n#plot(bmd_model)\n\n\n\nThe model result suggests that the standard deviation (\\(\\sigma\\)) of residuals is estimated to be around 0.16, with the uncertainty around this estimate being quite low (Est.Error = 0.01). The credible interval for sigma is between 0.14 and 0.17, and the MCMC sampling appears to have converged well based on the Rhat and ESS values.\n\n\n6.3.2 Exponential Prior\nAnother potential caldidate distribution for replacing the Inverse Gamma distribution for the variability parameter \\(\\sigma\\) is the Exponential distribution, i.e., \\(\\sigma \\sim \\text{Exp}(\\lambda)\\), with \\(\\lambda\\) as the hyper-parameter. This distribution is mathematically simple and computationally efficient. Using an exponential prior with a small rate (like \\(\\lambda = 1\\)) can be seen as a weakly informative prior. This means it doesn’t strongly influence the outcome but still provides some regularisation (keeping variance from growing excessively). This is helpful when you have limited prior knowledge about the variance, as it avoids over-penalising large values of the variance while still discouraging very small values.\nWe can get similar result using exponential prior distribution with rate hyper-parameter \\(\\lambda=1\\). Here in R code we need to replace\n\nprior(cauchy(0, 1), class = “sigma”)\n\nby\n\nprior(exponential(1), class = “sigma”)\n\nto get posterior distribution of the model parameter \\(\\sigma^2\\).\nIn particular, if we use \\(\\text{Half-Cauchy}(0,\\tau=1)\\) and \\(\\text{Exp}(\\lambda=1)\\), then this gives us the following prior distributions:\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyverse)\n\nexponential_density &lt;- dexp(x_sigma, rate = 1)  # Exponential with rate = 1\ndf_exp_sigma &lt;- tibble(\n  x = x_sigma,\n  density = exponential_density\n)\np4 &lt;- ggplot(df_exp_sigma, aes(x, density)) +\n  geom_line(color = \"darkorchid\", size = 1.2) +\n  labs(\n    title = expression(\"Exponential Prior for \" ~ sigma),\n    x = expression(sigma),\n    y = \"Density\"\n  ) +\n  theme_minimal()\n\nlibrary(gridExtra)\ngrid.arrange(p3,p4,ncol=2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#prior-for-slope",
    "href": "M03_2.html#prior-for-slope",
    "title": "6  Prior Tweaks and More",
    "section": "6.4 Prior for Slope",
    "text": "6.4 Prior for Slope\n\n\n\n6.4.1 Weakly Informative & Informative\nSuppose, instead using weakly informative prior for \\(\\beta_1\\) (the slope for BMI), we want to use an informative prior. This refers to considering one unit increase in BMI, BMD increases by approximately 0.05 units on average, say we also knowfrom the past data that the standard deviation related to this is very low, i.e., 0.01. Hence, we write the prior distribution as: \\(\\beta_1 \\sim N(0.05, 0.01^2)\\).\n\n\nCode\nlibrary(brms)\nbmd_model_inform &lt;- brm(\n  formula = BMD ~ BMI,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0.05, 0.01), class = \"b\", coef = \"BMI\"),   # Informative prior for beta_1\n    prior(normal(0, 10), class = \"Intercept\"),   # Intercept prior\n    prior(cauchy(0, 1), class = \"sigma\")  # Half-Cauchy prior for sigma\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.5e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.042 seconds (Warm-up)\nChain 1:                0.024 seconds (Sampling)\nChain 1:                0.066 seconds (Total)\nChain 1: \n\n\nCode\nsummary(bmd_model_inform)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI \n   Data: bmd_data (Number of observations: 169) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.36      0.07     0.23     0.50 1.00     1379      905\nBMI           0.02      0.00     0.01     0.02 1.00     1364      830\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.16      0.01     0.14     0.17 1.00      482      601\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nFrom the results related to informative prior for \\(\\beta_1\\), we can say that the informative prior for \\(\\beta_1\\) tightly constrained the estimate of the effect of BMI on BMD, yielding a posterior mean estimate of 0.02 with a narrow credible interval \\([0.01, 0.02]\\). The model shows very high precision for this parameter, with low uncertainty accordingly.\n\n\n6.4.2 Comparison\nNow we will provide a comparison of the \\(\\beta_1\\) estimates from two models: one where we used an informative prior, i.e., \\(\\beta_1\\sim N(0.05,0.01)\\) and another where we used a weakly informative prior \\(\\beta_1\\sim N(0,10^2)\\).\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\n\nx_vals &lt;- seq(-1, 1, length.out = 1000)\nprior_df &lt;- tibble(\n  beta_1 = x_vals,\n  Informative = dnorm(x_vals, mean = 0.05, sd = sqrt(0.01)),\n  Weakly_Informative = dnorm(x_vals, mean = 0, sd = 10)\n)\nprior_df_long &lt;- pivot_longer(\n  prior_df,\n  cols = c(\"Informative\", \"Weakly_Informative\"),\n  names_to = \"Prior_Type\",\n  values_to = \"Density\"\n)\np1 &lt;- ggplot(prior_df_long, aes(x = beta_1, y = Density, color = Prior_Type, fill = Prior_Type)) +\n  geom_line(size = 1.2) +\n  geom_area(alpha = 0.2) +\n  labs(\n    title = expression(\"Prior for \" ~ beta[1]),\n    x = expression(beta[1] ~ \"Prior\"),\n    y = \"Density\",\n    color = \"\",\n    fill = \"\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(tidyverse)\n\nposterior_inform &lt;- as_draws_df(bmd_model_inform)\nposterior_weak   &lt;- as_draws_df(bmd_model)\nbeta1_samples &lt;- bind_rows(\n  posterior_inform %&gt;% select(`b_BMI`) %&gt;% mutate(Model = \"Informative Prior\"),\n  posterior_weak %&gt;% select(`b_BMI`) %&gt;% mutate(Model = \"Weakly Informative Prior\")\n)\np2 &lt;- ggplot(beta1_samples, aes(x = b_BMI, fill = Model, color = Model)) +\n  geom_density(alpha = 0.4) +\n  labs(\n    title = expression(\"Posterior for \" ~ beta[1]),\n    x = expression(beta[1] ~ \"Posterior\"),\n    y = \"Density\",\n    fill = \"\",\n    color = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\"\n  )  \nlibrary(gridExtra)\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nThis above plots show how two different types of prior information affect our estimate of a parameter, \\(\\beta_1\\). The blue curve represents the informative prior, this results in a distribution indicating higher certainty. The red curve represents the weakly informative prior, meaning we have less prior knowledge about \\(\\beta_1\\). This results in a distribution that is more spread out, indicating less certainty.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#bayesian-vs.-frequentist",
    "href": "M03_2.html#bayesian-vs.-frequentist",
    "title": "6  Prior Tweaks and More",
    "section": "6.5 Bayesian vs. Frequentist",
    "text": "6.5 Bayesian vs. Frequentist\nNow we explain and compare the Bayesian and frequentist estimates, where we use informative prior distribution, i.e., \\(\\beta_1\\sim N(0.05,0.01)\\).\n\n\nCode\nlibrary(jtools)\nlm_model &lt;- lm(BMD ~ BMI, data = bmd_data)\njtools::summ(lm_model)\n\n\nMODEL INFO:\nObservations: 169\nDependent Variable: BMD\nType: OLS linear regression \n\nMODEL FIT:\nF(1,167) = 27.98, p = 0.00\nR² = 0.14\nAdj. R² = 0.14 \n\nStandard errors:OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.42   0.07     6.11   0.00\nBMI                 0.01   0.00     5.29   0.00\n-----------------------------------------------\n\n\nCode\nlm_coef &lt;- coef(summary(lm_model))\nbmi_est &lt;- lm_coef[\"BMI\", \"Estimate\"]\nbmi_se &lt;- lm_coef[\"BMI\", \"Std. Error\"]\nci_low &lt;- bmi_est - 1.96 * bmi_se\nci_high &lt;- bmi_est + 1.96 * bmi_se\n\npost &lt;- as_draws_df(bmd_model_inform)\npost_bmi &lt;- post$b_BMI\nbayes_mean &lt;- mean(post_bmi)\nbayes_ci &lt;- quantile(post_bmi, probs = c(0.025, 0.975))\n\np &lt;- ggplot() +\n  geom_density(aes(x = post_bmi), fill = \"skyblue\", alpha = 0.5, color = NA) +\n  geom_vline(xintercept = bmi_est, color = \"red\", size = 1) +\n  geom_vline(xintercept = ci_low, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = ci_high, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = bayes_mean, color = \"blue\", size = 1) +\n  geom_vline(xintercept = bayes_ci[1], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  geom_vline(xintercept = bayes_ci[2], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  labs(\n    title = \"Bayesian (informative) vs Frequentist Estimate of BMI\",\n    subtitle = \"Red: Frequentist (Mean & 95% Confidence Interval)\\nBlue: Bayesian (Posterior Mean & 95% Credible Interval)\",\n    x = \"Coefficient for BMI\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        plot.subtitle = element_text(size = 12))\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\n\nThe above plot shows the estimates of the BMI coefficient (\\(\\beta_1\\)) for BMD using both frequentist and Bayesian methods. On the x-axis, we see the coefficient for BMI, ranging from approximately 0.008 to 0.024, while the y-axis represents density, showing the distribution of the estimates.\nIn Bayesian inference, the blue shaded area represents our posterior distribution of \\(\\beta_1\\), which incorporates both prior information and observed data. The vertical blue solid line indicates our Bayesian posterior mean, and the vertical blue dashed lines show the 95% credible interval. This interval represents the range within which \\(\\beta_1\\) lies with 95% probability, given our prior and the data. The Bayesian approach provides a more nuanced estimate that reflects both our prior beliefs and the observed data, resulting in a posterior distribution that can be more or less spread out depending on the prior and the data.\nWhereas, the frequentist approach relies solely on the observed data to provide point estimates and confidence intervals. The vertical red solid line represents our frequentist maximum likelihood estimate (MLE) of \\(\\beta_1\\), and the vertical red dashed lines show the 95% confidence interval. This interval represents the range within which \\(\\beta_1\\) would lie in 95% of repeated samples, assuming the true value is fixed.\nThe key difference highlighted by this plot is how each method estimates and interprets \\(\\beta_1\\). We can see that the informative prior shifts the mean posterior distribution. We can also see that the Bayesian credible interval is much narrower due to the influence of the informative prior, suggesting that prior information has influenced the estimate.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_2.html#further-model-development",
    "href": "M03_2.html#further-model-development",
    "title": "6  Prior Tweaks and More",
    "section": "6.6 Further Model Development",
    "text": "6.6 Further Model Development\n\n\nGaussian Context\nFollowing the BMD example, where we explore the influence of BMI on BMD. Now, we might want to ask: What role does ‘Age’ or ‘Sex’ of the patient play in this relationship?\nAs people age, their BMD naturally decreases over time, and age also influences factors like BMI. Similarly, sex affects both BMI and BMD, with women being more likely to experience a decline in BMD, particularly in conditions like osteoporosis. These factors age and sex may act as confounders, influencing both BMI and BMD. Hence, we write the DAG using these variables:\n\n\n\n\n\n\n\nIn this case, the estimand is the specific effect of BMI on BMD, while accounting for the influence of age and sex as confounders. The goal is to isolate the effect of BMI on BMD after adjusting for these other variables.\nThe estimator we define here is the Bayesian model, i.e., the Bayesian multiple linear regression model to get the posterior distributions for the model parameters. This model adjusts for confounders like age and sex, helping us to estimate the causal effect of BMI on BMD.\nThe estimate is the posterior distribution of the estimand with some numerical values, such as mean or median derived from the posterior distribution. For example, if the posterior mean estimate is 0.03, this could represent the change in BMD associated with a one-unit increase in BMI, after accounting for the effects of age and sex.\n\n6.6.1 Model & DAG\nWe now develop the Bayesian model with all these four variables. Hence, we write the Bayesian model as:\n\\[\n\\text{BMD}_i \\sim N(\\beta_0 + \\beta_1 \\cdot \\text{BMI}_i + \\beta_2 \\cdot \\text{Age}_i + \\beta_3 \\cdot \\text{Sex}_i, \\sigma^2)\n\\]\nWhere, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the coefficient for BMI, \\(\\beta_2\\) is the coefficient for Age, \\(\\beta_3\\) is the coefficient for Sex (with a reference category; for example, if Sex is binary, it could be “Male” vs. “Female”). This model also includes the variability \\(\\sigma\\) of the error term. Now, assuming weakly informative prior we write:\n\n\\(\\beta_0 \\sim N(0, 10^2)\\)\n\\(\\beta_1 \\sim N(0, 10^2)\\)\n\\(\\beta_2 \\sim N(0, 10^2)\\)\n\\(\\beta_3 \\sim N(0, 10^2)\\)\n\\(\\sigma \\sim \\text{Half-Cauchy}(0, 1)\\)\n\nNote that the model equation can be also written as:\n\\[\n\\text{BMD}_i = \\beta_0 + \\beta_1 \\cdot \\text{BMI}_i + \\beta_2 \\cdot \\text{Age}_i + \\beta_3 \\cdot \\text{Sex}_i + \\epsilon_i\n\\]\nwhere, \\(\\epsilon_i\\) is the error term of the model.\nHence, we draw the DAG for this Bayesian model with prior and hyper-prior parameters as:\n\n\n\n\n\n\n\n\n6.6.2 Results & MCMC Diagnostics\nNow, we implement the Bayesian hierarchical model for this DAG, where we use weakly-informative priors for the model parameters.\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nbmd_data &lt;- read.csv(\"bmd_restricted.csv\")\nbmd_data$bmi &lt;- bmd_data$weight_kg/(bmd_data$height_cm/100)^2\nbmd_data &lt;- tibble(\n  BMD = bmd_data$bmd,\n  BMI = bmd_data$bmi,\n  Age = bmd_data$age,\n  Sex = as.factor(bmd_data$sex)\n)\nbmd_model_multi &lt;- brm(\n  formula = BMD ~ BMI + Age + Sex,\n  data = bmd_data,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"BMI\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"b\", coef = \"Age\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"b\", coef = \"SexM\"), # N(mean, sd)\n    prior(normal(0, 10), class = \"Intercept\"), # N(mean, sd)\n    prior(cauchy(0, 1), class = \"sigma\")  # Half-Cauchy prior for sigma\n    ),  \n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.101 seconds (Warm-up)\nChain 1:                0.05 seconds (Sampling)\nChain 1:                0.151 seconds (Total)\nChain 1: \n\n\nCode\n#prior_summary(bmd_model_multi, all = FALSE)\nprint(prior_summary(bmd_model_multi, all = FALSE), show_df = FALSE)\n\n\nb_Age ~ normal(0, 10)\nb_BMI ~ normal(0, 10)\nb_SexM ~ normal(0, 10)\nIntercept ~ normal(0, 10)\n&lt;lower=0&gt; sigma ~ cauchy(0, 1)\n\n\nCode\nprint(summary(bmd_model_multi), digits=3)\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: BMD ~ BMI + Age + Sex \n   Data: bmd_data (Number of observations: 169) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nIntercept    0.604     0.083    0.441    0.765 1.001     1168      803\nBMI          0.016     0.002    0.011    0.020 1.001     1071      536\nAge         -0.004     0.001   -0.006   -0.003 1.004     1128      692\nSexM         0.095     0.021    0.054    0.134 1.003      654      613\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\nsigma    0.139     0.008    0.125    0.155 1.001      574      579\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nWe can exlain the posterior estimates of the model parameters from the Bayesian model as follows:\n\n\n\n\n\n\n\n\n\nPredictor\nMean (95% Credible Interval)\nRhat\nExplanation\n\n\n\n\nBMI\n0.016 (0.010, 0.021)\n1.003\nA 1-unit increase in BMI is associated with a 0.016 unit increase in BMD, holding other variables constant. This is a small but credible positive effect.\n\n\nAge\n-0.004 (-0.006, -0.003)\n1.002\nEach additional year of age is associated with a 0.004 unit decrease in BMD, suggesting a consistent age-related decline.\n\n\nSex (Male)\n0.095 (0.050, 0.139)\n1.002\nMales have on average 0.095 units higher BMD than females, adjusting for BMI and age. This reflects a moderate and credible sex difference in BMD.\n\n\n\\(\\sigma\\)\n0.139 (0.124, 0.154)\n0.999\nRepresents residual variability in BMD not explained by BMI, age, or sex. The relatively small value suggests a good overall model fit.\n\n\n\nWe can also observe that all \\(\\hat{R}\\) values are \\(\\approx\\) 1.00, i.e., convergence is excellent. The Bulk and Tail ESS values are all \\(&gt;600\\), i.e., sufficient posterior sample size and good mixing of chains.\nTrace Plots\n\n\nCode\nplot(bmd_model_multi)\n\n\n\n\n\n\n\n\n\nCode\n#library(bayesplot)\n#library(brms)\n#posterior &lt;- as_draws_df(bmd_model_multi)\n#mcmc_areas(\n#  posterior,\n#  pars = c(\"b_BMI\", \"b_Age\", \"b_SexM\"),\n#  prob = 0.95  # 95% credible intervals\n#)\n#mcmc_trace(\n#  posterior,\n#  pars = c(\"b_Intercept\", \"b_BMI\", \"b_Age\", \"b_SexM\")\n#)\n\n\nTrace plots for the MCMC samples also shows a nice mixing and density (histogram) plots also shows a normal distributional shape, confirms a good MCMC mixing for the model parameters.\nConditional Effects\nWe can also plot the conditional effects of the predictor variables BMI, Age and Sex. Here, conditional effects refer to the effect of say BMI on BMD considering other variables (i.e., Age and Sex) fixed and so on for Age and Sex.\n\n\nCode\n#plot(conditional_effects(bmd_model_multi, effects = \"BMI\"), points = TRUE)\n#plot(conditional_effects(bmd_model_multi, effects = \"Age\"), points = TRUE)\n#plot(conditional_effects(bmd_model_multi, effects = \"Sex\"))\n\nce &lt;- conditional_effects(bmd_model_multi)\np1 &lt;- plot(ce, effects = \"BMI\", plot = FALSE, points = TRUE)[[1]]\np2 &lt;- plot(ce, effects = \"Age\", plot = FALSE, points = TRUE)[[2]]\np3 &lt;- plot(ce, effects = \"Sex\", plot = FALSE)[[3]]\n#library(patchwork)\n#combined_plot &lt;- p1 + p2 + p3  # 1 row # OR use / to stack vertically: combined_plot &lt;- p1 / p2 / p3\n#combined_plot\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, ncol = 3)\n\n\n\n\n\n\n\n\n\nIn the first plot, we see a positive trend, as BMI increases, BMD also tends to go up. The shaded area around the line shows the uncertainty, or the range where the true trend is likely to fall. The second plot shows a negative trend with Age, meaning that as people get older, their BMD tends to decrease. In the third plot, we compare BMD between males and females. We can see that males tend to have higher BMD than females. The vertical lines (error bars) show how much BMD varies within each group.\npredictive checks\nWe can also look at the posterior predictive plot to see how well the model fits the data. As we have discussed in one of the previous lectures, if the plot looks similar to the actual data, that means the model is doing a good job. But if the predicted values are too spread out, too narrow, or miss important patterns, we might need to adjust the model by adding better predictors, transforming variables, or trying a different type of model.\n\n\nCode\n# Posterior predictive check\n#pp_check(bmd_model_multi)\n#pp_check(bmd_model_multi, type = \"hist\")\n#pp_check(bmd_model_multi, type = \"boxplot\")\n#pp_check(bmd_model_multi, type = \"scatter_avg\")\n#pp_check(bmd_model_multi, type = \"ecdf_overlay\")\n\n#library(patchwork)\np1 &lt;- pp_check(bmd_model_multi)\np2 &lt;- pp_check(bmd_model_multi, type = \"ecdf_overlay\")\n#combined_plot &lt;- p1 + p2 \n#combined_plot\nlibrary(gridExtra)\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\nFrom the above plots, we can see that the replications in the posterior predictive plot of BMD match the actual observed BMD.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>**Prior Tweaks and More**</span>"
    ]
  },
  {
    "objectID": "M03_1.html#bayesian-vs.-frequentist",
    "href": "M03_1.html#bayesian-vs.-frequentist",
    "title": "5  Logical Connections",
    "section": "5.5 Bayesian vs. Frequentist",
    "text": "5.5 Bayesian vs. Frequentist\n\n\nNow, let us compare the posterior distributions we obtained from the Bayesian model with the estimates from frequentist linear regression model.\n\n\nCode\nlibrary(jtools)\nlm_model &lt;- lm(BMD ~ BMI, data = bmd_data)\njtools::summ(lm_model)\n\n\nMODEL INFO:\nObservations: 169\nDependent Variable: BMD\nType: OLS linear regression \n\nMODEL FIT:\nF(1,167) = 27.98, p = 0.00\nR² = 0.14\nAdj. R² = 0.14 \n\nStandard errors:OLS\n-----------------------------------------------\n                    Est.   S.E.   t val.      p\n----------------- ------ ------ -------- ------\n(Intercept)         0.42   0.07     6.11   0.00\nBMI                 0.01   0.00     5.29   0.00\n-----------------------------------------------\n\n\nCode\nlm_coef &lt;- coef(summary(lm_model))\nbmi_est &lt;- lm_coef[\"BMI\", \"Estimate\"]\nbmi_se &lt;- lm_coef[\"BMI\", \"Std. Error\"]\nci_low &lt;- bmi_est - 1.96 * bmi_se\nci_high &lt;- bmi_est + 1.96 * bmi_se\n\npost &lt;- as_draws_df(bmd_model)\npost_bmi &lt;- post$b_BMI\nbayes_mean &lt;- mean(post_bmi)\nbayes_ci &lt;- quantile(post_bmi, probs = c(0.025, 0.975))\n\np &lt;- ggplot() +\n  geom_density(aes(x = post_bmi), fill = \"skyblue\", alpha = 0.5, color = NA) +\n  geom_vline(xintercept = bmi_est, color = \"red\", size = 1) +\n  geom_vline(xintercept = ci_low, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = ci_high, linetype = \"dashed\", color = \"red\", size = 0.8) +\n  geom_vline(xintercept = bayes_mean, color = \"blue\", size = 1) +\n  geom_vline(xintercept = bayes_ci[1], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  geom_vline(xintercept = bayes_ci[2], linetype = \"dashed\", color = \"blue\", size = 0.8) +\n  labs(\n    title = \"Bayesian vs Frequentist Estimate of BMI\",\n    subtitle = \"Red: Frequentist (Mean & 95% Confidence Interval)\\nBlue: Bayesian (Posterior Mean & 95% Credible Interval)\",\n    x = \"Coefficient for BMI\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        plot.subtitle = element_text(size = 12))\nlibrary(plotly)\nggplotly(p)\n\n\n\n\n\n\nThe graph compares our Bayesian and frequentist estimates of the BMI coefficient. The x-axis shows the BMI coefficient, and the y-axis shows the density. For the Bayesian estimate, we use a blue shaded area, with a solid blue vertical line representing the posterior mean, and the shaded area showing the 95% credible interval. For the frequentist estimate, we use two red dashed vertical lines to mark the maximum likelihood estimate (MLE) and the 95% confidence interval. This comparison helps us see the differences in how we estimate the BMI coefficient and the uncertainty in each method.\nIn our next lecture, we will look at how different types of prior distributions affect the posterior in a Bayesian hierarchical model, and how these results differ from those in the frequentist approach.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Logical Connections**</span>"
    ]
  },
  {
    "objectID": "M04_2.html#bayesian-model-with-counts",
    "href": "M04_2.html#bayesian-model-with-counts",
    "title": "8  More on Non-Gaussian",
    "section": "8.4 Bayesian Model with Counts",
    "text": "8.4 Bayesian Model with Counts\n\n\n\n\nCode\nlibrary(brms)\nlibrary(tidyverse)\n\nicu_data &lt;- read.csv(\"icu_days.csv\")\nicu_data &lt;- tibble(\n  Ndays = icu_data$ndays,\n  Sex = factor(icu_data$sex),\n  Admission = factor(icu_data$admtype),\n  Age = icu_data$Age,\n  PRISM = icu_data$PRISM\n)\n\n# model\nicu_model &lt;- brm(\n  formula = Ndays ~ Sex + Admission + Age + PRISM,\n  data = icu_data,\n  family = poisson(),\n  prior = c(\n    prior(normal(0, 3), class = \"b\"), \n    prior(normal(0, 10), class = \"Intercept\")\n  ),\n  iter = 2000,\n  chains = 1,\n  cores = 3,\n  seed = 123\n)\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.00017 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.7 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 2.737 seconds (Warm-up)\nChain 1:                2.419 seconds (Sampling)\nChain 1:                5.156 seconds (Total)\nChain 1: \n\n\nCode\nsummary(icu_model)\n\n\n Family: poisson \n  Links: mu = log \nFormula: Ndays ~ Sex + Admission + Age + PRISM \n   Data: icu_data (Number of observations: 398) \n  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 1000\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept            1.89      0.05     1.79     1.98 1.00      832      704\nSexMale             -0.11      0.04    -0.19    -0.04 1.00      762      489\nAdmissionPlanned    -0.73      0.05    -0.83    -0.63 1.00      507      610\nAge                 -0.00      0.00    -0.00    -0.00 1.00      960      843\nPRISM                0.04      0.00     0.04     0.05 1.00      878      661\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nplot(icu_model)\n\n\n\n\n\n\n\n\n\nCode\nlibrary(bayesplot)\nposterior &lt;- as_draws_df(icu_model)\nposterior_rr &lt;- posterior %&gt;%\n  dplyr::select(starts_with(\"b_\")) %&gt;%\n  dplyr::mutate(across(everything(), exp))\nmcmc_trace(\n  posterior_rr,\n  pars = c(\"b_SexMale\",\"b_AdmissionPlanned\", \"b_Age\", \"b_PRISM\")\n) +\n  ggplot2::labs(title = \"Posterior Trace Plots of Risk Ratios\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**More on Non-Gaussian**</span>"
    ]
  }
]