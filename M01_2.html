<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Bayesian Inference – Bayesian Statistical Methods in Medicine &amp; Health</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./brief_module_02.html" rel="next">
<link href="./M01_1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-07c16812f08c4a1591d6ec4fc46327fa.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="site_libs/viz-1.8.2/viz.js"></script>

<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">

<script src="site_libs/grViz-binding-1.0.11/grViz.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./M01_2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Bayesian Inference</strong></span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistical Methods in Medicine &amp; Health</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Preface</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Introduction</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./installation_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>R and RStudio</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 1: Bayesian Dreams</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><strong>Navigating Evidence</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Bayesian Inference</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 2: Chaotics</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title"><strong>Prior and Posterior</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title"><strong>Generative Models and Tools</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 3: Bayeswatch - Gaussian</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 4: Non-Gaussian Bayeswatch</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title"><strong>Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title"><strong>More on Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 5: Clusterphobia</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - I</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - II</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 6: Wander into the Wonder!</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title"><strong>Size Matters!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title"><strong>Wander into the Wonder!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learnings" id="toc-learnings" class="nav-link active" data-scroll-target="#learnings"><span class="header-section-number">2.1</span> Learnings</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference"><span class="header-section-number">2.2</span> Inference</a></li>
  <li><a href="#bayesian-models" id="toc-bayesian-models" class="nav-link" data-scroll-target="#bayesian-models"><span class="header-section-number">2.3</span> Bayesian Models</a></li>
  <li><a href="#model-with-binary-variable" id="toc-model-with-binary-variable" class="nav-link" data-scroll-target="#model-with-binary-variable"><span class="header-section-number">2.4</span> Model with Binary Variable</a></li>
  <li><a href="#bayesian-odds" id="toc-bayesian-odds" class="nav-link" data-scroll-target="#bayesian-odds"><span class="header-section-number">2.5</span> Bayesian Odds</a></li>
  <li><a href="#bayesian-language" id="toc-bayesian-language" class="nav-link" data-scroll-target="#bayesian-language"><span class="header-section-number">2.6</span> Bayesian Language</a></li>
  <li><a href="#directed-acyclic-graph-dag" id="toc-directed-acyclic-graph-dag" class="nav-link" data-scroll-target="#directed-acyclic-graph-dag"><span class="header-section-number">2.7</span> Directed Acyclic Graph (DAG)</a></li>
  <li><a href="#more-examples" id="toc-more-examples" class="nav-link" data-scroll-target="#more-examples"><span class="header-section-number">2.8</span> More Examples</a>
  <ul class="collapse">
  <li><a href="#decision-making" id="toc-decision-making" class="nav-link" data-scroll-target="#decision-making"><span class="header-section-number">2.8.1</span> Decision Making</a></li>
  <li><a href="#comparison-of-two-means" id="toc-comparison-of-two-means" class="nav-link" data-scroll-target="#comparison-of-two-means"><span class="header-section-number">2.8.2</span> Comparison of Two Means</a></li>
  </ul></li>
  <li><a href="#bayesian-updating" id="toc-bayesian-updating" class="nav-link" data-scroll-target="#bayesian-updating"><span class="header-section-number">2.9</span> Bayesian Updating</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">2.10</span> Summary</a></li>
  <li><a href="#live-tutorial-and-discussion" id="toc-live-tutorial-and-discussion" class="nav-link" data-scroll-target="#live-tutorial-and-discussion"><span class="header-section-number">2.11</span> Live tutorial and discussion</a></li>
  <li><a href="#tutorial-exercises" id="toc-tutorial-exercises" class="nav-link" data-scroll-target="#tutorial-exercises"><span class="header-section-number">2.12</span> Tutorial Exercises</a></li>
  <li><a href="#preparation-for-week-3" id="toc-preparation-for-week-3" class="nav-link" data-scroll-target="#preparation-for-week-3"><span class="header-section-number">2.13</span> Preparation for Week 3</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Bayesian Inference</strong></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<iframe width="500" height="300" src="https://www.youtube.com/embed/C0MaCDPNQQU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="learnings" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="learnings"><span class="header-section-number">2.1</span> Learnings</h2>
<ul>
<li><strong>Outcomes</strong></li>
</ul>
<p>– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.</p>
<p>– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.</p>
<p>– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.</p>
<ul>
<li><strong>Objectives</strong></li>
</ul>
<p>By the end of this week you should be able to:</p>
<p>– Describe Bayesian inference using probability distributions.</p>
<p>– Understand Bayesian learning.</p>
<p>– Draw DAG for Bayesian models.</p>
<p>– Formulate examples.</p>
</section>
<section id="inference" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="inference"><span class="header-section-number">2.2</span> Inference</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/SrnrQgwR1Hk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<!--
explain the purpose of statistical inference: ref - Lambert, page 17, sec:2.4

more ref: http://www.stats.org.uk/

-->
<p>Bayesian inference is a method of statistical inference that updates the probability of a hypothesis <span class="math inline">\((H)\)</span> as more evidence or data <span class="math inline">\((D)\)</span> becomes available. It is based on Bayes’ theorem that we describe in our last lecture, where prior beliefs are updated with data. Following out previous lecture, if we denote <span class="math inline">\(Pr(H)\)</span> as the probability of initial belief about <span class="math inline">\(H\)</span> before seeing data, we can write the updated belief about <span class="math inline">\(H\)</span> given the data <span class="math inline">\(D\)</span> as:</p>
<p><span class="math display">\[
Pr(H|D) = \frac{Pr(D|H)\times Pr(H)}{Pr(D)}
\]</span></p>
<p>where, <span class="math inline">\(Pr(D)\)</span> is the probability of the data under all possible hypotheses.</p>
<p>In today’s lecture we will learn to the development of Bayesian model using probability distributions that incorporates Bayes throrem.</p>
</section>
<section id="bayesian-models" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="bayesian-models"><span class="header-section-number">2.3</span> Bayesian Models</h2>
<!--
asdf: explain bayesian inference using probability distributions ... this is a transition from probability to prob dist (i.e, parameter). ref: kruschke, page 105; sec 5.2 (Table 5.5)

Explain how one parameter dist (ber) with example ref: kruschke, page 109-111;

Estimand, Estimator &

\begin{align}
p(D|\theta) \times p(\theta)
\end{align}

-->
<p>We have explained Bayes’ rule in our previous lecture, now we will see how Bayes rule can be structured for model development using parameter and data. In a Bayesian model, a parameter is a quantity that we assume is uncertain and assign a probability distribution to it. Unlike in frequentist statistics, where parameters are fixed but unknown, Bayesian statistics treats parameters as random variables with their own probability distributions.</p>
<p>Let us denote <span class="math inline">\(\theta\)</span> as the parameter and <span class="math inline">\(D\)</span> as data. Hence, we write a model using the data likelihood <span class="math inline">\(p(D|\theta)\)</span>, and prior distribution <span class="math inline">\(p(\theta)\)</span> of the model parameter <span class="math inline">\(\theta\)</span> (note that we have changed the notation from <span class="math inline">\(Pr(.)\)</span> to <span class="math inline">\(p(.)\)</span>, where <span class="math inline">\(Pr(.)\)</span> refers to probability and <span class="math inline">\(p(.)\)</span> refers to probability distribution):</p>
<p><span class="math display">\[
p(D|\theta) \times p(\theta)
\]</span></p>
<p>Hence, Bayes rule can be used to understand the parameter values, given the data,, i.e.,</p>
<p><span class="math display">\[
p(\theta|D)
\]</span></p>
<p>Thus, using the Dual-Factor table explained in previous lecture, we can write</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig_M02_dataPara.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Data-Parameter; <span class="citation" data-cites="kruschke2014doing">Kruschke (<a href="references.html#ref-kruschke2014doing" role="doc-biblioref">2014</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>Where, each cell of the table holds the joint probability density of the specific combination of parameter value <span class="math inline">\(\theta\)</span> and data value <span class="math inline">\(D\)</span>, denoted <span class="math inline">\(p(D, \theta)\)</span>, and which we know can be algebraically re-expressed as <span class="math inline">\(p(D|\theta)\times p(\theta)\)</span>.</p>
<p>Thus, we write the Bayes rule for data and parameter model as:</p>
<p><span class="math display">\[
p(\theta|D) = \frac{p(D|\theta)\times p(\theta)}{p(D)};
\]</span></p>
<p>where,</p>
<p><span class="math display">\[\begin{align}
p(D) &amp;= \sum_{\theta^*} p(D|\theta^*) p(\theta^*); \quad \text{ if discrete}; \\
p(D) &amp;= \int p(D|\theta^*) p(\theta^*) \text{d}\theta^*; \quad \text{ if continuous};
\end{align}\]</span></p>
<p>Here, <span class="math inline">\(p(\theta)\)</span> is the prior information about <span class="math inline">\(\theta\)</span> without observing data; <span class="math inline">\(p(D|\theta)\)</span> is the likelihood, i.e., data could be generated with model parameter <span class="math inline">\(\theta\)</span>; and <span class="math inline">\(p(D)\)</span> is the marginal likelihood obtained from data by averaging across all possible parameters.</p>
<p>The posterior distribution of <span class="math inline">\(\theta\)</span> is:</p>
<p><span class="math display">\[
p(\theta|D) = \text{ Credibility of }\theta\text{ based on data and evidence}
\]</span></p>
<p>The posterior probability distribution <span class="math inline">\(p(\theta|D)\)</span> is the main goal of Bayesian inference. The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value, and this can be obtained by collecting more data.</p>
<p>We will now explore with examples on obtaining posterior distributions of the model parameter <span class="math inline">\(\theta\)</span> for different data distributions (i.e., models), e.g., binomial, normal and poisson distributions.</p>
</section>
<section id="model-with-binary-variable" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="model-with-binary-variable"><span class="header-section-number">2.4</span> Model with Binary Variable</h2>
<!--
gelman sec 2.1, page 29
-->
<p>Suppose we have a binary observation i.e., can take values either 0 or 1, which follows Bernoulli distribution with parameter <span class="math inline">\(\theta\)</span>. We already know that for <span class="math inline">\(n&gt;1\)</span> number of trials the Bernoulli distribution yields a Binomial distribution. Considering <span class="math inline">\(Y\)</span> as the random variable of number of successes in <span class="math inline">\(n\)</span> trials for the Binomial distribution, we can write:</p>
<p><span class="math display">\[
p(Y=y|\theta) = \begin{pmatrix}n\\y \end{pmatrix} \theta^y (1-\theta)^{n-y}
\]</span></p>
<p>This also represents the likelihood of a Bernoulli variable.</p>
<p>Now, if we consider a Beta prior distribution for <span class="math inline">\(\theta\)</span> with hyper-parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> (i.e., shape parameters of Beta distribution), then we can write the probability density function of the prior distribution as:</p>
<p><span class="math display">\[
p(\theta) = \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}
\]</span></p>
<p>where, <span class="math inline">\(B(a,b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\)</span> is the beta function. Thus, using Bayes theorem we write</p>
<p><span class="math display">\[
p(\theta|y) = \frac{\begin{pmatrix}n\\y \end{pmatrix} \theta^y (1-\theta)^{n-y}\times \theta^{a-1}(1-\theta)^{b-1}}{p(y)\times B(a,b)}
\]</span></p>
<p>With some simple calculations, we can write the marginal likelihood as:</p>
<p><span class="math display">\[
p(y) = \begin{pmatrix}n\\y \end{pmatrix}\frac{B(y+a,n-y+b)}{B(a,b)}
\]</span></p>
<p>Hence, we get the analytical form of the posterior distribution of <span class="math inline">\(\theta\)</span> as:</p>
<p><span class="math display">\[
p(\theta|y) = \frac{\theta^{y+a-1}(1-\theta)^{n-y+b-1}}{B(y+a,n-y+b)}
\]</span></p>
<p>which follows a Beta distribution with parameters <span class="math inline">\((a+y)\)</span> and <span class="math inline">\((b+n-y)\)</span>.</p>
<p><strong>Example:</strong></p>
<p>Let us explain this with the type-2 diabetes example we discussed earlier. Now, the medical practitioner is trying to estimate the probability that a patient has type-2 diabetes <span class="math inline">\(\theta\)</span> based on both prior knowledge and a new diagnostic test result.</p>
<p>Before any test, the medical practitioner relies on existing medical data. Suppose past research suggests that for a certain risk group the probability of having type-2 diabetes is 0.5. We represent this belief using a <span class="math inline">\(Beta(a=2,b=2)\)</span>. This prior suggests that while any probability is possible, <span class="math inline">\(\theta\)</span> is likely to be around 0.5, with room for updating.</p>
<p>Now, we assume the test result corresponds to 7 positive cases out of 10 tests, meaning, <span class="math inline">\(n=10\)</span> and <span class="math inline">\(y=7\)</span>.</p>
<p>Hence, we get the posterior distribution of medical practitioner’s new belief about the probability of the patient having the disease as: <span class="math inline">\(Beta(2+7,2+3)=Beta(9,5)\)</span>.</p>
<p>We can see from the density plots, the posterior shifts toward higher probabilities of type-2 diabetes, meaning the medical practitioner is now more confident that the patient may have type-2 diabetes.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a_prior <span class="ot">&lt;-</span> <span class="dv">2</span>   </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>b_prior <span class="ot">&lt;-</span> <span class="dv">2</span>   </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span>        </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">7</span>         </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>a_post <span class="ot">&lt;-</span> a_prior <span class="sc">+</span> y</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>b_post <span class="ot">&lt;-</span> b_prior <span class="sc">+</span> (n <span class="sc">-</span> y)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>prior_density <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta, a_prior, b_prior)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(y, <span class="at">size =</span> n, <span class="at">prob =</span> theta)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>posterior_density <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta, a_post, b_post)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta =</span> <span class="fu">rep</span>(theta, <span class="dv">3</span>),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> <span class="fu">c</span>(prior_density, likelihood, posterior_density),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">Distribution =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"Prior"</span>, <span class="st">"Likelihood"</span>, <span class="st">"Posterior"</span>), <span class="at">each =</span> <span class="fu">length</span>(theta))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> density, <span class="at">color =</span> Distribution)) <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Prior, Likelihood, and Posterior Distributions"</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">expression</span>(theta),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"green"</span>,<span class="st">"red"</span>,<span class="st">"blue"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M01_2_files/figure-html/bino-first-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="bayesian-odds" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="bayesian-odds"><span class="header-section-number">2.5</span> Bayesian Odds</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/uwIDw1UguNc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>We can also think of the Bayesian approach in terms of odds, such as what odds should I assign to an event or hypothesis. The simple definition of odds can be written as:</p>
<p><span class="math display">\[
\text{Odds of an event} = \frac{Pr(\text{event})}{1-Pr(\text{event})}
\]</span> which represents the ratio between the occurrence of an event and its non-occurrence.</p>
<p>Let’s revisit the medical practitioner example from our first lecture to clarify this concept. Imagine the practitioner assessing a patient for diabetes. Initially, they have a prior belief about the patient’s likelihood of having the condition. After conducting a blood test that reveals elevated sugar levels, this new evidence increases the probability of diabetes. The practitioner then updates their belief accordingly, refining their assessment based on the test results. We wanted to know, given this experimental evidence, how sure are the medical practitioner that their guess about the diabetes is accurate?</p>
<p>Thus, to reflect the medical practitioner example by Bayesian odds, we write:</p>
<p><span class="math display">\[
\text{Odds}(\text{G=[+]}|\text{E=[+]}) = \text{Odds}(\text{G}) \times \frac{Pr(\text{E=[+]}|\text{G=[+]})}{Pr(\text{E=[+]}|\text{G=[-]})}
\]</span></p>
<p>where, <span class="math inline">\(\text{Odds}(\text{G=[+]}|\text{E=[+]})\)</span> is the odds of the guess is correct given the evidence, and <span class="math inline">\(\text{Odds}(\text{G})\)</span> is the odds of the guess that we define:</p>
<p><span class="math display">\[
\text{Odds}(\text{G}) = \frac{Pr(\text{G=[+]})}{Pr(\text{G=[-]})}
\]</span></p>
<p>and <span class="math inline">\(\frac{Pr(\text{E=[+]}|\text{G=[+]})}{Pr(\text{E=[+]}|\text{G=[-]})}\)</span> is the ratio of evidence under the guess <span class="math inline">\(\text{G}\)</span>.</p>
<p>This reflects</p>
<p><span class="math display">\[
\text{posterior or updated odds} = \text{prior or initial odds}\times \text{relative explanatory power}
\]</span></p>
<p>This explains that evidence (i.e., data/information) always changes the outcome, which could be probability, probability distributions or odds or any other outcome of interest.</p>
<p><strong>Example</strong></p>
<p>Let us explain this again with the type-2 diabetes example, where based on the patient’s age, family history, and some initial symptoms, the medical practitioner guessed that there’s a 20% chance the patient has diabetes. This belief is a prior probability. The odds from of this probability is:</p>
<p><span class="math display">\[
\text{Odds}(\text{G}) = \frac{0.2}{0.8} = 0.25
\]</span></p>
<p>So, the prior odds of the patient having diabetes are 1:4 (one in four) guessed by the medical practitioner.</p>
<p>The blood test result shows elevated sugar levels. To assess how much this result affects our belief, we use the ratio of evidence under the guess <span class="math inline">\(\text{G}\)</span> (also known as the likelihood ratio).</p>
<p>Suppose the medical practitioner has historically observed from boold test that 85% of diabetic patients have elevated sugar levels, while only 10% of non-diabetic patients do (e.g., due to other factors). Hence, we write</p>
<p><span class="math display">\[
\frac{Pr(\text{E=[+]}|\text{G=[+]})}{Pr(\text{E=[+]}|\text{G=[-]})} = \frac{0.85}{0.10} = 8.5
\]</span></p>
<p>This means the test result (elevated sugar) is 8.5 times more likely in someone with diabetes than in someone without it.</p>
<p>Now, the posterior odds</p>
<p><span class="math display">\[
\text{Odds}(\text{G=[+]}|\text{E=[+]}) = 0.25 \times 8.5 = 2.125
\]</span></p>
<p>So, the updated odds is 2.125:1, i.e., the patient is 2.125 times more likely to have diabetes than non-diabetic individuals after considering the test result.</p>
<p>Using the well known relationship between odds and probability, we can also get back the posterior probability from the posterior odds as:</p>
<p><span class="math display">\[
Pr(\text{G=[+]}|\text{E=[+]}) = \frac{\text{Odds}(\text{G=[+]}|\text{E=[+]})}{1+\text{Odds}(\text{G=[+]}|\text{E=[+]})} = \frac{2.125}{1+2.125} = 0.68
\]</span></p>
<p>In summary we write, before the test, the medical practitioner believed there was a 20% chance of diabetes. After seeing the elevated blood sugar result, the probability increased to 68% (compare the example in lecture 1), because the test result is 8.5 times more likely in diabetic than non-diabetic individuals. The practitioner may now recommend further tests (e.g., an HbA1c test) before confirming the diagnosis.</p>
</section>
<section id="bayesian-language" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="bayesian-language"><span class="header-section-number">2.6</span> Bayesian Language</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/JKi5FdiksJ4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<!--
ref: McElreath page 77, a language for describing bayesian models
-->
<p>We will learn a common language for illustrating and denoting the Bayesian models. This will help us to develop and write complex Bayesian models in a simpler way that we will learn later in this course.</p>
<p>Let’s explain this using a Bernoulli model with parameter <span class="math inline">\(\theta\)</span>. Let <span class="math inline">\(x\)</span> be the random variable that follows Bernoulli distribution. If we have <span class="math inline">\(n\)</span> number of independent observations <span class="math inline">\((x_1,\ldots,x_n)'\)</span>, then denoting <span class="math inline">\(y=\sum_i^n x_i\)</span> we write the likelihood function as:</p>
<p><span class="math display">\[
\prod_i^n \theta^{x_i} (1-\theta)^{1-x_i} = \theta^{\sum_i^n x_i} (1-\theta)^{\sum_i^n (1-x_i)} = \theta^y (1-\theta)^{n-y}
\]</span></p>
<p>which we can write in the form of a Binomial distribution:</p>
<p><span class="math display">\[
p(y|\theta) \propto   \theta^y (1-\theta)^{n-y}
\]</span></p>
<p>Note that we replaced “=” with “<span class="math inline">\(\propto\)</span>” as the term <span class="math inline">\(\begin{pmatrix}n\\y \end{pmatrix}\)</span> is a constant, which does not depend on the parameter <span class="math inline">\(\theta\)</span>. Now, considering prior conjugacy, we assume that <span class="math inline">\(\theta\)</span> follows a Beta distribution with shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> and we write <span class="math inline">\(\theta \sim \text{Beta}(a,b)\)</span> and define</p>
<p><span class="math display">\[
p(\theta) \propto \theta^{a-1}(1-\theta)^{b-1}
\]</span></p>
<p>Thus, the posterior distribution of <span class="math inline">\(\theta\)</span> can be written as <span class="math inline">\(\theta|y \sim \text{Beta}(a+y,b+n-y)\)</span> and defined as:</p>
<p><span class="math display">\[
p(\theta|y) \propto \theta^y (1-\theta)^{n-y}\theta^{a-1}(1-\theta)^{b-1}
\]</span></p>
<p><span class="math display">\[
p(\theta|y) \propto \theta^{y+a-1} (1-\theta)^{n-y+b-1}
\]</span></p>
<p>We have again included the “<span class="math inline">\(\propto\)</span>” term, as we will learn in our next two lectures that the marginal distribution of the data, i.e., <span class="math inline">\(p(y)\)</span> does not depend on the model parameter and can therefore be omitted when obtaining the posterior distribution.</p>
</section>
<section id="directed-acyclic-graph-dag" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="directed-acyclic-graph-dag"><span class="header-section-number">2.7</span> Directed Acyclic Graph (DAG)</h2>
<!--
ref: paper: https://doi.org/10.1016/j.jclinepi.2021.08.001
-->
<p>The directed acyclic graph (DAG) is a graphical representation that illustrates the relationships and dependencies between different variables and parameters in a model. In a DAG, nodes represent variables/parameters, and directed edges indicate dependency relationships, pointing from one node to another. The acyclic nature ensures that there are no closed loops, maintaining a clear directionality of influence from parent nodes to child nodes.</p>
<p><strong>Bayesian models</strong></p>
<p>In the context of Bayesian modelling, DAGs are crucial as they visually provides the conditional dependencies between variables and model parameters, which enables a structured and intuitive approach to understand uncertainty and dependencies from the model.</p>
<p>Using the model with binary observations, we write a DAG as:</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-650a0c42d426f8fa41af" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-650a0c42d426f8fa41af">{"x":{"diagram":"\ndigraph flowchart {\n  graph [layout = dot, rankdir = LR]\n\n  node [shape = rectangle, style = filled, color = white]\n  \n  subgraph cluster_0 {\n    label = \"Hyper-parameter\"\n    color = lightblue\n    node [color=lightblue]\n    a [label=\"a\"]\n    b [label=\"b\"]\n  }\n\n  subgraph cluster_1 {\n    label = \"Parameter\"\n    color = lightgray\n    node [color=lightgray]\n    theta [label=\"θ\"]\n  }\n\n  subgraph cluster_2 {\n    label = \"Variable\"\n    color = lightsteelblue\n    node [color=lightsteelblue]\n    y [label=\"y\"]\n  }\n\n  edge[arrowhead=normal]\n\n  a -> theta\n  b -> theta\n  theta -> y\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>This is a simple graphical model, where <span class="math inline">\(y\)</span> depends on <span class="math inline">\(\theta\)</span>, with <span class="math inline">\(\theta\)</span> being a logical function of hyper-parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
</section>
<section id="more-examples" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="more-examples"><span class="header-section-number">2.8</span> More Examples</h2>
<section id="decision-making" class="level3" data-number="2.8.1">
<h3 data-number="2.8.1" class="anchored" data-anchor-id="decision-making"><span class="header-section-number">2.8.1</span> Decision Making</h3>
<!--

ref: https://statswithr.github.io/book/the-basics-of-bayesian-statistics.html#frequentist-vs.-bayesian-inference

-->
<p>Here, we will explore how Bayesian method can provide more insights compared to the frequentist approach for decision making with same information.</p>
<p>Let us assume that we have a population of patients, and in this population, the prevalence of a certain disease is either 10% or 20%. As a researcher you need to determine whether the true prevalence of the disease is 10% or 20%.</p>
<p>You are being asked to make a crucial decision, and if you make the correct determination, your research funding is renewed.</p>
<p>Hence, you conduct diagnostic tests on randomly selected patients from the population. Each test costs $200, and you must purchase tests in increments of $1,000 (5 tests at a time). You have a total budget of $4,000, meaning you can test 5, 10, 15, or 20 persons.</p>
<p>The cost of making an incorrect decision is high, as it could lead to misinformed healthcare policies or ineffective treatment strategies. However, conducting tests is also expensive, so you don’t want to spend more than necessary.</p>
<p>Suppose you observe one person with the disease in a sample size of 5, two persons in a sample size of 10, three persons in a sample size of 15, and four persons in a sample size of 20.</p>
<p><strong>Fequentists Method</strong></p>
<p>Based on the scenario we write the null <span class="math inline">\((H_0)\)</span> and alternative <span class="math inline">\((H_1)\)</span> hypotheses as:</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(10\)</span>% prevalence <span class="math inline">\(H_1\)</span>: <span class="math inline">\(&gt;10\)</span>% prevalence</p>
<p>p-value based on 5 samples:</p>
<p><span class="math display">\[
Pr(y\ge 1|n=5,p=0.10)=1-Pr(y= 0|n=5,p=0.10)=1-0.9^{5}\approx 0.41
\]</span></p>
<p>Note that the p-value represents the probability of observing the given results - or more extreme ones - assuming the null hypothesis is true.</p>
<p>Therefore, we fail to reject <span class="math inline">\(H_0\)</span> and conclude that the data do not provide convincing evidence that the prevalence of the disease is greater than 10%. This means that if we had to choose between a disease prevalence of 10% or 20%, even though this hypothesis test does not confirm the null hypothesis, we would likely stick with 10%, since we did not find sufficient evidence to suggest a higher prevalence.</p>
<p><strong>Bayesian Method</strong></p>
<p>From Bayesian perspective we can write:</p>
<p><span class="math inline">\(H_0\)</span>: 10% prevalence <span class="math inline">\(H_1\)</span>: 20% prevalence</p>
<p>We can also assume that priors related to the hypothesis same and equal, i.e, <span class="math inline">\(Pr(H_0)=Pr(H_1)=0.5\)</span>.</p>
<p>Considering the scenario with 5 samples, we write the likelihood for <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> as:</p>
<p><span class="math display">\[
Pr(y=1|H_0) = \begin{pmatrix} 5 \\ 1 \end{pmatrix} \times 0.1 \times 0.9^{4} \approx 0.33
\]</span></p>
<p><span class="math display">\[
Pr(y=1|H_1) = \begin{pmatrix} 5 \\ 1 \end{pmatrix} \times 0.2 \times 0.8^{4} \approx 0.41
\]</span></p>
<p>We get the posterior probability for <span class="math inline">\(H_0\)</span> as:</p>
<p><span class="math display">\[
Pr(H_0|y=1) = \frac{Pr(y=1|H_0)\times Pr(H_0)}{Pr(y=1)}=\frac{0.5\times 0.33}{0.5\times 0.33+0.5\times 0.41} \approx 0.45
\]</span></p>
<p>and for <span class="math inline">\(H_1\)</span> as:</p>
<p><span class="math display">\[
Pr(H_1|y=1) = 1- 0.45 = 0.55
\]</span></p>
<p>The posterior probabilities of <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with strong confidence based on the observed data. However, <span class="math inline">\(H_1\)</span> has a higher posterior probability than <span class="math inline">\(H_0\)</span>, so if we had to make a decision at this point, we should choose <span class="math inline">\(H_1\)</span>, meaning the disease prevalence is 20%. Note that this decision contradicts the conclusion reached using the frequentist approach.</p>
<p>We can write this example using a DAG, where we can represent the relationships between the prior probabilities, likelihoods, and posterior probabilities.</p>
<p><strong>Hypothesis (H₀ and H₁)</strong>: These represent the two possible prevalence values (10% for H₀, 20% for H₁).</p>
<p><strong>Data (y)</strong>: The observed data (the number of successes in 5 samples, e.g., the presence of disease).</p>
<p><strong>Likelihoods (Pr(y=1|H₀) and Pr(y=1|H₁))</strong>: The likelihood of observing the data under each hypothesis.</p>
<p><strong>Prior Probabilities (Pr(H₀) and Pr(H₁))</strong>: The prior belief about the hypotheses (both have a prior probability of 0.5).</p>
<p><strong>Posterior Probabilities (Pr(H₀|y=1) and Pr(H₁|y=1))</strong>: The updated belief about the hypotheses after observing the data.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DiagrammeR)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>dag <span class="ot">&lt;-</span> <span class="fu">grViz</span>(<span class="st">"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="st">digraph bayesian_dag {</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="st">  # Define the nodes</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="st">  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="st">  H0 [label = 'H₀: 10% prevalence', width = 1.5]</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="st">  H1 [label = 'H₁: 20% prevalence', width = 1.5]</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="st">  y [label = 'y: Data (Successes in 5 samples)', width = 1.5]</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="st">  PrH0 [label = 'Pr(H₀) = 0.5', width = 1.5]</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="st">  PrH1 [label = 'Pr(H₁) = 0.5', width = 1.5]</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="st">  LikelihoodH0 [label = 'Pr(y|H₀) ~ 0.33', width = 1.5]</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="st">  LikelihoodH1 [label = 'Pr(y|H₁) ~ 0.41', width = 1.5]</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="st">  PosteriorH0 [label = 'Pr(H₀|y=1) ~ 0.45', width = 1.5]</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="st">  PosteriorH1 [label = 'Pr(H₁|y=1) ~ 0.55', width = 1.5]</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="st">  # Define the edges (relationships)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="st">  PrH0 -&gt; LikelihoodH0</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="st">  PrH1 -&gt; LikelihoodH1</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="st">  H0 -&gt; LikelihoodH0</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="st">  H1 -&gt; LikelihoodH1</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="st">  LikelihoodH0 -&gt; y</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="st">  LikelihoodH1 -&gt; y</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="st">  y -&gt; PosteriorH0</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="st">  y -&gt; PosteriorH1</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="st">"</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>dag</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-fad7014def5ed361a493" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-fad7014def5ed361a493">{"x":{"diagram":"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = \"Helvetica\", fontsize = 14]\n  H0 [label = \"H₀: 10% prevalence\", width = 1.5]\n  H1 [label = \"H₁: 20% prevalence\", width = 1.5]\n  y [label = \"y: Data (Successes in 5 samples)\", width = 1.5]\n  PrH0 [label = \"Pr(H₀) = 0.5\", width = 1.5]\n  PrH1 [label = \"Pr(H₁) = 0.5\", width = 1.5]\n  LikelihoodH0 [label = \"Pr(y|H₀) ~ 0.33\", width = 1.5]\n  LikelihoodH1 [label = \"Pr(y|H₁) ~ 0.41\", width = 1.5]\n  PosteriorH0 [label = \"Pr(H₀|y=1) ~ 0.45\", width = 1.5]\n  PosteriorH1 [label = \"Pr(H₁|y=1) ~ 0.55\", width = 1.5]\n\n  # Define the edges (relationships)\n  PrH0 -> LikelihoodH0\n  PrH1 -> LikelihoodH1\n  H0 -> LikelihoodH0\n  H1 -> LikelihoodH1\n  LikelihoodH0 -> y\n  LikelihoodH1 -> y\n  y -> PosteriorH0\n  y -> PosteriorH1\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Now, we can summarise the results for all four seperate sample sizes using frequentist p-value and Bayesian methods, where</p>
<p><strong>Frequentist</strong></p>
<p><span class="math inline">\(H_0\)</span>: 10% prevalence and <span class="math inline">\(H_1\)</span>: <span class="math inline">\(&gt;10\)</span>% prevalence</p>
<p><span class="math inline">\(Pr(y \text{ or more} \mid 10\% \text{ prevalence})\)</span> = p-value</p>
<p><strong>Bayesian</strong></p>
<p><span class="math inline">\(H_0\)</span>: 10% prevalence and <span class="math inline">\(H_1\)</span>: 20% prevalence</p>
<p>Posterior for <span class="math inline">\(H_0\)</span>: <span class="math inline">\(Pr(10\% \text{ prevalence} \mid n, y)\)</span></p>
<p>Posterior for <span class="math inline">\(H_1\)</span>: <span class="math inline">\(Pr(20\% \text{ prevalence} \mid n, y)\)</span></p>
<p>And the results we get:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Data</strong></th>
<th><strong>p-value</strong></th>
<th><strong>Posterior</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><span class="math inline">\(H_0\)</span>: 10% prevalence</td>
<td><span class="math inline">\(H_0\)</span>: 10% prevalence</td>
<td><span class="math inline">\(H_1\)</span>: 20% prevalence</td>
</tr>
<tr class="even">
<td>n = 5, y = 1</td>
<td>0.41</td>
<td>0.45</td>
<td>0.55</td>
</tr>
<tr class="odd">
<td>n = 10, y = 2</td>
<td>0.26</td>
<td>0.39</td>
<td>0.61</td>
</tr>
<tr class="even">
<td>n = 15, y = 3</td>
<td>0.18</td>
<td>0.34</td>
<td>0.66</td>
</tr>
<tr class="odd">
<td>n = 20, y = 4</td>
<td>0.13</td>
<td>0.29</td>
<td>0.71</td>
</tr>
</tbody>
</table>
<p>In each of these scenarios, the frequentist approach produces a p-value higher than the significance level say 5%, leading us to fail to reject the null hypothesis for any of the samples. In contrast, the Bayesian method consistently assigns a higher posterior probability to the model where prevalence = 20%. As a result, the conclusions drawn from these two approaches are contradictory.</p>
<p>However, if we had structured the frequentist approach differently, say setting the null hypothesis as <span class="math inline">\(H_0\)</span>: 20% prevalence, we would have reached different conclusions.</p>
<p>This highlights the frequentist method’s sensitivity to the choice of the null hypothesis. In contrast, the Bayesian approach yields consistent results regardless of the order in which we evaluate the models.</p>
</section>
<section id="comparison-of-two-means" class="level3" data-number="2.8.2">
<h3 data-number="2.8.2" class="anchored" data-anchor-id="comparison-of-two-means"><span class="header-section-number">2.8.2</span> Comparison of Two Means</h3>
<p>Now, let us explain another example, where we want to find out if a new drug lowers systolic blood pressure (SBP) compared to standard of care (SOC).</p>
<p>The study involves two groups of patients: Group A (treatment group), where 10 patients are given the new medication, and Group B (control group), where 10 patients receive the standard of care (SOC), which includes existing medication for SBP.</p>
<p>After a period of four weeks, the SBP of all participants is recorded for analysis.</p>
<p>Now, we will use both the frequentist and Bayesian approaches to determine whether there are any differences between the treatment and SOC.</p>
<p><strong>Frequentist</strong></p>
<p>From the frequentist perspective, we wil test:</p>
<p><span class="math inline">\(H_0\)</span>: There is no difference in mean SBP between the two groups.</p>
<p><span class="math inline">\(H_1\)</span>: The treatment group has a different mean SBP than the SOC group.</p>
<p>Considering equal variance assumption, we use t-test as follows:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>group_A <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">120</span>, <span class="dv">118</span>, <span class="dv">122</span>, <span class="dv">115</span>, <span class="dv">119</span>, <span class="dv">117</span>, <span class="dv">121</span>, <span class="dv">116</span>, <span class="dv">118</span>, <span class="dv">119</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>group_B <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">130</span>, <span class="dv">128</span>, <span class="dv">135</span>, <span class="dv">132</span>, <span class="dv">129</span>, <span class="dv">131</span>, <span class="dv">134</span>, <span class="dv">133</span>, <span class="dv">137</span>, <span class="dv">130</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(group_A, group_B, <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  group_A and group_B
t = -11.834, df = 18, p-value = 6.315e-10
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -15.77898 -11.02102
sample estimates:
mean of x mean of y 
    118.5     131.9 </code></pre>
</div>
</div>
<p>We can see that the p-value is extremely small (much less than 0.05), which means we reject the null hypothesis. Si, there is strong evidence that the new drug significantly reduces systolic blood pressure compared to the placebo.</p>
<p><strong>Bayesian</strong></p>
<p>Now, we will use Bayesian approach to estimate the posterior probability distribution of the difference in mean systolic blood pressure between the treatment and SOC groups, and extract a 95% credible interval.</p>
<p>In most scenarios, we do not have prior information regarding the effectiveness of the new drug. However, sometimes we do have prior knowledge about the effectiveness of the SOC. Let us assume that, from a past study with 15 patients, for the SOC group, after a period of four weeks, the average SBP is around 110 mmHg with a variance of 25. This constitutes our prior knowledge about the control/SOC group.</p>
<p>Now, using these information we can get the posterior distributions for both groups and then compare their differences. Note that our variable of interest in this example is in continuous scale (SBP measured in mmHg), hence, we will use normal distributions for the SBP.</p>
<p>Here, we have observe data from 10 individuals for each groups. The posterior mean and variance calculation involves combining prior and observed data for the SOC (control) group, i.e., Group B. Whereas, for the treatment group we do not have any prior knowledge, i.e., the posterior for this group will reflect the observed data. Then we calculate the posterior mean and variance for the difference in means and extract the 95% credible interval for the difference.</p>
<p>We can write this mathematically as follows:</p>
<ul>
<li><span class="math inline">\(\mu_A\)</span>: True mean SBP of treatment group</li>
<li><span class="math inline">\(\mu_B\)</span>: True mean SBP of SOC group</li>
<li><span class="math inline">\(\delta = \mu_A - \mu_B\)</span>: Difference in means, this is our parameter of interest</li>
</ul>
<p>For observed data, Groups A (treatment) and B (SOC) with observed sample sizes <span class="math inline">\(n_A = n_B = 10\)</span>, we get observed means <span class="math inline">\(\bar{x}_A\)</span>, <span class="math inline">\(\bar{x}_B\)</span>, and variances <span class="math inline">\(s_A^2\)</span>, <span class="math inline">\(s_B^2\)</span>.</p>
<p>We will model SBP as Normally distributed:</p>
<ul>
<li><span class="math inline">\(X_A \sim N(\mu_A, \sigma^2_A)\)</span></li>
<li><span class="math inline">\(X_B \sim N(\mu_B, \sigma^2_B)\)</span></li>
</ul>
<p>Now, prior information on Group B, that we get from a previous study, where <span class="math inline">\(\mu_{B,0} = 110\)</span>, and prior variance <span class="math inline">\(\sigma^2_{B,0} = 25\)</span> from sample size <span class="math inline">\(n_{B,0} = 15\)</span>.</p>
<p>For the treatment group (i.e., A), we get the posterior distribution as:</p>
<p><span class="math display">\[
\mu_A \mid \text{data} \sim N\left( \bar{x}_A, \frac{s_A^2}{n_A} \right)
\]</span></p>
<p>Now, for the SOC group (i.e., B) we write the prior</p>
<p><span class="math display">\[
\mu_B \sim N\left( \mu_{B,0}, \frac{\sigma_{B,0}^2}{n_{B,0}} \right)
\]</span></p>
<p>Hence, with observed data <span class="math inline">\(\bar{x}_B\)</span> from <span class="math inline">\(n_B = 10\)</span> samples, the posterior becomes:</p>
<p><span class="math display">\[
\mu_B \mid \text{data} \sim N\left( \mu_{B,\text{post}}, \sigma^2_{B,\text{post}} \right)
\]</span></p>
<p>Where with simple calculation we write:</p>
<p><span class="math display">\[
\mu_{B,\text{post}} = \frac{ \frac{n_{B,0}}{\sigma^2_{B,0}} \mu_{B,0} + \frac{n_B}{s_B^2} \bar{x}_B }{ \frac{n_{B,0}}{\sigma^2_{B,0}} + \frac{n_B}{s_B^2} }
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\sigma^2_{B,\text{post}} = \left( \frac{n_{B,0}}{\sigma^2_{B,0}} + \frac{n_B}{s_B^2} \right)^{-1}
\]</span></p>
<p>Now, we get the posterior for difference in means assuming independence between <span class="math inline">\(\mu_A\)</span> and <span class="math inline">\(\mu_B\)</span> as:</p>
<p><span class="math display">\[
\delta = \mu_A - \mu_B \sim N(\mu_{\delta}, \sigma^2_{\delta})
\]</span></p>
<p>Where,</p>
<p><span class="math display">\[
\mu_{\delta} = \mu_{A,\text{post}} - \mu_{B,\text{post}} = \bar{x}_A - \mu_{B,\text{post}}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\sigma^2_{\delta} = \sigma^2_{A,\text{post}} + \sigma^2_{B,\text{post}} = \frac{s_A^2}{n_A} + \sigma^2_{B,\text{post}}
\]</span></p>
<p>Finally, we can calculate the 95% credible interval of <span class="math inline">\(\delta\)</span> from its posterior distribution.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>mu_prior_B <span class="ot">&lt;-</span> <span class="dv">110</span>    </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>var_prior_B <span class="ot">&lt;-</span> <span class="dv">25</span>    </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>n_prior_B <span class="ot">&lt;-</span> <span class="dv">15</span>       </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>n_B <span class="ot">&lt;-</span> <span class="fu">length</span>(group_B)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>mean_B <span class="ot">&lt;-</span> <span class="fu">mean</span>(group_B)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>var_B <span class="ot">&lt;-</span> <span class="fu">var</span>(group_B)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>n_A <span class="ot">&lt;-</span> <span class="fu">length</span>(group_A)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>mean_A <span class="ot">&lt;-</span> <span class="fu">mean</span>(group_A)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>var_A <span class="ot">&lt;-</span> <span class="fu">var</span>(group_A)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>mu_post_B <span class="ot">&lt;-</span> (n_B <span class="sc">*</span> mean_B <span class="sc">+</span> n_prior_B <span class="sc">*</span> mu_prior_B) <span class="sc">/</span> (n_B <span class="sc">+</span> n_prior_B)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>var_post_B <span class="ot">&lt;-</span> var_B <span class="sc">/</span> n_B</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>mu_post_A <span class="ot">&lt;-</span> mean_A</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>var_post_A <span class="ot">&lt;-</span> var_A <span class="sc">/</span> n_A</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>mean_diff <span class="ot">&lt;-</span> mu_post_A <span class="sc">-</span> mu_post_B</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>var_diff <span class="ot">&lt;-</span> var_post_A <span class="sc">+</span> var_post_B</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>sd_diff <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(var_diff)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>credible_interval <span class="ot">&lt;-</span> <span class="fu">c</span>(mean_diff <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> sd_diff, mean_diff <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> sd_diff)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Posterior mean difference in SBP:"</span>, <span class="fu">round</span>(mean_diff,<span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Posterior mean difference in SBP: -0.26 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"95% credible interval for difference in SBP:"</span>, <span class="fu">round</span>(credible_interval,<span class="dv">2</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>95% credible interval for difference in SBP: -2.48 1.96 </code></pre>
</div>
</div>
<p>The results shows, on average, the treatment group has a slightly lower SBP than the SOC group, just 0.26 mmHg lower, which is a very small difference. We can also see the 95% credible interval spans both negative and positive values, including zero, we can’t say with confidence whether the treatment lowers, increases, or has no effect on SBP.</p>
<p>This result from Bayesian analysis again contradicts with the frequentist method due to the consideration of prior information related to the SOC in the analysis.</p>
<p>We will explore more about how different prior information might influence our results throughout the course.</p>
<p>Note that in this example, we incorporate prior information as past data and thus update the posterior, which is in line with the Bayesian philosophy. It is also important to note that we might arrive at the same conclusion using a frequentist method, if we consider these historical data from <span class="math inline">\(n_{B,0}\)</span> samples.</p>
<p>In the following section, we discuss more on this type of Bayesian update accordingly.</p>
</section>
</section>
<section id="bayesian-updating" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="bayesian-updating"><span class="header-section-number">2.9</span> Bayesian Updating</h2>
<!--
updating example with plots. ref: McElreath page 29, sec 2.2.2
use McElreath's Fig 2.5, page 30

It is invariance to data-order ... ref: kruschke, page 107; sec 5.2.1

-->
<p>Suppose we observe some data <span class="math inline">\(D_1\)</span> and update our posterior belief <span class="math inline">\(p(\theta|D_1)\)</span> based on prior <span class="math inline">\(p(\theta)\)</span>. Now, if we observe some more data, say <span class="math inline">\(D_2\)</span>, then can update our belief from <span class="math inline">\(p(\theta|D_1)\)</span> to <span class="math inline">\(p(\theta|D_1,D_2)\)</span>. We can explain the Bayesian updating using a step-by-step process.</p>
<p>For example, we want to know the more about the severe side effects of an antibacterial drug. Here, we are considering the variable as either the drug has side effect or not. Initially, we might not know anything about the drug, in this case we do not have a prior information. Now we start to observe or collect data and can see the following patterns of the probabilities related to side effects.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fig_M02_BayesUpdate.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Bayesian Learning, <span class="citation" data-cites="mcelreath2020statistical">McElreath (<a href="references.html#ref-mcelreath2020statistical" role="doc-biblioref">2020</a>)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>This figure illustrates how our understanding of the probability of severe side effects from an antibacterial drug evolves as we collect more data. The x-axis represents the probability of side effects, while the y-axis represents the density of this probability distribution. The solid lines in each plot represent our updated belief based on collected data, whereas the dashed lines represent our prior belief before incorporating the new data. As we observe more cases, our confidence in estimating the probability of side effects changes dynamically.</p>
<p>In the first plot (<strong>n = 1, YES</strong>), we have only one observation, meaning we have very little information to work with. The probability distribution is relatively simple and does not strongly favor any particular probability value. Since the first observed case showed side effects, the probability of severe side effects starts increasing. In contrast, in the second plot (<strong>n = 2, NO</strong>), the second observation indicates no side effects, which alters our belief and introduces more uncertainty. The probability distribution now has a curved shape, reflecting this new piece of evidence.</p>
<p>As more data points are collected (<strong>n = 3, YES</strong> and <strong>n = 4, YES</strong>), our probability distribution starts forming a clearer peak. This means that we are beginning to refine our estimate of how likely the drug is to cause severe side effects. By <strong>n = 5 (YES)</strong>, the probability distribution has a well-defined peak, indicating that we are gaining confidence in our estimate. However, in <strong>n = 6 (NO)</strong>, the introduction of a new negative observation (no side effects) shifts our belief again. This suggests that the probability of side effects is not as high as previously estimated, and our model adjusts accordingly.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DiagrammeR)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>dag <span class="ot">&lt;-</span> <span class="fu">grViz</span>(<span class="st">"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="st">digraph bayesian_dag {</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="st">  # Define the nodes</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="st">  node [shape = rectangle, fontname = 'Helvetica', fontsize = 14]</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="st">  # Prior node</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="st">  Prior [label = 'Prior p(θ)', width = 1.5]</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="st">  # Data observations</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="st">  D1 [label = 'D₁: Observation (YES)', width = 2]</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="st">  Dots [label = '...', width = 0.5]</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="st">  D6 [label = 'D₆: Observation (NO)', width = 2]</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="st">  # Posterior updates</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="st">  Posterior_D1 [label = 'Posterior p(θ|D₁)', width = 2]</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="st">  Posterior_D6 [label = 'Posterior p(θ|D₁, ..., D₆)', width = 2]</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="st">  # Define the edges (relationships)</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="st">  Prior -&gt; D1</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="st">  D1 -&gt; Posterior_D1</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="st">  Posterior_D1 -&gt; Dots</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="st">  Dots -&gt; D6</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="st">  D6 -&gt; Posterior_D6</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="st">  # Layout: top to bottom style</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="st">  rankdir = TB</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="st">"</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>dag</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-fb51dfd8613290b2c189" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-fb51dfd8613290b2c189">{"x":{"diagram":"\ndigraph bayesian_dag {\n  # Define the nodes\n  node [shape = rectangle, fontname = \"Helvetica\", fontsize = 14]\n  \n  # Prior node\n  Prior [label = \"Prior p(θ)\", width = 1.5]\n  \n  # Data observations\n  D1 [label = \"D₁: Observation (YES)\", width = 2]\n  Dots [label = \"...\", width = 0.5]\n  D6 [label = \"D₆: Observation (NO)\", width = 2]\n  \n  # Posterior updates\n  Posterior_D1 [label = \"Posterior p(θ|D₁)\", width = 2]\n  Posterior_D6 [label = \"Posterior p(θ|D₁, ..., D₆)\", width = 2]\n\n  # Define the edges (relationships)\n  Prior -> D1\n  D1 -> Posterior_D1\n  Posterior_D1 -> Dots\n  Dots -> D6\n  D6 -> Posterior_D6\n\n  # Layout: top to bottom style\n  rankdir = TB\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p><strong>Invariance to data-order</strong></p>
<p>This Bayesian learning process for <span class="math inline">\(\theta\)</span> is very intuitive, where we can write</p>
<p><span class="math display">\[\begin{align}
p(\theta|D_1,D_2) = \frac{p(D_1,D_2|\theta)\times p(\theta)}{\sum_{\theta^*}p(D_1,D_2|\theta^*)\times p(\theta^*)}
\end{align}\]</span> If we consider <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> are independent, then <span class="math display">\[\begin{align}
p(D_1,D_2|\theta)=p(D_1|\theta)p(D_2|\theta)
\end{align}\]</span> This leads to a very simple formation of considering <span class="math display">\[\begin{align}
p(\theta|D_2,D_1) = \frac{p(D_2|\theta)\times p(\theta|D_1)}{\sum_{\theta^*}p(D_2,D_1|\theta^*)\times p(\theta^*)}
\end{align}\]</span></p>
<p>This implies, under the independence condition, the order of Bayesian updating has no effect on the final posterior. Hence, going back to Figure above: we will get same final result (i.e., posterior probability of side effect) for considering all six observations.</p>
</section>
<section id="summary" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="summary"><span class="header-section-number">2.10</span> Summary</h2>
<p>Today’s lecture explored Bayesian inference, focusing on how to derive it analytically, we also learn Bayesian updating, posterior odds and Directed Acyclic Graphs (DAGs).</p>
</section>
<section id="live-tutorial-and-discussion" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="live-tutorial-and-discussion"><span class="header-section-number">2.11</span> Live tutorial and discussion</h2>
<p>The final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!</p>
</section>
<section id="tutorial-exercises" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="tutorial-exercises"><span class="header-section-number">2.12</span> Tutorial Exercises</h2>
<p>Solutions will be provided later after the tutorial.</p>
</section>
<section id="preparation-for-week-3" class="level2" data-number="2.13">
<h2 data-number="2.13" class="anchored" data-anchor-id="preparation-for-week-3"><span class="header-section-number">2.13</span> Preparation for Week 3</h2>
<p>Next week we will start Module 02 of this unit, where our main focus will be to understand different types of prior distributions and how they influence the posteriors.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-kruschke2014doing" class="csl-entry" role="listitem">
Kruschke, J. 2014. <em>Doing Bayesian Data Analysis: A Tutorial with r, JAGS, and Stan</em>. Academic Press.
</div>
<div id="ref-mcelreath2020statistical" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course with Examples in r and Stan (2nd Edition)</em>. Chapman; Hall/CRC.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./M01_1.html" class="pagination-link" aria-label="**Navigating Evidence**">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><strong>Navigating Evidence</strong></span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./brief_module_02.html" class="pagination-link" aria-label="**Module 2: Chaotics**">
        <span class="nav-page-text"><strong>Module 2: Chaotics</strong></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>