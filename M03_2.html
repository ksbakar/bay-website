<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; Prior Tweaks and More – Bayesian Statistical Methods in Medicine &amp; Health</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./brief_module_04.html" rel="next">
<link href="./M03_1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-07c16812f08c4a1591d6ec4fc46327fa.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<script src="site_libs/viz-1.8.2/viz.js"></script>

<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">

<script src="site_libs/grViz-binding-1.0.11/grViz.js"></script>

<script src="site_libs/plotly-binding-4.10.4/plotly.js"></script>

<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>

<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>

<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">

<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>

<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">

<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./M03_2.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Statistical Methods in Medicine &amp; Health</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Preface</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Introduction</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./installation_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Software Installation Guide</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 1: Bayesian Dreams</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title"><strong>Navigating Evidence</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M01_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><strong>Bayesian Inference</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 2: Chaotics</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title"><strong>Prior and Posterior</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M02_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title"><strong>Generative Models and Tools</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 3: Bayeswatch - Gaussian</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M03_2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 4: Bayeswatch - Non Gaussian</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title"><strong>Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M04_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title"><strong>More on Non-Gaussian</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 5: Clusterphobia</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - I</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M05_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title"><strong>Clusterphobia? Part - II</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./brief_module_06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Module 6: Wander into the Wonder!</strong></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title"><strong>Size Matters!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./M06_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title"><strong>Wander into the Wonder!</strong></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learnings" id="toc-learnings" class="nav-link active" data-scroll-target="#learnings"><span class="header-section-number">6.1</span> Learnings</a></li>
  <li><a href="#prior-options" id="toc-prior-options" class="nav-link" data-scroll-target="#prior-options"><span class="header-section-number">6.2</span> Prior Options</a></li>
  <li><a href="#prior-for-variability" id="toc-prior-for-variability" class="nav-link" data-scroll-target="#prior-for-variability"><span class="header-section-number">6.3</span> Prior for Variability</a>
  <ul class="collapse">
  <li><a href="#half-cauchy-prior" id="toc-half-cauchy-prior" class="nav-link" data-scroll-target="#half-cauchy-prior"><span class="header-section-number">6.3.1</span> Half-Cauchy Prior</a></li>
  <li><a href="#exponential-prior" id="toc-exponential-prior" class="nav-link" data-scroll-target="#exponential-prior"><span class="header-section-number">6.3.2</span> Exponential Prior</a></li>
  </ul></li>
  <li><a href="#prior-for-slope" id="toc-prior-for-slope" class="nav-link" data-scroll-target="#prior-for-slope"><span class="header-section-number">6.4</span> Prior for Slope</a>
  <ul class="collapse">
  <li><a href="#weakly-informative-informative" id="toc-weakly-informative-informative" class="nav-link" data-scroll-target="#weakly-informative-informative"><span class="header-section-number">6.4.1</span> Weakly Informative &amp; Informative</a></li>
  <li><a href="#comparison" id="toc-comparison" class="nav-link" data-scroll-target="#comparison"><span class="header-section-number">6.4.2</span> Comparison</a></li>
  </ul></li>
  <li><a href="#bayesian-vs.-frequentist" id="toc-bayesian-vs.-frequentist" class="nav-link" data-scroll-target="#bayesian-vs.-frequentist"><span class="header-section-number">6.5</span> Bayesian vs.&nbsp;Frequentist</a></li>
  <li><a href="#further-model-development" id="toc-further-model-development" class="nav-link" data-scroll-target="#further-model-development"><span class="header-section-number">6.6</span> Further Model Development</a>
  <ul class="collapse">
  <li><a href="#model-dag" id="toc-model-dag" class="nav-link" data-scroll-target="#model-dag"><span class="header-section-number">6.6.1</span> Model &amp; DAG</a></li>
  <li><a href="#results-mcmc-diagnostics" id="toc-results-mcmc-diagnostics" class="nav-link" data-scroll-target="#results-mcmc-diagnostics"><span class="header-section-number">6.6.2</span> Results &amp; MCMC Diagnostics</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">6.7</span> Summary</a></li>
  <li><a href="#live-tutorial-and-discussion" id="toc-live-tutorial-and-discussion" class="nav-link" data-scroll-target="#live-tutorial-and-discussion"><span class="header-section-number">6.8</span> Live tutorial and discussion</a></li>
  <li><a href="#tutorial-exercises" id="toc-tutorial-exercises" class="nav-link" data-scroll-target="#tutorial-exercises"><span class="header-section-number">6.9</span> Tutorial Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><strong>Prior Tweaks and More</strong></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<iframe width="500" height="300" src="https://www.youtube.com/embed/fXWikRtWcp0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="learnings" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="learnings"><span class="header-section-number">6.1</span> Learnings</h2>
<ul>
<li><strong>Outcomes</strong></li>
</ul>
<p>– LO1: Explain the difference between Bayesian and frequentist concepts of statistical inference.</p>
<p>– LO2: Demonstrate how to specify and fit simple Bayesian models with appropriate attention to the role of the prior distribution and the data model.</p>
<p>– LO4: Demonstrate proficiency in using statistical software packages (R) to specify and fit models, assess model fit, detect and remediate non-convergence, and compare models.</p>
<p>– LO5: Engage in specifying, checking and interpreting Bayesian statistical analyses in practical problems using effective communication with health and medical investigators.</p>
<ul>
<li><strong>Objectives</strong></li>
</ul>
<p>By the end of this week you should be able to:</p>
<p>– Understand different aspects of prior distributions for variance parameter.</p>
<p>– Explain which prior to use for Bayesian model with multiple variables.</p>
<p>– Compare Bayesian and frequentist models.</p>
<p>– Interpret real-life problems in Bayesian context.</p>
</section>
<section id="prior-options" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="prior-options"><span class="header-section-number">6.2</span> Prior Options</h2>
<p>In our previous lecture, using Bayesian model, we explained the effect of body mass index (BMI) on bone mineral density (BMD). We used weakly informative prior, and we discussed in one of our previous lectures that use of weakly informative priors are common in modern Bayesian modeling, as it balances interpretability and robustness of the posterior distribution. Now, we will explain how different types of prior distributions can be used for the model variance and slope parameters.</p>
</section>
<section id="prior-for-variability" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="prior-for-variability"><span class="header-section-number">6.3</span> Prior for Variability</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/6LiEToERJuM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>Historically, Bayesian models used Inverse-Gamma priors for variability parameters, because it has support on positive values and has nice mathematical properties (conjugate prior for the normal distribution). However, in Bayesian model (e.g., Bayesian regression), this might cause problems. For example, to represent non-informativeness, we can consider <span class="math inline">\(\text{IG}(a=0.001,b=0.001)\)</span>, which uses very small values for the hyperparameters of the distribution. Even though <span class="math inline">\(\text{IG}(a=0.001,b=0.001)\)</span> appears non-informative, it biases the model toward very small variance values. It is “too informative” in a negative way, not because it is strong, but because it pretends to be weak while still influencing the outcome. Furthermore, the use of <span class="math inline">\(\text{IG}(a,b)\)</span> often favours small variances, which can lead to underestimating uncertainty in group-level effects. In addition, in regression settings, if the model is complex, the use of <span class="math inline">\(\text{IG}(a,b)\)</span> can make it difficult to achieve convergence in the MCMC sampling for the variance parameter, as the distribution can become spiky near zero, leading to unstable behavior during inference.</p>
<p>We have already discussed in our previous lecture that we can approximate the inverse Gamma prior with Student-t distribution. Still this will not aid some of the issues that we mentioned, such as not having a heavy tail. In today’s lecture will learn about some other distributions that can provide reasonable solutions.</p>
<section id="half-cauchy-prior" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="half-cauchy-prior"><span class="header-section-number">6.3.1</span> Half-Cauchy Prior</h3>
<p>To avoid the issues with inverse Gamma distribution, the half-Cauchy distribution (i.e., a Cauchy distribution restricted to positive values) is popularly used. Half-Cauchy also behaves as weakly informative prior and provides better inference (depending on the choice of hyper paramters).</p>
<p>We prefer using the half-Cauchy prior for the parameter <span class="math inline">\(\sigma\)</span> because it has several useful properties. It has heavy tails, which means it allows for large values of <span class="math inline">\(\sigma\)</span> when the data support it, rather than cutting them off or overly constraining them. Unlike the Inverse Gamma prior, it is less informative near zero and does not push the variance toward small values, which can be especially important in hierarchical models. It also provides a form of regularisation by gently pulling estimates toward smaller values without being too aggressive, allowing the data to guide the estimates more naturally.</p>
<p>One of the issues may arise for Half-Cauchy <span class="math inline">\(\sigma\)</span> prior in hierarchical Bayesian model relates to the non-conjugacy. However, use of cleaver MCMC sampling algorithm such as HMC-NUTS can provide a solution to this problem.</p>
<p>Now, we can rewrite the DAG we provided in our last lecture related to the BMD model, where we replace the Inverse Gamma prior by the Half-Cauchy.</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-4942b9d2a9b940e276fc" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-4942b9d2a9b940e276fc">{"x":{"diagram":"\n  digraph DAG {\n    rankdir=LR;  # Set direction from left to right\n    \n    # Nodes (parameters and variables)\n    BMI [label = \"BMI\", shape = ellipse, style = filled, fillcolor = lightblue]\n    BMD [label = \"BMD\", shape = ellipse, style = filled, fillcolor = lightcoral]\n    beta_0 [label = \"β₀\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_1 [label = \"β₁\", shape = box, style = filled, fillcolor = lightgrey]\n    sigma2 [label = \"σ\", shape = box, style = filled, fillcolor = lightgrey]\n    prior_beta_0 [label = \"Prior for β₀: N(μ₀, σ₀²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_beta_1 [label = \"Prior for β₁: N(μ₁, σ₁²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_sigma2 [label = \"Prior for σ: Half-Cauchy(0, τ)\", shape = box, style = dashed, fillcolor = lightyellow]\n    \n    # Edges (dependencies between nodes)\n    BMI -> BMD\n    beta_0 -> BMD\n    beta_1 -> BMD\n    sigma2 -> BMD\n    prior_beta_0 -> beta_0\n    prior_beta_1 -> beta_1\n    prior_sigma2 -> sigma2\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Here, we use the Half-Cauchy prior distribution separately for the variance parameter instead of the Inverse Gamma distribution, while keeping the priors for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, as normal distributions <span class="math inline">\(N(0,10^2)\)</span>, which gives us the following prior distributions:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>x_norm <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="dv">40</span>, <span class="at">length.out =</span> <span class="dv">500</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>normal_density <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x_norm, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>df_beta <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_norm,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> normal_density</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_beta, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Prior for "</span> <span class="sc">~</span> beta[<span class="dv">0</span>]),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">0</span>]),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_beta, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkgreen"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Priors for "</span> <span class="sc">~</span> beta[<span class="dv">1</span>] <span class="sc">*</span> <span class="st">" and "</span> <span class="sc">*</span> beta[<span class="dv">0</span>]),</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>x_sigma <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="dv">5</span>, <span class="at">length.out =</span> <span class="dv">500</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>half_cauchy_density <span class="ot">&lt;-</span> <span class="fu">dcauchy</span>(x_sigma, <span class="at">location =</span> <span class="dv">0</span>, <span class="at">scale =</span> <span class="dv">1</span>)  <span class="co"># Half-Cauchy with scale = 1</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>df_sigma <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_sigma,</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> half_cauchy_density</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_sigma, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"firebrick"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Half-Cauchy Prior for "</span> <span class="sc">~</span> sigma),</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(sigma),</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co">#library(patchwork)</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">#(p1 | p2 | p3) + plot_annotation(title = "Prior Distributions")</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p2,p3,<span class="at">ncol=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/bmd_prior_half_cauchy-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Hence, we get the posterior summaries based on the Half-Cauchy prior distribution with hyper-parmater one as follows. Note that for ‘brms’ R package, we define the prior distributions for <span class="math inline">\(\sigma\)</span> instead of <span class="math inline">\(\sigma^2\)</span>, which we write:</p>
<blockquote class="blockquote">
<p>prior(cauchy(0, 1), class = “sigma”)</p>
</blockquote>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"bmd_restricted.csv"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>bmd_data<span class="sc">$</span>bmi <span class="ot">&lt;-</span> bmd_data<span class="sc">$</span>weight_kg<span class="sc">/</span>(bmd_data<span class="sc">$</span>height_cm<span class="sc">/</span><span class="dv">100</span>)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMD =</span> bmd_data<span class="sc">$</span>bmd,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMI =</span> bmd_data<span class="sc">$</span>bmi,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># model</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>bmd_model <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> BMD <span class="sc">~</span> BMI,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> bmd_data,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"BMI"</span>),   <span class="co"># N(mean, sd) Slope priors</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"Intercept"</span>),   <span class="co"># N(mean, sd) Intercept prior</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> <span class="st">"sigma"</span>)  <span class="co"># Half-Cauchy prior for sigma</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">1</span>,</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">3</span>,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.06 seconds (Warm-up)
Chain 1:                0.045 seconds (Sampling)
Chain 1:                0.105 seconds (Total)
Chain 1: </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bmd_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: BMD ~ BMI 
   Data: bmd_data (Number of observations: 169) 
  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 1000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     0.42      0.07     0.29     0.57 1.00     1273      773
BMI           0.01      0.00     0.01     0.02 1.00     1233      872

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.16      0.01     0.14     0.17 1.00      700      608

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#posterior_summary(bmd_model)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(bmd_model)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<!--


1. **Estimate**: The point estimate of the variance parameter (**sigma**) is 0.15. This represents the estimated standard deviation of the residuals (or errors) in the model, which tells us how much the observed values deviate from the predicted values, on average.

2. **Est.Error**: The standard error of the estimate is 0.01. This measures the uncertainty or variability of the estimate for **sigma**. A smaller standard error indicates that the estimate of **sigma** is relatively precise.

3. **l-95% CI and u-95% CI**: These values represent the 95% credible interval for **sigma**, which means we are 95% confident that the true value of **sigma** lies between 0.14 and 0.17.

4. **Rhat**: The value for **Rhat** is 1.01, which indicates that the chains of the Markov Chain Monte Carlo (MCMC) sampling process have likely converged. **Rhat** values close to 1 suggest that the MCMC algorithm has run long enough for the results to be reliable. If **Rhat** is much greater than 1, it suggests that the chains have not fully converged, and the results may not be reliable.

5. **Bulk_ESS and Tail_ESS**: These are measures of the effective sample size for the bulk of the distribution (Bulk_ESS) and for the tails (Tail_ESS). Higher values indicate better sampling quality. In this case:
   - **Bulk_ESS** = 676: This suggests the MCMC process effectively sampled the bulk of the posterior distribution for **sigma**.
   - **Tail_ESS** = 555: This shows the effective sample size for the tail of the distribution, which is important for capturing extreme values or outliers. These values indicate reasonable mixing and convergence of the MCMC chains.

-->
<p>The model result suggests that the standard deviation (<span class="math inline">\(\sigma\)</span>) of residuals is estimated to be around 0.16, with the uncertainty around this estimate being quite low (Est.Error = 0.01). The credible interval for sigma is between 0.14 and 0.17, and the MCMC sampling appears to have converged well based on the Rhat and ESS values.</p>
</section>
<section id="exponential-prior" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="exponential-prior"><span class="header-section-number">6.3.2</span> Exponential Prior</h3>
<p>Another potential caldidate distribution for replacing the Inverse Gamma distribution for the variability parameter <span class="math inline">\(\sigma\)</span> is the Exponential distribution, i.e., <span class="math inline">\(\sigma \sim \text{Exp}(\lambda)\)</span>, with <span class="math inline">\(\lambda\)</span> as the hyper-parameter. This distribution is mathematically simple and computationally efficient. Using an exponential prior with a small rate (like <span class="math inline">\(\lambda = 1\)</span>) can be seen as a weakly informative prior. This means it doesn’t strongly influence the outcome but still provides some regularisation (keeping variance from growing excessively). This is helpful when you have limited prior knowledge about the variance, as it avoids over-penalising large values of the variance while still discouraging very small values.</p>
<p>We can get similar result using exponential prior distribution with rate hyper-parameter <span class="math inline">\(\lambda=1\)</span>. Here in R code we need to replace</p>
<blockquote class="blockquote">
<p>prior(cauchy(0, 1), class = “sigma”)</p>
</blockquote>
<p>by</p>
<blockquote class="blockquote">
<p>prior(exponential(1), class = “sigma”)</p>
</blockquote>
<p>to get posterior distribution of the model parameter <span class="math inline">\(\sigma^2\)</span>.</p>
<p>In particular, if we use <span class="math inline">\(\text{Half-Cauchy}(0,\tau=1)\)</span> and <span class="math inline">\(\text{Exp}(\lambda=1)\)</span>, then this gives us the following prior distributions:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>exponential_density <span class="ot">&lt;-</span> <span class="fu">dexp</span>(x_sigma, <span class="at">rate =</span> <span class="dv">1</span>)  <span class="co"># Exponential with rate = 1</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>df_exp_sigma <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_sigma,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">density =</span> exponential_density</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_exp_sigma, <span class="fu">aes</span>(x, density)) <span class="sc">+</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkorchid"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Exponential Prior for "</span> <span class="sc">~</span> sigma),</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(sigma),</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p3,p4,<span class="at">ncol=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/bmd_prior_expo-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="prior-for-slope" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="prior-for-slope"><span class="header-section-number">6.4</span> Prior for Slope</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/696qkYgd548" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="weakly-informative-informative" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="weakly-informative-informative"><span class="header-section-number">6.4.1</span> Weakly Informative &amp; Informative</h3>
<p>Suppose, instead using weakly informative prior for <span class="math inline">\(\beta_1\)</span> (the slope for BMI), we want to use an informative prior. This refers to considering one unit increase in BMI, BMD increases by approximately 0.05 units on average, say we also knowfrom the past data that the standard deviation related to this is very low, i.e., 0.01. Hence, we write the prior distribution as: <span class="math inline">\(\beta_1 \sim N(0.05, 0.01^2)\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>bmd_model_inform <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> BMD <span class="sc">~</span> BMI,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> bmd_data,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="fl">0.05</span>, <span class="fl">0.01</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"BMI"</span>),   <span class="co"># Informative prior for beta_1</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"Intercept"</span>),   <span class="co"># Intercept prior</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> <span class="st">"sigma"</span>)  <span class="co"># Half-Cauchy prior for sigma</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">1</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">3</span>,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 3.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.07 seconds (Warm-up)
Chain 1:                0.031 seconds (Sampling)
Chain 1:                0.101 seconds (Total)
Chain 1: </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bmd_model_inform)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: BMD ~ BMI 
   Data: bmd_data (Number of observations: 169) 
  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 1000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept     0.36      0.07     0.23     0.50 1.00     1379      905
BMI           0.02      0.00     0.01     0.02 1.00     1364      830

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.16      0.01     0.14     0.17 1.00      482      601

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<p>From the results related to informative prior for <span class="math inline">\(\beta_1\)</span>, we can say that the informative prior for <span class="math inline">\(\beta_1\)</span> tightly constrained the estimate of the effect of BMI on BMD, yielding a posterior mean estimate of 0.02 with a narrow credible interval <span class="math inline">\([0.01, 0.02]\)</span>. The model shows very high precision for this parameter, with low uncertainty accordingly.</p>
</section>
<section id="comparison" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="comparison"><span class="header-section-number">6.4.2</span> Comparison</h3>
<p>Now we will provide a comparison of the <span class="math inline">\(\beta_1\)</span> estimates from two models: one where we used an informative prior, i.e., <span class="math inline">\(\beta_1\sim N(0.05,0.01)\)</span> and another where we used a weakly informative prior <span class="math inline">\(\beta_1\sim N(0,10^2)\)</span>.</p>
<!--

In the model with the informative prior, the estimated mean value of $\beta_1$ is 0.02.Whereas, when using a weakly informative prior, the estimate is 0.01. This shows that when we include stronger prior knowledge suggesting that BMI has a positive effect on BMD, the model shifts the estimate slightly higher in that direction. We also see that both models have very low standard errors for $\beta_1$ meaning there is very little uncertainty around the estimate. The 95% credible intervals are also very similar, ranging from 0.01 to 0.02, but the one using the informative prior is slightly more centered around 0.02.

-->
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>prior_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">beta_1 =</span> x_vals,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">Informative =</span> <span class="fu">dnorm</span>(x_vals, <span class="at">mean =</span> <span class="fl">0.05</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="fl">0.01</span>)),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">Weakly_Informative =</span> <span class="fu">dnorm</span>(x_vals, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>prior_df_long <span class="ot">&lt;-</span> <span class="fu">pivot_longer</span>(</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  prior_df,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">cols =</span> <span class="fu">c</span>(<span class="st">"Informative"</span>, <span class="st">"Weakly_Informative"</span>),</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">names_to =</span> <span class="st">"Prior_Type"</span>,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">values_to =</span> <span class="st">"Density"</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(prior_df_long, <span class="fu">aes</span>(<span class="at">x =</span> beta_1, <span class="at">y =</span> Density, <span class="at">color =</span> Prior_Type, <span class="at">fill =</span> Prior_Type)) <span class="sc">+</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Prior for "</span> <span class="sc">~</span> beta[<span class="dv">1</span>]),</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>] <span class="sc">~</span> <span class="st">"Prior"</span>),</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">""</span>,</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">""</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>posterior_inform <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(bmd_model_inform)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>posterior_weak   <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(bmd_model)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>beta1_samples <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>  posterior_inform <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="st">`</span><span class="at">b_BMI</span><span class="st">`</span>) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Informative Prior"</span>),</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  posterior_weak <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="st">`</span><span class="at">b_BMI</span><span class="st">`</span>) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Model =</span> <span class="st">"Weakly Informative Prior"</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(beta1_samples, <span class="fu">aes</span>(<span class="at">x =</span> b_BMI, <span class="at">fill =</span> Model, <span class="at">color =</span> Model)) <span class="sc">+</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">expression</span>(<span class="st">"Posterior for "</span> <span class="sc">~</span> beta[<span class="dv">1</span>]),</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>] <span class="sc">~</span> <span class="st">"Posterior"</span>),</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">""</span>,</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">""</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"bottom"</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>  )  </span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/comp_wk_inf-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This above plots show how two different types of prior information affect our estimate of a parameter, <span class="math inline">\(\beta_1\)</span>. The blue curve represents the informative prior, this results in a distribution indicating higher certainty. The red curve represents the weakly informative prior, meaning we have less prior knowledge about <span class="math inline">\(\beta_1\)</span>. This results in a distribution that is more spread out, indicating less certainty.</p>
</section>
</section>
<section id="bayesian-vs.-frequentist" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="bayesian-vs.-frequentist"><span class="header-section-number">6.5</span> Bayesian vs.&nbsp;Frequentist</h2>
<p>Now we explain and compare the Bayesian and frequentist estimates, where we use informative prior distribution, i.e., <span class="math inline">\(\beta_1\sim N(0.05,0.01)\)</span>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(BMD <span class="sc">~</span> BMI, <span class="at">data =</span> bmd_data)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>jtools<span class="sc">::</span><span class="fu">summ</span>(lm_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="table-responsive">
<table class="table table-striped table-hover table-condensed caption-top table-sm small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">Observations</td>
<td style="text-align: right;">169</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold;">Dependent variable</td>
<td style="text-align: right;">BMD</td>
</tr>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">Type</td>
<td style="text-align: right;">OLS linear regression</td>
</tr>
</tbody>
</table>
</div>
 
<div class="table-responsive">
<table class="table table-striped table-hover table-condensed caption-top table-sm small" data-quarto-postprocess="true">
<tbody>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">F(1,167)</td>
<td style="text-align: right;">27.98</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold;">R²</td>
<td style="text-align: right;">0.14</td>
</tr>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">Adj. R²</td>
<td style="text-align: right;">0.14</td>
</tr>
</tbody>
</table>
</div>
 
<div class="table-responsive">
<table class="table table-striped table-hover table-condensed caption-top table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Est.</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">S.E.</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">t val.</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">(Intercept)</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: right;">6.11</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold;">BMI</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">5.29</td>
<td style="text-align: right;">0.00</td>
</tr>
</tbody><tfoot>
<tr class="odd">
<td style="text-align: left; padding: 0;"><sup></sup> Standard errors: OLS</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
</tfoot>

</table>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>lm_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">summary</span>(lm_model))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>bmi_est <span class="ot">&lt;-</span> lm_coef[<span class="st">"BMI"</span>, <span class="st">"Estimate"</span>]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>bmi_se <span class="ot">&lt;-</span> lm_coef[<span class="st">"BMI"</span>, <span class="st">"Std. Error"</span>]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>ci_low <span class="ot">&lt;-</span> bmi_est <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> bmi_se</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>ci_high <span class="ot">&lt;-</span> bmi_est <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> bmi_se</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">as_draws_df</span>(bmd_model_inform)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>post_bmi <span class="ot">&lt;-</span> post<span class="sc">$</span>b_BMI</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>bayes_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(post_bmi)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>bayes_ci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(post_bmi, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> post_bmi), <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="cn">NA</span>) <span class="sc">+</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bmi_est, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_low, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> ci_high, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_mean, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_ci[<span class="dv">1</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> bayes_ci[<span class="dv">2</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Bayesian (informative) vs Frequentist Estimate of BMI"</span>,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Red: Frequentist (Mean &amp; 95% Confidence Interval)</span><span class="sc">\n</span><span class="st">Blue: Bayesian (Posterior Mean &amp; 95% Credible Interval)"</span>,</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Coefficient for BMI"</span>,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">plot.subtitle =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-5b3ffb7a26432c3dcdf3" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-5b3ffb7a26432c3dcdf3">{"x":{"data":[{"x":[0.0085575209636878716,0.0085947683111633529,0.0086320156586388343,0.0086692630061143139,0.0087065103535897952,0.0087437577010652766,0.0087810050485407579,0.0088182523960162375,0.0088554997434917189,0.0088927470909672002,0.0089299944384426816,0.0089672417859181629,0.0090044891333936426,0.0090417364808691239,0.0090789838283446053,0.0091162311758200866,0.0091534785232955662,0.0091907258707710476,0.0092279732182465289,0.0092652205657220103,0.0093024679131974916,0.0093397152606729712,0.0093769626081484526,0.0094142099556239339,0.0094514573030994153,0.0094887046505748949,0.0095259519980503762,0.0095631993455258576,0.0096004466930013389,0.0096376940404768185,0.0096749413879522999,0.0097121887354277812,0.0097494360829032626,0.0097866834303787439,0.0098239307778542236,0.0098611781253297049,0.0098984254728051863,0.0099356728202806676,0.009972920167756149,0.010010167515231629,0.01004741486270711,0.010084662210182591,0.010121909557658073,0.010159156905133552,0.010196404252609034,0.010233651600084515,0.010270898947559996,0.010308146295035476,0.010345393642510957,0.010382640989986439,0.01041988833746192,0.010457135684937401,0.010494383032412881,0.010531630379888362,0.010568877727363844,0.010606125074839325,0.010643372422314806,0.010680619769790286,0.010717867117265767,0.010755114464741249,0.01079236181221673,0.010829609159692211,0.010866856507167691,0.010904103854643172,0.010941351202118654,0.010978598549594133,0.011015845897069615,0.011053093244545096,0.011090340592020577,0.011127587939496059,0.011164835286971538,0.01120208263444702,0.011239329981922501,0.011276577329397982,0.011313824676873464,0.011351072024348943,0.011388319371824425,0.011425566719299906,0.011462814066775387,0.011500061414250869,0.011537308761726348,0.01157455610920183,0.011611803456677311,0.011649050804152791,0.011686298151628272,0.011723545499103753,0.011760792846579235,0.011798040194054716,0.011835287541530196,0.011872534889005677,0.011909782236481158,0.01194702958395664,0.011984276931432121,0.012021524278907601,0.012058771626383082,0.012096018973858563,0.012133266321334043,0.012170513668809526,0.012207761016285006,0.012245008363760487,0.012282255711235968,0.012319503058711448,0.012356750406186929,0.012393997753662411,0.012431245101137892,0.012468492448613373,0.012505739796088853,0.012542987143564334,0.012580234491039816,0.012617481838515295,0.012654729185990778,0.012691976533466258,0.012729223880941739,0.012766471228417221,0.0128037185758927,0.012840965923368183,0.012878213270843663,0.012915460618319144,0.012952707965794626,0.012989955313270105,0.013027202660745588,0.013064450008221068,0.013101697355696549,0.013138944703172031,0.01317619205064751,0.013213439398122992,0.013250686745598473,0.013287934093073953,0.013325181440549436,0.013362428788024915,0.013399676135500397,0.013436923482975878,0.013474170830451358,0.013511418177926841,0.01354866552540232,0.013585912872877802,0.013623160220353283,0.013660407567828763,0.013697654915304246,0.013734902262779725,0.013772149610255207,0.013809396957730688,0.013846644305206168,0.013883891652681649,0.01392113900015713,0.01395838634763261,0.013995633695108093,0.014032881042583573,0.014070128390059054,0.014107375737534535,0.014144623085010015,0.014181870432485498,0.014219117779960978,0.014256365127436459,0.01429361247491194,0.01433085982238742,0.014368107169862903,0.014405354517338383,0.014442601864813864,0.014479849212289345,0.014517096559764825,0.014554343907240306,0.014591591254715788,0.014628838602191267,0.01466608594966675,0.01470333329714223,0.014740580644617711,0.014777827992093193,0.014815075339568672,0.014852322687044155,0.014889570034519635,0.014926817381995116,0.014964064729470598,0.015001312076946077,0.01503855942442156,0.01507580677189704,0.015113054119372521,0.015150301466848003,0.015187548814323482,0.015224796161798964,0.015262043509274445,0.015299290856749925,0.015336538204225408,0.015373785551700887,0.015411032899176369,0.01544828024665185,0.01548552759412733,0.015522774941602813,0.015560022289078292,0.015597269636553774,0.015634516984029255,0.015671764331504735,0.015709011678980214,0.015746259026455697,0.01578350637393118,0.01582075372140666,0.01585800106888214,0.015895248416357623,0.015932495763833102,0.015969743111308582,0.016006990458784065,0.016044237806259545,0.016081485153735024,0.016118732501210507,0.016155979848685987,0.01619322719616147,0.01623047454363695,0.016267721891112433,0.016304969238587912,0.016342216586063392,0.016379463933538875,0.016416711281014355,0.016453958628489834,0.016491205975965317,0.016528453323440797,0.016565700670916277,0.01660294801839176,0.016640195365867243,0.016677442713342719,0.016714690060818202,0.016751937408293685,0.016789184755769165,0.016826432103244644,0.016863679450720127,0.016900926798195607,0.016938174145671087,0.01697542149314657,0.017012668840622049,0.017049916188097529,0.017087163535573012,0.017124410883048495,0.017161658230523975,0.017198905577999454,0.017236152925474937,0.017273400272950417,0.017310647620425897,0.01734789496790138,0.017385142315376859,0.017422389662852339,0.017459637010327822,0.017496884357803305,0.017534131705278781,0.017571379052754264,0.017608626400229747,0.017645873747705227,0.017683121095180707,0.01772036844265619,0.017757615790131669,0.017794863137607149,0.017832110485082632,0.017869357832558112,0.017906605180033591,0.017943852527509074,0.017981099874984557,0.018018347222460034,0.018055594569935517,0.018092841917411,0.018130089264886479,0.018167336612361959,0.018204583959837442,0.018241831307312922,0.018279078654788401,0.018316326002263884,0.018353573349739364,0.018390820697214844,0.018428068044690327,0.01846531539216581,0.018502562739641289,0.018539810087116769,0.018577057434592252,0.018614304782067732,0.018651552129543211,0.018688799477018694,0.018726046824494174,0.018763294171969654,0.018800541519445137,0.01883778886692062,0.018875036214396096,0.018912283561871579,0.018949530909347062,0.018986778256822542,0.019024025604298021,0.019061272951773504,0.019098520299248984,0.019135767646724464,0.019173014994199947,0.019210262341675426,0.019247509689150906,0.019284757036626389,0.019322004384101872,0.019359251731577348,0.019396499079052831,0.019433746426528314,0.019470993774003794,0.019508241121479274,0.019545488468954757,0.019582735816430236,0.019619983163905716,0.019657230511381199,0.019694477858856679,0.019731725206332158,0.019768972553807641,0.019806219901283124,0.019843467248758604,0.019880714596234084,0.019917961943709567,0.019955209291185046,0.019992456638660526,0.020029703986136009,0.020066951333611489,0.020104198681086968,0.020141446028562451,0.020178693376037934,0.020215940723513411,0.020253188070988894,0.020290435418464377,0.020327682765939856,0.020364930113415336,0.020402177460890819,0.020439424808366299,0.020476672155841778,0.020513919503317261,0.020551166850792741,0.020588414198268221,0.020625661545743704,0.020662908893219187,0.020700156240694663,0.020737403588170146,0.020774650935645629,0.020811898283121109,0.020849145630596588,0.020886392978072071,0.020923640325547551,0.020960887673023031,0.020998135020498514,0.021035382367973993,0.021072629715449473,0.021109877062924956,0.021147124410400439,0.021184371757875919,0.021221619105351398,0.021258866452826881,0.021296113800302361,0.021333361147777841,0.021370608495253324,0.021407855842728803,0.021445103190204283,0.021482350537679766,0.021519597885155249,0.021556845232630725,0.021594092580106208,0.021631339927581691,0.021668587275057171,0.021705834622532651,0.021743081970008134,0.021780329317483613,0.021817576664959093,0.021854824012434576,0.021892071359910056,0.021929318707385535,0.021966566054861018,0.022003813402336501,0.022041060749811978,0.022078308097287461,0.022115555444762944,0.022152802792238423,0.022190050139713903,0.022227297487189386,0.022264544834664866,0.022301792182140345,0.022339039529615828,0.022376286877091308,0.022413534224566788,0.022450781572042271,0.022488028919517754,0.022525276266993233,0.022562523614468713,0.022599770961944196,0.022637018309419676,0.022674265656895155,0.022711513004370638,0.022748760351846118,0.022786007699321598,0.022823255046797081,0.02286050239427256,0.02289774974174804,0.022934997089223523,0.022972244436699006,0.023009491784174486,0.023046739131649965,0.023083986479125448,0.023121233826600928,0.023158481174076408,0.023195728521551891,0.02323297586902737,0.02327022321650285,0.023307470563978333,0.023344717911453816,0.023381965258929292,0.023419212606404775,0.023456459953880258,0.023493707301355738,0.023530954648831218,0.023568201996306701,0.02360544934378218,0.02364269669125766,0.023679944038733143,0.023717191386208623,0.023754438733684102,0.023791686081159585,0.023828933428635068,0.023866180776110545,0.023903428123586028,0.023940675471061511,0.02397792281853699,0.02401517016601247,0.024052417513487953,0.024089664860963433,0.024126912208438912,0.024164159555914395,0.024201406903389875,0.024238654250865358,0.024275901598340838,0.024313148945816317,0.0243503962932918,0.02438764364076728,0.024424890988242763,0.024462138335718243,0.024499385683193722,0.024536633030669205,0.024573880378144685,0.024611127725620168,0.024648375073095648,0.024685622420571127,0.02472286976804661,0.02476011711552209,0.02479736446299757,0.024834611810473053,0.024871859157948532,0.024909106505424015,0.024946353852899495,0.024983601200374975,0.025020848547850458,0.025058095895325937,0.02509534324280142,0.0251325905902769,0.02516983793775238,0.025207085285227863,0.025244332632703342,0.025281579980178825,0.025318827327654305,0.025356074675129785,0.025393322022605268,0.025430569370080747,0.025467816717556227,0.02550506406503171,0.02554231141250719,0.025579558759982673,0.025616806107458152,0.025654053454933632,0.025691300802409115,0.025728548149884595,0.025765795497360078,0.025803042844835557,0.025840290192311037,0.02587753753978652,0.025914784887262,0.025952032234737483,0.025989279582212962,0.026026526929688442,0.026063774277163925,0.026101021624639405,0.026138268972114884,0.026175516319590367,0.026212763667065847,0.02625001101454133,0.02628725836201681,0.026324505709492289,0.026361753056967772,0.026399000404443252,0.026436247751918735,0.026473495099394215,0.026510742446869694,0.026547989794345177,0.026585237141820657,0.02662248448929614,0.02665973183677162,0.026696979184247099,0.026734226531722582,0.026771473879198062,0.026808721226673542,0.026845968574149025,0.026883215921624504,0.026920463269099987,0.026957710616575467,0.026994957964050947,0.02703220531152643,0.027069452659001909,0.027106700006477392,0.027143947353952872,0.027181194701428352,0.027218442048903835,0.027255689396379314,0.027292936743854797,0.027330184091330277,0.027367431438805757,0.02740467878628124,0.027441926133756719,0.027479173481232199,0.027516420828707682,0.027553668176183162,0.027590915523658645,0.027590915523658645,0.027590915523658645,0.027553668176183162,0.027516420828707682,0.027479173481232199,0.027441926133756719,0.02740467878628124,0.027367431438805757,0.027330184091330277,0.027292936743854797,0.027255689396379314,0.027218442048903835,0.027181194701428352,0.027143947353952872,0.027106700006477392,0.027069452659001909,0.02703220531152643,0.026994957964050947,0.026957710616575467,0.026920463269099987,0.026883215921624504,0.026845968574149025,0.026808721226673542,0.026771473879198062,0.026734226531722582,0.026696979184247099,0.02665973183677162,0.02662248448929614,0.026585237141820657,0.026547989794345177,0.026510742446869694,0.026473495099394215,0.026436247751918735,0.026399000404443252,0.026361753056967772,0.026324505709492289,0.02628725836201681,0.02625001101454133,0.026212763667065847,0.026175516319590367,0.026138268972114884,0.026101021624639405,0.026063774277163925,0.026026526929688442,0.025989279582212962,0.025952032234737483,0.025914784887262,0.02587753753978652,0.025840290192311037,0.025803042844835557,0.025765795497360078,0.025728548149884595,0.025691300802409115,0.025654053454933632,0.025616806107458152,0.025579558759982673,0.02554231141250719,0.02550506406503171,0.025467816717556227,0.025430569370080747,0.025393322022605268,0.025356074675129785,0.025318827327654305,0.025281579980178825,0.025244332632703342,0.025207085285227863,0.02516983793775238,0.0251325905902769,0.02509534324280142,0.025058095895325937,0.025020848547850458,0.024983601200374975,0.024946353852899495,0.024909106505424015,0.024871859157948532,0.024834611810473053,0.02479736446299757,0.02476011711552209,0.02472286976804661,0.024685622420571127,0.024648375073095648,0.024611127725620168,0.024573880378144685,0.024536633030669205,0.024499385683193722,0.024462138335718243,0.024424890988242763,0.02438764364076728,0.0243503962932918,0.024313148945816317,0.024275901598340838,0.024238654250865358,0.024201406903389875,0.024164159555914395,0.024126912208438912,0.024089664860963433,0.024052417513487953,0.02401517016601247,0.02397792281853699,0.023940675471061511,0.023903428123586028,0.023866180776110545,0.023828933428635068,0.023791686081159585,0.023754438733684102,0.023717191386208623,0.023679944038733143,0.02364269669125766,0.02360544934378218,0.023568201996306701,0.023530954648831218,0.023493707301355738,0.023456459953880258,0.023419212606404775,0.023381965258929292,0.023344717911453816,0.023307470563978333,0.02327022321650285,0.02323297586902737,0.023195728521551891,0.023158481174076408,0.023121233826600928,0.023083986479125448,0.023046739131649965,0.023009491784174486,0.022972244436699006,0.022934997089223523,0.02289774974174804,0.02286050239427256,0.022823255046797081,0.022786007699321598,0.022748760351846118,0.022711513004370638,0.022674265656895155,0.022637018309419676,0.022599770961944196,0.022562523614468713,0.022525276266993233,0.022488028919517754,0.022450781572042271,0.022413534224566788,0.022376286877091308,0.022339039529615828,0.022301792182140345,0.022264544834664866,0.022227297487189386,0.022190050139713903,0.022152802792238423,0.022115555444762944,0.022078308097287461,0.022041060749811978,0.022003813402336501,0.021966566054861018,0.021929318707385535,0.021892071359910056,0.021854824012434576,0.021817576664959093,0.021780329317483613,0.021743081970008134,0.021705834622532651,0.021668587275057171,0.021631339927581691,0.021594092580106208,0.021556845232630725,0.021519597885155249,0.021482350537679766,0.021445103190204283,0.021407855842728803,0.021370608495253324,0.021333361147777841,0.021296113800302361,0.021258866452826881,0.021221619105351398,0.021184371757875919,0.021147124410400439,0.021109877062924956,0.021072629715449473,0.021035382367973993,0.020998135020498514,0.020960887673023031,0.020923640325547551,0.020886392978072071,0.020849145630596588,0.020811898283121109,0.020774650935645629,0.020737403588170146,0.020700156240694663,0.020662908893219187,0.020625661545743704,0.020588414198268221,0.020551166850792741,0.020513919503317261,0.020476672155841778,0.020439424808366299,0.020402177460890819,0.020364930113415336,0.020327682765939856,0.020290435418464377,0.020253188070988894,0.020215940723513411,0.020178693376037934,0.020141446028562451,0.020104198681086968,0.020066951333611489,0.020029703986136009,0.019992456638660526,0.019955209291185046,0.019917961943709567,0.019880714596234084,0.019843467248758604,0.019806219901283124,0.019768972553807641,0.019731725206332158,0.019694477858856679,0.019657230511381199,0.019619983163905716,0.019582735816430236,0.019545488468954757,0.019508241121479274,0.019470993774003794,0.019433746426528314,0.019396499079052831,0.019359251731577348,0.019322004384101872,0.019284757036626389,0.019247509689150906,0.019210262341675426,0.019173014994199947,0.019135767646724464,0.019098520299248984,0.019061272951773504,0.019024025604298021,0.018986778256822542,0.018949530909347062,0.018912283561871579,0.018875036214396096,0.01883778886692062,0.018800541519445137,0.018763294171969654,0.018726046824494174,0.018688799477018694,0.018651552129543211,0.018614304782067732,0.018577057434592252,0.018539810087116769,0.018502562739641289,0.01846531539216581,0.018428068044690327,0.018390820697214844,0.018353573349739364,0.018316326002263884,0.018279078654788401,0.018241831307312922,0.018204583959837442,0.018167336612361959,0.018130089264886479,0.018092841917411,0.018055594569935517,0.018018347222460034,0.017981099874984557,0.017943852527509074,0.017906605180033591,0.017869357832558112,0.017832110485082632,0.017794863137607149,0.017757615790131669,0.01772036844265619,0.017683121095180707,0.017645873747705227,0.017608626400229747,0.017571379052754264,0.017534131705278781,0.017496884357803305,0.017459637010327822,0.017422389662852339,0.017385142315376859,0.01734789496790138,0.017310647620425897,0.017273400272950417,0.017236152925474937,0.017198905577999454,0.017161658230523975,0.017124410883048495,0.017087163535573012,0.017049916188097529,0.017012668840622049,0.01697542149314657,0.016938174145671087,0.016900926798195607,0.016863679450720127,0.016826432103244644,0.016789184755769165,0.016751937408293685,0.016714690060818202,0.016677442713342719,0.016640195365867243,0.01660294801839176,0.016565700670916277,0.016528453323440797,0.016491205975965317,0.016453958628489834,0.016416711281014355,0.016379463933538875,0.016342216586063392,0.016304969238587912,0.016267721891112433,0.01623047454363695,0.01619322719616147,0.016155979848685987,0.016118732501210507,0.016081485153735024,0.016044237806259545,0.016006990458784065,0.015969743111308582,0.015932495763833102,0.015895248416357623,0.01585800106888214,0.01582075372140666,0.01578350637393118,0.015746259026455697,0.015709011678980214,0.015671764331504735,0.015634516984029255,0.015597269636553774,0.015560022289078292,0.015522774941602813,0.01548552759412733,0.01544828024665185,0.015411032899176369,0.015373785551700887,0.015336538204225408,0.015299290856749925,0.015262043509274445,0.015224796161798964,0.015187548814323482,0.015150301466848003,0.015113054119372521,0.01507580677189704,0.01503855942442156,0.015001312076946077,0.014964064729470598,0.014926817381995116,0.014889570034519635,0.014852322687044155,0.014815075339568672,0.014777827992093193,0.014740580644617711,0.01470333329714223,0.01466608594966675,0.014628838602191267,0.014591591254715788,0.014554343907240306,0.014517096559764825,0.014479849212289345,0.014442601864813864,0.014405354517338383,0.014368107169862903,0.01433085982238742,0.01429361247491194,0.014256365127436459,0.014219117779960978,0.014181870432485498,0.014144623085010015,0.014107375737534535,0.014070128390059054,0.014032881042583573,0.013995633695108093,0.01395838634763261,0.01392113900015713,0.013883891652681649,0.013846644305206168,0.013809396957730688,0.013772149610255207,0.013734902262779725,0.013697654915304246,0.013660407567828763,0.013623160220353283,0.013585912872877802,0.01354866552540232,0.013511418177926841,0.013474170830451358,0.013436923482975878,0.013399676135500397,0.013362428788024915,0.013325181440549436,0.013287934093073953,0.013250686745598473,0.013213439398122992,0.01317619205064751,0.013138944703172031,0.013101697355696549,0.013064450008221068,0.013027202660745588,0.012989955313270105,0.012952707965794626,0.012915460618319144,0.012878213270843663,0.012840965923368183,0.0128037185758927,0.012766471228417221,0.012729223880941739,0.012691976533466258,0.012654729185990778,0.012617481838515295,0.012580234491039816,0.012542987143564334,0.012505739796088853,0.012468492448613373,0.012431245101137892,0.012393997753662411,0.012356750406186929,0.012319503058711448,0.012282255711235968,0.012245008363760487,0.012207761016285006,0.012170513668809526,0.012133266321334043,0.012096018973858563,0.012058771626383082,0.012021524278907601,0.011984276931432121,0.01194702958395664,0.011909782236481158,0.011872534889005677,0.011835287541530196,0.011798040194054716,0.011760792846579235,0.011723545499103753,0.011686298151628272,0.011649050804152791,0.011611803456677311,0.01157455610920183,0.011537308761726348,0.011500061414250869,0.011462814066775387,0.011425566719299906,0.011388319371824425,0.011351072024348943,0.011313824676873464,0.011276577329397982,0.011239329981922501,0.01120208263444702,0.011164835286971538,0.011127587939496059,0.011090340592020577,0.011053093244545096,0.011015845897069615,0.010978598549594133,0.010941351202118654,0.010904103854643172,0.010866856507167691,0.010829609159692211,0.01079236181221673,0.010755114464741249,0.010717867117265767,0.010680619769790286,0.010643372422314806,0.010606125074839325,0.010568877727363844,0.010531630379888362,0.010494383032412881,0.010457135684937401,0.01041988833746192,0.010382640989986439,0.010345393642510957,0.010308146295035476,0.010270898947559996,0.010233651600084515,0.010196404252609034,0.010159156905133552,0.010121909557658073,0.010084662210182591,0.01004741486270711,0.010010167515231629,0.009972920167756149,0.0099356728202806676,0.0098984254728051863,0.0098611781253297049,0.0098239307778542236,0.0097866834303787439,0.0097494360829032626,0.0097121887354277812,0.0096749413879522999,0.0096376940404768185,0.0096004466930013389,0.0095631993455258576,0.0095259519980503762,0.0094887046505748949,0.0094514573030994153,0.0094142099556239339,0.0093769626081484526,0.0093397152606729712,0.0093024679131974916,0.0092652205657220103,0.0092279732182465289,0.0091907258707710476,0.0091534785232955662,0.0091162311758200866,0.0090789838283446053,0.0090417364808691239,0.0090044891333936426,0.0089672417859181629,0.0089299944384426816,0.0088927470909672002,0.0088554997434917189,0.0088182523960162375,0.0087810050485407579,0.0087437577010652766,0.0087065103535897952,0.0086692630061143139,0.0086320156586388343,0.0085947683111633529,0.0085575209636878716,0.0085575209636878716],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.88164668161804816,0.90303938078351886,0.92339569352503603,0.94242260725998139,0.96045263517223145,0.9775514577064921,0.99376227981522081,1.0091322017515238,1.0234932989556342,1.0371620667192121,1.0502038107934033,1.0626701549859265,1.0746109606515153,1.0859397274289591,1.0968611326727586,1.1074041101475742,1.1175901784458282,1.1274340601769108,1.1368364775536266,1.145900870150488,1.1546137453093468,1.1629577785171166,1.1709050054580334,1.1782821068365048,1.1851824239942947,1.1915748909024424,1.197429570601334,1.2027018772311084,1.2071849212833041,1.2110453628866016,1.2142812443328226,1.2168982554455712,1.2188894749413304,1.2201611255360889,1.2209599629096672,1.221364894391207,1.221468050287702,1.2213756664012505,1.2213075325766796,1.2214973894107788,1.2221400458295446,1.2234451427967032,1.2257114994208744,1.2296342685631501,1.2352521558354979,1.2428673817088411,1.2527911949834021,1.265558580079559,1.2823427065397817,1.3027657894639553,1.3271609771489672,1.3558556589085866,1.3895705689285194,1.4297065246112699,1.4753074241726887,1.5265952831709226,1.5837663187307687,1.6475415436162282,1.7190725204552171,1.7968505258510816,1.8808305934878173,1.9709265253729307,2.0675660029013714,2.1711480701044956,2.2799079067469949,2.3934550141602102,2.511358362939248,2.6334689657176877,2.7592038043177909,2.8870611025446355,3.0163822715581943,3.1464901651733332,3.2765548841070671,3.4052627279120133,3.531913329983551,3.6558157873644181,3.7762967179410527,3.8920396307558454,4.0016650399736209,4.105559686859289,4.2032956491879467,4.2944951647497609,4.3778206241840012,4.4525545146361258,4.5200246783127254,4.5802678306928337,4.6333823464744395,4.6785572304468497,4.7161051630486019,4.747759033700552,4.774017294101224,4.7954243937065764,4.8120757320915279,4.8251193150542884,4.8360205931227043,4.8455400313626704,4.854451120076571,4.8638100634079411,4.8749953075054506,4.8887090759267346,4.9056972033106883,4.926686835972462,4.953451918555384,4.9869659422216861,5.0270336482086826,5.0741792056348078,5.1288923206964609,5.1932992514558274,5.2676282684535289,5.3509852607032906,5.443615299021122,5.5457321683719449,5.6595237777820495,5.7845081512598222,5.9194475550519208,6.0643852825756586,6.2193488794202807,6.3864899152713104,6.5648851951345888,6.7532812498884311,6.9516647141169736,7.1600256746394537,7.3806008775488881,7.6123202327086776,7.8541178573181183,8.1060740660642772,8.3682894178546849,8.6434017633862066,8.9303500935520361,9.2283218947905166,9.5376047549942804,9.8585163097369133,10.194536654795233,10.544525301159315,10.907869202810028,11.28509905712767,11.676772736355481,12.087623656781325,12.516048441023514,12.961479304593926,13.424601356848457,13.906106509973375,14.412107562575212,14.939934552518359,15.48885023621639,16.059465764959985,16.652363984600232,17.274629167036316,17.921982550654295,18.593329017366713,19.288907395858036,20.008893281306261,20.760365148579279,21.537380773213432,22.338440272013376,23.163198772330009,24.011235261570285,24.888403891792901,25.787825835496136,26.707763521225566,27.647322611453617,28.605555598994041,29.58622803698594,30.582872836609596,31.593853274534219,32.618036815563656,33.654288553153215,34.704272661390029,35.763241383137554,36.830007990493215,37.903632116393894,38.983220622920719,40.069178097341691,41.158972470204255,42.252037555143112,43.347913648285946,44.446209564756636,45.54719292858244,46.649964627162213,47.754478761809061,48.860731830740946,49.968786676898638,51.079412189274251,52.192203781126942,53.307336037599313,54.42498577155169,55.545398924376528,56.669690706080715,57.797135996020089,58.927835386558456,60.061868319745997,61.199405491660251,62.341388990808632,63.486741893216369,64.635406057744746,65.78731301050334,66.942515159640976,68.101636627984163,69.263681818067226,70.428602371732069,71.596369969809231,72.767133560486954,73.941645555198079,75.11924757889534,76.300123022635518,77.48449033033161,78.672877842490692,79.866697805617619,81.065322392021088,82.269163781011102,83.4786426754644,84.694692232067624,85.919244838298667,87.151045073212984,88.390386700063672,89.637510099740368,90.893283149293183,92.159066650390727,93.432618928835041,94.713590751583283,96.001521289194599,97.296312217983981,98.597275011387282,99.901697740636678,101.20825815808165,102.5155160020126,103.82150083790884,105.12271725725074,106.41738566937154,107.70340987242086,108.97864496104575,110.23894958323338,111.47884036951125,112.6990986454056,113.89763306713812,115.07242769526538,116.21793109609108,117.32896731673193,118.40975359748091,119.45924424362919,120.47658803095896,121.45660473812045,122.39704407667544,123.30497014659088,124.18113723030631,125.02653868873537,125.83851329172118,126.61908095772171,127.37610637568424,128.11211188770972,128.8297862560047,129.53041080910629,130.21925955124439,130.90227362291293,131.58274812459337,132.26396483091565,132.95076901223118,133.64849484263834,134.35897834201813,135.0846267439818,135.82761665188971,136.59371168101578,137.38453798944514,138.19730841130362,139.03194920122982,139.88800908184726,140.76791519648756,141.66760362482938,142.58128230057429,143.50575520807888,144.43746804647313,145.37146238920047,146.29954763479304,147.21615828672034,148.11583639958954,148.99297165992022,149.83360442650468,150.63030065826985,151.38114179954491,152.08054272272136,152.7230714639467,153.28790656634067,153.77403943822659,154.1851392718045,154.51787704644545,154.76932508618904,154.91707012319955,154.96952330759197,154.93544030070694,154.81511958359258,154.60932148235437,154.30003407871874,153.90338154719799,153.43061489626439,152.88534062103955,152.27148195369662,151.57938781715865,150.82738955332081,150.0259767207701,149.18038323945285,148.29590765433002,147.3717356478104,146.42224217406579,145.45477906633991,144.47418871412378,143.48515548496525,142.49315975189532,141.50491070613742,140.52388258091574,139.55313186755413,138.59544870894422,137.65870339241607,136.74189196328985,135.84526551530385,134.96969719934557,134.11580393169112,133.29023686625499,132.4870564579536,131.70458437935827,130.94192271130788,130.19800235426504,129.47594581620646,128.76873002640539,128.07401574750173,127.38995809864588,126.7146521199503,126.04702621590258,125.38230620467104,124.71840048104742,124.05338714278173,123.38538118656462,122.70990629807036,122.0262280246338,121.33294574666192,120.62867798348573,119.91213079186656,119.17695906949473,118.42641138817773,117.65975915441155,116.87632716647649,116.0753620493567,115.25039403635154,114.40683877463522,113.5444368036498,112.66295780806499,111.76182846095271,110.83495628734015,109.88831248397848,108.92172657117423,107.93501591563448,106.92737601569148,105.89270522179559,104.83696975519217,103.75987555113976,102.66111869218118,101.53948818385142,100.3887115086771,99.215029575153295,98.018184395185983,96.797950091084672,95.55293846135794,94.277397834024953,92.978163149038039,91.655389022571924,90.30930609879394,88.938872078274372,87.540089891087106,86.120038912681281,84.67954818223393,83.219531798151607,81.739806941424419,80.239043145341853,78.723509879668683,77.194642201417636,75.653927810549703,74.102283526388874,72.541033678854461,70.974454656826339,69.404245684009709,67.832109143124129,66.259984772186186,64.69102926373148,63.126865043291907,61.56908406630194,60.019246725937883,58.480096734525453,56.955598354939077,55.444815375942547,53.949045576136001,52.469549121485038,51.009737452051517,49.573680318706643,48.158468316150874,46.765128045608996,45.394659514058837,44.051166082653928,42.738497417713376,41.452384079983865,40.1936650792954,38.963157693971169,37.765702876586943,36.604664471396354,35.47478166179787,34.376681718436934,33.310956011020728,32.283014965079126,31.295269039856212,30.341664454342791,29.422452277897392,28.53782287970343,27.693256396061649,26.88964548116282,26.120433842493227,25.385316931455538,24.683915363667502,24.021071931022128,23.395883959533744,22.801836873476667,22.238043527764844,21.703554219546291,21.201959515202432,20.730869556929974,20.284515300317747,19.861622372566544,19.460890745905502,19.084416209808374,18.729152028197635,18.390668397149334,18.067646178287767,17.758785240366294,17.464909857004191,17.183277867710483,16.911041270856526,16.647166776401782,16.390672518729204,16.141670185898835,15.898365868668339,15.659321984468747,15.423970177881936,15.191801890386353,14.962844983762391,14.736342997429842,14.511808507329553,14.289115397422261,14.068182465879529,13.849390397265319,13.63262960954823,13.417830392542022,13.205130887519257,12.994686445371736,12.787329476195739,12.583021758906328,12.381697217624692,12.183526408005122,11.988669927241965,11.798183419527174,11.61166808901905,11.428858674713631,11.249773558394617,11.074404912748088,10.903613439771458,10.736555339498125,10.572766458208443,10.412040118651953,10.254142952711685,10.099338624485275,9.9466161850215542,9.7954471720043763,9.6454560388179971,9.496254941032376,9.3473324114188721,9.1979906606947761,9.0478178143436274,8.8964250968062402,8.7434341319118705,8.587734082018061,8.4293504816171616,8.2681308663818207,8.1038546606746955,7.9363315302823709,7.764347071001219,7.5887203251690805,7.4095996365402055,7.2270442742138359,7.0411496596089238,6.8511932472339332,6.6584122936920274,6.4631786424209423,6.2658075149245489,6.0666385287904614,5.8658363912149465,5.6644018050581897,5.4627780826482475,5.2613912126253783,5.0606694507428154,4.8616755058147829,4.6645993314337408,4.4698121299487754,4.2776751612315591,4.0885507497986922,3.9040287796580371,3.7233538097726262,3.5467408483212344,3.3743822085876287,3.2065192201894477,3.04475195506939,2.8877201526145497,2.7354690751934805,2.588027705862836,2.4455332303069621,2.3093277229567781,2.1778643106613971,0],"text":["density:   2.1778643<br />post_bmi: 0.008557521","density:   2.3093277<br />post_bmi: 0.008594768","density:   2.4455332<br />post_bmi: 0.008632016","density:   2.5880277<br />post_bmi: 0.008669263","density:   2.7354691<br />post_bmi: 0.008706510","density:   2.8877202<br />post_bmi: 0.008743758","density:   3.0447520<br />post_bmi: 0.008781005","density:   3.2065192<br />post_bmi: 0.008818252","density:   3.3743822<br />post_bmi: 0.008855500","density:   3.5467408<br />post_bmi: 0.008892747","density:   3.7233538<br />post_bmi: 0.008929994","density:   3.9040288<br />post_bmi: 0.008967242","density:   4.0885507<br />post_bmi: 0.009004489","density:   4.2776752<br />post_bmi: 0.009041736","density:   4.4698121<br />post_bmi: 0.009078984","density:   4.6645993<br />post_bmi: 0.009116231","density:   4.8616755<br />post_bmi: 0.009153479","density:   5.0606695<br />post_bmi: 0.009190726","density:   5.2613912<br />post_bmi: 0.009227973","density:   5.4627781<br />post_bmi: 0.009265221","density:   5.6644018<br />post_bmi: 0.009302468","density:   5.8658364<br />post_bmi: 0.009339715","density:   6.0666385<br />post_bmi: 0.009376963","density:   6.2658075<br />post_bmi: 0.009414210","density:   6.4631786<br />post_bmi: 0.009451457","density:   6.6584123<br />post_bmi: 0.009488705","density:   6.8511932<br />post_bmi: 0.009525952","density:   7.0411497<br />post_bmi: 0.009563199","density:   7.2270443<br />post_bmi: 0.009600447","density:   7.4095996<br />post_bmi: 0.009637694","density:   7.5887203<br />post_bmi: 0.009674941","density:   7.7643471<br />post_bmi: 0.009712189","density:   7.9363315<br />post_bmi: 0.009749436","density:   8.1038547<br />post_bmi: 0.009786683","density:   8.2681309<br />post_bmi: 0.009823931","density:   8.4293505<br />post_bmi: 0.009861178","density:   8.5877341<br />post_bmi: 0.009898425","density:   8.7434341<br />post_bmi: 0.009935673","density:   8.8964251<br />post_bmi: 0.009972920","density:   9.0478178<br />post_bmi: 0.010010168","density:   9.1979907<br />post_bmi: 0.010047415","density:   9.3473324<br />post_bmi: 0.010084662","density:   9.4962549<br />post_bmi: 0.010121910","density:   9.6454560<br />post_bmi: 0.010159157","density:   9.7954472<br />post_bmi: 0.010196404","density:   9.9466162<br />post_bmi: 0.010233652","density:  10.0993386<br />post_bmi: 0.010270899","density:  10.2541430<br />post_bmi: 0.010308146","density:  10.4120401<br />post_bmi: 0.010345394","density:  10.5727665<br />post_bmi: 0.010382641","density:  10.7365553<br />post_bmi: 0.010419888","density:  10.9036134<br />post_bmi: 0.010457136","density:  11.0744049<br />post_bmi: 0.010494383","density:  11.2497736<br />post_bmi: 0.010531630","density:  11.4288587<br />post_bmi: 0.010568878","density:  11.6116681<br />post_bmi: 0.010606125","density:  11.7981834<br />post_bmi: 0.010643372","density:  11.9886699<br />post_bmi: 0.010680620","density:  12.1835264<br />post_bmi: 0.010717867","density:  12.3816972<br />post_bmi: 0.010755114","density:  12.5830218<br />post_bmi: 0.010792362","density:  12.7873295<br />post_bmi: 0.010829609","density:  12.9946864<br />post_bmi: 0.010866857","density:  13.2051309<br />post_bmi: 0.010904104","density:  13.4178304<br />post_bmi: 0.010941351","density:  13.6326296<br />post_bmi: 0.010978599","density:  13.8493904<br />post_bmi: 0.011015846","density:  14.0681825<br />post_bmi: 0.011053093","density:  14.2891154<br />post_bmi: 0.011090341","density:  14.5118085<br />post_bmi: 0.011127588","density:  14.7363430<br />post_bmi: 0.011164835","density:  14.9628450<br />post_bmi: 0.011202083","density:  15.1918019<br />post_bmi: 0.011239330","density:  15.4239702<br />post_bmi: 0.011276577","density:  15.6593220<br />post_bmi: 0.011313825","density:  15.8983659<br />post_bmi: 0.011351072","density:  16.1416702<br />post_bmi: 0.011388319","density:  16.3906725<br />post_bmi: 0.011425567","density:  16.6471668<br />post_bmi: 0.011462814","density:  16.9110413<br />post_bmi: 0.011500061","density:  17.1832779<br />post_bmi: 0.011537309","density:  17.4649099<br />post_bmi: 0.011574556","density:  17.7587852<br />post_bmi: 0.011611803","density:  18.0676462<br />post_bmi: 0.011649051","density:  18.3906684<br />post_bmi: 0.011686298","density:  18.7291520<br />post_bmi: 0.011723545","density:  19.0844162<br />post_bmi: 0.011760793","density:  19.4608907<br />post_bmi: 0.011798040","density:  19.8616224<br />post_bmi: 0.011835288","density:  20.2845153<br />post_bmi: 0.011872535","density:  20.7308696<br />post_bmi: 0.011909782","density:  21.2019595<br />post_bmi: 0.011947030","density:  21.7035542<br />post_bmi: 0.011984277","density:  22.2380435<br />post_bmi: 0.012021524","density:  22.8018369<br />post_bmi: 0.012058772","density:  23.3958840<br />post_bmi: 0.012096019","density:  24.0210719<br />post_bmi: 0.012133266","density:  24.6839154<br />post_bmi: 0.012170514","density:  25.3853169<br />post_bmi: 0.012207761","density:  26.1204338<br />post_bmi: 0.012245008","density:  26.8896455<br />post_bmi: 0.012282256","density:  27.6932564<br />post_bmi: 0.012319503","density:  28.5378229<br />post_bmi: 0.012356750","density:  29.4224523<br />post_bmi: 0.012393998","density:  30.3416645<br />post_bmi: 0.012431245","density:  31.2952690<br />post_bmi: 0.012468492","density:  32.2830150<br />post_bmi: 0.012505740","density:  33.3109560<br />post_bmi: 0.012542987","density:  34.3766817<br />post_bmi: 0.012580234","density:  35.4747817<br />post_bmi: 0.012617482","density:  36.6046645<br />post_bmi: 0.012654729","density:  37.7657029<br />post_bmi: 0.012691977","density:  38.9631577<br />post_bmi: 0.012729224","density:  40.1936651<br />post_bmi: 0.012766471","density:  41.4523841<br />post_bmi: 0.012803719","density:  42.7384974<br />post_bmi: 0.012840966","density:  44.0511661<br />post_bmi: 0.012878213","density:  45.3946595<br />post_bmi: 0.012915461","density:  46.7651280<br />post_bmi: 0.012952708","density:  48.1584683<br />post_bmi: 0.012989955","density:  49.5736803<br />post_bmi: 0.013027203","density:  51.0097375<br />post_bmi: 0.013064450","density:  52.4695491<br />post_bmi: 0.013101697","density:  53.9490456<br />post_bmi: 0.013138945","density:  55.4448154<br />post_bmi: 0.013176192","density:  56.9555984<br />post_bmi: 0.013213439","density:  58.4800967<br />post_bmi: 0.013250687","density:  60.0192467<br />post_bmi: 0.013287934","density:  61.5690841<br />post_bmi: 0.013325181","density:  63.1268650<br />post_bmi: 0.013362429","density:  64.6910293<br />post_bmi: 0.013399676","density:  66.2599848<br />post_bmi: 0.013436923","density:  67.8321091<br />post_bmi: 0.013474171","density:  69.4042457<br />post_bmi: 0.013511418","density:  70.9744547<br />post_bmi: 0.013548666","density:  72.5410337<br />post_bmi: 0.013585913","density:  74.1022835<br />post_bmi: 0.013623160","density:  75.6539278<br />post_bmi: 0.013660408","density:  77.1946422<br />post_bmi: 0.013697655","density:  78.7235099<br />post_bmi: 0.013734902","density:  80.2390431<br />post_bmi: 0.013772150","density:  81.7398069<br />post_bmi: 0.013809397","density:  83.2195318<br />post_bmi: 0.013846644","density:  84.6795482<br />post_bmi: 0.013883892","density:  86.1200389<br />post_bmi: 0.013921139","density:  87.5400899<br />post_bmi: 0.013958386","density:  88.9388721<br />post_bmi: 0.013995634","density:  90.3093061<br />post_bmi: 0.014032881","density:  91.6553890<br />post_bmi: 0.014070128","density:  92.9781631<br />post_bmi: 0.014107376","density:  94.2773978<br />post_bmi: 0.014144623","density:  95.5529385<br />post_bmi: 0.014181870","density:  96.7979501<br />post_bmi: 0.014219118","density:  98.0181844<br />post_bmi: 0.014256365","density:  99.2150296<br />post_bmi: 0.014293612","density: 100.3887115<br />post_bmi: 0.014330860","density: 101.5394882<br />post_bmi: 0.014368107","density: 102.6611187<br />post_bmi: 0.014405355","density: 103.7598756<br />post_bmi: 0.014442602","density: 104.8369698<br />post_bmi: 0.014479849","density: 105.8927052<br />post_bmi: 0.014517097","density: 106.9273760<br />post_bmi: 0.014554344","density: 107.9350159<br />post_bmi: 0.014591591","density: 108.9217266<br />post_bmi: 0.014628839","density: 109.8883125<br />post_bmi: 0.014666086","density: 110.8349563<br />post_bmi: 0.014703333","density: 111.7618285<br />post_bmi: 0.014740581","density: 112.6629578<br />post_bmi: 0.014777828","density: 113.5444368<br />post_bmi: 0.014815075","density: 114.4068388<br />post_bmi: 0.014852323","density: 115.2503940<br />post_bmi: 0.014889570","density: 116.0753620<br />post_bmi: 0.014926817","density: 116.8763272<br />post_bmi: 0.014964065","density: 117.6597592<br />post_bmi: 0.015001312","density: 118.4264114<br />post_bmi: 0.015038559","density: 119.1769591<br />post_bmi: 0.015075807","density: 119.9121308<br />post_bmi: 0.015113054","density: 120.6286780<br />post_bmi: 0.015150301","density: 121.3329457<br />post_bmi: 0.015187549","density: 122.0262280<br />post_bmi: 0.015224796","density: 122.7099063<br />post_bmi: 0.015262044","density: 123.3853812<br />post_bmi: 0.015299291","density: 124.0533871<br />post_bmi: 0.015336538","density: 124.7184005<br />post_bmi: 0.015373786","density: 125.3823062<br />post_bmi: 0.015411033","density: 126.0470262<br />post_bmi: 0.015448280","density: 126.7146521<br />post_bmi: 0.015485528","density: 127.3899581<br />post_bmi: 0.015522775","density: 128.0740157<br />post_bmi: 0.015560022","density: 128.7687300<br />post_bmi: 0.015597270","density: 129.4759458<br />post_bmi: 0.015634517","density: 130.1980024<br />post_bmi: 0.015671764","density: 130.9419227<br />post_bmi: 0.015709012","density: 131.7045844<br />post_bmi: 0.015746259","density: 132.4870565<br />post_bmi: 0.015783506","density: 133.2902369<br />post_bmi: 0.015820754","density: 134.1158039<br />post_bmi: 0.015858001","density: 134.9696972<br />post_bmi: 0.015895248","density: 135.8452655<br />post_bmi: 0.015932496","density: 136.7418920<br />post_bmi: 0.015969743","density: 137.6587034<br />post_bmi: 0.016006990","density: 138.5954487<br />post_bmi: 0.016044238","density: 139.5531319<br />post_bmi: 0.016081485","density: 140.5238826<br />post_bmi: 0.016118733","density: 141.5049107<br />post_bmi: 0.016155980","density: 142.4931598<br />post_bmi: 0.016193227","density: 143.4851555<br />post_bmi: 0.016230475","density: 144.4741887<br />post_bmi: 0.016267722","density: 145.4547791<br />post_bmi: 0.016304969","density: 146.4222422<br />post_bmi: 0.016342217","density: 147.3717356<br />post_bmi: 0.016379464","density: 148.2959077<br />post_bmi: 0.016416711","density: 149.1803832<br />post_bmi: 0.016453959","density: 150.0259767<br />post_bmi: 0.016491206","density: 150.8273896<br />post_bmi: 0.016528453","density: 151.5793878<br />post_bmi: 0.016565701","density: 152.2714820<br />post_bmi: 0.016602948","density: 152.8853406<br />post_bmi: 0.016640195","density: 153.4306149<br />post_bmi: 0.016677443","density: 153.9033815<br />post_bmi: 0.016714690","density: 154.3000341<br />post_bmi: 0.016751937","density: 154.6093215<br />post_bmi: 0.016789185","density: 154.8151196<br />post_bmi: 0.016826432","density: 154.9354403<br />post_bmi: 0.016863679","density: 154.9695233<br />post_bmi: 0.016900927","density: 154.9170701<br />post_bmi: 0.016938174","density: 154.7693251<br />post_bmi: 0.016975421","density: 154.5178770<br />post_bmi: 0.017012669","density: 154.1851393<br />post_bmi: 0.017049916","density: 153.7740394<br />post_bmi: 0.017087164","density: 153.2879066<br />post_bmi: 0.017124411","density: 152.7230715<br />post_bmi: 0.017161658","density: 152.0805427<br />post_bmi: 0.017198906","density: 151.3811418<br />post_bmi: 0.017236153","density: 150.6303007<br />post_bmi: 0.017273400","density: 149.8336044<br />post_bmi: 0.017310648","density: 148.9929717<br />post_bmi: 0.017347895","density: 148.1158364<br />post_bmi: 0.017385142","density: 147.2161583<br />post_bmi: 0.017422390","density: 146.2995476<br />post_bmi: 0.017459637","density: 145.3714624<br />post_bmi: 0.017496884","density: 144.4374680<br />post_bmi: 0.017534132","density: 143.5057552<br />post_bmi: 0.017571379","density: 142.5812823<br />post_bmi: 0.017608626","density: 141.6676036<br />post_bmi: 0.017645874","density: 140.7679152<br />post_bmi: 0.017683121","density: 139.8880091<br />post_bmi: 0.017720368","density: 139.0319492<br />post_bmi: 0.017757616","density: 138.1973084<br />post_bmi: 0.017794863","density: 137.3845380<br />post_bmi: 0.017832110","density: 136.5937117<br />post_bmi: 0.017869358","density: 135.8276167<br />post_bmi: 0.017906605","density: 135.0846267<br />post_bmi: 0.017943853","density: 134.3589783<br />post_bmi: 0.017981100","density: 133.6484948<br />post_bmi: 0.018018347","density: 132.9507690<br />post_bmi: 0.018055595","density: 132.2639648<br />post_bmi: 0.018092842","density: 131.5827481<br />post_bmi: 0.018130089","density: 130.9022736<br />post_bmi: 0.018167337","density: 130.2192596<br />post_bmi: 0.018204584","density: 129.5304108<br />post_bmi: 0.018241831","density: 128.8297863<br />post_bmi: 0.018279079","density: 128.1121119<br />post_bmi: 0.018316326","density: 127.3761064<br />post_bmi: 0.018353573","density: 126.6190810<br />post_bmi: 0.018390821","density: 125.8385133<br />post_bmi: 0.018428068","density: 125.0265387<br />post_bmi: 0.018465315","density: 124.1811372<br />post_bmi: 0.018502563","density: 123.3049701<br />post_bmi: 0.018539810","density: 122.3970441<br />post_bmi: 0.018577057","density: 121.4566047<br />post_bmi: 0.018614305","density: 120.4765880<br />post_bmi: 0.018651552","density: 119.4592442<br />post_bmi: 0.018688799","density: 118.4097536<br />post_bmi: 0.018726047","density: 117.3289673<br />post_bmi: 0.018763294","density: 116.2179311<br />post_bmi: 0.018800542","density: 115.0724277<br />post_bmi: 0.018837789","density: 113.8976331<br />post_bmi: 0.018875036","density: 112.6990986<br />post_bmi: 0.018912284","density: 111.4788404<br />post_bmi: 0.018949531","density: 110.2389496<br />post_bmi: 0.018986778","density: 108.9786450<br />post_bmi: 0.019024026","density: 107.7034099<br />post_bmi: 0.019061273","density: 106.4173857<br />post_bmi: 0.019098520","density: 105.1227173<br />post_bmi: 0.019135768","density: 103.8215008<br />post_bmi: 0.019173015","density: 102.5155160<br />post_bmi: 0.019210262","density: 101.2082582<br />post_bmi: 0.019247510","density:  99.9016977<br />post_bmi: 0.019284757","density:  98.5972750<br />post_bmi: 0.019322004","density:  97.2963122<br />post_bmi: 0.019359252","density:  96.0015213<br />post_bmi: 0.019396499","density:  94.7135908<br />post_bmi: 0.019433746","density:  93.4326189<br />post_bmi: 0.019470994","density:  92.1590667<br />post_bmi: 0.019508241","density:  90.8932831<br />post_bmi: 0.019545488","density:  89.6375101<br />post_bmi: 0.019582736","density:  88.3903867<br />post_bmi: 0.019619983","density:  87.1510451<br />post_bmi: 0.019657231","density:  85.9192448<br />post_bmi: 0.019694478","density:  84.6946922<br />post_bmi: 0.019731725","density:  83.4786427<br />post_bmi: 0.019768973","density:  82.2691638<br />post_bmi: 0.019806220","density:  81.0653224<br />post_bmi: 0.019843467","density:  79.8666978<br />post_bmi: 0.019880715","density:  78.6728778<br />post_bmi: 0.019917962","density:  77.4844903<br />post_bmi: 0.019955209","density:  76.3001230<br />post_bmi: 0.019992457","density:  75.1192476<br />post_bmi: 0.020029704","density:  73.9416456<br />post_bmi: 0.020066951","density:  72.7671336<br />post_bmi: 0.020104199","density:  71.5963700<br />post_bmi: 0.020141446","density:  70.4286024<br />post_bmi: 0.020178693","density:  69.2636818<br />post_bmi: 0.020215941","density:  68.1016366<br />post_bmi: 0.020253188","density:  66.9425152<br />post_bmi: 0.020290435","density:  65.7873130<br />post_bmi: 0.020327683","density:  64.6354061<br />post_bmi: 0.020364930","density:  63.4867419<br />post_bmi: 0.020402177","density:  62.3413890<br />post_bmi: 0.020439425","density:  61.1994055<br />post_bmi: 0.020476672","density:  60.0618683<br />post_bmi: 0.020513920","density:  58.9278354<br />post_bmi: 0.020551167","density:  57.7971360<br />post_bmi: 0.020588414","density:  56.6696907<br />post_bmi: 0.020625662","density:  55.5453989<br />post_bmi: 0.020662909","density:  54.4249858<br />post_bmi: 0.020700156","density:  53.3073360<br />post_bmi: 0.020737404","density:  52.1922038<br />post_bmi: 0.020774651","density:  51.0794122<br />post_bmi: 0.020811898","density:  49.9687867<br />post_bmi: 0.020849146","density:  48.8607318<br />post_bmi: 0.020886393","density:  47.7544788<br />post_bmi: 0.020923640","density:  46.6499646<br />post_bmi: 0.020960888","density:  45.5471929<br />post_bmi: 0.020998135","density:  44.4462096<br />post_bmi: 0.021035382","density:  43.3479136<br />post_bmi: 0.021072630","density:  42.2520376<br />post_bmi: 0.021109877","density:  41.1589725<br />post_bmi: 0.021147124","density:  40.0691781<br />post_bmi: 0.021184372","density:  38.9832206<br />post_bmi: 0.021221619","density:  37.9036321<br />post_bmi: 0.021258866","density:  36.8300080<br />post_bmi: 0.021296114","density:  35.7632414<br />post_bmi: 0.021333361","density:  34.7042727<br />post_bmi: 0.021370608","density:  33.6542886<br />post_bmi: 0.021407856","density:  32.6180368<br />post_bmi: 0.021445103","density:  31.5938533<br />post_bmi: 0.021482351","density:  30.5828728<br />post_bmi: 0.021519598","density:  29.5862280<br />post_bmi: 0.021556845","density:  28.6055556<br />post_bmi: 0.021594093","density:  27.6473226<br />post_bmi: 0.021631340","density:  26.7077635<br />post_bmi: 0.021668587","density:  25.7878258<br />post_bmi: 0.021705835","density:  24.8884039<br />post_bmi: 0.021743082","density:  24.0112353<br />post_bmi: 0.021780329","density:  23.1631988<br />post_bmi: 0.021817577","density:  22.3384403<br />post_bmi: 0.021854824","density:  21.5373808<br />post_bmi: 0.021892071","density:  20.7603651<br />post_bmi: 0.021929319","density:  20.0088933<br />post_bmi: 0.021966566","density:  19.2889074<br />post_bmi: 0.022003813","density:  18.5933290<br />post_bmi: 0.022041061","density:  17.9219826<br />post_bmi: 0.022078308","density:  17.2746292<br />post_bmi: 0.022115555","density:  16.6523640<br />post_bmi: 0.022152803","density:  16.0594658<br />post_bmi: 0.022190050","density:  15.4888502<br />post_bmi: 0.022227297","density:  14.9399346<br />post_bmi: 0.022264545","density:  14.4121076<br />post_bmi: 0.022301792","density:  13.9061065<br />post_bmi: 0.022339040","density:  13.4246014<br />post_bmi: 0.022376287","density:  12.9614793<br />post_bmi: 0.022413534","density:  12.5160484<br />post_bmi: 0.022450782","density:  12.0876237<br />post_bmi: 0.022488029","density:  11.6767727<br />post_bmi: 0.022525276","density:  11.2850991<br />post_bmi: 0.022562524","density:  10.9078692<br />post_bmi: 0.022599771","density:  10.5445253<br />post_bmi: 0.022637018","density:  10.1945367<br />post_bmi: 0.022674266","density:   9.8585163<br />post_bmi: 0.022711513","density:   9.5376048<br />post_bmi: 0.022748760","density:   9.2283219<br />post_bmi: 0.022786008","density:   8.9303501<br />post_bmi: 0.022823255","density:   8.6434018<br />post_bmi: 0.022860502","density:   8.3682894<br />post_bmi: 0.022897750","density:   8.1060741<br />post_bmi: 0.022934997","density:   7.8541179<br />post_bmi: 0.022972244","density:   7.6123202<br />post_bmi: 0.023009492","density:   7.3806009<br />post_bmi: 0.023046739","density:   7.1600257<br />post_bmi: 0.023083986","density:   6.9516647<br />post_bmi: 0.023121234","density:   6.7532812<br />post_bmi: 0.023158481","density:   6.5648852<br />post_bmi: 0.023195729","density:   6.3864899<br />post_bmi: 0.023232976","density:   6.2193489<br />post_bmi: 0.023270223","density:   6.0643853<br />post_bmi: 0.023307471","density:   5.9194476<br />post_bmi: 0.023344718","density:   5.7845082<br />post_bmi: 0.023381965","density:   5.6595238<br />post_bmi: 0.023419213","density:   5.5457322<br />post_bmi: 0.023456460","density:   5.4436153<br />post_bmi: 0.023493707","density:   5.3509853<br />post_bmi: 0.023530955","density:   5.2676283<br />post_bmi: 0.023568202","density:   5.1932993<br />post_bmi: 0.023605449","density:   5.1288923<br />post_bmi: 0.023642697","density:   5.0741792<br />post_bmi: 0.023679944","density:   5.0270336<br />post_bmi: 0.023717191","density:   4.9869659<br />post_bmi: 0.023754439","density:   4.9534519<br />post_bmi: 0.023791686","density:   4.9266868<br />post_bmi: 0.023828933","density:   4.9056972<br />post_bmi: 0.023866181","density:   4.8887091<br />post_bmi: 0.023903428","density:   4.8749953<br />post_bmi: 0.023940675","density:   4.8638101<br />post_bmi: 0.023977923","density:   4.8544511<br />post_bmi: 0.024015170","density:   4.8455400<br />post_bmi: 0.024052418","density:   4.8360206<br />post_bmi: 0.024089665","density:   4.8251193<br />post_bmi: 0.024126912","density:   4.8120757<br />post_bmi: 0.024164160","density:   4.7954244<br />post_bmi: 0.024201407","density:   4.7740173<br />post_bmi: 0.024238654","density:   4.7477590<br />post_bmi: 0.024275902","density:   4.7161052<br />post_bmi: 0.024313149","density:   4.6785572<br />post_bmi: 0.024350396","density:   4.6333823<br />post_bmi: 0.024387644","density:   4.5802678<br />post_bmi: 0.024424891","density:   4.5200247<br />post_bmi: 0.024462138","density:   4.4525545<br />post_bmi: 0.024499386","density:   4.3778206<br />post_bmi: 0.024536633","density:   4.2944952<br />post_bmi: 0.024573880","density:   4.2032956<br />post_bmi: 0.024611128","density:   4.1055597<br />post_bmi: 0.024648375","density:   4.0016650<br />post_bmi: 0.024685622","density:   3.8920396<br />post_bmi: 0.024722870","density:   3.7762967<br />post_bmi: 0.024760117","density:   3.6558158<br />post_bmi: 0.024797364","density:   3.5319133<br />post_bmi: 0.024834612","density:   3.4052627<br />post_bmi: 0.024871859","density:   3.2765549<br />post_bmi: 0.024909107","density:   3.1464902<br />post_bmi: 0.024946354","density:   3.0163823<br />post_bmi: 0.024983601","density:   2.8870611<br />post_bmi: 0.025020849","density:   2.7592038<br />post_bmi: 0.025058096","density:   2.6334690<br />post_bmi: 0.025095343","density:   2.5113584<br />post_bmi: 0.025132591","density:   2.3934550<br />post_bmi: 0.025169838","density:   2.2799079<br />post_bmi: 0.025207085","density:   2.1711481<br />post_bmi: 0.025244333","density:   2.0675660<br />post_bmi: 0.025281580","density:   1.9709265<br />post_bmi: 0.025318827","density:   1.8808306<br />post_bmi: 0.025356075","density:   1.7968505<br />post_bmi: 0.025393322","density:   1.7190725<br />post_bmi: 0.025430569","density:   1.6475415<br />post_bmi: 0.025467817","density:   1.5837663<br />post_bmi: 0.025505064","density:   1.5265953<br />post_bmi: 0.025542311","density:   1.4753074<br />post_bmi: 0.025579559","density:   1.4297065<br />post_bmi: 0.025616806","density:   1.3895706<br />post_bmi: 0.025654053","density:   1.3558557<br />post_bmi: 0.025691301","density:   1.3271610<br />post_bmi: 0.025728548","density:   1.3027658<br />post_bmi: 0.025765795","density:   1.2823427<br />post_bmi: 0.025803043","density:   1.2655586<br />post_bmi: 0.025840290","density:   1.2527912<br />post_bmi: 0.025877538","density:   1.2428674<br />post_bmi: 0.025914785","density:   1.2352522<br />post_bmi: 0.025952032","density:   1.2296343<br />post_bmi: 0.025989280","density:   1.2257115<br />post_bmi: 0.026026527","density:   1.2234451<br />post_bmi: 0.026063774","density:   1.2221400<br />post_bmi: 0.026101022","density:   1.2214974<br />post_bmi: 0.026138269","density:   1.2213075<br />post_bmi: 0.026175516","density:   1.2213757<br />post_bmi: 0.026212764","density:   1.2214681<br />post_bmi: 0.026250011","density:   1.2213649<br />post_bmi: 0.026287258","density:   1.2209600<br />post_bmi: 0.026324506","density:   1.2201611<br />post_bmi: 0.026361753","density:   1.2188895<br />post_bmi: 0.026399000","density:   1.2168983<br />post_bmi: 0.026436248","density:   1.2142812<br />post_bmi: 0.026473495","density:   1.2110454<br />post_bmi: 0.026510742","density:   1.2071849<br />post_bmi: 0.026547990","density:   1.2027019<br />post_bmi: 0.026585237","density:   1.1974296<br />post_bmi: 0.026622484","density:   1.1915749<br />post_bmi: 0.026659732","density:   1.1851824<br />post_bmi: 0.026696979","density:   1.1782821<br />post_bmi: 0.026734227","density:   1.1709050<br />post_bmi: 0.026771474","density:   1.1629578<br />post_bmi: 0.026808721","density:   1.1546137<br />post_bmi: 0.026845969","density:   1.1459009<br />post_bmi: 0.026883216","density:   1.1368365<br />post_bmi: 0.026920463","density:   1.1274341<br />post_bmi: 0.026957711","density:   1.1175902<br />post_bmi: 0.026994958","density:   1.1074041<br />post_bmi: 0.027032205","density:   1.0968611<br />post_bmi: 0.027069453","density:   1.0859397<br />post_bmi: 0.027106700","density:   1.0746110<br />post_bmi: 0.027143947","density:   1.0626702<br />post_bmi: 0.027181195","density:   1.0502038<br />post_bmi: 0.027218442","density:   1.0371621<br />post_bmi: 0.027255689","density:   1.0234933<br />post_bmi: 0.027292937","density:   1.0091322<br />post_bmi: 0.027330184","density:   0.9937623<br />post_bmi: 0.027367431","density:   0.9775515<br />post_bmi: 0.027404679","density:   0.9604526<br />post_bmi: 0.027441926","density:   0.9424226<br />post_bmi: 0.027479173","density:   0.9233957<br />post_bmi: 0.027516421","density:   0.9030394<br />post_bmi: 0.027553668","density:   0.8816467<br />post_bmi: 0.027590916","density:   0.8816467<br />post_bmi: 0.027590916","density:   0.8816467<br />post_bmi: 0.027590916","density:   0.9030394<br />post_bmi: 0.027553668","density:   0.9233957<br />post_bmi: 0.027516421","density:   0.9424226<br />post_bmi: 0.027479173","density:   0.9604526<br />post_bmi: 0.027441926","density:   0.9775515<br />post_bmi: 0.027404679","density:   0.9937623<br />post_bmi: 0.027367431","density:   1.0091322<br />post_bmi: 0.027330184","density:   1.0234933<br />post_bmi: 0.027292937","density:   1.0371621<br />post_bmi: 0.027255689","density:   1.0502038<br />post_bmi: 0.027218442","density:   1.0626702<br />post_bmi: 0.027181195","density:   1.0746110<br />post_bmi: 0.027143947","density:   1.0859397<br />post_bmi: 0.027106700","density:   1.0968611<br />post_bmi: 0.027069453","density:   1.1074041<br />post_bmi: 0.027032205","density:   1.1175902<br />post_bmi: 0.026994958","density:   1.1274341<br />post_bmi: 0.026957711","density:   1.1368365<br />post_bmi: 0.026920463","density:   1.1459009<br />post_bmi: 0.026883216","density:   1.1546137<br />post_bmi: 0.026845969","density:   1.1629578<br />post_bmi: 0.026808721","density:   1.1709050<br />post_bmi: 0.026771474","density:   1.1782821<br />post_bmi: 0.026734227","density:   1.1851824<br />post_bmi: 0.026696979","density:   1.1915749<br />post_bmi: 0.026659732","density:   1.1974296<br />post_bmi: 0.026622484","density:   1.2027019<br />post_bmi: 0.026585237","density:   1.2071849<br />post_bmi: 0.026547990","density:   1.2110454<br />post_bmi: 0.026510742","density:   1.2142812<br />post_bmi: 0.026473495","density:   1.2168983<br />post_bmi: 0.026436248","density:   1.2188895<br />post_bmi: 0.026399000","density:   1.2201611<br />post_bmi: 0.026361753","density:   1.2209600<br />post_bmi: 0.026324506","density:   1.2213649<br />post_bmi: 0.026287258","density:   1.2214681<br />post_bmi: 0.026250011","density:   1.2213757<br />post_bmi: 0.026212764","density:   1.2213075<br />post_bmi: 0.026175516","density:   1.2214974<br />post_bmi: 0.026138269","density:   1.2221400<br />post_bmi: 0.026101022","density:   1.2234451<br />post_bmi: 0.026063774","density:   1.2257115<br />post_bmi: 0.026026527","density:   1.2296343<br />post_bmi: 0.025989280","density:   1.2352522<br />post_bmi: 0.025952032","density:   1.2428674<br />post_bmi: 0.025914785","density:   1.2527912<br />post_bmi: 0.025877538","density:   1.2655586<br />post_bmi: 0.025840290","density:   1.2823427<br />post_bmi: 0.025803043","density:   1.3027658<br />post_bmi: 0.025765795","density:   1.3271610<br />post_bmi: 0.025728548","density:   1.3558557<br />post_bmi: 0.025691301","density:   1.3895706<br />post_bmi: 0.025654053","density:   1.4297065<br />post_bmi: 0.025616806","density:   1.4753074<br />post_bmi: 0.025579559","density:   1.5265953<br />post_bmi: 0.025542311","density:   1.5837663<br />post_bmi: 0.025505064","density:   1.6475415<br />post_bmi: 0.025467817","density:   1.7190725<br />post_bmi: 0.025430569","density:   1.7968505<br />post_bmi: 0.025393322","density:   1.8808306<br />post_bmi: 0.025356075","density:   1.9709265<br />post_bmi: 0.025318827","density:   2.0675660<br />post_bmi: 0.025281580","density:   2.1711481<br />post_bmi: 0.025244333","density:   2.2799079<br />post_bmi: 0.025207085","density:   2.3934550<br />post_bmi: 0.025169838","density:   2.5113584<br />post_bmi: 0.025132591","density:   2.6334690<br />post_bmi: 0.025095343","density:   2.7592038<br />post_bmi: 0.025058096","density:   2.8870611<br />post_bmi: 0.025020849","density:   3.0163823<br />post_bmi: 0.024983601","density:   3.1464902<br />post_bmi: 0.024946354","density:   3.2765549<br />post_bmi: 0.024909107","density:   3.4052627<br />post_bmi: 0.024871859","density:   3.5319133<br />post_bmi: 0.024834612","density:   3.6558158<br />post_bmi: 0.024797364","density:   3.7762967<br />post_bmi: 0.024760117","density:   3.8920396<br />post_bmi: 0.024722870","density:   4.0016650<br />post_bmi: 0.024685622","density:   4.1055597<br />post_bmi: 0.024648375","density:   4.2032956<br />post_bmi: 0.024611128","density:   4.2944952<br />post_bmi: 0.024573880","density:   4.3778206<br />post_bmi: 0.024536633","density:   4.4525545<br />post_bmi: 0.024499386","density:   4.5200247<br />post_bmi: 0.024462138","density:   4.5802678<br />post_bmi: 0.024424891","density:   4.6333823<br />post_bmi: 0.024387644","density:   4.6785572<br />post_bmi: 0.024350396","density:   4.7161052<br />post_bmi: 0.024313149","density:   4.7477590<br />post_bmi: 0.024275902","density:   4.7740173<br />post_bmi: 0.024238654","density:   4.7954244<br />post_bmi: 0.024201407","density:   4.8120757<br />post_bmi: 0.024164160","density:   4.8251193<br />post_bmi: 0.024126912","density:   4.8360206<br />post_bmi: 0.024089665","density:   4.8455400<br />post_bmi: 0.024052418","density:   4.8544511<br />post_bmi: 0.024015170","density:   4.8638101<br />post_bmi: 0.023977923","density:   4.8749953<br />post_bmi: 0.023940675","density:   4.8887091<br />post_bmi: 0.023903428","density:   4.9056972<br />post_bmi: 0.023866181","density:   4.9266868<br />post_bmi: 0.023828933","density:   4.9534519<br />post_bmi: 0.023791686","density:   4.9869659<br />post_bmi: 0.023754439","density:   5.0270336<br />post_bmi: 0.023717191","density:   5.0741792<br />post_bmi: 0.023679944","density:   5.1288923<br />post_bmi: 0.023642697","density:   5.1932993<br />post_bmi: 0.023605449","density:   5.2676283<br />post_bmi: 0.023568202","density:   5.3509853<br />post_bmi: 0.023530955","density:   5.4436153<br />post_bmi: 0.023493707","density:   5.5457322<br />post_bmi: 0.023456460","density:   5.6595238<br />post_bmi: 0.023419213","density:   5.7845082<br />post_bmi: 0.023381965","density:   5.9194476<br />post_bmi: 0.023344718","density:   6.0643853<br />post_bmi: 0.023307471","density:   6.2193489<br />post_bmi: 0.023270223","density:   6.3864899<br />post_bmi: 0.023232976","density:   6.5648852<br />post_bmi: 0.023195729","density:   6.7532812<br />post_bmi: 0.023158481","density:   6.9516647<br />post_bmi: 0.023121234","density:   7.1600257<br />post_bmi: 0.023083986","density:   7.3806009<br />post_bmi: 0.023046739","density:   7.6123202<br />post_bmi: 0.023009492","density:   7.8541179<br />post_bmi: 0.022972244","density:   8.1060741<br />post_bmi: 0.022934997","density:   8.3682894<br />post_bmi: 0.022897750","density:   8.6434018<br />post_bmi: 0.022860502","density:   8.9303501<br />post_bmi: 0.022823255","density:   9.2283219<br />post_bmi: 0.022786008","density:   9.5376048<br />post_bmi: 0.022748760","density:   9.8585163<br />post_bmi: 0.022711513","density:  10.1945367<br />post_bmi: 0.022674266","density:  10.5445253<br />post_bmi: 0.022637018","density:  10.9078692<br />post_bmi: 0.022599771","density:  11.2850991<br />post_bmi: 0.022562524","density:  11.6767727<br />post_bmi: 0.022525276","density:  12.0876237<br />post_bmi: 0.022488029","density:  12.5160484<br />post_bmi: 0.022450782","density:  12.9614793<br />post_bmi: 0.022413534","density:  13.4246014<br />post_bmi: 0.022376287","density:  13.9061065<br />post_bmi: 0.022339040","density:  14.4121076<br />post_bmi: 0.022301792","density:  14.9399346<br />post_bmi: 0.022264545","density:  15.4888502<br />post_bmi: 0.022227297","density:  16.0594658<br />post_bmi: 0.022190050","density:  16.6523640<br />post_bmi: 0.022152803","density:  17.2746292<br />post_bmi: 0.022115555","density:  17.9219826<br />post_bmi: 0.022078308","density:  18.5933290<br />post_bmi: 0.022041061","density:  19.2889074<br />post_bmi: 0.022003813","density:  20.0088933<br />post_bmi: 0.021966566","density:  20.7603651<br />post_bmi: 0.021929319","density:  21.5373808<br />post_bmi: 0.021892071","density:  22.3384403<br />post_bmi: 0.021854824","density:  23.1631988<br />post_bmi: 0.021817577","density:  24.0112353<br />post_bmi: 0.021780329","density:  24.8884039<br />post_bmi: 0.021743082","density:  25.7878258<br />post_bmi: 0.021705835","density:  26.7077635<br />post_bmi: 0.021668587","density:  27.6473226<br />post_bmi: 0.021631340","density:  28.6055556<br />post_bmi: 0.021594093","density:  29.5862280<br />post_bmi: 0.021556845","density:  30.5828728<br />post_bmi: 0.021519598","density:  31.5938533<br />post_bmi: 0.021482351","density:  32.6180368<br />post_bmi: 0.021445103","density:  33.6542886<br />post_bmi: 0.021407856","density:  34.7042727<br />post_bmi: 0.021370608","density:  35.7632414<br />post_bmi: 0.021333361","density:  36.8300080<br />post_bmi: 0.021296114","density:  37.9036321<br />post_bmi: 0.021258866","density:  38.9832206<br />post_bmi: 0.021221619","density:  40.0691781<br />post_bmi: 0.021184372","density:  41.1589725<br />post_bmi: 0.021147124","density:  42.2520376<br />post_bmi: 0.021109877","density:  43.3479136<br />post_bmi: 0.021072630","density:  44.4462096<br />post_bmi: 0.021035382","density:  45.5471929<br />post_bmi: 0.020998135","density:  46.6499646<br />post_bmi: 0.020960888","density:  47.7544788<br />post_bmi: 0.020923640","density:  48.8607318<br />post_bmi: 0.020886393","density:  49.9687867<br />post_bmi: 0.020849146","density:  51.0794122<br />post_bmi: 0.020811898","density:  52.1922038<br />post_bmi: 0.020774651","density:  53.3073360<br />post_bmi: 0.020737404","density:  54.4249858<br />post_bmi: 0.020700156","density:  55.5453989<br />post_bmi: 0.020662909","density:  56.6696907<br />post_bmi: 0.020625662","density:  57.7971360<br />post_bmi: 0.020588414","density:  58.9278354<br />post_bmi: 0.020551167","density:  60.0618683<br />post_bmi: 0.020513920","density:  61.1994055<br />post_bmi: 0.020476672","density:  62.3413890<br />post_bmi: 0.020439425","density:  63.4867419<br />post_bmi: 0.020402177","density:  64.6354061<br />post_bmi: 0.020364930","density:  65.7873130<br />post_bmi: 0.020327683","density:  66.9425152<br />post_bmi: 0.020290435","density:  68.1016366<br />post_bmi: 0.020253188","density:  69.2636818<br />post_bmi: 0.020215941","density:  70.4286024<br />post_bmi: 0.020178693","density:  71.5963700<br />post_bmi: 0.020141446","density:  72.7671336<br />post_bmi: 0.020104199","density:  73.9416456<br />post_bmi: 0.020066951","density:  75.1192476<br />post_bmi: 0.020029704","density:  76.3001230<br />post_bmi: 0.019992457","density:  77.4844903<br />post_bmi: 0.019955209","density:  78.6728778<br />post_bmi: 0.019917962","density:  79.8666978<br />post_bmi: 0.019880715","density:  81.0653224<br />post_bmi: 0.019843467","density:  82.2691638<br />post_bmi: 0.019806220","density:  83.4786427<br />post_bmi: 0.019768973","density:  84.6946922<br />post_bmi: 0.019731725","density:  85.9192448<br />post_bmi: 0.019694478","density:  87.1510451<br />post_bmi: 0.019657231","density:  88.3903867<br />post_bmi: 0.019619983","density:  89.6375101<br />post_bmi: 0.019582736","density:  90.8932831<br />post_bmi: 0.019545488","density:  92.1590667<br />post_bmi: 0.019508241","density:  93.4326189<br />post_bmi: 0.019470994","density:  94.7135908<br />post_bmi: 0.019433746","density:  96.0015213<br />post_bmi: 0.019396499","density:  97.2963122<br />post_bmi: 0.019359252","density:  98.5972750<br />post_bmi: 0.019322004","density:  99.9016977<br />post_bmi: 0.019284757","density: 101.2082582<br />post_bmi: 0.019247510","density: 102.5155160<br />post_bmi: 0.019210262","density: 103.8215008<br />post_bmi: 0.019173015","density: 105.1227173<br />post_bmi: 0.019135768","density: 106.4173857<br />post_bmi: 0.019098520","density: 107.7034099<br />post_bmi: 0.019061273","density: 108.9786450<br />post_bmi: 0.019024026","density: 110.2389496<br />post_bmi: 0.018986778","density: 111.4788404<br />post_bmi: 0.018949531","density: 112.6990986<br />post_bmi: 0.018912284","density: 113.8976331<br />post_bmi: 0.018875036","density: 115.0724277<br />post_bmi: 0.018837789","density: 116.2179311<br />post_bmi: 0.018800542","density: 117.3289673<br />post_bmi: 0.018763294","density: 118.4097536<br />post_bmi: 0.018726047","density: 119.4592442<br />post_bmi: 0.018688799","density: 120.4765880<br />post_bmi: 0.018651552","density: 121.4566047<br />post_bmi: 0.018614305","density: 122.3970441<br />post_bmi: 0.018577057","density: 123.3049701<br />post_bmi: 0.018539810","density: 124.1811372<br />post_bmi: 0.018502563","density: 125.0265387<br />post_bmi: 0.018465315","density: 125.8385133<br />post_bmi: 0.018428068","density: 126.6190810<br />post_bmi: 0.018390821","density: 127.3761064<br />post_bmi: 0.018353573","density: 128.1121119<br />post_bmi: 0.018316326","density: 128.8297863<br />post_bmi: 0.018279079","density: 129.5304108<br />post_bmi: 0.018241831","density: 130.2192596<br />post_bmi: 0.018204584","density: 130.9022736<br />post_bmi: 0.018167337","density: 131.5827481<br />post_bmi: 0.018130089","density: 132.2639648<br />post_bmi: 0.018092842","density: 132.9507690<br />post_bmi: 0.018055595","density: 133.6484948<br />post_bmi: 0.018018347","density: 134.3589783<br />post_bmi: 0.017981100","density: 135.0846267<br />post_bmi: 0.017943853","density: 135.8276167<br />post_bmi: 0.017906605","density: 136.5937117<br />post_bmi: 0.017869358","density: 137.3845380<br />post_bmi: 0.017832110","density: 138.1973084<br />post_bmi: 0.017794863","density: 139.0319492<br />post_bmi: 0.017757616","density: 139.8880091<br />post_bmi: 0.017720368","density: 140.7679152<br />post_bmi: 0.017683121","density: 141.6676036<br />post_bmi: 0.017645874","density: 142.5812823<br />post_bmi: 0.017608626","density: 143.5057552<br />post_bmi: 0.017571379","density: 144.4374680<br />post_bmi: 0.017534132","density: 145.3714624<br />post_bmi: 0.017496884","density: 146.2995476<br />post_bmi: 0.017459637","density: 147.2161583<br />post_bmi: 0.017422390","density: 148.1158364<br />post_bmi: 0.017385142","density: 148.9929717<br />post_bmi: 0.017347895","density: 149.8336044<br />post_bmi: 0.017310648","density: 150.6303007<br />post_bmi: 0.017273400","density: 151.3811418<br />post_bmi: 0.017236153","density: 152.0805427<br />post_bmi: 0.017198906","density: 152.7230715<br />post_bmi: 0.017161658","density: 153.2879066<br />post_bmi: 0.017124411","density: 153.7740394<br />post_bmi: 0.017087164","density: 154.1851393<br />post_bmi: 0.017049916","density: 154.5178770<br />post_bmi: 0.017012669","density: 154.7693251<br />post_bmi: 0.016975421","density: 154.9170701<br />post_bmi: 0.016938174","density: 154.9695233<br />post_bmi: 0.016900927","density: 154.9354403<br />post_bmi: 0.016863679","density: 154.8151196<br />post_bmi: 0.016826432","density: 154.6093215<br />post_bmi: 0.016789185","density: 154.3000341<br />post_bmi: 0.016751937","density: 153.9033815<br />post_bmi: 0.016714690","density: 153.4306149<br />post_bmi: 0.016677443","density: 152.8853406<br />post_bmi: 0.016640195","density: 152.2714820<br />post_bmi: 0.016602948","density: 151.5793878<br />post_bmi: 0.016565701","density: 150.8273896<br />post_bmi: 0.016528453","density: 150.0259767<br />post_bmi: 0.016491206","density: 149.1803832<br />post_bmi: 0.016453959","density: 148.2959077<br />post_bmi: 0.016416711","density: 147.3717356<br />post_bmi: 0.016379464","density: 146.4222422<br />post_bmi: 0.016342217","density: 145.4547791<br />post_bmi: 0.016304969","density: 144.4741887<br />post_bmi: 0.016267722","density: 143.4851555<br />post_bmi: 0.016230475","density: 142.4931598<br />post_bmi: 0.016193227","density: 141.5049107<br />post_bmi: 0.016155980","density: 140.5238826<br />post_bmi: 0.016118733","density: 139.5531319<br />post_bmi: 0.016081485","density: 138.5954487<br />post_bmi: 0.016044238","density: 137.6587034<br />post_bmi: 0.016006990","density: 136.7418920<br />post_bmi: 0.015969743","density: 135.8452655<br />post_bmi: 0.015932496","density: 134.9696972<br />post_bmi: 0.015895248","density: 134.1158039<br />post_bmi: 0.015858001","density: 133.2902369<br />post_bmi: 0.015820754","density: 132.4870565<br />post_bmi: 0.015783506","density: 131.7045844<br />post_bmi: 0.015746259","density: 130.9419227<br />post_bmi: 0.015709012","density: 130.1980024<br />post_bmi: 0.015671764","density: 129.4759458<br />post_bmi: 0.015634517","density: 128.7687300<br />post_bmi: 0.015597270","density: 128.0740157<br />post_bmi: 0.015560022","density: 127.3899581<br />post_bmi: 0.015522775","density: 126.7146521<br />post_bmi: 0.015485528","density: 126.0470262<br />post_bmi: 0.015448280","density: 125.3823062<br />post_bmi: 0.015411033","density: 124.7184005<br />post_bmi: 0.015373786","density: 124.0533871<br />post_bmi: 0.015336538","density: 123.3853812<br />post_bmi: 0.015299291","density: 122.7099063<br />post_bmi: 0.015262044","density: 122.0262280<br />post_bmi: 0.015224796","density: 121.3329457<br />post_bmi: 0.015187549","density: 120.6286780<br />post_bmi: 0.015150301","density: 119.9121308<br />post_bmi: 0.015113054","density: 119.1769591<br />post_bmi: 0.015075807","density: 118.4264114<br />post_bmi: 0.015038559","density: 117.6597592<br />post_bmi: 0.015001312","density: 116.8763272<br />post_bmi: 0.014964065","density: 116.0753620<br />post_bmi: 0.014926817","density: 115.2503940<br />post_bmi: 0.014889570","density: 114.4068388<br />post_bmi: 0.014852323","density: 113.5444368<br />post_bmi: 0.014815075","density: 112.6629578<br />post_bmi: 0.014777828","density: 111.7618285<br />post_bmi: 0.014740581","density: 110.8349563<br />post_bmi: 0.014703333","density: 109.8883125<br />post_bmi: 0.014666086","density: 108.9217266<br />post_bmi: 0.014628839","density: 107.9350159<br />post_bmi: 0.014591591","density: 106.9273760<br />post_bmi: 0.014554344","density: 105.8927052<br />post_bmi: 0.014517097","density: 104.8369698<br />post_bmi: 0.014479849","density: 103.7598756<br />post_bmi: 0.014442602","density: 102.6611187<br />post_bmi: 0.014405355","density: 101.5394882<br />post_bmi: 0.014368107","density: 100.3887115<br />post_bmi: 0.014330860","density:  99.2150296<br />post_bmi: 0.014293612","density:  98.0181844<br />post_bmi: 0.014256365","density:  96.7979501<br />post_bmi: 0.014219118","density:  95.5529385<br />post_bmi: 0.014181870","density:  94.2773978<br />post_bmi: 0.014144623","density:  92.9781631<br />post_bmi: 0.014107376","density:  91.6553890<br />post_bmi: 0.014070128","density:  90.3093061<br />post_bmi: 0.014032881","density:  88.9388721<br />post_bmi: 0.013995634","density:  87.5400899<br />post_bmi: 0.013958386","density:  86.1200389<br />post_bmi: 0.013921139","density:  84.6795482<br />post_bmi: 0.013883892","density:  83.2195318<br />post_bmi: 0.013846644","density:  81.7398069<br />post_bmi: 0.013809397","density:  80.2390431<br />post_bmi: 0.013772150","density:  78.7235099<br />post_bmi: 0.013734902","density:  77.1946422<br />post_bmi: 0.013697655","density:  75.6539278<br />post_bmi: 0.013660408","density:  74.1022835<br />post_bmi: 0.013623160","density:  72.5410337<br />post_bmi: 0.013585913","density:  70.9744547<br />post_bmi: 0.013548666","density:  69.4042457<br />post_bmi: 0.013511418","density:  67.8321091<br />post_bmi: 0.013474171","density:  66.2599848<br />post_bmi: 0.013436923","density:  64.6910293<br />post_bmi: 0.013399676","density:  63.1268650<br />post_bmi: 0.013362429","density:  61.5690841<br />post_bmi: 0.013325181","density:  60.0192467<br />post_bmi: 0.013287934","density:  58.4800967<br />post_bmi: 0.013250687","density:  56.9555984<br />post_bmi: 0.013213439","density:  55.4448154<br />post_bmi: 0.013176192","density:  53.9490456<br />post_bmi: 0.013138945","density:  52.4695491<br />post_bmi: 0.013101697","density:  51.0097375<br />post_bmi: 0.013064450","density:  49.5736803<br />post_bmi: 0.013027203","density:  48.1584683<br />post_bmi: 0.012989955","density:  46.7651280<br />post_bmi: 0.012952708","density:  45.3946595<br />post_bmi: 0.012915461","density:  44.0511661<br />post_bmi: 0.012878213","density:  42.7384974<br />post_bmi: 0.012840966","density:  41.4523841<br />post_bmi: 0.012803719","density:  40.1936651<br />post_bmi: 0.012766471","density:  38.9631577<br />post_bmi: 0.012729224","density:  37.7657029<br />post_bmi: 0.012691977","density:  36.6046645<br />post_bmi: 0.012654729","density:  35.4747817<br />post_bmi: 0.012617482","density:  34.3766817<br />post_bmi: 0.012580234","density:  33.3109560<br />post_bmi: 0.012542987","density:  32.2830150<br />post_bmi: 0.012505740","density:  31.2952690<br />post_bmi: 0.012468492","density:  30.3416645<br />post_bmi: 0.012431245","density:  29.4224523<br />post_bmi: 0.012393998","density:  28.5378229<br />post_bmi: 0.012356750","density:  27.6932564<br />post_bmi: 0.012319503","density:  26.8896455<br />post_bmi: 0.012282256","density:  26.1204338<br />post_bmi: 0.012245008","density:  25.3853169<br />post_bmi: 0.012207761","density:  24.6839154<br />post_bmi: 0.012170514","density:  24.0210719<br />post_bmi: 0.012133266","density:  23.3958840<br />post_bmi: 0.012096019","density:  22.8018369<br />post_bmi: 0.012058772","density:  22.2380435<br />post_bmi: 0.012021524","density:  21.7035542<br />post_bmi: 0.011984277","density:  21.2019595<br />post_bmi: 0.011947030","density:  20.7308696<br />post_bmi: 0.011909782","density:  20.2845153<br />post_bmi: 0.011872535","density:  19.8616224<br />post_bmi: 0.011835288","density:  19.4608907<br />post_bmi: 0.011798040","density:  19.0844162<br />post_bmi: 0.011760793","density:  18.7291520<br />post_bmi: 0.011723545","density:  18.3906684<br />post_bmi: 0.011686298","density:  18.0676462<br />post_bmi: 0.011649051","density:  17.7587852<br />post_bmi: 0.011611803","density:  17.4649099<br />post_bmi: 0.011574556","density:  17.1832779<br />post_bmi: 0.011537309","density:  16.9110413<br />post_bmi: 0.011500061","density:  16.6471668<br />post_bmi: 0.011462814","density:  16.3906725<br />post_bmi: 0.011425567","density:  16.1416702<br />post_bmi: 0.011388319","density:  15.8983659<br />post_bmi: 0.011351072","density:  15.6593220<br />post_bmi: 0.011313825","density:  15.4239702<br />post_bmi: 0.011276577","density:  15.1918019<br />post_bmi: 0.011239330","density:  14.9628450<br />post_bmi: 0.011202083","density:  14.7363430<br />post_bmi: 0.011164835","density:  14.5118085<br />post_bmi: 0.011127588","density:  14.2891154<br />post_bmi: 0.011090341","density:  14.0681825<br />post_bmi: 0.011053093","density:  13.8493904<br />post_bmi: 0.011015846","density:  13.6326296<br />post_bmi: 0.010978599","density:  13.4178304<br />post_bmi: 0.010941351","density:  13.2051309<br />post_bmi: 0.010904104","density:  12.9946864<br />post_bmi: 0.010866857","density:  12.7873295<br />post_bmi: 0.010829609","density:  12.5830218<br />post_bmi: 0.010792362","density:  12.3816972<br />post_bmi: 0.010755114","density:  12.1835264<br />post_bmi: 0.010717867","density:  11.9886699<br />post_bmi: 0.010680620","density:  11.7981834<br />post_bmi: 0.010643372","density:  11.6116681<br />post_bmi: 0.010606125","density:  11.4288587<br />post_bmi: 0.010568878","density:  11.2497736<br />post_bmi: 0.010531630","density:  11.0744049<br />post_bmi: 0.010494383","density:  10.9036134<br />post_bmi: 0.010457136","density:  10.7365553<br />post_bmi: 0.010419888","density:  10.5727665<br />post_bmi: 0.010382641","density:  10.4120401<br />post_bmi: 0.010345394","density:  10.2541430<br />post_bmi: 0.010308146","density:  10.0993386<br />post_bmi: 0.010270899","density:   9.9466162<br />post_bmi: 0.010233652","density:   9.7954472<br />post_bmi: 0.010196404","density:   9.6454560<br />post_bmi: 0.010159157","density:   9.4962549<br />post_bmi: 0.010121910","density:   9.3473324<br />post_bmi: 0.010084662","density:   9.1979907<br />post_bmi: 0.010047415","density:   9.0478178<br />post_bmi: 0.010010168","density:   8.8964251<br />post_bmi: 0.009972920","density:   8.7434341<br />post_bmi: 0.009935673","density:   8.5877341<br />post_bmi: 0.009898425","density:   8.4293505<br />post_bmi: 0.009861178","density:   8.2681309<br />post_bmi: 0.009823931","density:   8.1038547<br />post_bmi: 0.009786683","density:   7.9363315<br />post_bmi: 0.009749436","density:   7.7643471<br />post_bmi: 0.009712189","density:   7.5887203<br />post_bmi: 0.009674941","density:   7.4095996<br />post_bmi: 0.009637694","density:   7.2270443<br />post_bmi: 0.009600447","density:   7.0411497<br />post_bmi: 0.009563199","density:   6.8511932<br />post_bmi: 0.009525952","density:   6.6584123<br />post_bmi: 0.009488705","density:   6.4631786<br />post_bmi: 0.009451457","density:   6.2658075<br />post_bmi: 0.009414210","density:   6.0666385<br />post_bmi: 0.009376963","density:   5.8658364<br />post_bmi: 0.009339715","density:   5.6644018<br />post_bmi: 0.009302468","density:   5.4627781<br />post_bmi: 0.009265221","density:   5.2613912<br />post_bmi: 0.009227973","density:   5.0606695<br />post_bmi: 0.009190726","density:   4.8616755<br />post_bmi: 0.009153479","density:   4.6645993<br />post_bmi: 0.009116231","density:   4.4698121<br />post_bmi: 0.009078984","density:   4.2776752<br />post_bmi: 0.009041736","density:   4.0885507<br />post_bmi: 0.009004489","density:   3.9040288<br />post_bmi: 0.008967242","density:   3.7233538<br />post_bmi: 0.008929994","density:   3.5467408<br />post_bmi: 0.008892747","density:   3.3743822<br />post_bmi: 0.008855500","density:   3.2065192<br />post_bmi: 0.008818252","density:   3.0447520<br />post_bmi: 0.008781005","density:   2.8877202<br />post_bmi: 0.008743758","density:   2.7354691<br />post_bmi: 0.008706510","density:   2.5880277<br />post_bmi: 0.008669263","density:   2.4455332<br />post_bmi: 0.008632016","density:   2.3093277<br />post_bmi: 0.008594768","density:   2.1778643<br />post_bmi: 0.008557521","density:   2.1778643<br />post_bmi: 0.008557521"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"transparent","dash":"solid"},"fill":"toself","fillcolor":"rgba(135,206,235,0.5)","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.014298892399134707,0.014298892399134707],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.01429889","type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(255,0,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.0090005357312124556,0.0090005357312124556],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.009000536","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(255,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.019597249067056958,0.019597249067056958],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.01959725","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(255,0,0,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.016864436945945242,0.016864436945945242],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.01686444","type":"scatter","mode":"lines","line":{"width":3.7795275590551185,"color":"rgba(0,0,255,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.011389698653780367,0.011389698653780367],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.0113897","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(0,0,255,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.021893107831967185,0.021893107831967185],"y":[-7.748476165379599,162.71799947297157],"text":"xintercept: 0.02189311","type":"scatter","mode":"lines","line":{"width":3.0236220472440949,"color":"rgba(0,0,255,1)","dash":"dash"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":44.825238688252384,"r":7.3059360730593621,"b":40.182648401826491,"l":43.105022831050235},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"<b> Bayesian (informative) vs Frequentist Estimate of BMI <\/b>","font":{"color":"rgba(0,0,0,1)","family":"","size":18.596928185969279},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.0076058512356893329,0.028542585251657183],"tickmode":"array","ticktext":["0.010","0.015","0.020","0.025"],"tickvals":[0.01,0.014999999999999999,0.02,0.025000000000000001],"categoryorder":"array","categoryarray":["0.010","0.015","0.020","0.025"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"Coefficient for BMI","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-7.748476165379599,162.71799947297157],"tickmode":"array","ticktext":["0","50","100","150"],"tickvals":[0,50,100,150],"categoryorder":"array","categoryarray":["0","50","100","150"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"Density","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"2d943fb56ed5":{"x":{},"type":"scatter"},"2d944c8c4cd3":{"xintercept":{}},"2d942fabc4a":{"xintercept":{}},"2d94166e49af":{"xintercept":{}},"2d9465d12ee9":{"xintercept":{}},"2d947d994c54":{"xintercept":{}},"2d9445ac2738":{"xintercept":{}}},"cur_data":"2d943fb56ed5","visdat":{"2d943fb56ed5":["function (y) ","x"],"2d944c8c4cd3":["function (y) ","x"],"2d942fabc4a":["function (y) ","x"],"2d94166e49af":["function (y) ","x"],"2d9465d12ee9":["function (y) ","x"],"2d947d994c54":["function (y) ","x"],"2d9445ac2738":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>The above plot shows the estimates of the BMI coefficient (<span class="math inline">\(\beta_1\)</span>) for BMD using both frequentist and Bayesian methods. On the x-axis, we see the coefficient for BMI, ranging from approximately 0.008 to 0.024, while the y-axis represents density, showing the distribution of the estimates.</p>
<p>In Bayesian inference, the blue shaded area represents our posterior distribution of <span class="math inline">\(\beta_1\)</span>, which incorporates both prior information and observed data. The vertical blue solid line indicates our Bayesian posterior mean, and the vertical blue dashed lines show the 95% credible interval. This interval represents the range within which <span class="math inline">\(\beta_1\)</span> lies with 95% probability, given our prior and the data. The Bayesian approach provides a more nuanced estimate that reflects both our prior beliefs and the observed data, resulting in a posterior distribution that can be more or less spread out depending on the prior and the data.</p>
<p>Whereas, the frequentist approach relies solely on the observed data to provide point estimates and confidence intervals. The vertical red solid line represents our frequentist maximum likelihood estimate (MLE) of <span class="math inline">\(\beta_1\)</span>, and the vertical red dashed lines show the 95% confidence interval. This interval represents the range within which <span class="math inline">\(\beta_1\)</span> would lie in 95% of repeated samples, assuming the true value is fixed.</p>
<p>The key difference highlighted by this plot is how each method estimates and interprets <span class="math inline">\(\beta_1\)</span>. We can see that the informative prior shifts the mean posterior distribution. We can also see that the Bayesian credible interval is much narrower due to the influence of the informative prior, suggesting that prior information has influenced the estimate.</p>
</section>
<section id="further-model-development" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="further-model-development"><span class="header-section-number">6.6</span> Further Model Development</h2>
<iframe width="500" height="300" src="https://www.youtube.com/embed/1pHXkJKHZnc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p><strong>Gaussian Context</strong></p>
<p>Following the BMD example, where we explore the influence of BMI on BMD. Now, we might want to ask: What role does ‘Age’ or ‘Sex’ of the patient play in this relationship?</p>
<p>As people age, their BMD naturally decreases over time, and age also influences factors like BMI. Similarly, sex affects both BMI and BMD, with women being more likely to experience a decline in BMD, particularly in conditions like osteoporosis. These factors age and sex may act as confounders, influencing both BMI and BMD. Hence, we write the DAG using these variables:</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-e03fd367819a8897778f" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-e03fd367819a8897778f">{"x":{"diagram":"\n  digraph combined_DAGs {\n    \n    // Global graph layout direction\n    compound=true;\n    newrank=true;\n    ranksep=1.2;\n\n    // First DAG (Top)\n    subgraph cluster_1 {\n      label = \"Original DAG\";\n      style = dashed;\n\n      M1 [label = \"BMI\"]\n      B1 [label = \"BMD\"]\n      A1 [label = \"Age\"]\n      S1 [label = \"Sex\"]\n      \n      M1 -> B1\n      A1 -> M1\n      S1 -> M1\n      A1 -> B1\n      S1 -> B1\n    }\n\n    // Spacer node (invisible)\n    spacer [style=invis, height=0.1]\n\n    // Second DAG (Bottom)\n    subgraph cluster_2 {\n      label = \"Labeled DAG with Roles\";\n      style = dashed;\n\n      # Define nodes with positions to form a triangle\n      A2 [label = \"Age, Sex\\n(Confounder)\", pos=\"0,1!\"]\n      M2 [label = \"BMI\\n(Exposure)\", pos=\"1,2!\"]\n      B2 [label = \"BMD\\n(Outcome)\", pos=\"2,1!\"]\n\n      # Define edges\n      M2 -> B2\n      A2 -> M2\n      A2 -> B2\n    }    \n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<!--

library(DiagrammeR)

grViz("
  digraph combined_DAGs {
    
    // Global graph layout direction
    compound=true;
    newrank=true;
    ranksep=1.2;

    // First DAG (Top)
    subgraph cluster_1 {
      label = \"Original DAG\";
      style = dashed;

      M1 [label = 'BMI']
      B1 [label = 'BMD']
      A1 [label = 'Age']
      S1 [label = 'Sex']
      
      M1 -> B1
      A1 -> M1
      S1 -> M1
      A1 -> B1
      S1 -> B1
    }

    // Spacer node (invisible)
    spacer [style=invis, height=0.1]

    // Second DAG (Bottom)
    subgraph cluster_2 {
      label = \"Labeled DAG with Roles\";
      rankdir=LR;

      M2 [label = 'BMI\\n(Exposure)']
      B2 [label = 'BMD\\n(Outcome)']
      A2 [label = 'Age\\n(Confounder)']
      S2 [label = 'Sex\\n(Confounder)']

      M2 -> B2
      A2 -> M2
      S2 -> M2
      A2 -> B2
      S2 -> B2
    }
  }
")

###


-->
<p>In this case, the estimand is the specific effect of BMI on BMD, while accounting for the influence of age and sex as confounders. The goal is to isolate the effect of BMI on BMD after adjusting for these other variables.</p>
<p>The estimator we define here is the Bayesian model, i.e., the Bayesian multiple linear regression model to get the posterior distributions for the model parameters. This model adjusts for confounders like age and sex, helping us to estimate the causal effect of BMI on BMD.</p>
<p>The estimate is the posterior distribution of the estimand with some numerical values, such as mean or median derived from the posterior distribution. For example, if the posterior mean estimate is 0.03, this could represent the change in BMD associated with a one-unit increase in BMI, after accounting for the effects of age and sex.</p>
<section id="model-dag" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="model-dag"><span class="header-section-number">6.6.1</span> Model &amp; DAG</h3>
<p>We now develop the Bayesian model with all these four variables. Hence, we write the Bayesian model as:</p>
<p><span class="math display">\[
\text{BMD}_i \sim N(\beta_0 + \beta_1 \cdot \text{BMI}_i + \beta_2 \cdot \text{Age}_i + \beta_3 \cdot \text{Sex}_i, \sigma^2)
\]</span></p>
<p>Where, <span class="math inline">\(\beta_0\)</span> is the intercept, <span class="math inline">\(\beta_1\)</span> is the coefficient for BMI, <span class="math inline">\(\beta_2\)</span> is the coefficient for Age, <span class="math inline">\(\beta_3\)</span> is the coefficient for Sex (with a reference category; for example, if Sex is binary, it could be “Male” vs.&nbsp;“Female”). This model also includes the variability <span class="math inline">\(\sigma\)</span> of the error term. Now, assuming weakly informative prior we write:</p>
<ul>
<li><span class="math inline">\(\beta_0 \sim N(0, 10^2)\)</span></li>
<li><span class="math inline">\(\beta_1 \sim N(0, 10^2)\)</span></li>
<li><span class="math inline">\(\beta_2 \sim N(0, 10^2)\)</span></li>
<li><span class="math inline">\(\beta_3 \sim N(0, 10^2)\)</span></li>
<li><span class="math inline">\(\sigma \sim \text{Half-Cauchy}(0, 1)\)</span></li>
</ul>
<p>Note that the model equation can be also written as:</p>
<p><span class="math display">\[
\text{BMD}_i = \beta_0 + \beta_1 \cdot \text{BMI}_i + \beta_2 \cdot \text{Age}_i + \beta_3 \cdot \text{Sex}_i + \epsilon_i
\]</span></p>
<p>where, <span class="math inline">\(\epsilon_i\)</span> is the error term of the model.</p>
<p>Hence, we draw the DAG for this Bayesian model with prior and hyper-prior parameters as:</p>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-df0b5062fff9a80c3650" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-df0b5062fff9a80c3650">{"x":{"diagram":"\n  digraph DAG {\n    rankdir=LR;  # Set direction from left to right\n    \n    # Nodes (parameters and variables)\n    BMI [label = \"BMI\", shape = ellipse, style = filled, fillcolor = aquamarine2]\n    Age [label = \"Age\", shape = ellipse, style = filled, fillcolor = lightblue]\n    Sex [label = \"Sex\", shape = ellipse, style = filled, fillcolor = lightblue]\n    BMD [label = \"BMD\", shape = ellipse, style = filled, fillcolor = lightcoral]\n    beta_0 [label = \"β₀\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_1 [label = \"β₁\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_2 [label = \"β₂\", shape = box, style = filled, fillcolor = lightgrey]\n    beta_3 [label = \"β₃\", shape = box, style = filled, fillcolor = lightgrey]\n    sigma2 [label = \"σ\", shape = box, style = filled, fillcolor = lightgrey]\n    prior_beta_0 [label = \"Prior for β₀: N(μ₀, σ₀²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_beta_1 [label = \"Prior for β₁: N(μ₁, σ₁²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_beta_2 [label = \"Prior for β₂: N(μ₂, σ₂²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_beta_3 [label = \"Prior for β₃: N(μ₃, σ₃²)\", shape = box, style = dashed, fillcolor = lightyellow]\n    prior_sigma2 [label = \"Prior for σ: Half-Cauchy(0, τ)\", shape = box, style = dashed, fillcolor = lightyellow]\n    \n    # Edges (dependencies between nodes)\n    BMI -> BMD\n    Age -> BMD\n    Sex -> BMD\n    beta_0 -> BMD\n    beta_1 -> BMD\n    beta_2 -> BMD\n    beta_3 -> BMD\n    sigma2 -> BMD\n    prior_beta_0 -> beta_0\n    prior_beta_1 -> beta_1\n    prior_beta_2 -> beta_2\n    prior_beta_3 -> beta_3\n    prior_sigma2 -> sigma2\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
<section id="results-mcmc-diagnostics" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2" class="anchored" data-anchor-id="results-mcmc-diagnostics"><span class="header-section-number">6.6.2</span> Results &amp; MCMC Diagnostics</h3>
<p>Now, we implement the Bayesian hierarchical model for this DAG, where we use weakly-informative priors for the model parameters.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"bmd_restricted.csv"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>bmd_data<span class="sc">$</span>bmi <span class="ot">&lt;-</span> bmd_data<span class="sc">$</span>weight_kg<span class="sc">/</span>(bmd_data<span class="sc">$</span>height_cm<span class="sc">/</span><span class="dv">100</span>)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>bmd_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMD =</span> bmd_data<span class="sc">$</span>bmd,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">BMI =</span> bmd_data<span class="sc">$</span>bmi,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Age =</span> bmd_data<span class="sc">$</span>age,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sex =</span> <span class="fu">as.factor</span>(bmd_data<span class="sc">$</span>sex)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>bmd_model_multi <span class="ot">&lt;-</span> <span class="fu">brm</span>(</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> BMD <span class="sc">~</span> BMI <span class="sc">+</span> Age <span class="sc">+</span> Sex,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> bmd_data,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"BMI"</span>), <span class="co"># N(mean, sd)</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"Age"</span>), <span class="co"># N(mean, sd)</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"b"</span>, <span class="at">coef =</span> <span class="st">"SexM"</span>), <span class="co"># N(mean, sd)</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> <span class="st">"Intercept"</span>), <span class="co"># N(mean, sd)</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prior</span>(<span class="fu">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> <span class="st">"sigma"</span>)  <span class="co"># Half-Cauchy prior for sigma</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    ),  </span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> <span class="dv">1</span>,</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">3</span>,</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.173 seconds (Warm-up)
Chain 1:                0.085 seconds (Sampling)
Chain 1:                0.258 seconds (Total)
Chain 1: </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#prior_summary(bmd_model_multi, all = FALSE)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">prior_summary</span>(bmd_model_multi, <span class="at">all =</span> <span class="cn">FALSE</span>), <span class="at">show_df =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>b_Age ~ normal(0, 10)
b_BMI ~ normal(0, 10)
b_SexM ~ normal(0, 10)
Intercept ~ normal(0, 10)
&lt;lower=0&gt; sigma ~ cauchy(0, 1)</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(bmd_model_multi), <span class="at">digits=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: BMD ~ BMI + Age + Sex 
   Data: bmd_data (Number of observations: 169) 
  Draws: 1 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 1000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS
Intercept    0.604     0.083    0.441    0.765 1.001     1168      803
BMI          0.016     0.002    0.011    0.020 1.001     1071      536
Age         -0.004     0.001   -0.006   -0.003 1.004     1128      692
SexM         0.095     0.021    0.054    0.134 1.003      654      613

Further Distributional Parameters:
      Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS
sigma    0.139     0.008    0.125    0.155 1.001      574      579

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<p>We can exlain the posterior estimates of the model parameters from the Bayesian model as follows:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 49%">
<col style="width: 8%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Predictor</th>
<th>Mean (95% Credible Interval)</th>
<th>Rhat</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>BMI</strong></td>
<td>0.016 (0.010, 0.021)</td>
<td>1.003</td>
<td>A 1-unit increase in BMI is associated with a 0.016 unit increase in BMD, holding other variables constant. This is a small but credible positive effect.</td>
</tr>
<tr class="even">
<td><strong>Age</strong></td>
<td>-0.004 (-0.006, -0.003)</td>
<td>1.002</td>
<td>Each additional year of age is associated with a 0.004 unit decrease in BMD, suggesting a consistent age-related decline.</td>
</tr>
<tr class="odd">
<td><strong>Sex (Male)</strong></td>
<td>0.095 (0.050, 0.139)</td>
<td>1.002</td>
<td>Males have on average 0.095 units higher BMD than females, adjusting for BMI and age. This reflects a moderate and credible sex difference in BMD.</td>
</tr>
<tr class="even">
<td><strong><span class="math inline">\(\sigma\)</span></strong></td>
<td>0.139 (0.124, 0.154)</td>
<td>0.999</td>
<td>Represents residual variability in BMD not explained by BMI, age, or sex. The relatively small value suggests a good overall model fit.</td>
</tr>
</tbody>
</table>
<p>We can also observe that all <span class="math inline">\(\hat{R}\)</span> values are <span class="math inline">\(\approx\)</span> 1.00, i.e., convergence is excellent. The Bulk and Tail ESS values are all <span class="math inline">\(&gt;600\)</span>, i.e., sufficient posterior sample size and good mixing of chains.</p>
<p><strong>Trace Plots</strong></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bmd_model_multi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/bmd_multiple_plots-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(bayesplot)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#library(brms)</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#posterior &lt;- as_draws_df(bmd_model_multi)</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#mcmc_areas(</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  posterior,</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  pars = c("b_BMI", "b_Age", "b_SexM"),</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  prob = 0.95  # 95% credible intervals</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">#)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">#mcmc_trace(</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">#  posterior,</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  pars = c("b_Intercept", "b_BMI", "b_Age", "b_SexM")</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">#)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Trace plots for the MCMC samples also shows a nice mixing and density (histogram) plots also shows a normal distributional shape, confirms a good MCMC mixing for the model parameters.</p>
<p><strong>Conditional Effects</strong></p>
<p>We can also plot the conditional effects of the predictor variables BMI, Age and Sex. Here, conditional effects refer to the effect of say BMI on BMD considering other variables (i.e., Age and Sex) fixed and so on for Age and Sex.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(conditional_effects(bmd_model_multi, effects = "BMI"), points = TRUE)</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(conditional_effects(bmd_model_multi, effects = "Age"), points = TRUE)</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(conditional_effects(bmd_model_multi, effects = "Sex"))</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>ce <span class="ot">&lt;-</span> <span class="fu">conditional_effects</span>(bmd_model_multi)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">plot</span>(ce, <span class="at">effects =</span> <span class="st">"BMI"</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>, <span class="at">points =</span> <span class="cn">TRUE</span>)[[<span class="dv">1</span>]]</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">plot</span>(ce, <span class="at">effects =</span> <span class="st">"Age"</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>, <span class="at">points =</span> <span class="cn">TRUE</span>)[[<span class="dv">2</span>]]</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">plot</span>(ce, <span class="at">effects =</span> <span class="st">"Sex"</span>, <span class="at">plot =</span> <span class="cn">FALSE</span>)[[<span class="dv">3</span>]]</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">#library(patchwork)</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">#combined_plot &lt;- p1 + p2 + p3  # 1 row # OR use / to stack vertically: combined_plot &lt;- p1 / p2 / p3</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">#combined_plot</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, p3, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/bmd_multiple_marginal-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>In the first plot, we see a positive trend, as BMI increases, BMD also tends to go up. The shaded area around the line shows the uncertainty, or the range where the true trend is likely to fall. The second plot shows a negative trend with Age, meaning that as people get older, their BMD tends to decrease. In the third plot, we compare BMD between males and females. We can see that males tend to have higher BMD than females. The vertical lines (error bars) show how much BMD varies within each group.</p>
<p><strong>predictive checks</strong></p>
<p>We can also look at the posterior predictive plot to see how well the model fits the data. As we have discussed in one of the previous lectures, if the plot looks similar to the actual data, that means the model is doing a good job. But if the predicted values are too spread out, too narrow, or miss important patterns, we might need to adjust the model by adding better predictors, transforming variables, or trying a different type of model.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior predictive check</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#pp_check(bmd_model_multi)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">#pp_check(bmd_model_multi, type = "hist")</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">#pp_check(bmd_model_multi, type = "boxplot")</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">#pp_check(bmd_model_multi, type = "scatter_avg")</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">#pp_check(bmd_model_multi, type = "ecdf_overlay")</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co">#library(patchwork)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(bmd_model_multi)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">pp_check</span>(bmd_model_multi, <span class="at">type =</span> <span class="st">"ecdf_overlay"</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">#combined_plot &lt;- p1 + p2 </span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">#combined_plot</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="M03_2_files/figure-html/bmd_multiple_pp_check-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>From the above plots, we can see that the replications in the posterior predictive plot of BMD match the actual observed BMD.</p>
</section>
</section>
<section id="summary" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="summary"><span class="header-section-number">6.7</span> Summary</h2>
<p>Today’s lecture focused on understanding priors in Bayesian regression, specifically for variance and the coefficients. We discussed weakly-informative and informative priors for <span class="math inline">\(\beta_1\)</span>, and their implications in modeling. A comparison between Bayesian and frequentist approaches was made, particularly in the context of using an informative prior for <span class="math inline">\(\beta_1\)</span>. Finally, we explored how to further develop the model to better understand exposure and confounders, and how these can be incorporated into a Bayesian regression framework.</p>
</section>
<section id="live-tutorial-and-discussion" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="live-tutorial-and-discussion"><span class="header-section-number">6.8</span> Live tutorial and discussion</h2>
<p>The final learning activity for this week is the live tutorial and discussion. This tutorial is an opportunity for you to to interact with your teachers, ask questions about the course, and learn about biostatistics in practice. You are expected to attend these tutorials when possible for you to do so. For those that cannot attend, the tutorial will be recorded and made available on Canvas. We hope to see you there!</p>
</section>
<section id="tutorial-exercises" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="tutorial-exercises"><span class="header-section-number">6.9</span> Tutorial Exercises</h2>
<p>Solutions will be provided later after the tutorial.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./M03_1.html" class="pagination-link" aria-label="**Logical Connections**">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title"><strong>Logical Connections</strong></span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./brief_module_04.html" class="pagination-link" aria-label="**Module 4: Bayeswatch - Non Gaussian**">
        <span class="nav-page-text"><strong>Module 4: Bayeswatch - Non Gaussian</strong></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>